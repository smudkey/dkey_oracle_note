oracle 交换执行计划

0、准备环境：
SQL> create table test1 as select * from dba_objects;
Table created.
SQL> create index idx_test1_object_id on test1(object_id);
Index created.
1、执行两条语句并查看执行计划：
select * from test1 where object_id=20535走索引
select /*+full(test1)*/ * from test1 where object_id=20535走全表扫描
2、从v$sql中找到每条语句的hash_value,child_number
语句select * from test1 where object_id=20535的hash_value,child_number是3805445378,0，
语句select /*+full(test1)*/ * from test1 where object_id=20535是1970577185,0
3、创建outline
SQL> exec dbms_outln.create_outline(1970577185,0,'MYCAT1');
PL/SQL procedure successfully completed
SQL> exec dbms_outln.create_outline(3805445378,0,'MYCAT1');
PL/SQL procedure successfully completed
4、查看dba_outlines，分别将新生成的与这两个语句相符的OUTLINE改名
SQL> ALTER OUTLINE SYS_OUTLINE_10052616391800813 RENAME TO OL11;
Outline altered.
SQL> ALTER OUTLINE SYS_OUTLINE_10052616395727514 RENAME TO OL12;
Outline altered.
5、select * from outln.ol$ where ol_name in('OL11','OL12')
发现hintcount值都是5，可以不修改该列的值
6、交换执行计划，这里通过交换outln.ol$的ol_name的值实现
update outln.ol$ set ol_name='OL13' where ol_name='OL11';
update outln.ol$ set ol_name='OL11' where ol_name='OL12';
update outln.ol$ set ol_name='OL12' where ol_name='OL13';
commit;
7、查看执行计划是否被更改
SQL> ALTER SESSION SET USE_STORED_OUTLINES=MYCAT1;
Session altered.
SQL> set autotrace on
SQL> select * from test1 where object_id=20535;
OWNER
------------------------------
OBJECT_NAME
--------------------------------------------------------------------------------
SUBOBJECT_NAME                  OBJECT_ID DATA_OBJECT_ID OBJECT_TYPE
------------------------------ ---------- -------------- -------------------
CREATED      LAST_DDL_TIM TIMESTAMP           STATUS  T G S
------------ ------------ ------------------- ------- - - -
SYS
/998e3914_SunFileReader
                                    20535                JAVA CLASS
12-MAR-08    12-MAR-08    2008-03-12:00:53:29 VALID   N N N

Execution Plan
----------------------------------------------------------
Plan hash value: 2714293857
--------------------------------------------------------------------------------
-------------------
| Id  | Operation                   | Name                | Rows  | Bytes | Cost
(%CPU)| Time     |
--------------------------------------------------------------------------------
-------------------
|   0 | SELECT STATEMENT            |                     |   582 |   100K|
4   (0)| 00:00:01 |
|   1 |  TABLE ACCESS BY INDEX ROWID| TEST1               |   582 |   100K|
4   (0)| 00:00:01 |
|*  2 |   INDEX RANGE SCAN          | IDX_TEST1_OBJECT_ID |   233 |       |
1   (0)| 00:00:01 |
--------------------------------------------------------------------------------
-------------------

Predicate Information (identified by operation id):
---------------------------------------------------
   2 - access("OBJECT_ID"=20535)
Note
-----
   - outline "OL11" used for this statement

Statistics
----------------------------------------------------------
         35  recursive calls
        123  db block gets
         23  consistent gets
          0  physical reads
        568  redo size
       1420  bytes sent via SQL*Net to client
        492  bytes received via SQL*Net from client
          2  SQL*Net roundtrips to/from client
          2  sorts (memory)
          0  sorts (disk)
          1  rows processed

从上面可以看到，该语句执行使用了outline OL11
但是并没有走全表扫描，而是走了索引

附：
语句select OL_NAME,HINT#,CATEGORY,HINT_TYPE,HINT_TEXT from outln.ol$hints where ol_name in ('OL11','OL12');的输出：

OL11 1 MYCAT1 2 FULL(@"SEL$1" [email=]"TEST1"@"SEL$1[/email]")
OL11 2 MYCAT1 111 OUTLINE_LEAF(@"SEL$1")
OL11 3 MYCAT1 113 ALL_ROWS
OL11 4 MYCAT1 109 OPTIMIZER_FEATURES_ENABLE('10.2.0.4')
OL11 5 MYCAT1 108 IGNORE_OPTIM_××DED_HINTS
OL12 1 MYCAT1 52 INDEX_RS_ASC(@"SEL$1" [email=]"TEST1"@"SEL$1[/email]" ("TEST1"."OBJECT_ID"))
OL12 2 MYCAT1 111 OUTLINE_LEAF(@"SEL$1")
OL12 3 MYCAT1 113 ALL_ROWS
OL12 4 MYCAT1 109 OPTIMIZER_FEATURES_ENABLE('10.2.0.4')
OL12 5 MYCAT1 108 IGNORE_OPTIM_××DED_HINTS


root.sh
$ more deal_dbsoft_clone.sh
#!/bin/ksh

echo "######start make db soft for db version######"
 cp ${SOFTSEED} $OBASE/product
 cd $OBASE/product
 SOFTDB=${SOFTSEED##*/}
 gunzip ${SOFTDB}
 SOFTDB2=${SOFTDB%.*}
 echo ${SOFTDB}
 echo ${SOFTDB2}
 tar xvf ${SOFTDB2}

 echo "start soft clone!"

case ${VERSION%%.*} in
 11)
    $ORACLE_HOME/oui/bin/runInstaller -silent -clone ORACLE_HOME="$ORACLE_HOME" ORACLE_BASE="$ORACLE_BASE" ORACLE_HOME_NAME="oracle_home_${
NEWSID}" -invPtrLoc $ORACLE_BASE/oraInst.loc > $TMPDIR/${NEWSID}_softclone.log
    chmod 775 $ORACLE_HOME/lib/libclntsh.so.11.1
    ;;

 10)
    $ORACLE_HOME/oui/bin/runInstaller -silent -clone ORACLE_HOME="$ORACLE_HOME" ORACLE_HOME_NAME="oracle_home_${NEWSID}" -invPtrLoc $ORACLE
_BASE/oraInst.loc > $TMPDIR/${NEWSID}_softclone.log
    chmod 775 $ORACLE_HOME/lib/libclntsh.so.10.1
    ;;
  9)
    cd $ORACLE_HOME
    relink all
    ;;
  *)
    echo "i don not which db soft version should be clone!"
    exit 1
    ;;
esac

 echo "end soft clone!"


#####$ORACLE_HOME/OPatch/opatch lsinventory -invPtrLoc $ORACLE_BASE/oraInst.loc -bugs_fixed | grep -i 'DATABASE PSU'


echo "######end make db soft for db version######"


其实,许多人已经提到过这个东西了,我这里只是举一个简单的例子演示一遍具体的流程而已

比如说优化这个语句:
SELECT MAX(P.PAGEVIEW)
  FROM PRODUCT P, CATALOGRELATEPRODUCT CATAP
WHERE CATAP.CATALOGID = 291
   AND P.ID = CATAP.PRODUCTID
   AND PUBLISHSTATUS = 3;
我收集运行时的统计信息:
SELECT /*+ gather_plan_statistics ZHAOSJ1*/max(P.PAGEVIEW)
  FROM PRODUCT P, CATALOGRELATEPRODUCT CATAP
WHERE CATAP.CATALOGID = 291
   AND P.ID = CATAP.PRODUCTID
   AND PUBLISHSTATUS = 3;

实际的运行这个SQL语句,gather_plan_statistics是收集运行时的统计信息的提示,ZHAOSJ1 就是一个普通的注释,是为了唯一的标识这个游标的.

SQL> SELECT SQL_ID,CHILD_NUMBER FROM V$SQL  WHERE SQL_TEXT LIKE '%ZHAOSJ1%' AND SQL_TEXT NOT LIKE '%V$SQL%';

SQL_ID        CHILD_NUMBER
------------- ------------
79gcyuucwuzwg            0

查找刚才的游标.
SET PAGESIZE 200;
SET LINESIZE 200;
COL PLAN_TABLE_OUTPUT FOR A195;
SQL> SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY_CURSOR('79gcyuucwuzwg',0,'ALL IOSTATS LAST'));

PLAN_TABLE_OUTPUT
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
SQL_ID  79gcyuucwuzwg, child number 0
-------------------------------------
SELECT /*+ gather_plan_statistics ZHAOSJ1*/max(P.PAGEVIEW)   FROM PRODUCT P, CATALOGRELATEPRODUCT CATAP  WHERE CATAP.CATALOGID =
291    AND P.ID = CATAP.PRODUCTID    AND PUBLISHSTATUS = 3
Plan hash value: 745285829
--------------------------------------------------------------------------------------------------------------------------------------------
| Id  | Operation          | Name                        | Starts | E-Rows |E-Bytes| Cost (%CPU)| E-Time   | A-Rows |   A-Time   | Buffers |
--------------------------------------------------------------------------------------------------------------------------------------------
|   1 |  SORT AGGREGATE    |                             |      1 |      1 |    19 |            |          |      1 |00:00:00.08 |   17210 |
|   2 |   NESTED LOOPS     |                             |      1 |     50 |   950 |    27   (0)| 00:00:01 |   8557 |00:00:00.08 |   17210 |
|*  3 |    INDEX RANGE SCAN| INDEX2_CATALOGRELATEPRODUCT |      1 |     50 |   400 |     2   (0)| 00:00:01 |   8567 |00:00:00.01 |      30 |
|*  4 |    INDEX RANGE SCAN| INDEX2_PRODUCT              |   8567 |      1 |    11 |     1   (0)| 00:00:01 |   8557 |00:00:00.06 |   17180 |
--------------------------------------------------------------------------------------------------------------------------------------------
Query Block Name / Object Alias (identified by operation id):
-------------------------------------------------------------
   1 - SEL$1

PLAN_TABLE_OUTPUT
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
   3 - SEL$1 / [email=CATAP@SEL$1]CATAP@SEL$1[/email]
   4 - SEL$1 / [email=P@SEL$1]P@SEL$1[/email]
Predicate Information (identified by operation id):
---------------------------------------------------
   3 - access("CATAP"."CATALOGID"=291)
   4 - access("P"."ID"="CATAP"."PRODUCTID" AND "PUBLISHSTATUS"=3)
Column Projection Information (identified by operation id):
-----------------------------------------------------------
   1 - (#keys=0) MAX("P"."PAGEVIEW")[22]
   2 - "P"."PAGEVIEW"[NUMBER,22]
   3 - "CATAP"."PRODUCTID"[NUMBER,22]
   4 - "P"."PAGEVIEW"[NUMBER,22]


这里显示:这个语句总的逻辑IO是:17210(buffers 是实际的逻辑IO数量,这里是累计值,包括子操作的值)
starts 是对应的动作执行的次数
E-ROWS 是优化器估算这一步返回的数据行数
A-Rows  是这一步实际返回的数据行数

明显INDEX RANGE SCAN| INDEX2_CATALOGRELATEPRODUCT   这一步估算返回50行.但实际返回了8567行
因为估算返回50行,所以估算INDEX RANGE SCAN| INDEX2_PRODUCT 这一步会执行50次,但实际它执行了8567次.
显然估算与实际执行上存在着巨大的差异.

那优化器估算INDEX RANGE SCAN| INDEX2_CATALOGRELATEPRODUCT 这一步返回8567行的话,执行计划会是什么呢 实际的执行效果会怎样呢 
使用cardinality(t n) 提示不就可以了吗 !

SQL> SELECT /*+ CARDINALITY(CATAP 8500) gather_plan_statistics ZHAOSJ6*/max(P.PAGEVIEW)
  2    FROM PRODUCT P, CATALOGRELATEPRODUCT CATAP
  3   WHERE CATAP.CATALOGID = 291
  4     AND P.ID = CATAP.PRODUCTID
  5     AND PUBLISHSTATUS = 3;

MAX(P.PAGEVIEW)
---------------
          18524

SQL> SELECT SQL_ID,CHILD_NUMBER FROM V$SQL  WHERE SQL_TEXT LIKE '%ZHAOSJ6%' AND SQL_TEXT NOT LIKE '%V$SQL%';

SQL_ID        CHILD_NUMBER
------------- ------------
f9nj2kxhphm82            0

SQL> SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY_CURSOR('f9nj2kxhphm82',0,'ALL IOSTATS LAST'));

PLAN_TABLE_OUTPUT
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
SQL_ID  f9nj2kxhphm82, child number 0
-------------------------------------
SELECT /*+ CARDINALITY(CATAP 8500) gather_plan_statistics ZHAOSJ6*/max(P.PAGEVIEW)   FROM PRODUCT P, CATALOGRELATEPRODUCT CATAP  WHERE
CATAP.CATALOGID = 291    AND P.ID = CATAP.PRODUCTID    AND PUBLISHSTATUS = 3
Plan hash value: 2173417495
------------------------------------------------------------------------------------------------------------------------------------------------
| Id  | Operation              | Name                        | Starts | E-Rows |E-Bytes| Cost (%CPU)| E-Time   | A-Rows |   A-Time   | Buffers |
------------------------------------------------------------------------------------------------------------------------------------------------
|   1 |  SORT AGGREGATE        |                             |      1 |      1 |    19 |            |          |      1 |00:00:00.09 |    1413 |
|*  2 |   HASH JOIN            |                             |      1 |   8511 |   157K|   246   (3)| 00:00:03 |   8557 |00:00:00.09 |    1413 |
|*  3 |    INDEX RANGE SCAN    | INDEX2_CATALOGRELATEPRODUCT |      1 |   8500 | 68000 |     2   (0)| 00:00:01 |   8567 |00:00:00.01 |      30 |
|*  4 |    INDEX FAST FULL SCAN| INDEX2_PRODUCT              |      1 |    236K|  2535K|   242   (2)| 00:00:03 |    236K|00:00:00.01 |    1383 |
------------------------------------------------------------------------------------------------------------------------------------------------
Query Block Name / Object Alias (identified by operation id):
-------------------------------------------------------------
   1 - SEL$1

PLAN_TABLE_OUTPUT
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
   3 - SEL$1 / [email=CATAP@SEL$1]CATAP@SEL$1[/email]
   4 - SEL$1 / [email=P@SEL$1]P@SEL$1[/email]
Predicate Information (identified by operation id):
---------------------------------------------------
   2 - access("P"."ID"="CATAP"."PRODUCTID")
   3 - access("CATAP"."CATALOGID"=291)
   4 - filter("PUBLISHSTATUS"=3)
Column Projection Information (identified by operation id):
-----------------------------------------------------------
   1 - (#keys=0) MAX("P"."PAGEVIEW")[22]
   2 - (#keys=1) "P"."PAGEVIEW"[NUMBER,22]
   3 - "CATAP"."PRODUCTID"[NUMBER,22]
   4 - "P"."ID"[NUMBER,22], "P"."PAGEVIEW"[NUMBER,22]

明显hash join后估算的行数8511与实际返回的行数8557的差距已经很小了.
执行计划改变了.而且逻辑IO从1.7W下降到了1400.逻辑IO的下降还是很明显的

下面要做的就是通过使用提示使得它可以走这个执行计划:
SELECT /*+ use_hash(p catap)*/max(P.PAGEVIEW)
  FROM PRODUCT P, CATALOGRELATEPRODUCT CATAP
WHERE CATAP.CATALOGID = 291
   AND P.ID = CATAP.PRODUCTID
   AND PUBLISHSTATUS = 3;

但,事实上你要做的是查找一下优化器为什么估算返回的行数,估算错了呢 
SQL> select a.num_distinct,a.num_buckets,a.num_nulls,a.histogram,b.num_rows,round(b.num_rows/a.num_distinct) rows_per_key
  2  from user_tab_columns a,user_tables b where a.table_name='CATALOGRELATEPRODUCT' and a.column_name='CATALOGID' and b.table_name='CATALOGRELATEPRODUCT';

NUM_DISTINCT NUM_BUCKETS  NUM_NULLS HISTOGRAM         NUM_ROWS ROWS_PER_KEY
------------ ----------- ---------- --------------- ---------- ------------
       17943           1          0 NONE                904362           50
明显,这个列上并没有收集柱状图统计信息.所以对于min~max内的任意给定值,它估算的返回行数都是:num_rows/num_distinct =50
对于CATAP.CATALOGID = 291,估算确实不够准确.但问题在于两点:
1.应用程序中是使用绑定变量的.
2.对于典型输入值来说,确实返回不了几行数据(nl的执行计划确实是好的,不收集柱状图统计信息时,确实走NL了).291其实并不是一个典型输入值(对于这个非典型输入值来说,hash join确实是一个好的执行计划,而nl不是).所以如果收集了柱状图统计信息的话,每次硬分析的时候,都会peeking,这带有很大的随机性,如果peeking的刚好是291这个非典型输入值,采用hash join的话,对于一般的输入值来说,性能上其实是不好的.所以,其实就不应该收集柱状图统计信息:这样虽然对于极少数的输入值来说,执行计划并不好,但对于绝大多数的输入值来说,执行计划是很好的.对于极少数的非典型输入值来说,如果使用字面值的话,你可以使用use_hash之类的提示来纠正它的执行计划.


[1][2]基数、选择度：基 数被定义为一个谓语或执行步骤预期获取的数据行数。考虑一个假设列值均匀分布的列上的简单等式谓语。通过表中的数据行数与表中唯一值的个数相除来算出基 数。例如，在Sales表中，有918K行数据而Prod_id列上72个唯一值，因此Prod_id列上的等式谓语基数就是918K/72=12 750。那么，换句话说，谓语Prod_id=:b1预计将取出12750行数据。具有较低基数的列更适合作为索引的候选，因为索引的选择度要更好。对于 每个值都是唯一的列，等式谓语的基数为1。选择度是一个从0到1的度量值，简单定义为1/NDV，其中NDV表示唯一值的数目。因此，一个位于的数据可以 定义为选择度乘以表中的数据行数。

move一个表到另外一个表空间时,索引不会跟着一起move，而且会失效。（LOB类型例外）

SQL>set colsep' ';　　　　 //-域输出分隔符
SQL>set echo off;　　　　 //显示start启动的脚本中的每个sql命令，缺省为on
SQL> set echo on               //设置运行命令是是否显示语句
SQL> set feedback on;       //设置显示“已选择XX行”
SQL>set feedback off;　     //回显本次sql命令处理的记录条数，缺省为on
SQL>set heading off;　　   //输出域标题，缺省为on
SQL>set pagesize 0;　　    //输出每页行数，缺省为24,为了避免分页，可设定为0。
SQL>set linesize 80;　　    //输出一行字符个数，缺省为80
SQL>set numwidth 12;　    //输出number类型域长度，缺省为10
SQL>set termout off;　　   //显示脚本中的命令的执行结果，缺省为on
SQL>set trimout on;　　　//去除标准输出每行的拖尾空格，缺省为off
SQL>set trimspool on;　　//去除重定向（spool）输出每行的拖尾空格，缺省为off
SQL>set serveroutput on;  //设置允许显示输出类似dbms_output
SQL> set timing on;          //设置显示“已用时间：XXXX”
SQL> set autotrace on-;    //设置允许对执行的sql进行分析
SQL> set verify off                     //可以关闭和打开提示确认信息old 1和new 1的显示.

表move，我们分为：

*普通表move

*分区表move

*LONG,LOB大字段类型move来进行测试和说明。



索引的move，我们通过rebuild来实现

一：move普通表、索引基本语法：

alter table tab_name move tablespace tbs_name;

move过的普通表，在不用到失效的索引的操作语句中，语句执行正常，但如果操作的语句用到了索引（主键当做唯一索引），则此时报告用到的索引失效，语句执行失败，其他如外键，非空约束，缺省值等不会失效。

我们需要重新创建主键或索引，基本语法为：

1
2
alter index index_name rebuild;
alter index pk_name rebuild;
如果我们需要move索引，则使用rebuild语法：

1
2
alter index index_name rebuild tablespace tbs_name;
alter index pk_name rebuild tablespace tbs_name;
提示：查询表所具有的索引，可以使用user_indexes视图（索引和主键都在这个视图里可找到）。



二：move分区表及索引和普通表一样，索引会失效，区别的仅仅是语法而已。

分区基本语法：特别提醒注意，如果是单级分区，则使用关键字PARTITION，如果是多级分区，则使用SUBPARTITION替代PARTITION。

如果分区或分区索引比较大，可以使用并行move或rebuild，PARALLEL (DEGREE 2);如：

1
2
3
ALTER TABLE PART_ALARMTEXTDATA move SUBPARTITION ALARMTEXTDATA_050910_ATD01 TABLESPACE users PARALLEL (DEGREE 2);
ALTER INDEX GLOBAL_ALARMTEXTDATA REBUILD tablespace users PARALLEL (DEGREE 2);
ALTER INDEX LOCAL_ALARMTEXTDATA REBUILD SUBPARTITION ALARMTEXTDATA_050910_ATD01 TABLESPACE users PARALLEL (DEGREE 2);
移动表的某个分区：

1
ALTER TABLE tab_name move PARTITION partition_name TABLESPACE tbs_name;
重建全局索引：

1
2
ALTER INDEX global_index REBUILD;或
ALTER INDEX global_index REBUILD tablespace tbs_name;
注: 分区操作时可以带上with update global indexes选项更新全局索引

重建局部索引：

1
ALTER TABLE tab_name MODIFY PARTITION partition_name REBUILD UNUSABLE LOCAL INDEXES;
1
或
1
ALTER INDEX local_index_name REBUILD PARTITION partition_name TABLESPACE tbs_name;
提示：

USER_PART_TABLES

USER_IND_PARTITIONS

USER_IND_SUBPARTITIONS

USER_LOB_PARTITIONS

USER_LOB_SUBPARTITIONS

USER_PART_INDEXES

USER_PART_LOBS可查询分区相关内容，同时，分区对象，也是segment，所以也可在dba_segments里查的到。



三：move LONG,LOB类型（据说DBMS_REDEFINITION包可以提供一些方便，没用过。）

I:LONG类型

LONG类型不能通过MOVE来传输特别提示，尽量不要用LONG类型，特难管理。参考：http://www.anysql.net/2005/12/long_vs_lob.html

LONG不能使用insert into … select …等带select的模式。如

1
2
3
4
5
6
7
8
9
10
11
12
13
14
create table t123 (id int,en long);则
insert into t123(id,en) select * from t123;报告错误，可以用pl/sql来帮助解决，如：
declare
cursor cur_t123 is select * from t123;
use_t123 cur_t123%rowtype;
begin
open cur_t123;
loop
fetch cur_t123 into use_t123;
exit when cur_t123%notfound;
insert into t123(id,en) values (use_t123.id,use_t123.en);
end loop;
close cur_t123;
end;
对有LONG类型字段的表的转移，可以使用：

create新表的方法。

* create一个新的表，存储在需要转移的表空间。

* 创建新的索引（使用tablespace 子句指定新的表空间）。

* 把数据转移过来

方法一：用COPY的方法：

1
copy from bigboar/bigboar@bigboar_sid insert t123(id,en) using select id,en from t123;
方法二：PL/SQL（如上）

方法三：直接就把LONG转换成CLOB类型

1
2
create table t321(id int,en clob) tablespace users;
insert into t321(id,en) select id,to_lob(en) from t123;
方法四：exp/imp

1
2
exp bigboar/bigboar file=a.dat tables=t123
imp bigboar/bigboar file=a.dat full=y IGNORE =y
* drop掉旧表。

* rename 新表为旧表表名。

II:LOB类型在建立含有lob字段的表时，oracle会自动为lob字段建立两个单独的segment,一个用来存放数据（segment_type=LOBSEGMENT），另一个用来存放索引（segment_type=LOBINDEX）。默认它们会存储在和表一起的表空间。我们对表MOVE时，LOG类型字段和该字段的索引不会跟着MOVE，必须要单独来进行MOVE，语法如下如：

1
2
alter table t321 move tablespace users;
alter table t321 move lob(en) store as (tablespace users);

select   s.sid,s.username,s.sql_id,t.used_ublk*8/1014/1024 from v$transaction t ,v$session s
 where t.addr=s.taddr order by 4 desc;


 。查看锁（lock）情况
 select /*+ RULE */ ls.osuser os_user_name, ls.username user_name, decode(ls.type, 'RW', 'Row wait enqueue lock', 'TM', 'DML enqueue lock', 'TX', 'Transaction enqueue lock', 'UL', 'User supplied lock') lock_type, o.object_name object, decode(ls.lmode, 1, null, 2, 'Row Share', 3, 'Row Exclusive', 4, 'Share', 5, 'Share Row Exclusive', 6, 'Exclusive', null) lock_mode, o.owner, ls.sid, ls.serial# serial_num, ls.id1, ls.id2
 from sys.dba_objects o, ( select s.osuser, s.username, l.type, l.lmode, s.sid, s.serial#, l.id1, l.id2 from v$session s, v$lock l where s.sid = l.sid ) ls where o.object_id = ls.id1 and o.owner <> 'SYS' order by o.owner, o.object_name
 --查看低效率的SQL语句
 SELECT EXECUTIONS , DISK_READS, BUFFER_GETS, ROUND((BUFFER_GETS-DISK_READS)/BUFFER_GETS,2) Hit_radio, ROUND(DISK_READS/EXECUTIONS,2) Reads_per_run, SQL_TEXT FROM V$SQLAREA WHERE EXECUTIONS>0 AND BUFFER_GETS > 0 AND (BUFFER_GETS-DISK_READS)/BUFFER_GETS < 0.8 ORDER BY 4 DESC


然后查看这些占用 CPU 资源很高的 Oracle 进程究竟是在做什么操作，使用如下 SQL 语句：
select sql_text,sql_fulltext,spid,v$session.program,process  from
v$sqlarea,v$session,v$process
where v$sqlarea.address=v$session.sql_address
and v$sqlarea.hash_value=v$session.sql_hash_value
and v$session.paddr=v$process.addr
and v$process.spid in (PID);

基本上可以肯定是这个 SQL 引起了系统 CPU 资源大量被占用，那究竟是什么原因造成这个
SQL 这么大量地占用 CPU 资源呢，先来看看数据库的进程等待事件都有些什么：
SQL> select sid,event,p1,p1text from v$session_wait;


从上面的查询可以看出，大都是 latch free 的等待事件，然后接着查一下这些 latch 的等待都
是什么进程产生的：
SQL> select spid from v$process where addr in

    (select paddr from v$session where sid in(84,102,101,106,155,151));
由此看出 latch  free 这个等待事件导致了上面的那个 SQL 语句在等待，占用了大量的 CPU 资
源。下面来看看究竟主要是哪种类型的 latch 等待，根据下面的 SQL 语句：
SQL> SELECT latch#, name, gets, misses, sleeps
     FROM v$latch
     WHERE sleeps>0
     ORDER BY sleeps;

     由上面的查询可以看出最主要的 latch 等待是 cache buffers chains，这个 latch 等待表明数据
库存在单独的 block 竞争，下面来看这个 latch 存在的子 latch 及其对应的类型：
SQL> SELECT addr, latch#, gets, misses, sleeps
     FROM v$latch_children
     WHERE sleeps>0
     and latch# = 98
     ORDER BY sleeps desc;



    (select paddr from v$session where sid in(84,102,101,106,155,151));
SPID
------------
25774
26010
25873
25725
26014
26016
由此看出 latch  free 这个等待事件导致了上面的那个 SQL 语句在等待，占用了大量的 CPU 资
源。下面来看看究竟主要是哪种类型的 latch 等待，根据下面的 SQL 语句：
SQL> SELECT latch#, name, gets, misses, sleeps
     FROM v$latch
     WHERE sleeps>0
     ORDER BY sleeps;
LATCH#  NAME                          GETS     MISSES      SLEEPS
---------- ----------------------------------------------------------------
    15   messages                       96876       20          1
   159   library cache pin allocation   407322      43          1
   132   dml lock allocation            194533      213         2
     4   session allocation             304897      48          3
   115   redo allocation                238031      286         4
    17   enqueue hash chains            277510      85          5
     7   session idle bit               2727264     314         16
   158   library cache pin              3881788     5586        58
   156   shared pool                    2771629     6184        662
   157   library cache                  5637573     25246       801
    98   cache buffers chains           1722750424  758400      109837
由上面的查询可以看出最主要的 latch 等待是 cache buffers chains，这个 latch 等待表明数据
库存在单独的 block 竞争，下面来看这个 latch 存在的子 latch 及其对应的类型：
SQL> SELECT addr, latch#, gets, misses, sleeps
     FROM v$latch_children
     WHERE sleeps>0
     and latch# = 98
     ORDER BY sleeps desc;
ADDR                 LATCH#       GETS     MISSES     SLEEPS
---------------- ---------- ---------- ---------- ----------
000004000A3DFD10         98   10840661      82891        389
000004000A698C70         98     159510          2        244
0000040009B21738         98  104269771      34926        209
0000040009B227A8         98  107604659      35697        185
000004000A3E0D70         98    5447601      18922        156
000004000A6C2BD0         98     853375          7        134
0000040009B24888         98   85538409      25752        106
000004000A36B250         98    1083351        199         96
000004000A79EC70         98     257970         64         35
000004000A356AD0         98    1184810        160         34
……
接着来查看 sleep 较多的子 latch 都对应哪些对象：
SQL> select distinct a.owner,a.segment_name,a.segment_type from  294  Oracle 数据库性能优化

     dba_extents a,
 (select dbarfil,dbablk
from x$bh
where hladdr in
     (select addr
     from (select addr
     from v$latch_children
     order by sleeps desc)
     where rownum < 5)) b
     where a.RELATIVE_FNO = b.dbarfil
     and a.BLOCK_ID <= b.dbablk and a.block_id + a.blocks > b.dbablk;



     根据开始查到的引起 latch free 等待中的对象和 SQL 语句的执行计划，觉得 SERVICE 表上的
索引有问题，似乎存在了过多的扫描，于是将同样的 SQL 语句在其他的同样的数据库上执行一下，
查看相应的执行计划：

发现存在问题的数据库中的  SERVICE  表上不知怎么多出了  I_SERVICE_PRICEPLANID、
I_SERVICE_SERVICESPECID 和 I_SERVICE_SUBSIDIARYID 三个索引，而这些索引就是导致了开始那
个 SQL 语句用了不该用的索引，引起 latch  free 等待和 CPU 占用很高的罪魁祸首，于是删除了这
三个索引，重新执行相应的 SQL 语句，很快就得出了结果，CPU 的利用率也马上下降为正常了，



这里推荐一种方法来发现当前谁正在使用某个 Package/Procedure/Function/View：
SQL> create or replace procedure who_is_using(obj_name varchar2) is
  2  begin
  3   dbms_output.enable(1000000);
  4     for i in (SELECT distinct b.username ， b.sid
  5               FROM SYS.x$kglpn a ， v$session b ， SYS.x$kglob c
  6               WHERE a.KGLPNUSE = b.saddr
  7                 and upper(c.KGLNAOBJ)  like upper(OBJ_NAME)
  8                 and a.KGLPNHDL = c.KGLHDADR) loop
  9     dbms_output.put_line('('||to_char(i.sid)||') - '||i.username);
 10     end loop;
 11  end;
 12  /

Procedure created.

SQL> execute who_is_using('STANDARD%');
 (9) - SYS





，v$sort_segment 字典记载 temp 表空间比较详细的使用情况，而 v$sort_usage 字典将会告诉 DBA 是谁在做什么，具体的 SQL 还需
要稍做加工，才可以得出更详细的结果。
select se.username,p.spid,su.blocks*8192/1024/1024 Space,sql_text
    from v$sort_usage su,v$session se,v$sql s,v$process p
where su.session_addr=se.saddr and s.hash_value=su.sqlhash
    and s.address=su.sqladdr and p.addr = se.paddr
order by se.username,se.sid;

，空闲事件指 Oracle 正在等待某种工作，常见的空闲等待事件有
client message、
null event、
pipe get、
pmon/smon timer、
rdbms rpc message

及 SQL*Net 等；非空闲等待事件有
buffer busy waits、
db file scattered read、
db file sequential read、
enqueue、
free buffer waits、
latch free、
log file sync、
log file paralle write 等。


Buffer Busy Wait
此类对缓冲区的等待是由于该缓冲区的非共享工作方式，或者是由于该缓冲区正在通过其
他会话读取数据块中的内容所致。缓冲区忙等待不应超过 1%的额度。请检查 Statspack 的缓冲
区等待的部分（或者检查  v$waitstat  视图），看看等待是否发生于段头上。若是，则应增加该
段的 Freelist  Groups 或者增大 PCTFREE 和 PCTUSED 之间的差。如果等待发生于 undo  header
上，则可以通过增加回滚段来解决问题；如果等待发生于 undo block 上，则可以考虑减少驱动
此一致性读的表上面的数据密度，或者增大 DB_CACHE_SIZE。如果等待发生于 data block 上，
则可以把该块上的数据搬到另一数据块上以避免“热点”，增大表的 Freelists 或者采用本地管理
的表空间（LMT’s）。如果等待发生于 index block 上，则可以重建索引、将索引分区或者采用反
向关键字索引。为避免与数据块相关的缓冲区忙等待，可以转而采用较小的 blocksize：每一块
里现在只能容纳较少的记录，该块也就不会再像以前那样“热”了。当执行一条 DML（增、删
或改）时，Oracle 数据库会向数据块里写信息，其中包括对该数据块状态“感兴趣”的用户信
息（Interested Transaction List，简称 ITL）。为减少在这一部分上的等待，可以增大 initrans 参
数，从而在数据块中为更多的 ITL 槽预留空间；还可以增大表的 PCTFREE 参数，这样，在  initrans
没有为足够多 ITL 槽预留空间的情况下，更多 ITL 槽（受 maxtrans 的封顶限制）可以被动态地
分配给空间。


-- 求等待事件及其对应的 latch
col event format a32
col name format a32
select sid,event,p1 as file_id, p2 as "block_id/latch", p3 as blocks,l.name
  from v$session_wait sw,v$latch l
where event not like '%SQL%' and event not like '%rdbms%'
and event not like '%mon%' and sw.p2 = l.latch#(+);
-- 求等待事件及其热点对象
col owner format a18
col segment_name format a32
col segment_type format a32
select owner,segment_name,segment_type
  from DBA_extents
where file_id = &file_id and &block_id between block_id
and block_id + &blocks - 1;
-- 综合以上两条 SQL ，同时显示 latch 及热点对象（速度较慢）
select sw.sid,event,l.name,de.segment_name
  from v$session_wait sw,v$latch l,DBA_extents de
where event not like '%SQL%' and event not like '%rdbms%'
and event not like '%mon%' and sw.p2 = l.latch#(+) and sw.p1 = de.file_id(+) and p2 between
de.block_id and de.block_id + de.blocks - 1;
-- 如果是非空闲等待事件，通过等待会话的 SID 可以求出该会话在执行的 SQL
select sql_text
 from v$sqltext_with_newlines st,v$session se
where st.address=se.sql_address and st.hash_value=se.sql_hash_value
and se.sid =&wait_sid order by piece;




session数设置的小了，想修改最大session参数，客户要历史连接的最大session数，然后参考这个值进行设置
我没查出来这个最大连接数  请教一下 怎么查看这个历史最大连接session数
select * from dba_high_water_mark_statistics;



通过如下sql 看 pace 最近7天的latch free 等待总量和时间趋势图及pa 上的性能数据，

with
e as (
select t1.instance_number, to_char(t2.snap_time,'yyyy-mm-dd hh24:mi:ss') snap_time,
 t1.event,t1.snap_id,
 t1.total_waits-lag(t1.total_waits ,1) over(partition by t1.instance_number order by t1.snap_id) as t_waits,
 t1.time_waited_micro-lag(t1.time_waited_micro ,1) over(partition by t1.instance_number order by t1.snap_id) as t_waitime
 from STATS$SYSTEM_EVENT t1, stats$snapshot t2
where t1.snap_id = t2.snap_id
 and t1.event = 'latch free'
 and t2.snap_time>sysdate-7
 )
 select snap_id,snap_time,t_waits as total_waits,round(t_waitime/10000) total_waitime,round(t_waitime/t_waits)*10 wtime_per
 from e where snap_id not in ('66314','66414') order by snap_time asc;


查找过度频繁语句:
select t1.sid,  t1.value,    t2.name from v$sesstat t1,     v$statname t2
where t2.name  like  '%user commits%'
     and t1.statistic#  = t2.statistic#
     and   value >=10000
     order by value desc;
跟踪日志暴增故障：
select  *  from  (
   select  to_char(begin_interval_time,  'YYYY_MM_DD HH24:MI'）  snap_time, dhsso.object_name,sum(db_block_changs_delta)
   from dba_hist_seg_stat dhss, dba_hist_seg_stat_obj dhsso,  dba_hist_snapshot dhs
    where  dhs.snap_id=dhss.snap_id
    and  dhs.instance_number =dhss.instance_number  and dhss.obj# = dhsso.obj# and dhss.dataobj#=dhsso.dataobj#
    and begin_interval_time >sysdate-60/1440
    group by to_char(begin_interval_time, 'YYYY_MM_DD HH24:MI'), dhsso.object_name order by 3 desc
    where rownum<=3;


select to_char(begin_interval_time,'YYYY_MM_DD HH24:MI'), dbms_lob.substr(sql_text,4000,1),  dhss.sql_id,  executions_delta,
rows_processed_delta from dba_hist_sqlstat dhss,  dba_hist_snapshot dhs , dba_hist_sqltext dhst
where  upper(dhst.sql_text) like '%TEST REDO%'   and dhss.snap_id=dhs.snap_id
and dhss.instance_number = dhs.instance_number  and dhss.sql_id=dhst.sql_id;



/********************************************

    功能说明： 数据库日常管理常用sql脚本
    参数说明：
    创建人：   李兵
    创建日期： 2008-6-3
    复核人：
    修改人：
    修改日期：
    修改说明：

    目录： ###########查询类###########

           关于session:
               kill session和kill -9
               查询session信息以及process信息
               查找产生大量物理读的进程
               查找产生redo log过快的进程
               获取大批量数据操作测试的耗费时间和产生redo量
               查询tmep表空间的使用情况
               查询哪些回滚段被大量占用 for 8i

           关于sql和执行计划:
               查看某用户当前执行的sql语句
               查看某用户之前执行的sql语句
               根据sid或spid查询执行的sql语句
               查询执行计划并格式化输出
               查找未使用绑定变量产生大量硬解析的语句
               查找当前硬解析过多的session
               查询各种等待事件对应的sql语句

           关于锁:
               查询锁
               有session调用package导致无法编译
               分布式事务锁的处理

           关于等待事件
               查询等待事件
               library cache pin等待事件的处理
               cache buffers chains等待事件的处理
               db file sequential read等待事件的分析
               db file scattered read等待事件的分析

           关于trace和event:
               设置trace和event
               查询audit审计记录

           关于监控巡检语句：
               mon_long_session 长连接的session监控
               mon_rbs 占用大量回滚段的监控
               mon_ckpt active redo log及其相关session和sql的监控
               mon_xatrans 分布式事务锁的监控
               mon_swait 等待事件的监控
               mon_sqlarea 未使用绑定变量的sql监控
               mon_sharepool 占用大量内存的sql监控
               mon_redo 产生大量redo log的session和sql监控
               mon_temp 占用大量temp表空间的session和sql监控

           关于数据库实例：
               了解当前ASMM 自动调整的内存参数情况


           ###########操作类###########
           关于redo log、archive log、checkpoint
               加大（或减少）redo log尺寸的操作步骤

           关于备份和恢复:
               加快实例crash后的恢复速度
               redo log header corrupt处理方法
               recover命令：完全恢复
               recover命令：不完全恢复
               recover命令：恢复数据文件或表空间

           关于cbo统计信息
               快速恢复旧的统计信息 for 9i
               快速恢复旧的统计信息 for 10g
               搜集统计信息
               导入统计信息

           关于保留现场信息或oradebug
               使用oradebug搜集现场信息
               使用rda搜集当前系统信息供GCS工程师分析问题

           采用OUTLN技术将正确的执行计划从其它环境导入到生产库

           ###########操作系统类###########
           关于主机资源消耗
               CPU使用情况
               设备使用情况
               虚拟内存使用情况

********************************************/



######################################查询类#######################################


#################################关于session#################################

*********************************kill session和kill -9***********************************
--kill数据库内部的session     immediate  IMMEDIATE 
alter system kill session '&SID,&SERIAL#';

--生成kill所有active session的脚本
select 'alter system kill session ' || '''' || sid || ',' || serial# || '''' || ';'from v$session where status='ACTIVE' and username is not null;

--生成按用户名kill所有session的脚本
select 'alter system kill session ' || '''' || sid || ',' || serial# || '''' || ';'from v$session where username=upper('&USERNAME';

--kill后台所有LOCAL=NO的session
kill -9 `ps -ef|grep oplpms|grep LOCAL=NO|awk '{print $2}'`

--从数据库生成kill所有活动的后台进程的脚本
select ' kill -9 ' || spid from (select spid from v$process where addr in(select paddr from v$session where status='ACTIVE' and username is not null));

--kill掉造成某一类等待事件的所有活动session
select 'alter system kill session ' || '''' || sid || ',' || serial# || '''' || ';'
  from v$session
 where status = 'ACTIVE'
   and sid in (select sid
                 from v$session_wait
                where event in ('&EVENT_NAME'));
*********************************************************************************




*********************************查询session信息以及process信息*********************************
--根据username查询sid和后台spid
select a.username,a.sid,a.serial#,b.spid,a.STATUS,a.OSUSER,a.MACHINE,a.PROGRAM from v$session a,v$process b where a.PADDR=b.ADDR and a.username=&USERNAME;

--根据后台spid查询sid
select username,sid,serial#,STATUS,OSUSER,MACHINE,PROGRAM from v$session where paddr = (select addr from v$process where spid = &SPID);

--根据sid查询后台spid
select spid from v$process where addr = (select paddr from v$session where sid = &SID);

--查询自己session的后台spid
select a.username,a.sid,a.serial#,b.spid,a.STATUS,a.OSUSER,a.MACHINE,a.PROGRAM from v$session a,v$process b where a.PADDR=b.ADDR and a.sid=(select distinct sid from v$mystat);
************************************************************************************************




*********************************查找产生大量物理读的进程*********************************
 select * from (select * from (select st.sid,st.value,sn.name,s.username,s.logon_time
    from v$sesstat st,v$statname sn ,v$session s
     where st.sid=s.sid AND st.statistic#=sn.statistic# and st.value>100000 and s.username is not null
         and sn.name like '%physical read%' order by 2 desc));
**************************************************************************************




*********************************查找产生redo log过快的进程*********************************
col machine format a20
col osuser format a20
set lines 150
select sysdate,
       se.username,
       se.sid,
       se.serial#,
       se.SQL_HASH_VALUE,
       se.status,
       se.machine,
       se.osuser,
       round(st.value / 1024 / 1024) redosize,
       sa.sql_text
  from v$session se, v$sesstat st, v$sqlarea sa
 where se.sid = st.sid
   and st.STATISTIC# =
       (select STATISTIC# from v$statname where NAME = 'redo size')
      --and se.username is not null
   and st.value > 10 * 1024 * 1024
   and se.SQL_ADDRESS = sa.ADDRESS
   and se.SQL_HASH_VALUE = sa.HASH_VALUE
 order by redosize;
********************************************************************************************




*********************************获取大批量数据操作测试的耗费时间和产生redo量*********************************
set serveroutput on;
DECLARE
start_time NUMBER;
end_time NUMBER;
start_redo_size NUMBER;
end_redo_size NUMBER;
BEGIN
start_time := dbms_utility.get_time;
SELECT VALUE INTO start_redo_size FROM v$mystat m,v$statname s
WHERE m.STATISTIC#=s.STATISTIC#
AND s.NAME='redo size';
--transaction start
用户脚本
--transaction end
end_time := dbms_utility.get_time;
SELECT VALUE INTO end_redo_size FROM v$mystat m,v$statname s
WHERE m.STATISTIC#=s.STATISTIC#
AND s.NAME='redo size';
dbms_output.put_line('Escape Time:'||to_char(end_time-start_time)||' centiseconds');
dbms_output.put_line('Redo Size:'||to_char(end_redo_size-start_redo_size)||' bytes');
END;
/


--如果用户的脚本无法嵌入到如上的匿名块中，则使用如下脚本获取时间点和redo值前后相减即可：
SELECT to_char(sysdate,'yyyy-mm-dd hh24:mi:ss'),VALUE||' bytes' FROM v$mystat m,v$statname s WHERE m.STATISTIC#=s.STATISTIC# AND s.NAME='redo size';
--transaction start
执行用户脚本
--transaction end
SELECT to_char(sysdate,'yyyy-mm-dd hh24:mi:ss'),VALUE||' bytes' FROM v$mystat m,v$statname s WHERE m.STATISTIC#=s.STATISTIC# AND s.NAME='redo size';
**************************************************************************************************************




*********************************查询tmep表空间的使用情况*********************************
--哪个进程占用临时表空间
select s.username, u.tablespace, u.contents, u.extents, u.blocks
from v$session s, v$sort_usage u
where s.saddr = u.session_addr
and u.contents = 'TEMPORARY'

--temp空间使用率
select (s.tot_used_blocks/f.total_blocks)*100 as pctused
from (select sum(used_blocks) tot_used_blocks
      from v$sort_segment
      where tablespace_name='TEMP') s,
      (select sum(blocks) total_blocks
       from dba_temp_files
       where tablespace_name='TEMP') f;

--监控temp表空间的增长情况
select su.extents, su.segtype, su.sqlhash, s.sid, s.serial#, s.last_call_et,
       s.username, s.machine,
 from v$sort_usage su, v$session s
where su.session_addr=s.saddr
and su.extents>10;

select su.segtype, sum(su.extents) from v$sort_usage su group by su.segtype;

9i:
   V$TEMPSEG_USAGE    This view describes temporary segment usage.从9i R2开始v$sort_usage就改名为V$TEMPSEG_USAGE
   V$TEMPSTAT         This view contains information about file read/write statistics.
*******************************************************************************************




*********************************查询哪些回滚段被大量占用 for 8i*********************************
--查找使用回滚段的进程
SELECT s.sid "sid", s.serial# "serial#",s.username "username",s.status, t.start_time,
   t.xidusn "xidusn", drs.segment_name "segment_name",ds. header_file "file_h",
   ds.header_block "blk_h"
FROM V$session s, V$transaction t, V$rollstat r ,dba_segments ds,dba_rollback_segs drs
WHERE s.saddr=t.ses_addr
AND t.xidusn=r.usn
and r.usn=drs.segment_id
and ds.segment_name=drs.segment_name
AND ((r.curext=t.start_uext-1) OR
((r.curext=r.extents-1) AND t.start_uext=0))
order by r.usn;

--查询哪些回滚段被大量占用
  select segment_name, tablespace_name, r.status,
  (initial_extent/1024) InitialExtent,(next_extent/1024) NextExtent,
  max_extents, v.curext CurExtent From dba_rollback_segs r,
  v$rollstat v
  Where r.segment_id = v.usn(+) order by segment_name;

--查出来结果以后看该rbs是否确实太小，用如下语句调整大小：
  alter rollback segment r13 storage(maxextents 32765);

--查出有 100 个以上 extent 的回滚段
Select usn, extents, curext from v$rollstat where extents>100;

--对其中返回的每个 usn 检查其中的事务情况：查某个回滚段中的事务情况
select t.start_uext, t.used_ublk, t.start_time, s.sid, s.serial#, s.last_call_et,
       s.username, s.machine
 from v$transaction t, v$session s
where t.ses_addr=s.saddr
and t.xidusn=&usn;

--以下语句为查可能导致回滚段持续增长的会话
select s.sid, s.serial#, t.start_time, t.xidusn, s.username
from v$session s, v$transaction t , v$rollstat r
where s.saddr=t.ses_addr
and t.xidusn=r.usn
and ((r.curext=t.start_uext-1) or
((r.curext=r.extents-1) and t.start_uext=0));
**************************************************************************************************






########################################关于sql和执行计划########################################

*********************************查看某用户当前执行的sql语句*********************************
  set pages 500
  set lines 160
  break on sid nodup on serial# nodup on user nodup on machine nodup on logontime nodup
  col machine format a20
  col text format a64
  col user format a10
  col logontime format a10
  col sid format 99999
  col serial# format 99999

  select b.sql_text text,a.sid sid,a.serial# serial#,a.username "user",a.machine machine,to_char(logon_time,'dd/hh24:mi') "logontime"
  from v$session a,v$sqltext b
  where a.username like upper('&1')
  and b.address = a.sql_address
  and b.hash_value = a.sql_hash_value
  order by a.sid,a.serial#,b.piece;
*********************************************************************************************




*********************************查看某用户之前执行的sql语句*********************************
  set pages 500
  set lines 120
  break on sid nodup on serial# nodup on machine nodup
  col machine format a20
  select b.sql_text text, a.sid sid, a.serial# serial#, a.machine machine
  from v$session a, v$sqltext b
  where a.username = upper('&1')
   and b.address = a.prev_sql_addr
   and b.hash_value = a.prev_hash_value
  order by a.sid, a.serial#, b.piece;
*********************************************************************************************




*********************************查询执行计划并格式化输出*********************************
--直接查询library cache中的sql真实的执行计划（9i以上），sql_hash_value 从 v$session 中查到：
select '| Operation                         | PHV/Object Name               |  Rows | Bytes|   Cost |'
as "Optimizer Plan:" from dual
union all
select
    rpad('| '||substr(lpad(' ',1*(depth-1))||operation||
     decode(options, null,'',' '||options), 1, 35), 36, ' ')||'|'||
  rpad(decode(id, 0, '------------- '
    , substr(decode(substr(object_name, 1, 7), 'SYS_LE_', null, object_name)
       ||' ',1, 30)), 31, ' ')||'|'||
   lpad(decode(cardinality,null,'  ',
      decode(sign(cardinality-1000), -1, cardinality||' ',
      decode(sign(cardinality-1000000), -1, trunc(cardinality/1000)||'K',
      decode(sign(cardinality-1000000000), -1, trunc(cardinality/1000000)||'M',
      trunc(cardinality/1000000000)||'G')))), 7, ' ') || '|' ||
  lpad(decode(bytes,null,' ',
    decode(sign(bytes-1024), -1, bytes||' ',
    decode(sign(bytes-1048576), -1, trunc(bytes/1024)||'K',
       decode(sign(bytes-1073741824), -1, trunc(bytes/1048576)||'M',
         trunc(bytes/1073741824)||'G')))), 6, ' ') || '|' ||
    lpad(decode(cost,null,' ', decode(sign(cost-10000000), -1, cost||' ',
                decode(sign(cost-1000000000), -1, trunc(cost/1000000)||'M',
                       trunc(cost/1000000000)||'G'))), 8, ' ') || '|' as "Explain plan"
from v$sql_plan sp
where sp.hash_value=&SQL_HASH_VALUE;

--或者预生成执行计划：
EXPLAIN PLAN set statement_id='MYSQL1' FOR
--(表示为以下sql语句生成执行计划,不会执行该语句)
&SQL语句

--格式化输出：
select plan_table_output from table(dbms_xplan.display('plan_table',null,'serial'));

--查找执行计划版本超过10个的sql语句
select sa.sql_text,sa.version_count ,ss.*from v$sqlarea sa,v$sql_shared_cursor ss where
sa.address=ss.KGLHDPAR and sa.version_count > 10 order by sa.version_count ;
******************************************************************************************




*********************************查找未使用绑定变量产生大量硬解析的语句*********************************
SELECT substr(sql_text, 1, 40) "SQL", count(*), sum(executions) "TotExecs"
  FROM v$sqlarea
 WHERE executions <5
 GROUP BY substr(sql_text, 1, 40)
HAVING count(*) > 100
 ORDER BY 2;

--执行了许多硬解析的当前会话
select c.sid||','||c.serial#,c.username,b.name,a.value,
       round((sysdate-c.logon_time)*24) hours_connected
from v$sesstat a,v$statname b,v$session c
where c.sid=a.sid
      and a.statistic#=b.statistic#
      and a.value>0
      and b.name='parse count (hard)'
order by a.value desc;
********************************************************************************************************




*********************************根据sid或spid查询执行的sql语句*********************************
--根据sid查询执行的sql语句
select se.username,
       se.sid,
       se.serial#,
       se.osuser,
       se.machine,
       se.program,
       se.logon_time,
       sa.sql_text
  from v$session se, v$sqlarea sa
 where se.SQL_ADDRESS = sa.ADDRESS
   and se.SQL_HASH_VALUE = sa.HASH_VALUE
   and se.sid = '&SID';

--根据spid查询执行的sql语句
select se.username,
       se.sid,
       se.serial#,
       se.osuser,
       se.machine,
       se.program,
       se.logon_time,
       sa.sql_text
  from v$session se, v$sqlarea sa, v$process pr
 where se.SQL_ADDRESS = sa.ADDRESS
   and se.SQL_HASH_VALUE = sa.HASH_VALUE
   and se.PADDR=pr.ADDR
   and pr.spid = '&SPID';
************************************************************************************************




*********************************查找当前硬解析过多的session*********************************
select c.username,
       c.sid,
       c.serial#,
       b.name,
       a.value,
       round((sysdate - c.logon_time) * 24) hours_connected
  from v$sesstat a, v$statname b, v$session c
 where c.sid = a.sid
   and a.statistic# = b.statistic#
   and a.value > 1000
   and b.name = 'parse count (hard)'
 order by a.value;
*********************************************************************************************




*********************************查询各种等待事件对应的sql语句*********************************
set pages 500
set lines 160
break on sid nodup on serial# nodup on user nodup on machine nodup on logontime nodup
col machine format a20
col text format a64
col user format a10
col logontime format a10
col sid format 99999
col serial# format 99999
select b.sql_text text,
       a.sid sid,
       a.serial# serial#,
       a.username "user",
       a.machine machine,
       to_char(logon_time,'dd/hh24:mi')  "logontime"
from v$session a,v$sqltext b, v$session_wait c
where a.sid = c.sid
      and c.event = '&EVENT_NAME'
      and b.address = a.sql_address
      and b.hash_value = a.sql_hash_value
order by a.sid,a.serial#,b.piece;
***********************************************************************************************




#######################################关于锁#######################################
补充：latch
      到对象
*******************************************查询锁****************************************
--查看整个instance的锁情况
select * from dba_locks;

--查看整个instance的dml锁情况
select * from v$lock where type in ('TX','TM');
select * from v$lock where type in ('TX','TM') and sid='&SID';

--查看session锁定的对象
select * from v$locked_object;

--查询锁的holder和waiter：
select decode(request, 0, 'Holder:', 'Waiter:') || sid,
       id1,
       id2,
       lmode,
       request,
       type
  from v$lock
 where (id1, id2, type) in
       (select id1, id2, type from v$lock where request > 0)
 order by id1, request;

--查询表是否有锁：
  select oracle_username,owner,object_name,object_type,session_id,locked_mode
  from v$locked_object v, dba_objects d
  where v.object_id = d.object_id
  and object_name=upper('&1')
  order by object_name ;

--查找所有被锁的对象：
  select oracle_username,owner,object_name,object_type,session_id,locked_mode,l.type,l.block
  from v$locked_object v, dba_objects d,v$lock l
  where l.block>0 and v.session_id=l.sid
  and d.object_id=v.object_id
  order by object_name,l.block ;

--查看DML LOCK情况和锁定的对象情况：
select a.sid,
   decode(a.type,
   'MR', 'Media Recovery',
   'RT', 'Redo Thread',
   'UN', 'User Name',
   'TX', 'Transaction',
   'TM', 'DML',
   'UL', 'PL/SQL User Lock',
   'DX', 'Distributed Xaction',
   'CF', 'Control File',
   'IS', 'Instance State',
   'FS', 'File Set',
   'IR', 'Instance Recovery',
   'ST', 'Disk Space Transaction',
   'IR', 'Instance Recovery',
   'ST', 'Disk Space Transaction',
   'TS', 'Temp Segment',
   'IV', 'Library Cache Invalidation',
   'LS', 'Log Start or Switch',
   'RW', 'Row Wait',
   'SQ', 'Sequence Number',
   'TE', 'Extend Table',
   'TT', 'Temp Table',
   a.type) lock_type,
   decode(a.lmode,
   0, 'None',           /* Mon Lock equivalent */
   1, 'Null',           /* N */
   2, 'Row-S (SS)',     /* L */
   3, 'Row-X (SX)',     /* R */
   4, 'Share',          /* S */
   5, 'S/Row-X (SSX)',  /* C */
   6, 'Exclusive',      /* X */
   to_char(a.lmode)) mode_held,
   decode(a.request,
   0, 'None',           /* Mon Lock equivalent */
   1, 'Null',           /* N */
   2, 'Row-S (SS)',     /* L */
   3, 'Row-X (SX)',     /* R */
   4, 'Share',          /* S */
   5, 'S/Row-X (SSX)',  /* C */
   6, 'Exclusive',      /* X */
   to_char(a.request)) mode_requested,
   a.ctime        lock_time,
   to_char(a.id1) lock_id1,
   c.object_name  lock_object_name,
   c.object_type  lock_object_type,
   to_char(a.id2) lock_id2
from v$lock a,dba_objects c
   where (id1,id2) in
     (select b.id1, b.id2 from v$lock b where b.id1=a.id1 and b.id2=a.id2 )
     and a.type in ('TX','TM')
     and a.id1=c.object_id(+);

--存在多个BLOCKER时，查出源头的BLOCKER：
SELECT *
  FROM V$LOCK
 WHERE SID IN (SELECT SID SESSION_ID
                 FROM V$LOCK
                WHERE BLOCK > 0
               MINUS
               SELECT W.SID SESSION_ID
                 FROM V$SESSION_WAIT W
                WHERE W.EVENT = 'enqueue');

--查看BLOCKER对应的SESSION的状态和等待事件：
SELECT S.SID,
       S.USERNAME,
       S.STATUS,
       W.EVENT,
       L.TYPE,
       L.ID1,
       L.ID2,
       L.LMODE,
       L.CTIME,
       L.BLOCK
    FROM V$SESSION S, V$SESSION_WAIT W, V$LOCK L
   WHERE S.SID = W.SID
    AND S.SID = L.SID
    AND L.BLOCK > 0;

--查出WAITER等待的记录行：
 --首先查出WAITER等待的资源：
 SELECT ROW_WAIT_OBJ# ,
       ROW_WAIT_FILE# ,
       ROW_WAIT_BLOCK# ,
       ROW_WAIT_ROW#
    FROM V$SESSION
    WHERE SID IN (SELECT DISTINCT SID FROM V$LOCK WHERE REQUEST > 0 )
    AND ROW_WAIT_OBJ# <> -1;
--再根据OBJECT_ID得出具体的对象属主和名称：
SELECT OWNER,OBJECT_NAME,OBJECT_TYPE FROM DBA_OBJECTS WHERE OBJECT_ID=< ROW_WAIT_OBJ#>
--根据以上得到的OBJECT_ID,FILE_ID,BLOCK_ID,ROW#，就构成标准的ROWID，查出记录行：
   SELECT *
  FROM < OWNER > . < OBJECT_NAME >
 WHERE ROWID = DBMS_ROWID.ROWID_CREATE(1,
                                       ROW_WAIT_OBJ#,
                                       ROW_WAIT_FILE#,
                                       ROW_WAIT_BLOCK#,
                                       ROW_WAIT_ROW#);
******************************************************************************************




*********************************有session调用package导致无法编译*********************************
--编译package被锁,可以查询v$access和v$session确定哪个用户在调用这个package
select b.sql_text text,a.sid sid ,a.serial# sria#,a.username username, c.type type,a.machine machine
from v$session a ,v$sqltext b ,v$access c
where c.object=upper('&OBJECT_NAME')
and c.type in ('TABLE','PACKAGE','PROCEDURE','FUNCTION','PACKAGE BODY')
and a.sid=c.sid
and b.address = a.sql_address
and b.hash_value = a.sql_hash_value
order by a.sid,a.serial#,b.piece;

--直接生成kill session脚本
select username,'alter system kill session '''||sid||','||serial#||''';' from v$session where sid in(
select distinct sid from v$access where object in
('&OBJECT_NAME')
)
***************************************************************************************************




*********************************分布式事务锁的处理*********************************
select a.local_tran_id,statu from dba_2pc_pending a where state='prepared';
处理：
rollback force '&LOCAL_TRAN_ID';
commit;
execute DBMS_TRANSACTION.PURGE_LOST_DB_ENTRY('&LOCAL_TRAN_ID');
commit;
************************************************************************************************





#######################################关于等待事件#######################################

*******************************************查询等待事件****************************************
select sw.seq#,
       sw.sid || ',' || s.serial# sids,
       s.username,
       sw.event,
       sw.P1,
       sw.p2,
       sw.p3,
       sw.wait_time "WAIT",
       sw.state,
       sw.seconds_in_wait sec,
       s.status,
       to_char(s.logon_time, 'dd/hh24:mi:ss') logon_time,
       s.MACHINE,
       s.TERMINAL,
       s.PROGRAM
       --,sa.SQL_TEXT
  from v$session s, v$session_wait sw
--,v$sqlarea sa
 where sw.sid = s.sid
   --and s.SQL_ADDRESS=sa.ADDRESS
   --and s.SQL_HASH_VALUE=sa.HASH_VALUE
   and s.username is not null
   and sw.event not like '%SQL*Net%'
   and sw.event not like 'PX Deq%'
   and sw.event not like 'rdbms ipc message'
 order by sw.event, s.username;
*************************************************************************************************




*********************************library cache pin等待事件的处理*********************************
在后台sys用户下执行：
select s.sid || ',' || s.serial# sid_serial,
       kglpnmod "mode held",
       kglpnreq "request"
  from sys.x$kglpn p, v$session s
 where p.kglpnuse = s.saddr
   and kglpnhdl = (select p1raw
                     from v$session_wait
                    where sid = &SID_IN_LIBRARY_CACHE_PIN);

或者：
select sid Holder ,KGLPNUSE Sesion , KGLPNMOD Held, KGLPNREQ Req
 from x$kglpn , v$session
 where KGLPNHDL in (select p1raw from v$session_wait
 where wait_time=0 and event like 'library%')
 and KGLPNMOD <> 0
 and v$session.saddr=x$kglpn.kglpnuse ;

或者：
 select sql_text from v$sqlarea
  where (v$sqlarea.address,v$sqlarea.hash_value)
      in (select sql_address,sql_hash_value from v$session where sid in (
 select sid
 from x$kglpn , v$session
 where KGLPNHDL in (select p1raw from v$session_wait
 where wait_time=0 and event like 'library%')
 and KGLPNMOD <> 0
 and v$session.saddr=x$kglpn.kglpnuse );

查到held>0 的sid，如果local=no ，请沟通是否可以kill掉这个进程
*************************************************************************************************




*********************************cache buffers chains等待事件的处理*********************************
查询等待事件的类型是否是latch free：
select sw.sid || ',' || s.serial# sids,
       s.username,
       sw.event,
       sw.P1,
       sw.p2,
       sw.p3,
       sw.p1raw,
       sw.wait_time "WAIT",
       sw.state,
       sw.seconds_in_wait sec,
       s.status,
       to_char(s.logon_time, 'dd/hh24:mi:ss') log_time
  from v$session s, v$session_wait sw
 where s.username is not null
   and sw.sid = s.sid
   and sw.event not like '%SQL*Net%'
   and sw.event not like 'PX Deq%'
 order by sw.event;

如果是latch free，则其中p2字段的值表示latch number，据此可以查出是什么原因引起的latch free：
select * from v$latchname where latch#=&P2;

如果等待的latch是cache buffers chains，则需要根据p1raw查出被争用的hot block和segment名称：
--在后台sys用户下执行，查找热块
select /*+ RULE */
       e.owner || '.' || e.segment_name segment_name,
       e.extent_id extent#,
       x.dbablk - e.block_id + 1 block#,
       x.tch,
       l.child#
  from sys.v$latch_children l, sys.x$bh x, sys.dba_extents e
 where x.hladdr = '&P1RAW'
   and e.file_id = x.file#
   and x.hladdr = l.addr
   and x.dbablk between e.block_id and e.block_id + e.blocks - 1
 order by x.tch desc;

column segment_name format a30
select distinct e.owner,e.segment_name,e.segment_type
from dba_extents e,
    (select * from (select addr,ts#,file#,dbarfil,dbablk,tch from x$bh order by tch desc )where rownum<11) b
    where e.relative_fno=b.dbarfil
    and e.block_id<=b.dbablk
    and e.block_id+e.blocks>b.dbablk;

--查找产生热块的sql：
column segment_name format a35
select /*+ rule */ hash_value,sql_text from v$sqltext
where (hash_value,address ) in (
   select a.hash_value,a.address from v$sqltext a ,
   (select distinct e.owner,e.segment_name,e.segment_type
    from dba_extents e,
    (select * from (select addr,ts#,file#,dbarfil,dbablk,tch from x$bh order by tch desc )where rownum<11) b
    where e.relative_fno=b.dbarfil
    and e.block_id<=b.dbablk
    and e.block_id+e.blocks>b.dbablk ) b
    where a.sql_text like '%'||b.segment_name||'%'
    and b.segment_type='TABLE')
    order by hash_value,address,piece;

找到latch holder所在session的sid和serial#，考虑是否可以kill掉，缓解数据库的压力：
--这个latchhold变化得非常快，每刷新一次都会变化
select a.username, a.sid, a.serial#, a.status, b.pid, b.laddr, b.name
  from v$session a, v$latchholder b
 where a.sid = b.sid;
***************************************************************************************************




*********************************db file sequential read等待事件的分析*********************************
--当等待事件为db file sequential read时，P1对应file_id，P2对应&block_id
--通过下面这个语句可以查询到正在等待什么对象
   select owner,segment_name,segment_type
   from dba_extents
   where file_id = &file_id
   and &block_id between block_id and block_id+blocks-1;
*******************************************************************************************************




*********************************db file scattered read等待事件的分析*********************************
--当等待事件是db file scattered read时，用以下语句检查执行计划：
   select hash_value,child_number,
   lpad(' ',2*depth)||operation||' '||options||decode(id,0,substr(optimizer,1,6)||' Cost='||to_char(cost)) operation,
   object_name object,cost,cardinality,round(bytes/1024) kbytes
   from v$sql_plan
   where hash_value in
   (select a.sql_hash_value from v$session a,v$session_wait b
   where a.sid=b.sid
   and b.event='db file scattered read')
   order by hash_value,child_number,id;
*******************************************************************************************************









#############################################关于trace和event#############################################

*********************************设置trace和event*********************************
--设置autotrace
set autotrace on
SET AUTOT[RACE] {OFF | ON | TRACE[ONLY] } [EXP[LAIN]] [STAT[ISTICS] ]

--设置sql trace
alter session set sql_trace=true;    --my session
execute dbms_system.set_sql_trace_in_session(&SID,&SERIAL#,true);  --other session

--设置10046 event
Alter session set events '10046 trace name context forever,level 12';  --my session
alter session set events '10046 trace name context off';   --close

Exec dbms_system.set_ev(&SID,&SERIAL#,10046,12,'');  --open  other session
Exec dbms_system.set_ev(&SID,&SERIAL#,10046,0,'');   --close other session

ALTER SYSTEM SET EVENTS='10046 trace name context forever, level 4' SCOPE=spfile;  --system level
**********************************************************************************




*********************************查询audit审计记录*********************************
查看数据表修改的审计记录
Select * from dba_audit_object where obj_name='&OBJ_NAME';

查看用户登陆的审计记录
Select * from dba_audit_session where username='&USERNAME';

查看审计策略
SELECT * FROM DBA_STMT_AUDIT_OPTS;

查询某段时间某用户的登陆记录
--conn dbqua@cmmrep
--如果是两周以前的数据，要到isw中心库取(DBQDATA.DBQC$SESSION_COLLECT)
Select SNAP_ID,
       SNAP_TIME,
       SID,
       SERIAL#,
       USERNAME,
       STATUS,
       MACHINE,
       PROGRAM,
       LOGON_TIME
  from dbq$session_detail
 where snap_time >= to_date('20071122', 'yyyymmdd')
   and snap_time < to_date('20071123', 'yyyymmdd')
   and username = 'EPRPNET'
 ORDER BY SNAP_ID;
***********************************************************************************




#####################################################关于监控巡检语句#####################################################

*********************************mon_long_session 长连接的session监控*********************************
select a.sid,
       a.serial#,
       a.machine,
       a.osuser,
       a.username,
       trunc(a.last_call_et / 60) last_call_et,
       to_char(a.LOGON_TIME, 'yyyymmdd hh24:mi:ss') logon_time,
       trunc((sysdate - a.logon_time) * 24 * 60) remain_time,
       b.sql_text SQL
  from v$session a, v$sqltext b
 where a.status = 'ACTIVE'
   and username not in ('SYS')
   and a.last_call_et / 60 >= 240
   and a.username <> 'CIF_AQ'
   and a.sql_address = b.address
   and a.username is not null
 order by a.username, a.last_call_et desc, a.sid, b.address, b.piece;
******************************************************************************************************




*********************************mon_rbs 占用大量回滚段的监控*********************************
select s.sid,
       s.serial#,
       s.machine,
       s.OSUSER,
       s.username,
       s.status,
       round(s.last_call_et / 60) "IDLE_Min",
       round((sysdate - to_date(t.start_time, 'mm/dd/yy hh24:mi:ss')) * 24 * 60) "Trans_Min",
       r.usn,
       round(r.RSSIZE / 1024 / 1024) rbssize_M,
       round(r.OPTSIZE / 1024 / 1024) optsize_M,
       s.logon_time,
       s.program,
       q.sql_text,
       q.hash_value
  FROM V$session s, V$transaction t, V$rollstat r,v$sqlarea q
 WHERE s.saddr = t.ses_addr
   AND t.xidusn = r.usn
   AND s.sql_address=q.address
   AND s.sql_hash_value=q.hash_value
   AND ((((r.curext = t.start_uext - 1) OR
       ((r.curext = r.extents - 1) AND t.start_uext = 0))
   and s.last_call_et /60 > 30
   and r.rssize>r.optsize
   and r.rssize > 50*1024*1024)
    or r.rssize >100*1024*1024)
 order by last_call_et desc;
**********************************************************************************************




*********************************mon_ckpt active redo log及其相关session和sql的监控*********************************
select status,count(*) from v$log where status in ('ACTIVE','CURRENT') group by status;
********************************************************************************************************************




*********************************mon_xatrans 分布式事务锁的监控*********************************
select a.local_tran_id,statu from dba_2pc_pending a where state='prepared';
处理：
rollback force '&LOCAL_TRAN_ID';
commit;
execute DBMS_TRANSACTION.PURGE_LOST_DB_ENTRY('&LOCAL_TRAN_ID');
commit;
************************************************************************************************




*********************************mon_swait 等待事件的监控*********************************
select sw.seq#,sw.sid||','||s.serial# sids,s.username,sw.event,sw.P1,sw.p2,sw.p3,sw.wait_time "WAIT",
   sw.state,sw.seconds_in_wait sec,s.status,to_char(s.logon_time,'dd/hh24:mi:ss') logon_time
   from v$session s,v$session_wait sw
   where
   sw.sid =s.sid
   and s.username is not null
   and sw.event not like '%SQL*Net%'
   and sw.event not like 'PX Deq%'
   and sw.event not like 'rdbms ipc message'
   and sw.event not like 'queue messages'
   order by sw.event,s.username ;
******************************************************************************************




*********************************mon_sqlarea 未使用绑定变量的sql监控*********************************
select substr(sql_text, 1, 50) "SQL", count(*) cnt, sum(sharable_mem) "TotExecs"
  FROM v$sqlarea
 WHERE executions =1
 GROUP BY substr(sql_text, 1, 50)
HAVING count(*) > 5000
 ORDER BY 2;
*****************************************************************************************************




*********************************mon_sharepool 占用大量内存的sql监控*********************************
select se.sid,se.SERIAL#,pr.SPID,se.osuser,se.MACHINE,sq.SHARABLE_MEM/1024/1024 ,se.PROGRAM,sq.SQL_TEXT
from v$sqlarea sq,v$session se,v$process pr
where se.PADDR=pr.ADDR
and ((se.SQL_ADDRESS=sq.ADDRESS and se.SQL_HASH_VALUE=sq.HASH_VALUE)
    or
    (se.PREV_SQL_ADDR=sq.ADDRESS and se.PREV_HASH_VALUE=sq.HASH_VALUE))
and sq.SHARABLE_MEM>20*1024*1024
order by sq.SHARABLE_MEM/1024/1024;
*****************************************************************************************************




*********************************mon_redo 产生大量redo log的session和sql监控*********************************
select se.username,
       se.sid,
       se.serial#,
       pr.spid,
       se.status,
       se.machine,
       se.osuser,
       round(st.value / 1024 / 1024) redosize,
       sa.sql_text
  from v$session se, v$sesstat st, v$sqlarea sa ,v$process pr
 where se.sid = st.sid
   and st.STATISTIC# =
       (select STATISTIC# from v$statname where NAME = 'redo size')
      and se.username is not null
   and st.value > 50 * 1024 * 1024
   and se.SQL_ADDRESS = sa.ADDRESS
   and se.SQL_HASH_VALUE = sa.HASH_VALUE
   and se.paddr=pr.addr
 order by redosize;
*************************************************************************************************************




*********************************mon_temp 占用大量temp表空间的session和sql监控*********************************
select su.extents, su.segtype, su.sqlhash, se.sid, se.serial#, se.last_call_et, se.username, se.machine ,sa.sql_text
 from v$sort_usage su, v$session se ,v$sqlarea sa
where su.session_addr=se.saddr
   and se.SQL_ADDRESS = sa.ADDRESS
   and se.SQL_HASH_VALUE = sa.HASH_VALUE
   and su.extents>10;

select su.segtype, sum(su.extents) from v$sort_usage su group by su.segtype;
***************************************************************************************************************





#################################关于数据库实例######################################

*********************************了解当前ASMM 自动调整的内存参数情况*********************************
column "Parameter" format a20 truncate
column size_m format 9999
select a.ksppinm "Parameter",
c.ksppstvl/1048576 size_m
from sys.x$ksppi a, sys.x$ksppcv b, sys.x$ksppsv c
where a.indx = b.indx and a.indx = c.indx
and a.ksppinm in ('__shared_pool_size','shared_pool_size','__large_pool_size','large_pool_size',
'__db_cache_size','db_cache_size','__streams_pool_size','streams_pool_size',
'__java_pool_size','java_pool_size','_kghdsidx_count','sga_target','sga_max')
/
*****************************************************************************************************






######################################操作类#######################################

#################################关于redo log、archive log、checkpoint######################################

*********************************加大（或减少）redo log尺寸的操作步骤*********************************
(1)查询哪个redo log可以drop
仅 ARCHIVED='YES' AND STATUS='INACTIVE'  的可以drop，这表示该redo log已经被归档且当前未使用。
未完成归档的，或者状态为ACTIVE和CURRENT的都不允许drop。
select * from v$log;

(2)删除旧的redo log
alter database drop logfile group 1;

(3)添加新size的redo log
alter database add logfile <'/paic/sx/ims/data/oradata/ims/redo07.log'> size 400m;

(4)检查v$log确认操作效果
select * from v$log;
******************************************************************************************************




#################################关于备份和恢复######################################

*********************************加快实例crash后的恢复速度***********************************
(1)由当前spfile文件生成新的参数文件，并在其中设置数据库参数：
   Parallel_execution_message_size=16384
   _parallel_min_message_pool=8192000

(2)关闭并重启数据库至 mount 状态
Shutdown abort
Startup mount;
recover database parallel 8;

(3)打开数据库
Alter database open;
*********************************************************************************************




*********************************redo log header corrupt处理方法***********************************
(1)查询redo log的情况，确定损坏的log group
select * from v$log;
select * from v$logfile;

(2)切换redo log，根据剩余可用的redo log，不要切换多次
alter system switch logfile;

(3)清掉已经坏的redo log
alter database clear unarchived logfile group <&损坏的log group>;
--检查结果
select * from v$log;

(4)重设log archive dest
alter system archive log all;
alter system set  log_archive_dest_1='LOCATION=/paic/hq/gccsu/log/gccsu';
--检查
select * from v$log;

(5)手工归档
alter system archive log all;

(6)重建损坏的logfile group 5
alter database drop logfile group <5需要修改>;
select * from v$logfile;
alter database add logfile '/paic/hq/gccsu/data/oradata/gccsu/redo11.log' size 100m;
**************************************************************************************************




*********************************recover命令：完全恢复***********************************
(1)确定需要恢复的数据文件
select file#,error,change# from v$recover_file;

(2)恢复还原的数据文件
Recover database;
*****************************************************************************************




*********************************recover命令：不完全恢复***********************************
--基于时间的恢复
Alter database recover until time '2002-01-04:09:07:10';
--基于SCN的恢复
Select * from v$log_history;  --根据sequence#和first_time确定change#
Alter database recover until change 8175667922546 using backup controlfile;
--基于取消的恢复
Alter database recover until cancel using backup controlfile;
*******************************************************************************************




*********************************recover命令：恢复数据文件或表空间***********************************
Alter database recover [from /path] datafile 5;
Alter database recover tablespace tools;
*****************************************************************************************************




#####################################################关于cbo统计信息#####################################################

*********************************快速恢复旧的统计信息 for 9i*********************************
(1)创建统计信息备份表（如果已有，则无需创建）
execute dbms_stats.create_stat_table(ownname => 'dbmgr',stattab => 'stat_bak_all');

(2)按备份现有的统计信息
execute dbms_stats.export_table_stats(ownname => 'PA18CLM',tabname => 'T_DISPATCH',stattab => 'stat_bak_all',statown => 'dbmgr',cascade => true);

(3)查出备份的最近一次统计信息收集的statid
select distinct statid from dbstats.stab__pa18clm where c1='T_DISPATCH';

(4)按statid恢复表的统计信息，同时失效现有的执行计划
execute dbms_stats.import_table_stats(ownname => 'pa18clm',tabname => 'T_DISPATCH',stattab => 'stab__pa18clm',statown => 'dbstats',cascade => true,no_invalidate => false,statid => '640--07-12-22 01:31');

(5)如果执行计划没有恢复，则按以上方法备份和恢复其它表的统计信息
execute dbms_stats.import_table_stats(ownname => 'pa18clm',tabname => 'T_DISPATCH_DETAIL',stattab => 'stab__pa18clm',statown => 'dbstats',cascade => true,no_invalidate => false,statid => '640--07-12-22 01:31');
*********************************************************************************************




*********************************快速恢复旧的统计信息 for 10g*********************************
(1)检查该table最近几次统计信息收集的信息
select owner,table_name,stats_update_time from dba_tab_stats_history where table_name ='SICS_INSCARD_CLIENT_INFO';
OWNER        TABLE_NAME                   STATS_UPDATE_TIME
---------- -------------------------  -------------------------------
SICSDATA    SICS_INSCARD_CLIENT_INFO   17-DEC-07 10.16.50.435300 PM +08:00
SICSDATA    SICS_INSCARD_CLIENT_INFO   18-DEC-07 01.47.32.624219 PM +08:00
SICSDATA    SICS_INSCARD_CLIENT_INFO   18-DEC-07 01.56.19.437726 PM +08:00
--其中STATS_UPDATE_TIME表示的是收集的时间和收集的ID(stat_id)

(2)要将该表的统计信息恢复到17号的状态
dbms_stats.restore_table_stats(ownname => 'SICSDATA',
                               tabname => 'SICS_INSCARD_CLIENT_INFO',
                               as_of_timestamp => '17-DEC-07 10.16.50.435300 PM +08:00',
                               no_invalidate => FALSE);
*********************************************************************************************




*********************************搜集统计信息 for 10g*********************************
--设置默认收集参数为不收集直方图：
execute dbms_stats.set_param('METHOD_OPT','FOR ALL COLUMNS SIZE 1');
select DBMS_STATS.GET_PARAM('METHOD_OPT') from dual;

--第一次使用手工收集统计信息：
execute dbms_stats.gather_database_stats(method_opt=>'FOR ALL COLUMNS SIZE 1');

--搜集schema的统计信息
exec dbms_stats.gather_schema_stats(ownname     => '&USERNAME',
                                    method_opt  => 'FOR ALL COLUMNS SIZE 1',
                                    degree      => 8,
                                    cascade     => TRUE );

--收集用户表（包括索引）的统计信息，同时设置为不收集直方图
exec DBMS_STATS.GATHER_TABLE_STATS(OWNNAME=>'&OWNER',TABNAME=>'&TABLE_NAME',METHOD_OPT=>'FOR ALL COLUMNS SIZE 1',NO_INVALIDATE=>FALSE,CASCADE=>TRUE);
--生成批次搜集的脚本
select 'exec dbms_stats.gather_table_stats(''' || owner || ''', ''' || table_name || ''', method_opt=>''FOR ALL COLUMNS SIZE 1'',NO_INVALIDATE=>FALSE,CASCADE=>TRUE);'
from dba_tables where owner not in ('SYS','SYSTEM');
**************************************************************************************




*********************************导入统计信息***************************************
已将luhz0的imsqueue.ims_output_queue_table的统计信息导入luzz0为例：

(1)  conn dbmgr@luhz0
exec dbms_stats.create_stat_table('DBMGR','EXP_STATS_TMP');

EXEC dbms_stats.export_table_stats(ownname => 'IMSQUEUE',tabname => 'IMS_OUTPUT_QUEUE_TABLE',stattab => 'EXP_STATS_TMP',cascade => TRUE,statown => 'DBMGR');

(2)  logon to luhz0.db.paic.com.cn
cd $HOME/tmp
exp dbmgr tables=EXP_STATS_TMP file=queue_stats_luhz0.dmp log=exp.log

(3)  logon to luzz0.db.paic.com.cn
cd $HOME/tmp
scp user@luhz0.db.paic.com.cn:/paic/hz/lbs/data/opluhz0/tmp/queue_stats_luhz0.dmp ./
imp dbmgr file=queue_stats_luhz0.dmp full=y log=imp.log

(4)  conn dbmgr@luzz0
select to_char(last_analyzed,'yyyy-mm-dd hh24:mi:ss') from dba_tab_statistics where owner='IMSQUEUE' and table_name='IMS_OUTPUT_QUEUE_TABLE';

exec dbms_stats.import_table_stats(ownname => 'IMSQUEUE',tabname => 'IMS_OUTPUT_QUEUE_TABLE',stattab => 'EXP_STATS_TMP',statown => 'DBMGR',cascade => TRUE,no_invalidate => FALSE,force => TRUE);

select to_char(last_analyzed,'yyyy-mm-dd hh24:mi:ss') from dba_tab_statistics where owner='IMSQUEUE' and table_name='IMS_OUTPUT_QUEUE_TABLE';

--是否锁定视情况而定：exec dbms_stats.lock_table_stats('IMSQUEUE','IMS_OUTPUT_QUEUE_TABLE');
**************************************************************************************






#################################################关于保留现场信息或oradebug#################################################

*********************************使用oradebug搜集现场信息***********************************
(1).	Systemstate dump
-	login sqlplus internal
-	oradebug setmypid
-	oradebug unlimit
-	oradebug dump systemstate 10
-	repeat 3 times with 5 minutes interval
(2).	Hang analyze
- 	login sqlplus internal
- 	oradebug setmypid
- 	oradebug unlimit
-	oradebug dump hanganalyze 10
(3).	errorstack dump
- 	login sqlplus internal
- 	oradebug setospid <suspected process>
- 	oradebug unlimit
-	oradebug dump errorstack 3
(4).	processstate dump
- 	login sqlplus internal
- 	oradebug setospid <suspected process>
- 	oradebug unlimit
-	oradebug dump processstate 10
**********************************************************************************************




*********************************使用rda搜集当前系统信息供GCS工程师分析问题***********************************
(1)获取rda工具并解压，可以从metalink下载，Doc ID:  Note:314422.1
unzip rda.zip
cd rda

(2)修改权限
chmod +x rda.sh

(3)初始化，需要提供dba权限的用户（能够用connect user_name AS SYSDBA连接数据库）
./rda.sh -S

(4)运行脚本，得到html的输出结果
./rda.sh -v
*************************************************************************************************************




****************采用OUTLN技术将正确的执行计划从其它环境如测试库导入到生产库************************************************************************************************************
以下操作务必在sqlplus工具中进行，不能在其它工具中进行。
1在生产库获得sql hash value，并且获取当前执行计划
2 找到有好的执行计划其它环境如测试库
3 如果没有好的执行计划需要想办法在其它环境制造出好的执行计划
1 在生产库获得该top sql的sql text
select sql_text ||to_char(length(sql_text)) sql_text from v$sqltext where hash_value=2092045661
order by piece;
SQL_TEXT
--------------------------------------------------------------------------------------------------------
  SELECT OB_RESULT_SEQ obResultSeq,rs.TASK_CODE taskCode,     rs64
.SPECIAL_CASE_CODE specialCaseCode,rs.DATA_SEQ dataSeq,     rs.Q64
UESTIONNAIRE_CODE questionnaireCode,to_char(rs.OB_DATE,'yyyy-mm-64
dd hh24:mi:ss') obDate ,     rs.OB_TSR obTsr,rs.OB_RESULT_STATE 64
obResultState,     rs.REJECT_REASON rejectReason,rs.REMARK remar64
k,rs.RECORD_NO recordNo,     rs.DATA_STATE dataState,rs.BEGIN_PR64
OCESS_TIME beginProcessTime,     rs.END_PROCESS_TIME endProcessT64
ime,rs.BEGIN_CALL_TIME beginCallTime,     rs.END_CALL_TIME endCa64
llTime,rs.OB_TEL obTel,     rs.OB_TEL_TYPE obTelType,rs.OB_TYPE 64
obType,rs.OB_TIMES obTimes ,           po.PARTY_NO partyNo ,sp.S64
PECIAL_CASE_NAME specialCaseName,      po.BATCH batch , po.TABLE64
_ID tableId , drs.state_name   FROM c_ob_result rs , c_obd_commo64
n_info po ,         c_special_case_info sp ,c_ob_data_result_tbl64
 drs          WHERE rs.data_seq = po.data_seq    AND rs.special_64
case_code = sp.special_case_code   AND rs.ob_result_state = drs.64
state_code          and     po.CLIENT_NO = :1                and64
     rs.ob_date > sysdate - :2               ORDER BY rs.ob_resu64
lt_seq desc   14

2 取到SQL后在UltraEdit中整理sql ：
去掉每行尾部长度的数字，从第2行开始复制每一行粘贴到第一行的末尾，把整个sql粘贴成一行，注意首尾空格绝对不能丢失，在sql尾部增加一个;分号。
  SELECT OB_RESULT_SEQ obResultSeq,rs.TASK_CODE taskCode,     rs.SPECIAL_CASE_CODE specialCaseCode,rs.DATA_SEQ dataSeq,     rs.QUESTIONNAIRE_CODE questionnaireCode,to_char(rs.OB_DATE,'yyyy-mm-dd hh24:mi:ss') obDate ,     rs.OB_TSR obTsr,rs.OB_RESULT_STATE obResultState,     rs.REJECT_REASON rejectReason,rs.REMARK remark,rs.RECORD_NO recordNo,     rs.DATA_STATE dataState,rs.BEGIN_PROCESS_TIME beginProcessTime,     rs.END_PROCESS_TIME endProcessTime,rs.BEGIN_CALL_TIME beginCallTime,     rs.END_CALL_TIME endCallTime,rs.OB_TEL obTel,     rs.OB_TEL_TYPE obTelType,rs.OB_TYPE obType,rs.OB_TIMES obTimes ,           po.PARTY_NO partyNo ,sp.SPECIAL_CASE_NAME specialCaseName,      po.BATCH batch , po.TABLE_ID tableId , drs.state_name   FROM c_ob_result rs , c_obd_common_info po ,         c_special_case_info sp ,c_ob_data_result_tbl drs          WHERE rs.data_seq = po.data_seq    AND rs.special_case_code = sp.special_case_code   AND rs.ob_result_state = drs.state_code          and     po.CLIENT_NO = :1                and     rs.ob_date > sysdate - :2               ORDER BY rs.ob_result_seq desc   ;

3 在其它环境如测试库中解锁outln用户并修改密码及授权
alter user outln identified by outln account unlock;
grant create any outline to outln;
grant drop any outline to outln;
grant all on plan_table to outln;
--如果没有plan_table，则以 sys 用户执行以下操作：
--@ /rdbms/admin/utlxplan.sql;
--create public synonym plan_table for plan_table;
--grant select ,insert, update, delete on plan_table to public;

4 在其它环境如测试库使用DBA角色用户dbmgr,dba实名,sys,system或表属主用户授权该SQL涉及到的所有表及视图的select权限给outln用户，例如：
grant select on icssobdata.c_ob_result to outln;
grant select on icssobdata.c_obd_common_info to outln;
grant select on icssobdata.c_special_case_info to outln;
grant select on icssobdata.c_ob_data_result_tbl to outln;

3 将整理出的SQL在其它环境如测试库确认执行计划是否是好的执行计划：
explain plan for 上面整理后的语句,举例：
explain plan for
  SELECT OB_RESULT_SEQ obResultSeq,rs.TASK_CODE taskCode,     rs.SPECIAL_CASE_CODE specialCaseCode,rs.DATA_SEQ dataSeq,     rs.QUESTIONNAIRE_CODE questionnaireCode,to_char(rs.OB_DATE,'yyyy-mm-dd hh24:mi:ss') obDate ,     rs.OB_TSR obTsr,rs.OB_RESULT_STATE obResultState,     rs.REJECT_REASON rejectReason,rs.REMARK remark,rs.RECORD_NO recordNo,     rs.DATA_STATE dataState,rs.BEGIN_PROCESS_TIME beginProcessTime,     rs.END_PROCESS_TIME endProcessTime,rs.BEGIN_CALL_TIME beginCallTime,     rs.END_CALL_TIME endCallTime,rs.OB_TEL obTel,     rs.OB_TEL_TYPE obTelType,rs.OB_TYPE obType,rs.OB_TIMES obTimes ,           po.PARTY_NO partyNo ,sp.SPECIAL_CASE_NAME specialCaseName,      po.BATCH batch , po.TABLE_ID tableId , drs.state_name   FROM c_ob_result rs , c_obd_common_info po ,         c_special_case_info sp ,c_ob_data_result_tbl drs          WHERE rs.data_seq = po.data_seq    AND rs.special_case_code = sp.special_case_code   AND rs.ob_result_state = drs.state_code          and     po.CLIENT_NO = :1                and     rs.ob_date > sysdate - :2               ORDER BY rs.ob_result_seq desc   ;
select * from table(dbms_xplan.display);

6 在有好的执行计划的其它环境如测试库创建outline ,如：
Create outline <outline名字stg_OB_RESULT_SEQ> for category special on
  SELECT OB_RESULT_SEQ obResultSeq,rs.TASK_CODE taskCode,     rs.SPECIAL_CASE_CODE specialCaseCode,rs.DATA_SEQ dataSeq,     rs.QUESTIONNAIRE_CODE questionnaireCode,to_char(rs.OB_DATE,'yyyy-mm-dd hh24:mi:ss') obDate ,     rs.OB_TSR obTsr,rs.OB_RESULT_STATE obResultState,     rs.REJECT_REASON rejectReason,rs.REMARK remark,rs.RECORD_NO recordNo,     rs.DATA_STATE dataState,rs.BEGIN_PROCESS_TIME beginProcessTime,     rs.END_PROCESS_TIME endProcessTime,rs.BEGIN_CALL_TIME beginCallTime,     rs.END_CALL_TIME endCallTime,rs.OB_TEL obTel,     rs.OB_TEL_TYPE obTelType,rs.OB_TYPE obType,rs.OB_TIMES obTimes ,           po.PARTY_NO partyNo ,sp.SPECIAL_CASE_NAME specialCaseName,      po.BATCH batch , po.TABLE_ID tableId , drs.state_name   FROM c_ob_result rs , c_obd_common_info po ,         c_special_case_info sp ,c_ob_data_result_tbl drs          WHERE rs.data_seq = po.data_seq    AND rs.special_case_code = sp.special_case_code   AND rs.ob_result_state = drs.state_code          and     po.CLIENT_NO = :1                and     rs.ob_date > sysdate - :2               ORDER BY rs.ob_result_seq desc   ;

7 在有好的执行计划的其它环境如测试库检查outline的sql 长度和sql文本
set long 10000
set pagesize 100
set linesize 120
select OL_NAME,TEXTLEN,SQL_TEXT from outln.ol$;
确认长度和文本是否正确（outline可能将SQL最前面的空格截掉，像这种情况可以忽略，长度为原长度减去被截去前面空格的大小）
例如上面sql 原长度为1102，创建outline后的长度为1100，前面两个空格被截去

STG_OB_RESULT_SEQ                    1100
SELECT OB_RESULT_SEQ obResultSeq,rs.TASK_CODE taskCode,     rs.SPECIAL_CASE_CODE
 specialCaseCode,rs.DATA_SEQ dataSeq,     rs.QUESTIONNAIRE_CODE questionnaireCod
e,to_char(rs.OB_DATE,'yyyy-mm-dd hh24:mi:ss') obDate ,     rs.OB_TSR obTsr,rs.OB
_RESULT_STATE obResultState,     rs.REJECT_REASON rejectReason,rs.REMARK remark,
rs.RECORD_NO recordNo,     rs.DATA_STATE dataState,rs.BEGIN_PROCESS_TIME beginPr
ocessTime,     rs.END_PROCESS_TIME endProcessTime,rs.BEGIN_CALL_TIME beginCallTi
me,     rs.END_CALL_TIME endCallTime,rs.OB_TEL obTel,     rs.OB_TEL_TYPE obTelTy
pe,rs.OB_TYPE obType,rs.OB_TIMES obTimes ,           po.PARTY_NO partyNo ,sp.SPE
CIAL_CASE_NAME specialCaseName,      po.BATCH batch , po.TABLE_ID tableId , drs.
state_name   FROM c_ob_result rs , c_obd_common_info po ,         c_special_case
_info sp ,c_ob_data_result_tbl drs          WHERE rs.data_seq = po.data_seq    A
ND rs.special_case_code = sp.special_case_code   AND rs.ob_result_state = drs.st
ate_code          and     po.CLIENT_NO = :1                and     rs.ob_date >
sysdate - :2               ORDER BY rs.ob_result_seq desc


8 在其它环境如测试库exp出outline
exp outln/outln owner=outln file=ol.dmp log=ol_exp.log

9 在生产库将导出的dmp文件scp从测试库取到生产库主机
scp padba@

3 在生产库解锁outln用户并修改密码
alter user outln identified by outln account unlock;


10 在生产库imp outline (8i是两个表ol$ ol$hints，9i是三个表)
imp outln/outln file=ol.dmp full=y ignore=y log=ol_imp.log

11 在生产库启用outline
exec dbms_outln.update_signatures;
alter system set use_stored_outlines=special;


12 在生产库检查执行计划：
explain plan for 上面整理后的语句。
explain plan for
  SELECT OB_RESULT_SEQ obResultSeq,rs.TASK_CODE taskCode,     rs.SPECIAL_CASE_CODE specialCaseCode,rs.DATA_SEQ dataSeq,     rs.QUESTIONNAIRE_CODE questionnaireCode,to_char(rs.OB_DATE,'yyyy-mm-dd hh24:mi:ss') obDate ,     rs.OB_TSR obTsr,rs.OB_RESULT_STATE obResultState,     rs.REJECT_REASON rejectReason,rs.REMARK remark,rs.RECORD_NO recordNo,     rs.DATA_STATE dataState,rs.BEGIN_PROCESS_TIME beginProcessTime,     rs.END_PROCESS_TIME endProcessTime,rs.BEGIN_CALL_TIME beginCallTime,     rs.END_CALL_TIME endCallTime,rs.OB_TEL obTel,     rs.OB_TEL_TYPE obTelType,rs.OB_TYPE obType,rs.OB_TIMES obTimes ,           po.PARTY_NO partyNo ,sp.SPECIAL_CASE_NAME specialCaseName,      po.BATCH batch , po.TABLE_ID tableId , drs.state_name   FROM c_ob_result rs , c_obd_common_info po ,         c_special_case_info sp ,c_ob_data_result_tbl drs          WHERE rs.data_seq = po.data_seq    AND rs.special_case_code = sp.special_case_code   AND rs.ob_result_state = drs.state_code          and     po.CLIENT_NO = :1                and     rs.ob_date > sysdate - :2               ORDER BY rs.ob_result_seq desc   ;
select * from table(dbms_xplan.display);
执行计划应该正常

13 在生产库kill还在使用原执行计划的session，以便使用新计划

14 在生产库和测试库修改outln密码成复杂密码并锁定outln用户
alter user outln  identified by <密码> account lock;


######################################操作系统类#######################################


#################################关于主机资源消耗#################################

*********************************CPU使用情况***********************************
top或glance
或
sar -u 5 1000
u:    about CPU
5:    以秒为单位的测量周期
1000: 测量周期中重复测量的次数

输出结果：
11:32:42    %usr    %sys    %wio   %idle
11:32:47       4       3       0      93
11:32:53       5       5       0      91

解释：
%usr:    指用户进程使用的CPU比例，包括oracle的用户
%sys:    指操作系统完成自己的工作（切换、中断等）使用的CPU比例
%wio:    为特定进程的度量，这些进程当前正使用CPU却在等待IO请求服务
%idle:   CPU空闲率

%sys和%wio应该小于10%到15%

是否CPU空闲率为0%的系统存在CPU瓶颈？要看有多少进程在等待CPU，只要CPU的平均可执行队列小于2*CPU数目，则CPU空闲率0%是可以接受的。
可以使用sar -q 5 1000测定系统上的可执行队列
*******************************************************************************




*******************************设备使用情况************************************
top或glance
或
sar -d 5 1000
iostat

输出结果：
11:41:44   device        %busy   avque   r+w/s  blks/s  avwait  avserv
11:41:49   md10              0     0.0       0       0     0.0     0.0
           md11              0     0.0       0       0     0.0     0.0

解释：
device:    设备名
%busy：    设备繁忙程度，最好低于60%
avque：    设备队列的平均长度
r+w/s:     每秒读出+写入数
blks/s:    每秒传输的块数(以512b的块计量)
avwait：   五秒周期内每个I/O操作的平均等待时间，以毫秒为单位
avserv:    服务I/O操作所用的平均时间
*******************************************************************************




*******************************虚拟内存使用情况**********************************
vmstat -S 5 1000

输出结果：
 kthr      memory            page            disk          faults      cpu
 r b w   swap  free  si  so pi po fr de sr m1 m1 m1 m2   in   sy   cs us sy id
 0 0 0 65706952 19722504 0 0 729 272 271 0 0 1 1  1  0  992 29474 2978 1  1 98
 0 0 0 60526056 12733720 0 0 35324 0 0 0 0  0  0  0  0 1591 6047 3225  3  2 96

解释：
kthr(r b w):    r指出执行队列中的进程（等待使用CPU执行）
                b指出被诸如I/O、分页等资源阻塞的进程
                w指出可执行单当前正交换（可能处于内存极为缺乏）的进程
memory(swap free):    swap以K字节指出当前可用的交换空间量
                      free以K字节指出内存自由表的大小
page(si so pi po fr de sr):    si和so指出换入和换出内存K字节数
                               pi和po指出调入页和调出页的内存K字节数
                               fr指出空闲的K字节数
                               de以K字节指出预期的短期内存不足
                               sr指出以时钟算法扫描的页面（以页面尺寸设置大小）数
disk(m1 m1 m1 m2):    最多提供四个值得注意的设备信息。这些数指出每秒I/O操作的数据。不是很有用，可从sar -d得到更好的信息
faults(in sy cs):     in指出设备终端的数目
                      sy指出系统调用的数目
                      cs指出CPU环境切换的数目
cpu(us sy id):        us指出用户进程使用时间的百分比
                      sy指出系统进程使用时间的百分比
                      id指出非当前使用时间的百分比（包括所有等待I/O数据）
*******************************************************************************





TNS-12533: TNS:illegal ADDRESS parameters
连接串配置有问题。

du -h -d / | egrep '[0-9]G'






回滚段的分配和使用
1 select segment_id,setgment_name from dba_rollback_segs;
2 要指定事务使用某个回滚段：
set transaction use rollback segment rbs6;


CBO (cost-based optimizer)可使用数据值的histogram 来对列数据的分布有精确的估计。Histograms 在数据为skew 时，提高了选择性的估计，从而对非均一的数据分布产生较优的执行计划。
CBO 的一个基本任务为决定查询中出现的predicates的选择性。选择性的估计为用于决定何时使用索引，及关联表的顺序。有些表的列并不是均一分布的。CBO使用特定的列上的 height-based histograms来描述非均一分布的列的数据分布。对于一个height-based histogram, 列值按照使得每个band包含有大约相同数目的值的方式将列值分入band 中。因而，histogram提供的有用的信息为值的endpoints 的范围。
Histograms 可能影响性能，因而应仅用于当其将充分地改进查询的执行计划时。由于histogram 统计数据是永久存放的，因而，保留该数据所需的空间取决于sample尺寸。通常，应对具有高度skewed 数据分布的，在where 子句中频繁使用的列收集histograms。对于均一分布的数据，CBO可以在不使用histogram 的情况下，对其执行成本有相当精确的估计。
Histograms, 象其它优化器统计一样，是静态的。它们仅当其反映一列的当前数据分布时才有用。 (只要列的分布保持不变，列的数据可以变化。) 若列的数据分布频繁地改变，则你必须频繁地重计算其histogram。
Histograms 对以下特征的列用处不大：
列的所有predicates 使用bind变量(这项在9i中随着bind peeking 技术的引入，而可以利用histograms 了)
列数据为均一的分布的
列数据为唯一的且仅用在equality predicates 中。
使用DBMS_STATS 包来收集histograms。 你可以为表或分区的列收集histograms。如，以下语句将为scott 用户的emp 表的 SAL 列创建一个 10-bucket 的histogram：
EXECUTE DBMS_STATS.GATHER_TABLE_STATS
('scott','emp', METHOD_OPT => 'FOR COLUMNS SIZE 10 sal');
SIZE 关键字定义该histogram 的最大 bucket 数。若大量的雇员有相同的salary，而仅有少量的雇员有不同的salary时，你应为SAL 列创建 histogram。
Oracle 公司建议使用DBMS_STATS 包的 SIZE AUTO来让数据库自动决定使用多少buckets 来收集各列的histograms。


./mysqld --defaults-file=/paic/t0fusion/rdbms/mysql/5.6/my.cnf --skip-grant-tables

./mysqld --defaults-file=/paic/t0fusion/rdbms/mysql/5.6/my.cnf &

mysql -u root --protocol=tcp -P 3306 -p


mysql> Grant select,insert, update, delete on fusion.* to pa18shopcctjs@'%' IDENTIFIED BY 'ppaa1122';

update mysql.user set password=password('ppaa1122') where User="pa18shopcctjs" and Host="%";

delete from mysql.user  where user is NULL
UPDATE mysql.user SET Password=PASSWORD('mysql') where USER='root' and host='cnsz131026' ;

 FLUSH PRIVILEGES;

set password for 'root'@'localhost'=password('');
flush privileges;


cnsh043154:t0gsch >mysql -uroot
ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)
cnsh043154:t0gsch >mysql -uroot --socket=/paic/mydat/3900/var/mysql.sock
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 1
Server version: 5.6.16-enterprise-commercial-advanced-log MySQL Enterprise Server - Advanced Edition (Commercial)

Copyright (c) 2000, 2014, Oracle and/or its affiliates. All rights reserved.

Oracle is a registere
熊浪(xionglang619)   2014-04-04 19:40:15
知道怎么不加socket登陆么？
董魁锋(dongkuifeng611)   2014-04-04 19:34:10
mysql -u root --protocol=tcp -P 3960 -p
熊浪(xionglang619)   2014-04-04 19:43:59
还有其他什么办法只用mysql -uroot -p就能登陆么？
熊浪(xionglang619)   2014-04-04 19:45:16
找到了。。把my.cnf copy一份到$MYSQL_HOME

insert优化

要想提高insert的速度，首先要知道什么影响insert慢，在执行insert的过程中产生redo和undo，要想提高insert的速度，在充分利用系统资源的条件下就要尽量减少insert产生的redo和undo，undo的大小没办法改变，但是我们可以改变redo的量。下面是提高insert方法。

1. 增加hint /*+ append */                                           --不用在高水位下查找可insert的空间，直接在高水位之上insert
2. 增加hint /*+ parallel(tab,4) */
   或者alter session enable/disable parallel dml;         ---充分利用系统硬件资源
3. alter table tablename nologging/logging               ----关闭表的log服务，减少redo产生
4. 如果业务允许的话，可以先删除索引，insert之后再重建.   ---减少在insert时维护索引的开销
5. 可以增加临时中间表                                                    ----减少此事务对undo的使用
6. 增大sort_area_size或PGA                                       ----增加排序空间，避免磁盘操作
7. 优化sql语句本身
8. pl/sql批处理                                                              ---化整为零，把大事务变成零散的小事务

说明：tb_order_detail_his ：7000W记录
      tb_order_detail     ：2000W记录

优化前：
INSERT INTO /*+ append */  tablename_his
SELECT *  FROM  tablename  PARTITION (TB_ORDER_DE_WAREID40) WHERE ID NOT IN (
SELECT tcc.id FROM  tablename  PARTITION (TB_ORDER_DE_WAREID40) tcc , tablename_his  tcch WHERE tcc.id=tcch.id
)

在做数据归档时，需要做大数据量的insert，对于insert内容少还是可以胜任的，可当要把200多万的数据归档，2个小时都没有成功，
于是对其优化改造，利用append，parallel,分批处理，nologging方法，使这个200W的数据归档在15分钟就完成


优化后：


通过 mod(tcc.id,10)把内容分10部分提交归档

INSERT INTO /*+ append */ tablename_his
SELECT  *  FROM tablename PARTITION (TB_ORDER_DE_WAREID40) tcc  WHERE  NOT EXISTS (
SELECT /*+ parallel(tcch,7) parallel(tcc,7) */ tcch.id FROM tablename_his tcch WHERE tcc.id=tcch.id
) AND mod(tcc.id,10)=9


---查询数据库隐含参数
SQL> select
  2    x.ksppinm  name,
  3    y.ksppstvl  value,
  4    y.ksppstdf  isdefault,
  5    decode(bitand(y.ksppstvf,7),1,'MODIFIED',4,'SYSTEM_MOD','FALSE')  ismod,
  6    decode(bitand(y.ksppstvf,2),2,'TRUE','FALSE')  isadj
  7  from
   sys.x$ksppi x,
   sys.x$ksppcv y  8    9
 10  where
 11    x.inst_id = userenv('Instance') and
 12    y.inst_id = userenv('Instance') and
 13    x.indx = y.indx and
  x.ksppinm like '%_&par%' 14
 15  order by
  translate(x.ksppinm, ' _', ' ')
/
 16   17  Enter value for par: nets
old  14:   x.ksppinm like '%_&par%'
new  14:   x.ksppinm like '%_nets%'


-------sqlldr

csv  ^M
终于发现我把文件中的内容放到在linux下新建的文件中，加载OK，但是看起内容一样的csv怎么改都不行，我就怀疑看起来一样的东西是不是隐藏了什么不为我察觉的差异。带着这个疑问上网搜索了一下，果然有人遇到相同的问题，隐藏的差异就是csv文件行末藏了回车符。在linux下查看对比：

[oracle@nathan-rhel5 ~]$ cat -v ldr_case2.csv
SMITH,CLEAK,3904^M
ALLEN,"SALER,M",2891^M
WARD,"SALER,""S""",3128^M
KING,PRESIDENT,2523^M
[oracle@nathan-rhel5 ~]$ cat -v ldr_case2.dat0
SMITH,CLEAK,3904
ALLEN,"SALER,M",2891
WARD,"SALER,""S""",3128
KING,PRESIDENT,2523

原来作祟的就是文件行末的^M啊！！！

把csv文件转一下格式：
[oracle@nathan-rhel5 ~]$ dos2unix ldr_case2.csv
dos2unix: converting file ldr_case2.csv to UNIX format ...
[oracle@nathan-rhel5 ~]$ cat -v ldr_case2.csv
SMITH,CLEAK,3904
ALLEN,"SALER,M",2891
WARD,"SALER,""S""",3128
KING,PRESIDENT,2523

然后再重新加载一次数据成功了：

在Linux下查看文件格式：

# file filename

# 20140304110001.csv: ISO-8859 text //不带有^M

# 20140304110002.csv: ISO-8859 text, with CRLF line terminators //带有^M

Windows下处理的文件就带有CRLF行终止符。

以下有几种处理方式:

1. vi命令行模式下输入

:%s/^M$//g # 去掉行尾的^M。
:%s/^M//g # 去掉所有的^M。
:%s/^M/[ctrl-v]+[enter]/g # 将^M替换成回车。
:%s/^M/\r/g # 将^M替换成回车。

2. 使用sed命令。和vi的用法相似：

# sed -e 's/^M/\n/g'  filename
注意：这里的“^M”要使用“CTRL-V CTRL-M”生成，而不是直接键入“^M”。

3. 使用命令

使用dos2unix命令，一般的*nix发布版本都带有这个小工具，即Windows - *nix文件转换。

格式: dos2unix filename

转换多个文件

格式：dos2unix file1 file2 file3 ….

上面转换文件的时候都会修改原来的文件，使用 -k参数，或者 -n参数可以不改变文件属性。

格式：dos2unix -n oldfile newfile //新建一个文件，保持源文件不变

格式：dos2unix -k filename //保持文件时间戳不变

同样工具提供了*nix - windows文件格式转换命令：unix2dos，参数同dos2unix。

*注："^M",需要使用Ctrl + V + Ctrl + M键入，而不是数字6上面的^+字母M。


(转)sqlldr常规应用 (总结篇) (2012-11-28 13:01:54)转载▼
标签： 杂谈	分类： oracle

load data
infile *                                              ---指定加载文件   *表示数据就在控制文件后面
into table bonus                            ---指定表名
fields terminated by ","                 ---指定区域分隔符就是逗号
(ename,job,sal)                            ---指定表的列名
begindata                                       ---仅当infile 指定*时有效
smith,cleak,3904
allen,salesman,2891
ward,salesman,3128
........
把上术文件保存成a.ctl文件，用如下命令就可以导入
sqlldr userid/pass control=a.ctl
一,要加载的文件不是以逗号作分隔
a,修改原始数据，将分隔符替换成逗号
b,修改控制文件,将fields terminated by 的值修改成实际的分隔符
二,要加载的数据中包含分隔符怎么办，如下表kkk.dat
smith,cleak,3904
allen,"salesman,"ak"",2891
ward,"salesman,M",3128
这个时候就要修改控制文件
load data
infile kkk.dat                                   ---指定加载文件   *表示数据就在控制文件后面
into table bonus                            ---指定表名
fields terminated by ","   optinonally enclosed by ' " '               ---指定区域分隔符就是逗号
(ename,job,sal)                            ---指定表的列名
optinonally enclosed by ' " ' 默认就是双引号,如果是其他的,把双引号更改就可以了
三,数据文件没有分隔符怎么办,是定长字符串kkk,dat
smith   cleak           3904
allen    salesman 2891
ward    salesman 3128
修改控制文件
load data
infile kkk.dat
truncate table bonus
(
ename position(1:5),                  position(1:5)指的是从第一个字符载止到第五个字符作为ename的值,绝对偏移量
job position(7:15),
sal position(17:20)
)
position(*+2:15) ,相对偏移量, 表示从上一个位置结束后偏移二个开始取字符,载止到实际第15个字符
position(*)char(9) 相对偏移量+类型和长度的优势在于,你只需要为第一列指定开始位置，其他的只需要指定列长度就可以了
四，数据文件中的列比要导入的表的列少,且空列又必须赋值
如bonus中多一列comm,并赋初始值0，则可以这么写
load data
infile kkk.dat
truncate table bonus
(
ename position(1:5),
job position(7:15),
sal position(17:20),
comm '0'
)
如果要输入特殊值,则可以用函数来解决
load data
infile kkk.dat
truncate table bonus
(
ename position(1:5),
job position(7:15),
sal position(17:20),
comm "substr(:sal,1,1)"      取sal值的第一列，并赋值给comm列
)
当然也可以用pl/sql编写自定义的函数来赋值
五，数据文件中的列比要导入的表中列多怎么办
a,将数据文件中多的列删除
b,采用过滤，或在控制文件中不录这列数据
load data
infile kkk.dat
truncate table bonus
(
ename position(1:5),
job position(7:15),
sal position(17:20),
tcol filler position(22:30) ,                       --tcol假设这列不录入,就过滤掉,或这行根本不出现在控制文件中
)
如果此时数据文件是以分隔符出现的则这样写
load data
infile kkk.dat
truncate table bonus
fields terminated by ","
(ename , job ,sal, tcol filler)
六,多个数据文件导同一张表,条件就是这些数据文件的格式要相同
load data
infile kkk.dat
infile kkk2.dat
infile kkk3.dat
truncate table bonus
fields terminated by ","
(ename , job ,sal )
七，同一个数据文件要导入不同的表
bon         smith         cleak        3904
bon         allen           saler         2891
mgr         king            tech           2543
mgr         smm     admd        3032
要把这里面的数据导到b和m表
load data
infile kkk.dat
discardfile ldr_case9.dsc
truncate
   into table b
    when tab='bon'                                    如果此处判断关键字有多个,只能用and,不能用or
(tab filler position(1:3),
ename position(5:9),
job position(*+1:18),
sal position(*+1)
)
into table m
when tab='mgr'
(tab filler position(1:3),
ename position(5:9),
job position(*+1:18),
sal position(*+1)
)
八,数据文件前n行不导入
sqlddr scott/scott control=ldr_case1.ctl skip=3   意思前三行不导入,从第四行工始
sqlddr scott/scott control=ldr_case1.ctl skip=3 load=6 前三行不导入，导入接下来的6行
九,要加载的数据中有换行符
手工指定的换行符,数据文件的换行符并不是标准的换行标志,而是用户自定义的一个标识字符或多个字符组成,
10, smith,sales amnager,this is amith,\nhe is a sales manager.
11, allen.w,tech manager,this is allen.w.\nhe is a tech manager.
16, blake,hr manager,this is blake.\nhe is a hr manager.
控制文件的写法
load data
infile ldr_case11_1.dat
truncate into table manager
fields terminated by ","
( mgrno,mname,job,
remark "replace(:remark,'\\n',chr(10))"
)
如果数据文件是定长字符呢.
smith   sales   manager   this is smith
he is a sales manager
allenw tech     manager this is allen w
he is a tech manager.
blake    hr         manager this is blake
he is a hr manager.
load data infile ldr_case11_2.dat "fix 68"     就是加载文件之前,先通过fix值属性指定每行的长度,这里每行68个字符包括换行符在内,
                                        到了指定长度就换行,不管中间有没有换行符，因此仅能用于定长字符串的数据文件,
                                        因为只有字符串定长,你才知道应该在infile处指定什么值
truncate into table manager
(
ename position(1:8),
job position(10:16),
zhiwei position(*+1:22),
remark position(*+1:65)
)
windows中换行实际上由二个字符组成,回车加换行 chr(13)+chr(10), linux/unix下只需一个字符chr(10)即可
char_string：普通字符,即标准的可见字符,
\n，表示换行, \t 表示行制表符, \f 表示换页 \v 表示列制表符 \r 表示回车
windows下用\r\n    linux/unix下用\n就可以了
行尾部换行标识例:
数据文件
10,smith,sales manager,this is smith.
he is a sales manager. |
11,allen.w,tech manager,this is allen.w.
he is a tech manager. |
控制文件
load data
infile ldr_case1_4.dat "str ' | \r\n"
truncate into table manager
fields terminated by ','
(mgrno,maname,job,remarek)
十,要导入大字段(lob类型)
1，数据保存在数据文件中
load data
infile ldr_case12_1.dat "str '|\r\n'"
truncate into table manager
fields terminated by "," optionally enclosed by '"',
(mgrno,mname,job,remark char(10000))
假定remark列有大量文本，就可以这么定义
2，数据文件保存在独立的文件中
SQL> create table lobtbl(
2 fileowner varchar2(30),
3 filename varchar2(200),
4 filesize number,
5 filedata clob,
6 create_date date);
数据文件如下 ldr_case12_2.dat
2009-03-17 09:43 154   junsansi   f:\oracle\script\ldr_case11_1.ctl
2009_03_17 09:44 189   junsansi   f:\oracle\script\ldr_case11_1.dat
2009_03_17 09:45 2,639 junsansi   f:\oracle\script\ldr_case11_4.log
控制文件如下
load date
infile ldr__case12_2.dat
truncate into table lobtbl
(create_date position(1:17) date 'yyyy-mm-dd hh24:mi',
filesize position(*+1:25) "to_number(:filesize, '99,999,999')",
fileowner position(*+1:34),
filename position(*+1) char(200) "substr(:FILENAME,INSTR(:FILENAME,'\\',-1)+1)",
filedata lobfile(filename) terminated by eof)

十一,某些字段有空值:
load data
infile ldr_case13.dat
truncate into table bonus
fields terminated by "," trailing nullcols
(ename,job,sal)
十二,大量数据的导入
sqlldr scott/scott control=ldr_object.ctl errors=10 rows=640
表示10行出错就跳出,每次加载640行.默认是64行
如果640行太大,日志信息里面有提示,这个时候就要修改bindsize参数,默认就是256k,我们将其修改为10m(
1024X1024X10=10485760)同时这一次将行提高到5000行.
这样会更快,
sqlldr control=ldr_object.ctl errors=10 rows=5000 bindsize=10485760
但还可以更快.
sqlldr scott/scott control=ldr_object.ctl direct=true;
但还可以更快
streamsize:直接路径加载默认读取全部记录, 因此不需要设置rows参数,读取到的数据处理后存入缓存区,即
streamsize参数,该参数为256k,这里加大到10mb
date_cache: 该参数指定一个转换后日期格式的缓存区,以条为单位,默认值1000条,即保存1000条转换后的日期格式,
由于我们要导入的数据中有日期格式,因此加大该参数到5000，以降低日期转换操作带来的开销.
sqlldr scott/tiger control=ldr_object.ctl direct=true streamsize=10485760 date_cache=5000


OPTIONS(BINDSIZE=8388608,READSIZE=8388608,ROWS=10000)
LOAD DATA
INFILE  'D:\Users\dongkuifeng611\Desktop\20131230\t_cch_detail.csv'
BADFILE 'D:\Users\dongkuifeng611\Desktop\20131230\t_cch_detail.bad'
DISCARDFILE  'D:\Users\dongkuifeng611\Desktop\20131230\t_cch_detail.dis'
insert into TABLE  PUB_TEST.T_CCH_DETAIL Fields TERMINATED BY ',' optionally enclosed by '"' (detail_id,paramid,type_code,type_name,unit_code,unit_name,cchd_cch_id,add_time DATE "YYYY-MM-DD HH24:MI:SS")


D:\Users\dongkuifeng611>sqlldr devmgr@testt1iocrp log='D:\Users\dongkuifeng611\Desktop\20131230\aaa.log'
D:\Users\dongkuifeng611>sqlldr devmgr@testt1iocrp control = D:\Users\dongkuifeng611\Desktop\20131230\t_cch_detail.ctl
口令:

oracle sqlldr控制文件模板

  1Sqlldr userid=lgone/tiger control=a.ctl
  2LOAD DATA
  3INFILE 't.dat' // 要导入的文件
  4// INFILE 'tt.date' // 导入多个文件
  5// INFILE * // 要导入的内容就在control文件里 下面的BEGINDATA后面就是导入的内容, *和't.dat'不能同时存在
  6
  7INTO TABLE table_name // 指定装入的表
  8BADFILE 'c:bad.txt' // 指定坏文件地址
  9
 10************* 以下是4种装入表的方式
 11APPEND // 原先的表有数据 就加在后面
 12// INSERT // 装载空表 如果原先的表有数据 sqlloader会停止 默认值
 13// REPLACE // 原先的表有数据 原先的数据会全部删除
 14// TRUNCATE // 指定的内容和replace的相同 会用truncate语句删除现存数据
 15
 16************* 指定的TERMINATED可以在表的开头 也可在表的内部字段部分
 17FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '"'
 18// 装载这种数据: 10,lg,"""lg""","lg,lg"
 19// 在表中结果: 10 lg "lg" lg,lg
 20// TERMINATED BY X '09' // 以十六进制格式 '09' 表示的
 21// TERMINATED BY WRITESPACE // 装载这种数据: 10 lg lg
 22
 23TRAILING NULLCOLS ************* 表的字段没有对应的值时允许为空
 24
 25************* 下面是表的字段
 26(
 27col_1 , col_2 ,col_filler FILLER // FILLER 关键字 此列的数值不会被装载
 28// 如: lg,lg,not 结果 lg lg
 29)
 30// 当没声明FIELDS TERMINATED BY ',' 时
 31// (
 32// col_1 [interger external] TERMINATED BY ',' ,
 33// col_2 [date "dd-mon-yyy"] TERMINATED BY ',' ,
 34// col_3 [char] TERMINATED BY ',' OPTIONALLY ENCLOSED BY 'lg'
 35// )
 36// 当没声明FIELDS TERMINATED BY ','用位置告诉字段装载数据
 37// (
 38// col_1 position(1:2),
 39// col_2 position(3:10),
 40// col_3 position(*:16), // 这个字段的开始位置在前一字段的结束位置
 41// col_4 position(1:16),
 42// col_5 position(3:10) char(8) // 指定字段的类型
 43// )
 44
 45BEGINDATA // 对应开始的 INFILE * 要导入的内容就在control文件里
 4610,Sql,what
 4720,lg,show
 48
 49=====================================================================================
 50/**///////////// 注意begindata后的数值前面不能有空格
 51
 521 ***** 普通装载
 53LOAD DATA
 54INFILE *
 55INTO TABLE DEPT
 56REPLACE
 57FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '"'
 58(DEPTNO,
 59DNAME,
 60LOC
 61)
 62BEGINDATA
 6310,Sales,"""USA"""
 6420,Accounting,"Virginia,USA"
 6530,Consulting,Virginia
 6640,Finance,Virginia
 6750,"Finance","",Virginia // loc 列将为空
 6860,"Finance",,Virginia // loc 列将为空
 69
 702 ***** FIELDS TERMINATED BY WHITESPACE 和 FIELDS TERMINATED BY x'09' 的情况
 71LOAD DATA
 72INFILE *
 73INTO TABLE DEPT
 74REPLACE
 75FIELDS TERMINATED BY WHITESPACE
 76-- FIELDS TERMINATED BY x'09'
 77(DEPTNO,
 78DNAME,
 79LOC
 80)
 81BEGINDATA
 8210 Sales Virginia
 83
 843 ***** 指定不装载那一列
 85LOAD DATA
 86INFILE *
 87INTO TABLE DEPT
 88REPLACE
 89FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '"'
 90( DEPTNO,
 91FILLER_1 FILLER, // 下面的 "Something Not To Be Loaded" 将不会被装载
 92DNAME,
 93LOC
 94)
 95BEGINDATA
 9620,Something Not To Be Loaded,Accounting,"Virginia,USA"
 97
 984 ***** position的列子
 99LOAD DATA
100INFILE *
101INTO TABLE DEPT
102REPLACE
103( DEPTNO position(1:2),
104DNAME position(*:16), // 这个字段的开始位置在前一字段的结束位置
105LOC position(*:29),
106ENTIRE_LINE position(1:29)
107)
108BEGINDATA
10910Accounting Virginia,USA
110
1115 ***** 使用函数 日期的一种表达 TRAILING NULLCOLS的使用
112LOAD DATA
113INFILE *
114INTO TABLE DEPT
115REPLACE
116FIELDS TERMINATED BY ','
117TRAILING NULLCOLS // 其实下面的ENTIRE_LINE在BEGINDATA后面的数据中是没有直接对应
118// 的列的值的 如果第一行改为 10,Sales,Virginia,1/5/2000,, 就不用TRAILING NULLCOLS了
119(DEPTNO,
120DNAME "upper(:dname)", // 使用函数
121LOC "upper(:loc)",
122LAST_UPDATED date 'dd/mm/yyyy', // 日期的一种表达方式 还有'dd-mon-yyyy' 等
123ENTIRE_LINE ":deptno||:dname||:loc||:last_updated"
124)
125BEGINDATA
12610,Sales,Virginia,1/5/2000
12720,Accounting,Virginia,21/6/1999
12830,Consulting,Virginia,5/1/2000
12940,Finance,Virginia,15/3/2001
130
1316 ***** 使用自定义的函数 // 解决的时间问题
132create or replace
133my_to_date( p_string in varchar2 ) return date
134as
135type fmtArray is table of varchar2(25);
136
137l_fmts fmtArray := fmtArray( 'dd-mon-yyyy', 'dd-month-yyyy',
138'dd/mm/yyyy',
139'dd/mm/yyyy hh24:mi:ss' );
140l_return date;
141begin
142for i in 1 .. l_fmts.count
143loop
144begin
145l_return := to_date( p_string, l_fmts(i) );
146exception
147when others then null;
148end;
149EXIT when l_return is not null;
150end loop;
151
152if ( l_return is null )
153then
154l_return :=
155new_time( to_date('01011970','ddmmyyyy') + 1/24/60/60 *
156p_string, 'GMT', 'EST' );
157end if;
158
159return l_return;
160end;
161/
162
163LOAD DATA
164INFILE *
165INTO TABLE DEPT
166REPLACE
167FIELDS TERMINATED BY ','
168TRAILING NULLCOLS
169(DEPTNO,
170DNAME "upper(:dname)",
171LOC "upper(:loc)",
172LAST_UPDATED "my_to_date( :last_updated )" // 使用自定义的函数
173)
174BEGINDATA
17510,Sales,Virginia,01-april-2001
17620,Accounting,Virginia,13/04/2001
17730,Consulting,Virginia,14/04/2001 12:02:02
17840,Finance,Virginia,987268297
17950,Finance,Virginia,02-apr-2001
18060,Finance,Virginia,Not a date
181
1827 ***** 合并多行记录为一行记录
183LOAD DATA
184INFILE *
185concatenate 3 // 通过关键字concatenate 把几行的记录看成一行记录
186INTO TABLE DEPT
187replace
188FIELDS TERMINATED BY ','
189(DEPTNO,
190DNAME "upper(:dname)",
191LOC "upper(:loc)",
192LAST_UPDATED date 'dd/mm/yyyy'
193)
194BEGINDATA
19510,Sales, // 其实这3行看成一行 10,Sales,Virginia,1/5/2000
196Virginia,
1971/5/2000
198// 这列子用 continueif list="," 也可以
199告诉sqlldr在每行的末尾找逗号 找到逗号就把下一行附加到上一行
200
201LOAD DATA
202INFILE *
203continueif this(1:1) = '-' // 找每行的开始是否有连接字符 - 有就把下一行连接为一行
204// 如 -10,Sales,Virginia,
205// 1/5/2000 就是一行 10,Sales,Virginia,1/5/2000
206// 其中1:1 表示从第一行开始 并在第一行结束 还有continueif next 但continueif list最理想
207INTO TABLE DEPT
208replace
209FIELDS TERMINATED BY ','
210(DEPTNO,
211DNAME "upper(:dname)",
212LOC "upper(:loc)",
213LAST_UPDATED date 'dd/mm/yyyy'
214)
215BEGINDATA // 但是好象不能象右面的那样使用
216-10,Sales,Virginia, -10,Sales,Virginia,
2171/5/2000 1/5/2000
218-40, 40,Finance,Virginia,13/04/2001
219Finance,Virginia,13/04/2001
220
2218 ***** 载入每行的行号
222
223load data
224infile *
225into table t
226replace
227( seqno RECNUM //载入每行的行号
228text Position(1:1024))
229BEGINDATA
230fsdfasj //自动分配一行号给载入 表t 的seqno字段 此行为 1
231fasdjfasdfl // 此行为 2
232
2339 ***** 载入有换行符的数据
234注意: unix 和 windows 不同 & /n
235< 1 > 使用一个非换行符的字符
236LOAD DATA
237INFILE *
238INTO TABLE DEPT
239REPLACE
240FIELDS TERMINATED BY ','
241TRAILING NULLCOLS
242(DEPTNO,
243DNAME "upper(:dname)",
244LOC "upper(:loc)",
245LAST_UPDATED "my_to_date( :last_updated )",
246COMMENTS "replace(:comments,'n',chr(10))" // replace 的使用帮助转换换行符
247)
248BEGINDATA
24910,Sales,Virginia,01-april-2001,This is the SalesnOffice in Virginia
25020,Accounting,Virginia,13/04/2001,This is the AccountingnOffice in Virginia
25130,Consulting,Virginia,14/04/2001 12:02:02,This is the ConsultingnOffice in Virginia
25240,Finance,Virginia,987268297,This is the FinancenOffice in Virginia
253
254< 2 > 使用fix属性
255LOAD DATA
256INFILE demo17.dat "fix 101"
257INTO TABLE DEPT
258REPLACE
259FIELDS TERMINATED BY ','
260TRAILING NULLCOLS
261(DEPTNO,
262DNAME "upper(:dname)",
263LOC "upper(:loc)",
264LAST_UPDATED "my_to_date( :last_updated )",
265COMMENTS
266)
267demo17.dat
26810,Sales,Virginia,01-april-2001,This is the Sales
269Office in Virginia
27020,Accounting,Virginia,13/04/2001,This is the Accounting
271Office in Virginia
27230,Consulting,Virginia,14/04/2001 12:02:02,This is the Consulting
273Office in Virginia
27440,Finance,Virginia,987268297,This is the Finance
275Office in Virginia
276
277// 这样装载会把换行符装入数据库 下面的方法就不会 但要求数据的格式不同
278
279LOAD DATA
280INFILE demo18.dat "fix 101"
281INTO TABLE DEPT
282REPLACE
283FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '"'
284TRAILING NULLCOLS
285(DEPTNO,
286DNAME "upper(:dname)",
287LOC "upper(:loc)",
288LAST_UPDATED "my_to_date( :last_updated )",
289COMMENTS
290)
291demo18.dat
29210,Sales,Virginia,01-april-2001,"This is the Sales
293Office in Virginia"
29420,Accounting,Virginia,13/04/2001,"This is the Accounting
295Office in Virginia"
29630,Consulting,Virginia,14/04/2001 12:02:02,"This is the Consulting
297Office in Virginia"
29840,Finance,Virginia,987268297,"This is the Finance
299Office in Virginia"
300
301< 3 > 使用var属性
302LOAD DATA
303INFILE demo19.dat "var 3"
304// 3 告诉每个记录的前3个字节表示记录的长度 如第一个记录的 071 表示此记录有 71 个字节
305INTO TABLE DEPT
306REPLACE
307FIELDS TERMINATED BY ','
308TRAILING NULLCOLS
309(DEPTNO,
310DNAME "upper(:dname)",
311LOC "upper(:loc)",
312LAST_UPDATED "my_to_date( :last_updated )",
313COMMENTS
314)
315demo19.dat
31607110,Sales,Virginia,01-april-2001,This is the Sales
317Office in Virginia
31807820,Accounting,Virginia,13/04/2001,This is the Accounting
319Office in Virginia
32008730,Consulting,Virginia,14/04/2001 12:02:02,This is the Consulting
321Office in Virginia
32207140,Finance,Virginia,987268297,This is the Finance
323Office in Virginia
324
325< 4 > 使用str属性
326// 最灵活的一中 可定义一个新的行结尾符 win 回车换行 : chr(13)||chr(10)
327
328此列中记录是以 a|rn 结束的
329select utl_raw.cast_to_raw('|'||chr(13)||chr(10)) from dual;
330结果 7C0D0A
331
332LOAD DATA
333INFILE demo20.dat "str X'7C0D0A'"
334INTO TABLE DEPT
335REPLACE
336FIELDS TERMINATED BY ','
337TRAILING NULLCOLS
338(DEPTNO,
339DNAME "upper(:dname)",
340LOC "upper(:loc)",
341LAST_UPDATED "my_to_date( :last_updated )",
342COMMENTS
343)
344demo20.dat
34510,Sales,Virginia,01-april-2001,This is the Sales
346Office in Virginia|
34720,Accounting,Virginia,13/04/2001,This is the Accounting
348Office in Virginia|
34930,Consulting,Virginia,14/04/2001 12:02:02,This is the Consulting
350Office in Virginia|
35140,Finance,Virginia,987268297,This is the Finance
352Office in Virginia|
353
354==============================================================================
355象这样的数据 用 nullif 子句
356
35710-jan-200002350Flipper seemed unusually hungry today.
35810510-jan-200009945Spread over three meals.
359
360id position(1:3) nullif id=blanks // 这里可以是blanks 或者别的表达式
361// 下面是另一个列子 第一行的 1 在数据库中将成为 null
362LOAD DATA
363INFILE *
364INTO TABLE T
365REPLACE
366(n position(1:2) integer external nullif n='1',
367v position(3:8)
368)
369BEGINDATA
3701 10
37120lg
372------------------------------------------------------------

t1fls数据库执行pkg或dml脚本时会报如下错误，但脚本实际已经执行成功：
Error accessing PRODUCT_USER_PROFILE
Warning:Product user profile information not loaded!
You may need to run PUPBLD.SQL as SYSTEM

 以system用户进去然后运行$oracle_home/sqlplus/admin/pupbld.sql就可以了


 查看package body的权限
 grant create any procedure to username;
 grant alter any procedure to username;

phenomenon
startup
ORA-00444: background process “MMAN” failed while starting
ORA-07446: sdnfy: bad value ” for parameter .
Problem
The path to bdump,adump or udump does not exist. Oracle itself does not create any path if a path does not exist. So, you have to change the value of user_dump_dest in the initialize parameter.
Solution
If you use pfile to start your database then edit the pfile with any editor (for example vi on unix) and either change the location of user_dump_dest or remove the parameter user_dump_dest from pfile. And then perform. startup.



connect by
[例1]
创建一个部门表，这个表有三个字段，分别对应部门ID，部门名称，以及上级部门ID

 
1
2
3
4
5
6
7
8 -- Create table
create table DEP
(
  DEPID      number(10) not null,
  DEPNAME    varchar2(256),
  UPPERDEPID number(10)
)
;
初始化一些数据


23 SQL> INSERT INTO DEP(DEPID, DEPNAME, UPPERDEPID) VALUES (0, '总经办', null);
1 row inserted

SQL> INSERT INTO DEP(DEPID, DEPNAME, UPPERDEPID) VALUES (1, '开发部', 0);
1 row inserted

SQL> INSERT INTO DEP(DEPID, DEPNAME, UPPERDEPID) VALUES (2, '测试部', 0);
1 row inserted

SQL> INSERT INTO DEP(DEPID, DEPNAME, UPPERDEPID) VALUES (3, 'Sever开发部', 1);
1 row inserted

SQL> INSERT INTO DEP(DEPID, DEPNAME, UPPERDEPID) VALUES (4, 'Client开发部', 1);
1 row inserted

SQL> INSERT INTO DEP(DEPID, DEPNAME, UPPERDEPID) VALUES (5, 'TA测试部', 2);
1 row inserted

SQL> INSERT INTO DEP(DEPID, DEPNAME, UPPERDEPID) VALUES (6, '项目测试部', 2);
1 row inserted

SQL> commit;
Commit complete

13 SQL> SELECT * FROM DEP;

      DEPID DEPNAME                                                                           UPPERDEPID
----------- -------------------------------------------------------------------------------- -----------
          0 General Deparment
          1 Development                                                                                0
          2 QA                                                                                         0
          3 Server Development                                                                         1
          4 Client Development                                                                         1
          5 TA                                                                                         2
          6 Porject QA                                                                                 2

7 rows selected
现在我要根据“CONNECT BY”来实现树状查询结果


20 SQL> SELECT RPAD( ' ', 2*(LEVEL-1), '-' ) || DEPNAME "DEPNAME",
CONNECT_BY_ROOT DEPNAME "ROOT",
CONNECT_BY_ISLEAF "ISLEAF",
LEVEL ,
SYS_CONNECT_BY_PATH(DEPNAME, '/') "PATH"
FROM DEP
START WITH UPPERDEPID IS NULL
CONNECT BY PRIOR DEPID = UPPERDEPID;

DEPNAME                        ROOT                    ISLEAF      LEVEL PATH
------------------------------ ------------------- ---------- ---------- --------------------------------------------------------------------------------
General Deparment              General Deparment            0          1 /General Deparment
 -Development                  General Deparment            0          2 /General Deparment/Development
 ---Server Development         General Deparment            1          3 /General Deparment/Development/Server Development
 ---Client Development         General Deparment            1          3 /General Deparment/Development/Client Development
 -QA                           General Deparment            0          2 /General Deparment/QA
 ---TA                         General Deparment            1          3 /General Deparment/QA/TA
 ---Porject QA                 General Deparment            1          3 /General Deparment/QA/Porject QA

7 rows selected
说明：
1. CONNECT_BY_ROOT 返回当前节点的最顶端节点
2. CONNECT_BY_ISLEAF 判断是否为叶子节点，如果这个节点下面有子节点，则不为叶子节点
3. LEVEL 伪列表示节点深度
4. SYS_CONNECT_BY_PATH函数显示详细路径，并用“/”分隔

[例2]
通过CONNECT BY生成序列


16 SQL> SELECT ROWNUM FROM DUAL CONNECT BY ROWNUM <= 10;

    ROWNUM
----------
         1
         2
         3
         4
         5
         6
         7
         8
         9
        10

10 rows selected
[例3]
通过CONNECT BY用于十六进度转换为十进制


27 CREATE OR REPLACE FUNCTION f_hex_to_dec(p_str IN VARCHAR2) RETURN VARCHAR2 IS
    ----------------------------------------------------------------------------------------------------------------------
    -- 对象名称: f_hex_to_dec
    -- 对象描述: 十六进制转换十进制
    -- 输入参数: p_str 十六进制字符串
    -- 返回结果: 十进制字符串
    -- 测试用例: SELECT f_hex_to_dec('78A') FROM dual;
    ----------------------------------------------------------------------------------------------------------------------
    v_return  VARCHAR2(4000);
  BEGIN
    SELECT SUM(DATA) INTO v_return
      FROM (SELECT (CASE upper(substr(p_str, rownum, 1))
                     WHEN 'A' THEN '10'
                     WHEN 'B' THEN '11'
                     WHEN 'C' THEN '12'
                     WHEN 'D' THEN '13'
                     WHEN 'E' THEN '14'
                     WHEN 'F' THEN '15'
                     ELSE substr(p_str, rownum, 1)
                   END) * power(16, length(p_str) - rownum) DATA
              FROM dual
            CONNECT BY rownum <= length(p_str));
    RETURN v_return;
  EXCEPTION
    WHEN OTHERS THEN
      RETURN NULL;
  END;
说明：

1. CONNECT BY rownum <= length(p_str))对输入的字符串进行逐个遍历

2. 通过CASE语句，来解析十六进制中的A-F对应的10进制值


1.连接数与会话的关系
    在已建立的连接上,建立会话.
    1个process对应1个或者对于1个的session.
    Oracle的sessions和processes的关系是:
        sessions=1.1*processes + 5
2.查看process最大值
    在sqlplus中
        SQL> show parameter process;
    输出结果中的name的值为 processes这一行中,value的值就是oracle数据库支持的最大连接数.
    如果数据库上连接被占用完,新的连接过来时,会在客户端产生:"ORA-12519, TNS:no appropriate service handler found "的报错信息.
3.修改连接数的上限值
    SQL> alter system set processes=400 scope = spfile;
    这个是把process的最大数设置为400.设置完成后重启下数据库就行了.


z4ch2021:t0bishm > wget -c http://10.11.100.193/silent_install/devstg/all.tar
sh: wget:  not found.

这个是因为这个机器上wget 默认没有安装
直接到   主机：10.11.100.193 上把目录/paic/dba/dbsoft/home/dbsoft/silent_install/devstg 下的all.tar 拷贝到你机器上$HOME/ksjf/$ORACLE_SID/目录下即可。
   用户名密码：opdba/Paic1234(注：P是大写的）
谢谢~~





在linux或unix 中，一般使用tar 命令解压 tar压缩包，那么如何解压到指定目录呢？

以下提供两种方式：

方式一：使用shell 函数

脚本名： tar_target.sh

脚本内容：

#!/bin/sh
this_dir=`pwd`
target_dir="$2"
if [ ! -d "$target_dir" ];then
    mkdir -p "$target_dir"
fi
cd "$target_dir"
tar xf "$1"
cd $this_dir


该脚本有两个参数：tar压缩包路径    目标路径

例如要把/home/whuang/tar_study/test.tar 解压到 /tmp/whuang/ccc中：

sh tar_target.sh /home/whuang/tar_study/test.tar  /tmp/whuang/ccc


方式二：

tar -xjvf test.tar.bz2 -C ./test

-C 表示指定解压到指定目录，

注意：该目录必须已经存在。


然后一些其他的设置
set tabstop=4
set softtabstop=4
set shiftwidth=4
set autoindent
set cindent
set cinoptions={0,1s,t0,n-2,p2s,(03s,=.5s,>1s,=1s,:1s
set nu   //自动显示行号
set hlsearch  //搜索结果高亮显示


----查询文件号、对象号对应的对象、文件
select owner, segment_name, segment_type, tablespace_name from dba_extents
      where file_id = &file_id
        and &block_id between block_id and block_id + blocks - 1;

你可以用这个语句查询数据文件当前的状态。
当system表空间数据文件的status为0或8192，其他文件的status全为0时这个库的数据文件是一致的，可以打开。
seq#是当前scn所在的日志序列号。

set linesize 300 pagesize 999 numformat 999999999999999999999999999
select hxfil file#,fhsta status,fhscn scn ,fhrba_seq seq# from x$kcvfh;

让它恢复到指定的scn。
我选的是197743号日志的里的终点scn，这个scn需要到生产库的v$archived_log里查。
select next_change#,al.SEQUENCE# from v$archived_log al where al.SEQUENCE#>=197743

这次是运气比较好，这个scn的内容在197743号日志里就结束了，一个scn内的日志是可能存在于多个日志内的，如果是这样的话还需要从生产拷贝接下来的几个日志才能完成恢复。


RMAN> recover database until scn 9164574936046;

Starting recover at 2013-12-10 19:53:47
using channel ORA_DISK_1

starting media recovery

archive log thread 1 sequence 197743 is already on disk as file /paic/nj/lbs/log/slunj0/RLUNJ0/archivelog/2013_12_10/o1_mf_1_197743_9bdnv2lw_.arc
archive log filename=/paic/nj/lbs/log/slunj0/RLUNJ0/archivelog/2013_12_10/o1_mf_1_197743_9bdnv2lw_.arc thread=1 sequence=197743
media recovery complete, elapsed time: 00:02:53
Finished recover at 2013-12-10 19:56:47

RMAN>


还有个问题，刚才那些不一致的数据文件是怎么查出来并恢复的呀？  恢复到哪个点？。。



桂花宝典。。。以后注意检查。。
set wrap off
col name format a120
col checkpoint_change# format 999999999999999999999999999999
select checkpoint_change# from v$database;--system scn
select distinct checkpoint_change# from v$datafile;--datafile scn
select distinct checkpoint_change# from v$datafile_header;--start scn
select distinct last_change# from v$datafile;--end scn

--如果system scn和datafile scn、start scn不等，则需要介质恢复。但DG库一般都是system scn比datafile scn、start scn小
--如果end scn为空，则需要实例恢复

alter tablespace PAYDATA add datafile '/paic/t3pay/data01/oradata/paydata03.dbf'  size 100m  AUTOEXTEND ON NEXT 2M MAXSIZE 20000M;

CREATE TABLESPACE userdata02
 DATAFILE '/u01/oradata/userdata02.dbf' SIZE 5M
 AUTOEXTEND ON NEXT 2M MAXSIZE 200M;


 IMPORTANT: Set "_SYSTEM_TRIG_ENABLED=FALSE"
ORA-00604: error occurred at recursive SQL level 1
ORA-25153: Temporary Tablespace is Empty
ORA-06512: at "DBMGR.PRC_DDL_RESTRICTION", line 10

※   Oracle在线重定义—分区表改造

目标：需要将一个普通表在线转为按月分区表以提高查询效率

一、建立测试表
SQL> CREATE TABLE T(ID NUMBER ,TIME DATE);
Table created.

SQL> INSERT INTO T SELECT ROWNUM,CREATED FROM ALL_OBJECTS;
17979 rows created.

二、测试表是否可以在线重定义
SQL> EXEC DBMS_REDEFINITION.CAN_REDEF_TABLE('test','T', DBMS_REDEFINITION.CONS_USE_PK);
BEGIN DBMS_REDEFINITION.CAN_REDEF_TABLE('test','T', DBMS_REDEFINITION.CONS_USE_PK); END;
                                                    *
ERROR at line 1:
ORA-06550: line 1, column 53:
PLS-00201: identifier 'DBMS_REDEFINITION' must be declared
ORA-06550: line 1, column 7:
PL/SQL: Statement ignored
出错原因是没有赋予‘DBMS_REDEFINITION' 的执行权限。解决的办法是：
dba用户授予权限
SQL> GRANT ALL ON SYS.DBMS_REDEFINITION TO TEST;
Grant succeeded.

SQL>  GRANT CREATE ANY TABLE, ALTER ANY TABLE, DROP ANY TABLE, LOCK ANY TABLE, SELECT ANY TABLE TO TEST;
Grant succeeded.
回到test用户继续验证
SQL> EXEC DBMS_REDEFINITION.CAN_REDEF_TABLE('test', 'T', DBMS_REDEFINITION.CONS_USE_PK);
BEGIN DBMS_REDEFINITION.CAN_REDEF_TABLE('test', 'T', DBMS_REDEFINITION.CONS_USE_PK); END;

ERROR at line 1:
ORA-12089: cannot online redefine table "test"."T" with no primary key
ORA-06512: at "SYS.DBMS_REDEFINITION", line 137
ORA-06512: at "SYS.DBMS_REDEFINITION", line 1479
ORA-06512: at line 1
如果没有定义主键会提示以上错误信息
建立主键：
SQL> alter table t add constraint pk_t primary key(id);
Table altered.
再次验证成功
SQL> EXEC DBMS_REDEFINITION.CAN_REDEF_TABLE('test','T',DBMS_REDEFINITION.CONS_USE_PK);
PL/SQL procedure successfully completed.
三、建立中间表及分区
SQL> select to_char(min(time),'YYYY-MM-DD HH24:MI:SS') from t;
TO_CHAR(MIN(TIME),'
-------------------
2003-06-13 21:11:01

SQL> select to_char(max(time),'YYYY-MM-DD HH24:MI:SS') from t;
TO_CHAR(MAX(TIME),'
-------------------
2013-05-07 21:40:35

SQL> CREATE TABLE T_NEW (ID NUMBER PRIMARY KEY, TIME DATE) PARTITION BY RANGE (TIME)
  2       (PARTITION T_2003 VALUES LESS THAN (TO_DATE('2004-1-1', 'YYYY-MM-DD')),
  3       PARTITION T_2004 VALUES LESS THAN (TO_DATE('2005-1-1', 'YYYY-MM-DD')),
  4       PARTITION T_2005 VALUES LESS THAN (TO_DATE('2006-1-1', 'YYYY-MM-DD')),
  5       PARTITION T_2006 VALUES LESS THAN (TO_DATE('2007-1-1', 'YYYY-MM-DD')),
  6       PARTITION T_2007 VALUES LESS THAN (TO_DATE('2008-1-1', 'YYYY-MM-DD')),
  7      PARTITION T_2008 VALUES LESS THAN (TO_DATE('2009-1-1', 'YYYY-MM-DD')),
  8      PARTITION T_2009 VALUES LESS THAN (TO_DATE('2010-1-1', 'YYYY-MM-DD')),
  9      PARTITION T_2010 VALUES LESS THAN (TO_DATE('2011-1-1', 'YYYY-MM-DD')),
10      PARTITION T_2011 VALUES LESS THAN (TO_DATE('2012-1-1', 'YYYY-MM-DD')),
11      PARTITION T_2012 VALUES LESS THAN (TO_DATE('2013-1-1', 'YYYY-MM-DD')),
12      PARTITION T_2013 VALUES LESS THAN (TO_DATE('2014-1-1', 'YYYY-MM-DD')));
四、在线重新定义操作
SQL> exec dbms_redefinition.start_redef_table('TEST','T','T_NEW');
PL/SQL procedure successfully completed.
五、执行重定义后的分区数据同步
SQL>  exec dbms_redefinition.sync_interim_table('TEST','T','T_NEW');
PL/SQL procedure successfully completed.
六、完成在线重定义操作
SQL>  EXEC DBMS_REDEFINITION.FINISH_REDEF_TABLE('TEST','T','T_NEW');
PL/SQL procedure successfully completed.
注：如果执行在线重定义的过程中需回退，可以在执行dbms_redefinition.start_redef_table之后到执行dbms_redefinition.finish_redef_table之前的时间里执行：DBMS_REDEFINITION.abort_redef_table('test', 't', 't_new')以放弃执行在线重定义



此文将给出在使用Oracle临时表的过程中需要注意的事项，并对这些特点进行验证。
  ①临时表不支持物化视图
  ②可以在临时表上创建索引
  ③可以基于临时表创建视图
  ④临时表结构可被导出，但内容不可以被导出
  ⑤临时表通常是创建在用户的临时表空间中的，不同用户可以有自己的独立的临时表空间
  ⑥不同的session不可以互相访问对方的临时表数据
  ⑦临时表数据将不会上DML（Data Manipulation Language）锁


临时表：像普通表一样，有结构，但是对数据的管理上不一样，临时表存储事务或会话的中间结果集，临时表中保存的数据只对当前 会话可见，所有会话都看不到其他会话的数据，即使其他会话提交了，也看不到。临时表不存在并发行为，因为他们对于当前会话都是独立的。

创建临时表时，Oracle只创建了表的结构（在数据字典中定义），并没有初始化内存空间，当某一会话使用临时表时，ORALCE会从当前用户的 临时表空间分配一块内存空间。也就是说只有向临时表中插入数据时，才会给临时表分配存储空间。

临时表分事务级临时表和会话级临时表。
事务级临时表只对当前事务有效，通过语句：ON COMMIT DELETE ROWS 指定。
会话级临时表对当前会话有效，通过语句：ON COMMIT PRESERVE ROWS语句指定。

用法举例（在SCOTT模式下）：
CREATE GLOBAL TEMPORARY TABLE session_temp_tab ON COMMIT PRESERVE ROWS AS SELECT * FROM emp WHERE 1=2;
 ON COMMIT PRESERVE ROWS语句指定所创建的临时表是会话级临时表，当我们断开连接或手动执行DELETE或TRUNCATE之前，临时表中的数据一直存
 在，并且只有当前会话可以看到，其他会话看不到。

 CREATE GLOBAL TEMPORARY TABLE transaction_temp_tab ON COMMIT DELETE ROWS AS SELECT * FROM emp WHERE 1=2;
 ON COMMIT DELETE ROWS语句指定所创建的临时表是事务级临时表，当COMMIT或ROLLBACK之前，这些数据一直存在，当事务提交之后，表中数据自动清除。


insert into session_temp_tab select * from emp ;
insert into transaction_temp_tab select * from emp ;


 SQL> select count(*) from session_temp_tab ;

 COUNT(*)
----------
        14

 SQL> select count(*) from transaction_temp_tab ;

 COUNT(*)
----------
        14
SQL> commit;

 Commit complete

 SQL> select count(*) from session_temp_tab ;

 COUNT(*)
----------
        14

 SQL> select count(*) from transaction_temp_tab ;

 COUNT(*)
----------
        0


当COMMIT之后事务级临时表中的数据自动清除，所以再次查询的时候得到结果为0；
SQL> disconnect ;
Not logged on

 SQL> connect scott/tiger ;
Connected to Oracle Database 11g Enterprise Edition Release 11.1.0.6.0
Connected as scott

 SQL> select count(*) from transaction_temp_tab ;

 COUNT(*)
----------
        0

 SQL> select count(*) from session_temp_tab ;

 COUNT(*)
----------
        0
当断开之后重新连接之后，会话级临时表中的数据也被自动删除了。




在启动Open模式时，添加restrict关键字：startup restrict

设置或取消受限状态：alter system enable\disable restricted session;
alter system disable restricted session;

受限状态，当打开的数据库被设置为受限状态时，只有Create Session 和 Restricted Session系统权限 或者 具有SYSDBA  和 SYSPORE 系统权限的用户才能连接到数据库。但进入受限状态后，系统中仍然可能会存在活动的普通用户会话。

受限状态用途：

(1)执行数据导入或导出操作；

(2)暂时拒绝普通用户访问数据库；

(3)进行数据库移植或升级操作。

修改oracle用户密码使用 * 等特殊符号打头报错ORA-00988解决方法
===========================================================
作者: tolywang(http://tolywang.itpub.net)
发表于:2006.06.11 16:43
分类: Oracle数据库管理
出处：http://tolywang.itpub.net/post/48/113193
---------------------------------------------------------------

SQL> alter user cis identified by *cis_host;
alter user cis identified by *cis_host
*
ERROR at line 1:
ORA-00988: missing or invalid password(s)



---oracle数据库特殊密码：
ORA-00988: missing or invalid password(s)

SQL> alter user cis identified by '*cis_host' ;
alter user cis identified by '*cis_host'
*
ERROR at line 1:
ORA-00988: missing or invalid password(s)


alter user cis identified by "*cis_lhhost" ;


单引号也搞不定 。 还必须用双引号 。


cnsz081044: > more bk_full0814.sh
log_file=./full_backup_${ORACLE_SID}_`date '+%Y%m%d_%H%M%S'`.log
export log_file
rman target / << EOF > ${log_file} 2>&1
#sql 'alter system switch logfile';
run
{
allocate channel c1 type disk;
allocate channel c2 type disk;
allocate channel c3 type disk;
allocate channel c4 type disk;
allocate channel c5 type disk;
allocate channel c6 type disk;
allocate channel c7 type disk;
allocate channel c8 type disk;
BACKUP as compressed backupset full DATABASE FORMAT '/paic/hq/bk/restore/full_%T-%d-%u-%p' filesperset=10;
backup as copy current controlfile format '/paic/hq/bk/restore/ctrl_%t-%s-%p.f';
release channel c1;
release channel c2;
release channel c3;
release channel c4;
release channel c5;
release channel c6;
release channel c7;
release channel c8;
}
EOF
echo "Backup finished at `date '+%Y%m%d_%H%M%S'`" >> ${log_file}
cnsz081044: >


select * from dba_users where username='EGISINTF'
EGISINTF	1172	43680886BA963019
alter user EGISINTF identified by ppaa1122;
alter user EGISINTF identified by values '43680886BA963019';

select * from dba_db_links where db_link like '%EGISLINK%'
3	EGISINTF	EGISLINK.WORLD	GBSINTF	(description = (address = (protocol = tcp)(host = 10.31.9.12)(port = 1531)) (connect_data = (sid = t5egis)))	2013/2/21 15:53:08
drop database link   EGISLINK

create database link EGISLINK connect to GBSINTF identified by aaaa1111 using
'(description = (address = (protocol = tcp)(host = 10.31.9.12)(port = 1531)) (connect_data = (sid = t5egis)))'

进入#{i：数据库sid}数据文件等所在路径，删除相关文件.

若是10g以上版本，可执行下面操作删除：
sqlplus '/as sysdba'

startup nomount;

alter database mount exclusive;

alter system enable restricted session;

drop database;

 注意：

请保留库文件删除前后该卷的大小对比，并回复到该步骤里面。以便后面存储组可以看出下线库的数据文件确实被删除了。

示例脚本位置： $ORACLE_HOME/rdbms/admin/utlsampl.sql


SQL> alter table scott.test rename to scott.test1;
alter table scott.test rename to scott.test1
                                    *
ERROR 位于第 1 行:
ORA-14047: ALTER TABLE|INDEX RENAME 不可以与其它分区组合


SQL> alter table scott.test rename to test1;

表已更改。

我们来分析一下这个问题,当你执行alter table scott.test的时候,你已经告诉oracle你要修改哪个用户下的哪个表了,
所以在rename to 的时候就不需要在指定用户名称了.如果在写用户名的话,oracle也许会认为你是要把scott下的test表改名存储到其他用户下面去,oracle不允许这么做!


--改变job启动时间 ：
declare
  x number;
begin
  select job into x from dba_jobs
  where schema_user='EPCISJOB' and what='job_package.job_314;' and rownum=1;
  sys.dbms_job.change(job => x,
                      what => 'job_package.job_314;',
                      next_date => trunc(sysdate) + 20/24 + 13/(24*60),
                      interval => 'trunc(sysdate+1) + 02/24 + 00/(24*60)');
  commit;
  SYS.DBMS_OUTPUT.PUT_LINE('Job Number is: ' || to_char(x));
exception when others then
  rollback;
end;
/



登陆到monitor生产库查询
select * from dbmgr.sensitive_info_all_db where db_name=lower('&db_name')

col ins_name for a10;
col DBVERSION for a10;
col VIP for a16;
col PORT for a6;
col CATEGORY for a10;
col APP_CNNAME for a28;
col DB_LEVEL for a10;
col CHAR_SET for a10;
col DEV_DEPT for a16;
col SERVICE_USER for a18;
col DA for a10;
col DBA for a10;

select INSTANCE_NAME as ins_name,
       CATEGORY,
       APP_CNNAME,
       DB_LEVEL,
       DA,
       DB_PRIMARY_DBA DBA,
       DEV_DEPT,
       SERVICE_USER,
       VIP,
       PORT,
       DBVERSION,
       CHAR_SET
  from dbmon.database_info2
 where dbname = upper(trim('&1'));

今天遇到一个很奇怪的问题，job到点了不运行。
根据经验首先会想到job_queue_processes是否设置正确了，数据库显示正确。
SQL> show parameter job_queue_processes
NAME                                 TYPE                              VALUE
------------------------------------ --------------------------------- ------------------------------
job_queue_processes                  integer                           20
排除这个错误，是否job的状态为broken，查询了下也是不是。
程序的时间是否写错呢？
declare
job_name varchar2(100):='pacs_sync_user_info_job';
begin
sys.dbms_job.submit(job_name,
what => 'pacsdata.pacs_sync_user_info.sync_user_info;',
next_date => to_date('05-11-2013 14:20:00', 'dd-mm-yyyy hh24:mi:ss'),
interval => 'TRUNC(SYSDATE+1)+5/24');
commit;
end;
/
也没有任何问题。
程序是否还在继续跑没有结束呢？
检查了下也不是。
每一个job都无法定时执行，但是单独执行没有任何问题。
这是为啥呢？
主机上alert日志没有明显的报错。但是发现没有ora_j0**的进程。但是这个进程是怎么启动呢？
Metlink上查询下执行ora_j0**进程是有ora_cjq0进程管理的。The CJQ0 process is the one which processes the dba_jobs/dbms_scheduler_jobs.说明cjq0进程是管理job的进程，而j0**进程是job运行的进程。如果cjq0进程没有启动那么job是无法运行的。
所以如果job不运行还需要检查cjq0是否正常运行。

总结下：job为啥没有运行
1，	检查程序时间是否正确
2，	检查job是否还在运行
3，	检查参数job_queue_processes进程是否设置
4，	检查cjq0进程是否运行正常

下面是metlink上解决cjq0进程没有启动的方式：
Symptoms
Jobs (dba_jobs/dbms_scheduler_jobs) are not running at specified timestamp.
Checking makes it clear that CJQ0 process is not running.


Changes
The problem might have been introduced in pre-migrate/upgrade steps which have disabled scheduler.

Cause
The scheduler was disabled which implies that no CJQ0 process was started as part of database startup. The CJQ0 process is the one which processes the dba_jobs/dbms_scheduler_jobs.

Solution
1) Check if the scheduler is indeed disabled:

SQL>
connect / as sysdba
set pagesize 9999
select * from dba_objects where object_name='SCHEDULER_DISABLED';

-- In case a row as following is returned it implies that scheduler is disabled:

OWNER
------------------------------
OBJECT_NAME
--------------------------------------------------------------------------------
SUBOBJECT_NAME                 OBJECT_ID  DATA_OBJECT_ID OBJECT_TYPE
------------------------------ ---------- -------------- -------------------
CREATED   LAST_DDL_ TIMESTAMP           STATUS  T G S NAMESPACE
--------- --------- ------------------- ------- - - - ----------
EDITION_NAME
------------------------------
SYS
SCHEDULER_DISABLED
                                    71649                UNDEFINED
03-FEB-10 03-FEB-10 2010-02-03:10:29:55 VALID   N N N 51
2) Enable the scheduler:
SQL>
connect / as sysdba
set pagesize 9999
exec dbms_scheduler.set_scheduler_attribute('SCHEDULER_DISABLED','FALSE');Check if scheduler has been enabled:

SQL> select * from dba_objects where object_name='SCHEDULER_DISABLED';

no rows selectedAlso check the process on OS level, e.g.:

$> ps -ef|grep $ORACLE_SID|grep -i cjq0
oracle 14116 1 0 10:30   00:00:00 ora_cjq0_v111


Oracle Job不能正常运行的问题解决思路
1) Instance in RESTRICTED SESSIONS mode 

Check if the instance is in restricted sessions mode:

select instance_name,logins from v$instance;

If logins=RESTRICTED, then:

alter system disable restricted session;

^-- Checked!





2) JOB_QUEUE_PROCESSES=0

Make sure that job_queue_processes is > 0

show parameter job_queue_processes

^-- Checked!



3) _SYSTEM_TRIG_ENABLED=FALSE

Check if _system_enabled_trigger=false

col parameter format a25

col value format a15

select a.ksppinm parameter,b.ksppstvl value from x$ksppi a,x$ksppcv b

Where a.indx=b.indx and ksppinm=’_system_trig_enabled’;

^-- Checked!



4) Is the job BROKEN 

select job,broken from dba_jobs where job=<job_number>;

If broken, then check the alert log and trace files to diagnose the issue.

^-- Checked! The job is not broken.


5) Is the job COMMITted 

Make sure a commit is issued after submitting the job:

DECLARE X NUMBER;

BEGIN

SYS.DBMS_JOB.SUBMIT

(

job => X

,what => 'dbms_utility.analyze_schema

(''SCOTT'',''COMPUTE'',NULL,NULL,NULL);'

,next_date => to_date('08/06/200509:35:00','dd/mm/yyyy hh24:mi:ss')

,no_parse => FALSE

);

COMMIT;

END;

/

If the job executes fine if forced (i.e., exec dbms_jobs.run(<job_no>);), then likely a commit

is missing.

^-- Checked! The job is committed after submission.


6) UPTIME > 497 days

Check if the server (machine) has been up for more than 497 days:

For SUN , use 'uptime' OS command.

If uptime>497 and the jobs do not execute automatically, then you are hitting bug 3427424

(Jobs may stop running after 497 days uptime) which is fixed in 9206 and A102

^-- Checked! The server in this case has been up 126 days only


7) DBA_JOBS_RUNNING

Check dba_jobs_running to see if the job is still running:

select * from dba_jobs_running;

if the job is running,check the next two view v$access and v$locked_object to

find out what resources which the job is using are locking by other process.

^-- Checked! The job is not running.


8) LAST_DATE and NEXT_DATE

Check if the last_date and next_date for the job are proper:

select Job,Next_date,Last_date from dba_jobs where job=<job_number>;

^-- NEXT_DATE is porper, however LAST_DATE is null since the job never executes automatically.


9) NEXT_DATE and INTERVAL

Check if the Next_date is changing properly as per the interval set in dba_jobs:

select Job,Interval,Next_date,Last_date from dba_jobs where job=<job_number>;

^-- This is not possible since the job never gets executed automatically.


10) Toggle value for JOB_QUEUE_PROCESSES

Set job_queue_processes=0, wait some time and then and set it back to the original value:

alter system set job_queue_processes=0 ;

--<Wait for some time>

alter system set job_queue_processes=4 ;

Ref: Bug 2649244 (fixed by: 9015,9203,A000)

^-- Done but did not help


11) DBMS_IJOB(Non-documented):

Last ditch effort.

Either restart the database or try the following:

exec dbms_ijob.set_enabled(true);

Ref: Bug 3505718 (Closed, Not a Bug)

@Note 90989.1 (Using DBMS_IJOB) INTERNAL NOTE

Done but did not help

These are the most common causes for this behavior.

Solution

The solution ended up to be the server (machine) uptime.

Even though it was up for only 126 days, after the server was rebooted all jobs were able to execute automatically.



 To implement the solution, please execute the following steps:



1. Shutdown all applications, including databases.

2. Shutdown the server (machine)

3. Restart all applications, including databases.

4. Check that jobs are executing automatically.


一。job的运行频率设置

1.每天固定时间运行，比如早上8:10分钟：Trunc(Sysdate+1) + (8*60+10)/24*60

2.Toad中提供的：

每天：trunc(sysdate+1)

每周：trunc(sysdate+7)

每月：trunc(sysdate+30)

每个星期日：next_day(trunc(sysdate),'SUNDAY')

每天6点：trunc(sysdate+1)+6/24

半个小时：sysdate+30/1440

3.每个小时的第15分钟运行，比如：8:15，9:15，10:15...：trunc(sysdate,'hh')+75/1440。原先我设置的是trunc(sysdate,'hh')+15/1440，发现居然不行。

二。JOB为什么不运行？job运行 job不运行

1.先来了解一下JOB的参数说明：与job相关的参数一个是job_queue_processes，这个是运行JOB时候所起的进程数，当然系统里面JOB大于这个数值后，就会有排队等候的，最小值是0，表示不运行JOB，最大值是36，在OS上对应的进程时SNPn，9i以后OS上管理JOB的进程叫CJQn。可以使用下面这个SQL确定目前有几个SNP/CJQ在运行。

select * from v$bgprocess，这个paddr不为空的snp/cjq进程就是目前空闲的进程，有的表示正在工作的进程。

另外一个是job_queue_interval，范围在1--3600之间，单位是秒，这个是唤醒JOB的process，因为每次snp运行完他就休息了，需要定期唤醒他，这个值不能太小，太小会影响数据库的性能。

2.诊断：先确定上面这两个参数设置是否正确，特别是第一个参数，设置为0了，所有JOB就不会跑，确认无误后，我们继续向下。

3.使用下面的SQL察看JOB的的broken,last_date和next_date，last_date是指最近一次job运行成功的结束时间，next_date是根据设置的频率计算的下次执行时间，根据这个信息就可以判断JOB上次是否正常，还可以判断下次的时间对不对，SQL如下：

select * from dba_jobs

有时候我们发现他的next_date是4000年1月1日，说明job要不就是在running，要不就是状态是break(broken=Y)，如果发现JOB的broken值为Y，找用户了解一下，确定该JOB是否可以broken，如果不能broken，那就把broken值修改成N，修改再使用上面的SQL察看就发现他的last_date已经变了，JOB即可正常运行，修改broken状态的SQL如下：

declare

BEGIN

DBMS_JOB.BROKEN(<JOB_ID>,FALSE);

END;

4.使用下面的SQL查询是否JOB还在Running

select * from dba_jobs_running

如果发现JOB已经Run了很久了还没有结束，就要查原因了。一般的JOB running时会锁定相关的相关的资源，可以查看一下v$access和v$locked_object这两个view，如果发现其他进程锁定了与JOB相关的Object，包括PKG/Function/Procedure/Table等资源，那么就要把其他进程删除，有必要的话，把JOB的进程也删除，再重新跑看看结果。

5.如果上面都正常，但是JOB还不run，怎么办？那我们要考虑把JOB进程重启一次，防止是SNP进程死了造成JOB不跑，指令如下：

alter system set job_queue_processes=0 --关闭job进程，等待5--10秒钟

alter system set job_quene_processes=50 --恢复原来的值

6.Oracle的BUG

Oracle9i里面有一个BUG，当计数器到497天时，刚好达到它的最大值，再计数就会变成-1，继续计数就变成0了，然后计数器将不再跑了。如果碰到这种情况就得重启数据库，我们这边有一个生产型的数据库版本是9205，就发生过这样一次问题，后来和用户约时间重启后就没问题了。但是其他的Oracle7345和Oracle8i的数据库没有发现这个问题。

7.数据库上的检查基本上就这多，如果JOB运行还有问题，那需要配合用户察看一下是否是程序本身的问题，比如处理的资料量大，或者网络速度慢等造成运行时过长，那就需要具体情况具体分析了。我们可以通过下面的SQL手工执行一下JOB看看：

declare

begin

dbms_job.run(<job>_ID)

end;

如果发现JOB执行不正常，就要结合程序具体分析一下。



"sqlplus '/as sysdba'
SQL> exec dbms_stats.gather_dictionary_stats;
SQL> alter system set aq_tm_processes = 1 scope = both;
SQL> exec dbms_stats.gather_fixed_objects_stats;
"


USING INDEX的实验：
1、USING INDEX可以让你在创建主键、唯一性约束的时候使用指定的索引或创建索引、或修改索引的存储结构。
ＯＫ，我先不用USING INDEX，创建主键时Oracle自动创建唯一索引。

[html] view plaincopy
gyj@MYDB> alter table emp add constraint emp_id_pk primary key(employee_id);

Table altered.

gyj@MYDB> select INDEX_NAME from user_constraints where CONSTRAINT_NAME='EMP_ID_PK';

INDEX_NAME
------------------------------
EMP_ID_PK

gyj@MYDB> select UNIQUENESS from user_indexes where index_name='EMP_ID_PK';

UNIQUENES
---------
UNIQUE


2、这时我想把主键删除，但我想保留唯一索引EMP_ID_PK，即约束可以被独立drop，而索引可以保留。
[html] view plaincopy
gyj@MYDB> ALTER TABLE emp DROP PRIMARY KEY KEEP INDEX;

Table altered.

gyj@MYDB> select UNIQUENESS from user_indexes where index_name='EMP_ID_PK';

UNIQUENES
---------
UNIQUE

gyj@MYDB>  select INDEX_NAME from user_constraints where CONSTRAINT_NAME='EMP_ID_PK';

no rows selected

3、然后我又想创建主键，但我想直接用刚刚创建的唯一索引EMP_ID_PK。此时我就要用USING INDEX。
[html] view plaincopy
gyj@MYDB> alter table emp add constraint emp_id_pk primary key(employee_id) using index EMP_ID_PK;

Table altered.


二、      USING INDEX在官方文的解释：
Using Indexes to Enforce Constraints
When defining the state of a unique or primary key constraint, you can specify an index for Oracle to use to enforce the constraint, or you can instruct Oracle to create the index used to enforce the constraint.
using_index_clauseYou can specify theusing_index_clause only when enabling unique or primary key constraints. You can specify the clauses of theusing_index_clause in any order, but you can specify each clause only once.
If you specify schema.index, then Oracle attempts to enforce the constraint using the specified index. If Oracle cannot find the index or cannot use the index to enforce the constraint, then Oracle returns an error.
If you specify the create_index_statement, then Oracle attempts to create the index and use it to enforce the constraint. If Oracle cannot create the index or cannot use the index to enforce the constraint, then Oracle returns an error.
If you neither specify an existing index nor create a new index, then Oracle creates the index. In this case:
The index receives the same name as the constraint.
If table is partitioned, then you can specify a locally or globally partitioned index for the unique or primary key constraint.
Restrictions on theusing_index_clauseThe following restrictions apply to theusing_index_clause:
You cannot specify this clause for a view constraint.
You cannot specify this clause for a NOT NULL, foreign key, or check constraint.
You cannot specify an index (schema.index) or create an index (create_index_statement) when enabling the primary key of an index-organized table.
You cannot specify the domain_index_clause of index_properties or theparallel_clause ofindex_attributes.




convert datafile需要在目标数据库做的，你是在目标库做的吗？

参考：Online Doc（http://docs.oracle.com/cd/E11882_01/backup.112/e10642/rcmxplat.htm#sthref1873）
You can use the CONVERT DATAFILE command to convert files on the destination host, but not on the source host.




---跨平台转换数据文件
源库执行的脚本如下：
convert database new database 'd3egis'
transport script '/paic/g2bh8050/dev/gbs2_tmp/egisdev_conv/oratmpscriptts.sql'
to platform 'Solaris[tm] OE (64-bit)'
db_file_name_convert=( '/paic/g2bh8050/dev/gbs2/oradata/egisdev/','/paic/g2bh8050/dev/gbs2_tmp/egisdev_conv/',
'/paic/g2bh8050/soft/10g1/app/oracle/product/10.2.0/dbs/','/paic/g2bh8050/dev/gbs2_tmp/egisdev_conv/')
PARALLELISM 8;



------远程导入数据库
在目标数据库上创建目录：
create or replace directory as '/usr2/ORADATA/bak/';
三、在目标数据库上创建dblink：
create public database link hq connect to hq identified by hq using ’209’;
这里，第一个hq是dblink名，第二个hq是源数据库用户名，第三个hq是源数据库hq用户密码，209是网络连接服务名，从tnsnames.ora文件中获取的。
四、在目标数据库上执行impdp：
-bash-3.00$ impdp system/system SCHEMAS=(hq) directory=exp_dir network_link=hq logfile=imp.log




SQL> @mycon.sql

Control file created.

SQL> alter database open resetlogs;
alter database open resetlogs
*
ERROR at line 1:
ORA-01194: file 1 needs more recovery to be consistent
ORA-01110: data file 1: '/paic/t1invdl/data02/oradata/t1invdl/system01.dbf'


SQL>
SQL> exit
Disconnected from Oracle Database 10g Enterprise Edition Release 10.2.0.5.0 - 64bit Production
With the Partitioning, Oracle Label Security, Data Mining and Real Application Testing options
z4cs2011:t1invdl > cd /paic/t1invdl/data01/oradata/t1invdl/
z4cs2011:t1invdl > ls
1                  control01.ctl      i3_orcl01.dbf      redo02.log         tradedata03.dbf    tradedata11.dbf    zl
2                  control01.ctl.bak  nohup.out          redo03.log         tradedata06.dbf    tradeidx01.dbf
3                  dbadata01.dbf      pausers01.dbf      tradedata01.dbf    tradedata07.dbf    tradeidx03.dbf
auddata01.dbf      dmlbakdata01.dbf   redo01.log         tradedata02.dbf    tradedata08.dbf    undotbs01.dbf
z4cs2011:t1invdl > pwd
/paic/t1invdl/data01/oradata/t1invdl
z4cs2011:t1invdl > sqlplus '/as sysdba'

SQL*Plus: Release 10.2.0.5.0 - Production on Thu Oct 31 14:29:39 2013

Copyright (c) 1982, 2010, Oracle.  All Rights Reserved.


Connected to:
Oracle Database 10g Enterprise Edition Release 10.2.0.5.0 - 64bit Production
With the Partitioning, Oracle Label Security, Data Mining and Real Application Testing options

SQL> select status from v$instance;

STATUS
------------------------------------
MOUNTED

SQL> recover database using backup controlfile until cancel;
ORA-00279: change 9102195340162 generated at 10/30/2013 12:27:06 needed for
thread 1
ORA-00289: suggestion :
/paic/t1invdl/rdbms/oracle/product/10.2.0/dbs/arch1_57_829576311.dbf
ORA-00280: change 9102195340162 for thread 1 is in sequence #57


Specify log: {<RET>=suggested | filename | AUTO | CANCEL}
/paic/t1invdl/data01/oradata/t1invdl/redo03.log
Log applied.
Media recovery complete.
SQL> alter database open resetlogs;

Database altered.

SQL> !
$
$
$
$ cd

查看恢复文件
1、列出需要恢复的数据文件
当数据文件出现介质失败时，通过查询动态性能视图v$recover_file，可以列出需要恢复的数据文件。
col error format a20
select file#,error,change# from v$recover_file;
  FILE# ERROR            CHANGE#
---------- ------------------ ----------
   5       file not found     0

复制了数据文件备份之后，重新查询V$RECOVER_FILE
select file#,error,change# from v$recover_file;
  FILE# ERROR            CHANGE#
---------- ------------------ ----------
   5                         1481225
表示数据文件备份的SCN值为   1481225  当恢复数据文件时，从该SCN值开始应用事务变化

2、类出日志历史信息
当执行介质恢复时，需要根据日志序列号确定要应用的归档日志和重做日志。
通过查询v$loghist,可以显示日志历史信息。
可以确定从哪个日志序列号开始应用事务变化
select sequence# from v$loghist
 where 1481225 between first_change# and switch_change#;
 SEQUENCE#
----------
   1

 SEQUENCE# 用于标识日志序列号，first_change#用户标识特定日志序列号对应的起始SCN值，switch_change#用于标识特定日志序列号的下一个日志序列号
 对应的起始SCN值


 3、列出恢复要使用的归档日志
 通过查询v$archived_log，可以显示所有的归档日志，通过查询v$recovery_log，可以显示恢复所需的归档日志。
 col archive_name format a30
 select sequence#,archive_name from v$recovery_log;
 SEQUENCE# ARCHIVE_NAME
---------- --------------------------------------------------------------------------------
  1           路径

sequence#用户标识日志序列号,archive_name  用于标识恢复要应用的归档日志。

非活动日志组的所有日志成员全部损坏

当非活动日志组的所有日志成员全部出现介质失败时，如果数据库处于关闭状态，那么打开数据库时将会显示错误信息，
如果数据库处于open状态，那么当切换到该日志组时，数据库将处于等待状态。
在open状态非活动日志组的所有日志成员全部损坏
切换到该日志组时，应为其内容不能被归档，所以后台进程lgwr处于等待状态，为了使lgwr可继续工作，消炎药清除该日志组
alter database clear unarchived logfile group 1;
当执行了上述命令后，oracle会重新建立日志组1的所有成员，此时后台进程lgwr可以继续正常工作。但因为日志组内容没有被归档，所以会导致过去的数据文件备份不能使用。
通过查看aler文件，可以取得相应警告信息。

2、在关闭状态下非活动日志组的所有日志成员全部损坏
dba可以增加新日志组，删除原有的日志组，然后打开数据库
alter database add logfile

alter database drop logfile group 1;
alter database open;


3、当前 日志组的所有日志成员全部损坏
若在open状态下当前日志组所有日志成员全部出现介质失败，oracle会终止例程；若在关闭状态下当前日志组所有日志成员全部出现介质失败，那么数据库将不能打开、


当关闭状态下当前日志组所有日志成员全部出现介质失败时，因为数据文件、控制文件都处于完全一致状态，所以dba只需要使用
recover database until cancel 命令执行基于取消的不完全恢复，然后用resetlogs选项打开数据库即可。
当使用resetlogs选项打开数据库之后，会重新建立所有日志成员，并且过去的备份不能直接使用，所以需要重新备份所有数据文件和控制文件

2、在open状态下当前日志组所有日志成员全部损坏

当数据库处于open状态时，如果当前日志组的所有日志成员全部出现介质失败，如误删除，那么后台进程lgwr将事务变化写入该日志组时，例程会被自动关闭，并显示错误信息。
则必须要使用数据文件备份、归档日志执行给予取消的不完全恢复



当执行了不完全恢复或使用resetlogs选项打开数据库之后，会导致过去的临时文件不能使用。另外，当临时文件出现介质失败时，统一会导致临时文件不能使用，当临时文件不能使用时，排序操作可能会失败。


处理损坏数据块
使用ramn的blockrecover命令恢复损坏的数据块。
使用pl/sql 包dbms_repair处理损坏的数据块
1、建立修复表
修复表必须要带有repair_前缀（大写）
EXEC dbms_repair.admin.tables('REPAIR_TABLE',DBMS_REPAIR.REPAIR_TABLE,DBMS_REPAIR.CREATE_ACTION)
2、确定损坏块个数
建立修复表之后， 通过使用check_object可以检查特定对象所包含的损坏块个数。 需要提供方案名和对象名，并且必须要定义变量用以存放损坏块个数
var cc number
exec dbms_repair.check_object('SCOTT','CUSTOMERS',corrupt_count=>:cc);
print cc

3、标记损坏块。为了跳过损坏数据块，需要将损坏数据块标记为“损坏”。通过使用fix_corrupt_blocks,可以将损坏数据块标记为
“损坏”， 当标记损坏数据块时，需要提供方案名和对象名，并且需要定义变量用以存放被修复的数据块个数。
VAR fc number
exec dbms_repair.fix_corrupt_blocks('SCOTT','CUSTOMERS',fix_count=>:fc);
print fc

4、跳过损坏块，通过使用skip_corrupt_blocks,可以跳过损坏数据块。
EXEC dbms_repair.skip_corrupt_blocks('SCOTT','CUTSTOMERS');

5、去定指向损坏块的索引入口。

rman介绍
rman 组件
1、目标数据库
指要执行备份、转储和恢复操作的数据库，实际是指应用系统所涉及到的产品数据库
2、服务器进程
连接到目标数据库时，会建立两个连到目标数据库的服务器进程，其中默认服务器进程用于解析rman命令，并生成隐含执行的pl/sql
块，沦陷服务器进程用于检查备份、转储和恢复操作是否已经完成.

3、通道
用于执行和记录备份、转储和恢复操作。 当使用rman在存储设备(磁带或磁盘)上执行备份、转储和恢复操作时，rman需要在存储设备和目标数据库之间建立连接。
该连接被称为通道。

 4、rman资料库和rman元数据
 rman元数据是指rman在备份、转储和恢复操作中所使用的数据，rman元数据的集合被成为rman资料库。
 当使用rman执行备份、转储和恢复操作时，oracle总数将rman元数据存放到目标数据库的控制文件中。如果配置了恢复目录，那么rman元数据还会被存放到恢复目录中。

 5、恢复目录
 恢复目录用于存放rman元数据，它是存放rman元数据的一个可选设置。当使用目标数据库控制文件存放rman元数据时，在rman元数据存放天数达到初始化
 参数control_file_rcord_keep_time的值之后，其源数据可能会被覆盖，从而导致之前的备份不能使用；通过使用恢复目录，可以永久保留需要的rman元数据，另外，在恢复目录中还可以存放存储脚本。

 6、介质管理层
 7、rman包

 1. rman target sys/***@demo nocatalog
 rman nocatalog
 connect target sys/***@demo

 2.rman target sys/***@demo catalog rman/***@rcat
 rman
 connect target sys/***@demo
 connect catalog rman/***@rcat

 3.rman target sys/***@demo auxiliary sys/***@aux
 rman
 connect target sys/***@demo
 connect auxiliary sys/***@aux



log_file=/paic/stg/oracle/11g/otzj11g/xltmp/full_backup_${ORACLE_SID}_`date '+%Y%m%d_%H%M%S'`.log
export log_file
rman << EOF > ${log_file} 2>&1
connect TARGET sys/paic1234@stginvdw2--源库
connect AUXILIARY sys/paic1234@stginvdw3--目标库
DUPLICATE TARGET DATABASE
      TO 'HDINVDW3' --目标库的DB_NAME
      FROM ACTIVE DATABASE
      DB_FILE_NAME_CONVERT=('+DATA2_DG/invest/datafile/'--源库datafile文件路径,'+DATA3_DG/HDINVDW3/datafile/',--目标库datafile文件路径
'+DATA2_DG/invest/tempfile/','+DATA3_DG/HDINVDW3/tempfile/')
    LOGFILE
      GROUP 1 ('+DATA3_DG',
               '+FRA3_DG') SIZE 50M,
      GROUP 2 ('+DATA3_DG',
               '+FRA3_DG') SIZE 50M,
      GROUP 3 ('+DATA3_DG',
               '+FRA3_DG') SIZE 50M REUSE;
EOF
echo "Backup finished at `date '+%Y%m%d_%H%M%S'`" >> ${log_file}


 /*******************************************
功能说明：lbs中ddl语言触发器
参数说明：
创建人：  陈敬梅
创建日期：2006-1-23


修改人：
修改日期：
修改说明：
********************************************/
--Version 1.0
create or replace trigger dbtr_create_alter_restriction
before create or alter on database
DECLARE
  v_object_name varchar2(30);
  v_count       number;
begin
  v_object_name:=DICTIONARY_OBJ_NAME;
--1. Can not create table or view with the same name of tables ofLIFEDATA/LIFEBASE/ACCTMAN/LIFEREPT/REINSMAN/VOUDATA/LIFELOG
  if DICTIONARY_OBJ_TYPE='TABLE'
  or DICTIONARY_OBJ_TYPE='VIEW'
  then
    select count(user) into v_count from dual where user not in ('LIFEDATA','LIFEBASE','ACCTMAN','LIFEREPT','REINSMAN','VOUDATA','LIFELOG');
    if v_count>0 then
      select count(*)
        into v_count
        from dba_objects
       where object_name=v_object_name
         and owner in ('LIFEDATA','LIFEBASE','ACCTMAN','LIFEREPT','REINSMAN','VOUDATA','LIFELOG')
         and object_type in ('TABLE','VIEW')
         and rownum=1;
      if V_COUNT=1 then
        raise_application_error(-20905,'Can not create or alter tables/views with the same name of tables of LIFEDATA/LIFEBASE/ACCTMAN/LIFEREPT/REINSMAN/VOUDATA/LIFELOG in LBS production database!');
      end if;
    end if;
  else
--2.REPs and oa_users can not create procedure or package with the same name of LIFEMAN
  if DICTIONARY_OBJ_TYPE='FUNCTION'
  or DICTIONARY_OBJ_TYPE='PROCEDURE'
  or DICTIONARY_OBJ_TYPE='PACKAGE'
  or DICTIONARY_OBJ_TYPE='PACKATE BODY'
  then
    select count(*) into v_count
      from dba_users
     where username=user
       and (username like 'REP%' or username in (select oa_name from per_user_list where oa_name<>cn_name))
       and rownum=1;
    if v_count=1 then
      select count(*)
        into v_count
        from dba_objects
       where object_name=v_object_name
         and owner in ('LIFEMAN')
         and object_type in ('FUNCTION','PROCEDURE','PACKAGE','PACKATE BODY')
         and rownum=1;
      if V_COUNT=1 then
        raise_application_error(-20906,'Can not create or alter objects with the same name of that of LIFEMAN in LBS production database!');
      end if;
    end if;
  else
  if DICTIONARY_OBJ_TYPE='SYNONYM'
  then
    select count(*) into v_count
      from dba_users
     where username=user
       and (username like 'REP%' or username in (select oa_name from per_user_list where oa_name<>cn_name))
       and rownum=1;
    if v_count=1 then
      raise_application_error(-20907,'Can not create synonyms in LBS production database!');
    end if;
  end if;
  end if;
  end if;
end;
/


--Version 2.0
create OR REPLACE TRIGGER dbtr_drop_grant_restriction
before drop or truncate or grant or revoke on database
DECLARE
  v_object_name varchar2(30);
  v_count       number;
begin
  select count(*) into v_count
    from dba_users
   where username=user
     and (username like 'REP%' or username in (select oa_name from per_user_list where oa_name<>cn_name) or username in ('MISSEL','MISTRPE'))
     and rownum=1;
  if v_count=1 then
    raise_application_error(-20908,'Can not do DROP/TRUNCATE/GRANT/REVOKE operation in LBS production database!');
  end if;
end;
/


--以下为当前采用的版本：
--VERSION 3.0
--不作ddl限制的用户清单表：
create table ddl_allow_user (username varchar2(30));

--ddl限制时间段配置表：
create table ddl_deny_time (
  deny_date       varchar2(3),
  deny_start varchar2(4),
  deny_end   varchar2(4) );

comment on table ddl_deny_time  is '禁止DDL操作的时间';
comment on column ddl_deny_time.deny_date  is '日期：1～31表示日期，SAT表示周六，SUN表示周日';

--插入不作限制的用户：
insert into ddl_allow_user values (       'SYS'   );
insert into ddl_allow_user values (    'SYSTEM'   );
insert into ddl_allow_user values (     'DBMGR'   );
insert into ddl_allow_user values ('LIFEDECIDE'   );
insert into ddl_allow_user values (  'LIFEBASE'   );
insert into ddl_allow_user values (  'LIFEDATA'   );
insert into ddl_allow_user values (   'ACCTMAN'   );
insert into ddl_allow_user values (  'REINSMAN'   );
insert into ddl_allow_user values (   'VOUDATA'   );
insert into ddl_allow_user values (   'LIFELOG'   );
insert into ddl_allow_user values (   'LIFEBAK'   );
insert into ddl_allow_user values (  'LIFEMENU'   );
insert into ddl_allow_user values (  'LIFEREPT'   );
insert into ddl_allow_user values (   'LIFEJOB'   );
insert into ddl_allow_user values (   'RESPMAN'   );
insert into ddl_allow_user values (  'PERFSTAT'   );
insert into ddl_allow_user values (   'LIFEMAN'   );
insert into ddl_allow_user values ( 'LIFESUPER'   );
insert into ddl_allow_user values (   'ACCTOPA'   );
insert into ddl_allow_user values (   'MENUMAN'   );
insert into ddl_allow_user values (    'CRMQRY'   );
---
insert into ddl_allow_user values ('ACTRESV' );
insert into ddl_allow_user values ( 'MISSEL' );
insert into ddl_allow_user values ('MISTREP' );
insert into ddl_allow_user values ('LIFEKPI' );
---
insert into ddl_allow_user values ('LIFEJ2EE' );

--插入限制的时间段配置：
insert into ddl_deny_time values ('1','0830','2030');
insert into ddl_deny_time values ('2','0830','2030');
insert into ddl_deny_time values ('3','0830','2030');
insert into ddl_deny_time values ('4','0830','2030');
insert into ddl_deny_time values ('5','0830','2030');
insert into ddl_deny_time values ('6','0830','2030');
insert into ddl_deny_time values ('7','0830','2030');
insert into ddl_deny_time values ('8','0830','2030');
insert into ddl_deny_time values ('9','0830','2030');
insert into ddl_deny_time values ('10','0830','2030');
insert into ddl_deny_time values ('11','0830','2030');
insert into ddl_deny_time values ('12','0830','2030');
insert into ddl_deny_time values ('13','0830','2030');
insert into ddl_deny_time values ('14','0830','2030');
insert into ddl_deny_time values ('15','0830','2030');
insert into ddl_deny_time values ('16','0830','2030');
insert into ddl_deny_time values ('17','0830','2030');
insert into ddl_deny_time values ('18','0830','2030');
insert into ddl_deny_time values ('19','0830','2030');
insert into ddl_deny_time values ('20','0830','2030');
insert into ddl_deny_time values ('21','0830','2030');
insert into ddl_deny_time values ('22','0830','2030');
insert into ddl_deny_time values ('23','0830','2030');
insert into ddl_deny_time values ('24','0830','2130');
insert into ddl_deny_time values ('25','0830','2130');
insert into ddl_deny_time values ('26','0830','2130');
insert into ddl_deny_time values ('27','0830','2130');
insert into ddl_deny_time values ('28','0830','2130');
insert into ddl_deny_time values ('29','0830','2130');
insert into ddl_deny_time values ('30','0830','2130');
insert into ddl_deny_time values ('31','0830','2130');
insert into ddl_deny_time values ('SAT','0900','1100');
insert into ddl_deny_time values ('SAT','1400','1600');
insert into ddl_deny_time values ('SUN','','');
commit;

--DDL操作限制的trigger，在ddl操作前触发。
--注意，该trigger要求数据库的compatible参数在8.1.6以上。
create OR REPLACE TRIGGER dbtr_ddl_restriction
before ddl on database
DECLARE
  v_object_name varchar2(30);
  v_count       number;
  v_count1      number;
  v_day         varchar2(3);  ---Day of week
  v_date        varchar2(3);  ---date of month
  v_time        varchar2(4);  ---time
begin
  select count(*) into v_count
    from ddl_allow_user
   where username=user;
  select count(*) into v_count1
    from user_list
   where user_name=user;
  if v_count=0 and v_count1=0 then
    select to_char(sysdate,'d') into v_day from dual;
    select to_char(sysdate,'dd') into v_date from dual;
    select to_char(sysdate,'hh24mi') into v_time from dual;
    --not Saturday and not Sunday
    if upper(trim(v_day))<>'7' and upper(trim(v_day))<>'1' then
      select count(*) into v_count
        from ddl_deny_time
       where deny_date=v_date and deny_start<= v_time and deny_end>=v_time;
    else
      --Saturday or Sunday
      if upper(trim(v_day))='7' then
        v_day:='SAT';
      else
        v_day:='SUN';
      end if;
      select count(*) into v_count
        from ddl_deny_time
       where deny_date=v_day and deny_start<= v_time and deny_end>=v_time;
    end if;
    if v_count>0 then
      if DICTIONARY_OBJ_TYPE='TABLE'
      or DICTIONARY_OBJ_TYPE='VIEW'
      or DICTIONARY_OBJ_TYPE='INDEX'
      or DICTIONARY_OBJ_TYPE='SYNONYM'
      or DICTIONARY_OBJ_TYPE='FUNCTION'
      or DICTIONARY_OBJ_TYPE='PROCEDURE'
      or DICTIONARY_OBJ_TYPE='PACKAGE'
      or DICTIONARY_OBJ_TYPE='PACKAGE BODY'
      or DICTIONARY_OBJ_TYPE='OBJECT PRIVILEGE'
      then
        raise_application_error(-20908,DICTIONARY_OBJ_TYPE||':Can not do DDL operation in LBS production database now!');
      end if;
    end if;
  end if;
end;
/






 有些时候因为测试环境需要,我们需要使用生产库的备份集在另外一台新的机器上做恢复(前提是新机器事先安装Oracle软件,版本跟原库一致),下面是恢复过程.

1.在原库上做全备(在原库上操作)
run{
allocate channel c1 device type disk;
allocate channel c2 device type disk;
backup format '/u02/rman_backup/full_backup/full_backup_%T_%s' database;
sql 'alter system archive log current';
backup format '/u02/rman_backup/full_backup/arc_backup_%T_%s' archivelog all;
release channel c1;
release channel c2;
}
2.查看原库的DBID(在原库上操作)
因为在做恢复的过程中需要设定DBID,这里需要找到原库的DBID
SQL> select dbid from v$database;
      DBID
----------
1820932955

-----以下的操作没有特殊说明,全部在目的库上操作-----
3.使用ftp将原库上的备份集拷贝到目的库的目录/u02/ftp/(具体操作省略)

4.在新机器上创建如下目录
mkdir /u02/mydb
mkdir -p /u02/mydb/oracl/{adump,bdump,cdump,dpdump,udump,pfile}
mkdir -p /u02/mydb/oradata/oracl
mkdir -p /u02/mydb/flash_recovery_area

5.创建密码文件
orapwd file=/u01/app/oracle/product/10.2.0/db_1/dbs/orapworacl.ora password=oracle

6.恢复参数文件
[oracle@hxlbak ~]$ rman target /

Recovery Manager: Release 10.2.0.1.0 - Production on Fri Jun 29 06:51:54 2012

Copyright (c) 1982, 2005, Oracle.  All rights reserved.

connected to target database (not started)

RMAN>set dbid 1820932955 -- 这里的dbid需要跟原库保持一致

RMAN> startup nomount

startup failed: ORA-01078: failure in processing system parameters
LRM-00109: could not open parameter file '/u01/app/oracle/product/10.2.0/db_1/dbs/initoracl.ora'

starting Oracle instance without parameter file for retrival of spfile
Oracle instance started

Total System Global Area     159383552 bytes

Fixed Size                     1218268 bytes
Variable Size                 54528292 bytes
Database Buffers             100663296 bytes
Redo Buffers                   2973696 bytes

RMAN> restore spfile to pfile '/u01/app/oracle/product/10.2.0/db_1/dbs/initoracl.ora' from '/u02/ftp/full_backup_20120628_37';

Starting restore at 29-JUN-12
using target database control file instead of recovery catalog
allocated channel: ORA_DISK_1
channel ORA_DISK_1: sid=36 devtype=DISK

channel ORA_DISK_1: autobackup found: /u02/ftp/full_backup_20120628_37
channel ORA_DISK_1: SPFILE restore from autobackup complete
Finished restore at 29-JUN-12


备份集full_backup_20120628_3里7包含了参数文件,我们在备份数据的时候会默认备份参数文件,可以在原库使用list backup查看,list backup输出部分内容如下:

BS Key  Type LV Size       Device Type Elapsed Time Completion Time
------- ---- -- ---------- ----------- ------------ ---------------
35      Full    80.00K     DISK        00:00:01     28-JUN-12
        BP Key: 35   Status: AVAILABLE  Compressed: NO  Tag: TAG20120628T184555
        Piece Name: /u02/rman_backup/full_backup/full_backup_20120628_37
  SPFILE Included: Modification time: 28-JUN-12

恢复了参数文件initoracl.ora后,因为原库和目的库各文件保存的路径不一致,这个时候需要修改参数文件,修改的地方如下,各文件路径指向新目录:

*.audit_file_dest='/u02/mydb/oracl/adump'
*.background_dump_dest='/u02/mydb/oracl/bdump'
*.control_files='/u02/mydb/oradata/oracl/control01.ctl','/u02/mydb/oradata/oracl/control02.ctl','/u02/mydb/oradata/oracl/control03.ctl'
*.core_dump_dest='/u02/mydb/oracl/cdump'
*.db_recovery_file_dest='/u02/mydb/flash_recovery_area'
*.user_dump_dest='/u02/mydb/oracl/udump'

7.使用编辑好的参数文件启动数据库到nomount状态并恢复控制文件

SQL> startup nomount pfile=/u01/app/oracle/product/10.2.0/db_1/dbs/initoracl.ora
ORACLE instance started.

Total System Global Area 1048576000 bytes
Fixed Size                  1223368 bytes
Variable Size             310379832 bytes
Database Buffers          734003200 bytes
Redo Buffers                2969600 bytes
SQL>

恢复控制文件
RMAN> restore controlfile from '/u02/ftp/full_backup_20120628_36';

Starting restore at 29-JUN-12
using target database control file instead of recovery catalog
allocated channel: ORA_DISK_1
channel ORA_DISK_1: sid=155 devtype=DISK

channel ORA_DISK_1: restoring control file
channel ORA_DISK_1: restore complete, elapsed time: 00:00:05
output filename=/u02/mydb/oradata/oracl/control01.ctl
output filename=/u02/mydb/oradata/oracl/control02.ctl
output filename=/u02/mydb/oradata/oracl/control03.ctl
Finished restore at 29-JUN-12

跟参数文件一样,在备份数据的时候会默认备份了控制文件,备份集full_backup_20120628_36中包含了控制文件,同样可以在原库使用list backup查看,list backup输出部分内容如下:

BS Key  Type LV Size       Device Type Elapsed Time Completion Time
------- ---- -- ---------- ----------- ------------ ---------------
34      Full    6.98M      DISK        00:00:02     28-JUN-12
        BP Key: 34   Status: AVAILABLE  Compressed: NO  Tag: TAG20120628T184555
        Piece Name: /u02/rman_backup/full_backup/full_backup_20120628_36
  Control File Included: Ckp SCN: 1545845      Ckp time: 28-JUN-12

8.启动数据库到mount状态并注册备份集
RMAN> alter database mount;

database mounted
released channel: ORA_DISK_1

注册备份集,因为控制文件中的保留的备份信息是原库的,我们这里需要重新注册新库路径下的备份集
RMAN> catalog start with '/u02/ftp/';

Starting implicit crosscheck backup at 29-JUN-12
allocated channel: ORA_DISK_1
channel ORA_DISK_1: sid=155 devtype=DISK
Crosschecked 29 objects
Finished implicit crosscheck backup at 29-JUN-12

Starting implicit crosscheck copy at 29-JUN-12
using channel ORA_DISK_1
Finished implicit crosscheck copy at 29-JUN-12

searching for all files in the recovery area
cataloging files...
no files cataloged

searching for all files that match the pattern /u02/ftp/

List of Files Unknown to the Database
=====================================
File Name: /u02/ftp/full_backup_20120628_35
File Name: /u02/ftp/full_backup_20120628_37
File Name: /u02/ftp/full_backup_20120628_34
File Name: /u02/ftp/arc_backup_20120628_38
File Name: /u02/ftp/arc_backup_20120628_40
File Name: /u02/ftp/full_backup_20120628_36
File Name: /u02/ftp/full_backup_20120628_31
File Name: /u02/ftp/full_backup_20120628_33
File Name: /u02/ftp/arc_backup_20120628_39
File Name: /u02/ftp/full_backup_20120628_32
File Name: /u02/ftp/full_backup_20120628_30

Do you really want to catalog the above files (enter YES or NO)  yes
cataloging files...
cataloging done

List of Cataloged Files
=======================
File Name: /u02/ftp/full_backup_20120628_35
File Name: /u02/ftp/full_backup_20120628_37
File Name: /u02/ftp/full_backup_20120628_34
File Name: /u02/ftp/arc_backup_20120628_38
File Name: /u02/ftp/arc_backup_20120628_40
File Name: /u02/ftp/full_backup_20120628_36
File Name: /u02/ftp/full_backup_20120628_31
File Name: /u02/ftp/full_backup_20120628_33
File Name: /u02/ftp/arc_backup_20120628_39
File Name: /u02/ftp/full_backup_20120628_32
File Name: /u02/ftp/full_backup_20120628_30

9.列出当前的所有数据文件

SQL> column name format a60;
SQL> select file# as "file/grp#", name from v$datafile;
 file/grp# NAME
---------- ------------------------------------------------------------
         1 /u01/app/oracle/oradata/oracl/system01.dbf';
         2 /u01/app/oracle/oradata/oracl/undotbs01.dbf';
         3 /u01/app/oracle/oradata/oracl/sysaux01.dbf';
         4 /u01/app/oracle/oradata/oracl/users01.dbf';
         5 /u01/app/oracle/oradata/oracl/hxl01.dbf';
         6 /u01/app/oracle/oradata/oracl/hxl02.dbf';
         7 /u01/app/oracle/oradata/oracl/hxl03.dbf';
         8 /u01/app/oracle/oradata/oracl/hxl04.dbf';
         9 /u01/app/oracle/oradata/oracl/hxl05.dbf';
        10 /u02/app/oracle/oradata/oracl/hxl06.dbf';
        11 /u02/app/oracle/oradata/oracl/hxl07.dbf';
 file/grp# NAME
---------- ------------------------------------------------------------
        12 /u02/app/oracle/oradata/oracl/hxl08.dbf';
        13 /u02/app/oracle/oradata/oracl/hxl09.dbf';
        14 /u02/app/oracle/oradata/oracl/hxl10.dbf';

可以看到,当前控制文件中记录的数据文件的路径是原来的路径,我们在做恢复的时候需要指向新的路径.

10.恢复数据库
RMAN> run{
set newname for datafile  1 to '/u02/mydb/oradata/oracl/system01.dbf';
set newname for datafile  2 to '/u02/mydb/oradata/oracl/undotbs01.dbf';
set newname for datafile  3 to '/u02/mydb/oradata/oracl/sysaux01.dbf';
set newname for datafile  4 to '/u02/mydb/oradata/oracl/users01.dbf';
set newname for datafile  5 to '/u02/mydb/oradata/oracl/hxl01.dbf';
set newname for datafile  6 to '/u02/mydb/oradata/oracl/hxl02.dbf';
set newname for datafile  7 to '/u02/mydb/oradata/oracl/hxl03.dbf';
set newname for datafile  8 to '/u02/mydb/oradata/oracl/hxl04.dbf';
set newname for datafile  9 to '/u02/mydb/oradata/oracl/hxl05.dbf';
set newname for datafile 10 to '/u02/mydb/oradata/oracl/hxl06.dbf';
set newname for datafile 11 to '/u02/mydb/oradata/oracl/hxl07.dbf';
set newname for datafile 12 to '/u02/mydb/oradata/oracl/hxl08.dbf';
set newname for datafile 13 to '/u02/mydb/oradata/oracl/hxl09.dbf';
set newname for datafile 14 to '/u02/mydb/oradata/oracl/hxl10.dbf';
restore database;
switch datafile all;
recover database;
}

11.打开数据库
alter database open resetlogs;

-- The End --


enqueue 等待通常是就 ST  enqueue、HW  enqueue
和 TX4 enqueue 而言。ST enqueue 在数据字典管理方式表空间的物理空间分配和管理上发挥作
用。当某些以数据字典管理的表空间不断出现问题时，可以转而采用本地管理的表空间 （LMT），
或者预先分配扩展，再或者至少使下一扩展增大一些。HW enqueue 同段的高水位线一起使用，
手工分配扩展可以避免其上的等待。TX4 是各种 enqueue 等待中所最为常见的，它的出现通常是
由下述三种问题之一所造成的结果。第一种，惟一索引的重复，您需要 commit/rollback 以释放
enqueue。第二种，多个并发的对同一位图索引片的修改。因为一个位图索引片内可能有多个
rowids，当多位用户试图修改同一片时，就需要 commit/rollback 来释放 enqueue。第三种，也是
最可能发生的一种，多用户同时修改相同的数据块，而如果已经没有空闲的 ITL 槽，则会引发一
数据块级的锁。运用增大 initrans 或 maxtrans 以容纳更多 ITL 槽的方法，可以解决这个问题，增
大表的 PCTFREE 也可以解决这个问题。现在来谈一谈 TM 锁──一种行级锁。如果有外键，则务
必要为它们创建索引以避免这种常见的锁的麻烦。

。空闲事件被放在 stats$idle_event 表里。



等待问题  可能的解决方法
Sequential Read    表明有很多索引读——调整代码（特别是表连接部分）
Scattered Read    表明有很多全表扫描——调整代码、将小表放入内存
Free Buffer    增大 DB_CACHE_SIZE、加速检查点和调整代码
Buffer Busy    段头——增加 freelists 或者 freelist groups
Buffer Busy    数据块——分离“热点”数据、采用反向关键字索引、采用小的数据块
Buffer Busy    数据块——增大 initrans 和 maxtrans
Buffer Busy    undo header——增加回滚段
Buffer Busy    undo block——增加提交频度、增大回滚段
Latch Free  研究 Latch 细节（可以参考下文）
Enqueue - ST  使用本地表空间或者预先分配大扩展
Enqueue - HW  预先分配扩展于高水位线之上
Enqueue - TX4  增大表或索引的 initrans 和 maxtrans
Enqueue - TM  为外键建立索引，查看应用程序中的表锁
Log Buffer Space  增大日志缓冲区，重做日志放在快速磁盘上
Log File Switch  归档设备太慢或者太满，增加或者扩大重做日志
Log File Sync  每次提交更多记录、更快的存放重做日志的磁盘、裸设备
Idle Event  忽略





常见的空闲事件包括以下：
    dispatcher timer（共享服务器空闲事件）；
    lock manager wait for remote message（RAC 空闲事件）；
    pipe get（用户进程空闲事件）；
    pmon timer（后台进程空闲事件）；
    PX Idle Wait（并行查询空闲事件）；
    PX Deq Credit: need buffer（并行查询空闲事件）；
    PX Deq Credit: send blkd（并行查询空闲事件）；
    rdbms ipc message（后台进程空闲事件）；
    smon timer（后台进程空闲事件）；
    SQL*Net message from client（用户进程空闲事件）；
    virtual circuit status（共享服务器空闲事件）。


Oracle的update语句优化研究
一、         update语句的语法与原理
1.     语法
单表：UPDATE 表名称 SET 列名称 = 新值 WHERE 列名称 = 某值
如：update t_join_situation set join_state='1'whereyear='2011'
更新年度为“2011”的数据的join_state字段为“1”。如果更新的字段加了索引，更新时会重建索引，更新效率会慢。
   多表关联，并把一个表的字段值更新到另一个表中的字段去：
update 表a set a.字段1 = (select b.字段1 from 表b where a.字段2=b.字段2) where exists(select 1 from 表b where a.字段2=b.字段2)
oracle的更新语句不通MSSQL那么简单易写，就算写出来了，但执行时可能会报
这是由于set哪里的子查询查出了多行数据值，oracle规定一对一更新数据，所以提示出错。要解决这样必须保证查出来的值一一对应。
2.     原理
Update语句的原理是先根据where条件查到数据后，如果set中有子查询，则执行子查询把值查出来赋给更新的字段，执行更新。
如：update 表a set a.字段1 = (select b.字段1 from 表b where a.字段2=b.字段2) where exists(select 1 from 表b where a.字段2=b.字段2)。查表a的所有数据，循环每条数据，验证该条数据是否符合exists(select 1 from 表b where a.字段2=b.字段2)条件，如果是则执行(select b.字段1 from 表b where a.字段2=b.字段2)查询，查到对应的值更新a.字段1中。关联表更新时一定要有exists(select 1 from 表b where a.字段2=b.字段2)这样的条件，否则将表a的其他数据的字段1更新为null值。
二、         提高oracle更新效率的各种解决方案
1.     标准update语法
当你需要更新的表是单个或者被更新的字段不需要关联其他表带过来，则最后选择标准的update语句，速度最快，稳定性最好，并返回影响条数。如果where条件中的字段加上索引，那么更新效率就更高。但对需要关联表更新字段时，update的效率就非常差。
2.     inline view更新法
inline view更新法就是更新一个临时建立的视图。如：update (select a.join_state as join_state_a,b.join_state as join_state_b
from t_join_situation a, t_people_info b where a.people_number=b.people_number
and a.year='2011'and a.city_number='M00000'and a.town_number='M51000') set join_state_a=join_state_b
括号里通过关联两表建立一个视图，set中设置好更新的字段。这个解决方法比写法较直观且执行速度快。但表B的主键一定要在where条件中，并且是以“=”来关联被更新表，否则报一下错误：

3.merge更新法
merge是oracle特有的语句，语法如下：
MERGE INTO table_name alias1
USING (table|view|sub_query) alias2
ON (join condition)
WHEN MATCHED THEN
    UPDATE table_name
    SET col1 = col_val1,
        col2     = col2_val
WHEN NOT MATCHED THEN
    INSERT (column_list) VALUES (column_values);
它的原理是在alias2中Select出来的数据，每一条都跟alias1进行 ON (join condition)的比较，如果匹配，就进行更新的操作(Update),如果不匹配，就进行插入操作(Insert)。执行merge不会返回影响的行数。Merge语句的写法比较繁琐，并且最多只能两个表关联，复杂的语句用merge更新法将力不从心且效率差。
4.快速游标更新法
语法如：
begin
for cr in (查询语句) loop –-循环
   --更新语句（根据查询出来的结果集合）
endloop; --结束循环
end;
oracle支持快速游标，不需要定义直接把游标写到for循环中，这样就方便了我们批量更新数据。再加上oracle的rowid物理字段（oracle默认给每个表都有rowid这个字段，并且是唯一索引），可以快速定位到要更新的记录上。
例子如下：
begin
for cr in (select a.rowid,b.join_state from t_join_situation a,t_people_info b
where a.people_number=b.people_number
and a.year='2011'and a.city_number='M00000'and a.town_number='M51000') loop
update t_join_situation set join_state=cr.join_state where
rowid = cr.rowid;
endloop;
end;
使用快速游标的好处很多，可以支持复杂的查询语句，更新准确，无论数据多大更新效率仍然高，但执行后不返回影响行数。
三、结论
方案
建议
标准update语法
单表更新或较简单的语句采用使用此方案更优。
inline view更新法
两表关联且被更新表通过关联表主键关联的，采用此方案更优。
merge更新法
两表关联且被更新表不是通过关联表主键关联的，采用此方案更优。
快速游标更新法
多表关联且逻辑复杂的，采用此方案更优。


实时测试的速度：
--48466条数据
--1.297
update (select a.join_state as join_state_a,b.join_state as join_state_b
from t_join_situation a, t_people_info b where a.people_number=b.people_number
and a.year='2011'and a.city_number='M00000'and a.town_number='M51000'
) set join_state_a=join_state_b

--7.156
update t_join_situation a set a.join_state=(select b.join_state from t_people_info b
where a.people_number=b.people_number
and a.year='2011'and a.city_number='M00000'and a.town_number='M51000')
whereexists (select1from t_people_info b
where a.people_number=b.people_number
and a.year='2011'and a.city_number='M00000'and a.town_number='M51000')

--3.281
begin
for cr in (select a.rowid,b.join_state from t_join_situation a,t_people_info b
where a.people_number=b.people_number
and a.year='2011'and a.city_number='M00000'and a.town_number='M51000') loop
update t_join_situation set join_state=cr.join_state where
rowid = cr.rowid;
endloop;
end;

--1.641
mergeinto t_join_situation a
using t_people_info b
on (a.people_number=b.people_number
and a.year='2011'and a.city_number='M00000'and a.town_number='M51000')
whenmatchedthenupdateset a.join_state=b.join_state













TNS-04414,TNS-04610错误 .
分类： Oracle troubleshoot oracle net 2012-12-05 11:17 211人阅读 评论(0) 收藏 举报
使用SQL连接刚配置的tnsnames.ora，出现下面错误：

ERROR:
ORA-12154: TNS: 无法解析指定的连接标识符

用NETCA图形配置，点下步出现：

ServiceAliasException: 无法列出网络服务名: TNS-04404: 没有错误
  caused by: oracle.net.config.ConfigException: TNS-04414: 文件错误
  caused by: TNS-04610: 没有其他文字, 已到达 NV 对结尾



最后经检查是tnsnames.ora的配置文件中少了一个括号：

   )
  )






SQL> alter database open read only;
alter database open read only
*
ERROR at line 1:
ORA-16006: audit_trail destination incompatible with database open mode


SQL> show parameter audit_trail

NAME                                 TYPE
------------------------------------ ----------------------
VALUE
------------------------------
audit_trail                          string
DB
SQL> alter system set audit_trail = none scope = spfile;

System altered.

SQL> shutdown immediate
ORA-01109: database not open


Database dismounted.
ORACLE instance shut down.
SQL> startup mount

SQL> alter database open read only;

Database altered.


ALTER TRIGGER  GBSTRG.TR_DROPDENY_DEPEND_CHECK DISABLE;
ORA-20008: 该对象被其他对象依赖,不能删除,请检查dba_dependencies!

查询状态正常enabled 但是失效的trigger
-- trigger启用，但是失效了
select o.owner,o.object_name,o.status as is_VALID,t.trigger_type,t.table_name,t.column_name,t.status as is_ENABLED
 from all_objects o,all_triggers t
where o.object_name=t.trigger_name
and o.status='INVALID'
and t.status='ENABLED'  AND t.owner= 'INSLOG'




账号密码永不过期

处理过程：
1、查看用户的proifle是那个，一般是default：
sql>SELECT username,PROFILE FROM dba_users;
2、查看指定概要文件（如default）的密码有效期设置：
sql>SELECT * FROM dba_profiles s WHERE s.profile='DEFAULT' AND resource_name='PASSWORD_LIFE_TIME';
3、将密码有效期由默认的180天修改成“无限制”：
ALTER PROFILE DEFAULT LIMIT PASSWORD_LIFE_TIME UNLIMITED;
（前三步已经解决第四步没必要）
4、修改后，还没有被提示ORA-28002警告的用户不会再碰到同样的提示；
   已经被提示的用户必须再改一次密码，举例如下：
   $sqlplus / as sysdba
    sql> alter user wapgw identified by  <原来的密码>
password_lock_time    UNLIMITED

sqlplus -prelim / as sysdba    强制登陆系统
因为sqlplus  / as sysdba登陆时，会读取系统环境，包括数据字典

但是数据库HANG住后，数据字典也被HANG了
 而sqlplus -prelim / as sysdba是不读取数据字典的
 但是可以用Hanganalyze ，SystemState这样的命令
 来DUMP出内存数据




hanganalyze是ORACLE的一款性能诊断工具，这个款工具是从oracle 8.0.6开始可用，在oracle数据库出现严重的性能问题的时候它可以帮助你定位问题所在。



1.首先说说hanganalyze工具的用法

对于单实例数据库语法如下

alter session set events 'immediate trace name hanganalyze level <level>';

或则使用oradebug进行hanganalyze

conn /as sysdba

SQLPLUS>oradebug hanganalyze <level>;



对于RAC数据的语法如下

con /as sysda

SQLPLUS> oradebug setmypid

SQLPLUS>oradebug setinst all

SQLPLUS>oradebug -g def hanganalyze <level>





关于level的说明：

10     Dump all processes (IGN state)

5      Level 4 + Dump all processes involved in wait chains (NLEAF state)

4      Level 3 + Dump leaf nodes (blockers) in wait chains (LEAF,LEAF_NW,IGN_DMP state)

3      Level 2 + Dump only processes thought to be in a hang (IN_HANG state)

1-2    Only HANGANALYZE output, no process dump at all

#############################

[level  4] :  23 node dumps -- [LEAF] [LEAF_NW] [IGN_DMP]

[level  5] :  36 node dumps -- [NLEAF]

[level 10] : 130 node dumps -- [IGN]







2.dump文件的分析



下面是一个例子：

[oracle@SHDBService01 ~]$ more /data/oracle/admin/ora10g/udump/ora10g_ora_28378.trc

/data/oracle/admin/ora10g/udump/ora10g_ora_28378.trc

Oracle Database 10g Enterprise Edition Release 10.2.0.4.0 - 64bit Production

With the Partitioning, OLAP, Data Mining and Real Application Testing options

ORACLE_HOME = /data/oracle/product/10.2.1

System name:

Linux

Node name:

SHDBService01

Release:



2.6.9-67.ELlargesmp

Version:



#1 SMP Wed Nov 7 14:07:22 EST 2007

Machine:



x86_64

Instance name: ora10g

Redo thread mounted by this instance: 1

Oracle process number: 62

Unix process pid: 28378, image: oracle@SHDBService01 (TNS V1-V3)



*** ACTION NAME:() 2009-08-21 13:36:46.238

*** MODULE NAME:(sqlplus@SHDBService01 (TNS V1-V3)) 2009-08-21 13:36:46.238

*** SERVICE NAME:(SYS$USERS) 2009-08-21 13:36:46.238

*** SESSION ID:(532.3192) 2009-08-21 13:36:46.238

*** 2009-08-21 13:36:46.238

==============

HANG ANALYSIS:

==============

Open chains found:

Chain 1 : <cnode/sid/sess_srno/proc_ptr/ospid/wait_event> :

<0/542/2126/0xd1006f28/25642/SQL*Net message from client>

-- <0/1097/44386/0xd2001048/26064/enq: TX - row lock contention>

Other chains found:

Chain 2 : <cnode/sid/sess_srno/proc_ptr/ospid/wait_event> :

<0/532/3192/0xd1007710/28378/No Wait>

Chain 3 : <cnode/sid/sess_srno/proc_ptr/ospid/wait_event> :

<0/534/3/0xd10096b0/30838/Streams AQ: waiting for time man>

Chain 4 : <cnode/sid/sess_srno/proc_ptr/ospid/wait_event> :

<0/539/3/0xd1008ec8/30830/Streams AQ: qmn coordinator idle>

Chain 5 : <cnode/sid/sess_srno/proc_ptr/ospid/wait_event> :

<0/541/2497/0xd1005f58/16409/jobq slave wait>

Chain 6 : <cnode/sid/sess_srno/proc_ptr/ospid/wait_event> :

<0/1099/3/0xd2002fe8/30840/Streams AQ: qmn slave idle wait>

Extra information that will be dumped at higher levels:

[level  4] :   1 node dumps -- [REMOTE_WT] [LEAF] [LEAF_NW]

[level  5] :   5 node dumps -- [SINGLE_NODE] [SINGLE_NODE_NW] [IGN_DMP]

[level  6] :   1 node dumps -- [NLEAF]

[level 10] :  17 node dumps -- [IGN]



State of nodes

([nodenum]/cnode/sid/sess_srno/session/ospid/state/start/finish/[adjlist]/predecessor):

[531]/0/532/3192/0xd13bd850/28378/SINGLE_NODE_NW/1/2//none

[532]/0/533/655/0xd13bedb8/19321/IGN/3/4//none

[533]/0/534/3/0xd13c0320/30838/SINGLE_NODE/5/6//none

[538]/0/539/3/0xd13c6e28/30830/SINGLE_NODE/7/8//none

[540]/0/541/2497/0xd13c98f8/16409/SINGLE_NODE/9/10//none

[541]/0/542/2126/0xd13cae60/25642/LEAF/11/12//1096

[542]/0/543/1/0xd13cc3c8/30755/IGN/13/14//none

[543]/0/544/1/0xd13cd930/30753/IGN/15/16//none

[544]/0/545/1/0xd13cee98/30751/IGN/17/18//none

[545]/0/546/1/0xd13d0400/30749/IGN/19/20//none

[546]/0/547/1/0xd13d1968/30746/IGN/21/22//none

[547]/0/548/1/0xd13d2ed0/30744/IGN/23/24//none

[548]/0/549/1/0xd13d4438/30734/IGN/25/26//none

[549]/0/550/1/0xd13d59a0/30732/IGN/27/28//none

[550]/0/551/1/0xd13d6f08/30730/IGN/29/30//none

[551]/0/552/1/0xd13d8470/30728/IGN/31/32//none

[1096]/0/1097/44386/0xd23cee98/26064/NLEAF/33/34/[541]/none

[1098]/0/1099/3/0xd23d1968/30840/SINGLE_NODE/35/36//none

[1099]/0/1100/6/0xd23d2ed0/30861/IGN/37/38//none

[1101]/0/1102/1/0xd23d59a0/30742/IGN/39/40//none

[1102]/0/1103/1/0xd23d6f08/30736/IGN/41/42//none

[1651]/0/1652/3/0xd13d3c50/30858/IGN/43/44//none

[1653]/0/1654/1/0xd13d6720/30738/IGN/45/46//none

[2204]/0/2205/1/0xd03d6720/30740/IGN/47/48//none

====================

END OF HANG ANALYSIS

====================





open chains部分例子

Chain 1 : <cnode/sid/sess_srno/proc_ptr/ospid/wait_event> :

<0/542/2126/0xd1006f28/25642/SQL*Net message from client>

-- <0/1097/44386/0xd2001048/26064/enq: TX - row lock contention>

Other chains found:



sid        = Session ID

sess_srno  = Serial#

proc_ptr   = Process Pointer

ospid      = OS Process Id

wait_event = Waitevent

cnode      = Node Id (Only available since Oracle9i)



State of nodes部分例子：

[nodenum]/cnode/sid/sess_srno/session/ospid/state/start/finish/[adjlist]/predecessor

[541]/0/542/2126/0xd13cae60/25642/LEAF/11/12//1096

[1096]/0/1097/44386/0xd23cee98/26064/NLEAF/33/34/[541]/none





Nodenum   = This is secuencial number used by HANGANALYZE to identify each session

 sid       = Session ID

 sess_srno = Serial#

 ospid      = OS Process Id

 state     = State of the node

 adjlist   = adjacent node  (Usually represents a blocker node)

 predecessor = predecessor node (Usually represents a waiter node)

 cnode      = Node number (Only available since Oracle9i)



IN_HANG: This might be considered as the most critical STATE. Basically a node in this state is involved in a deadlock, or is hung. Usually there will be another “adjacent node” in the same status. For example:



LEAF and LEAF_NW: Leaf nodes are considered on top of the wait chain (usually blockers). They are considered “Blockers” when there is another session waiting. This can be easily identified using the “predecesor” field. If there is a node referenced in the ‘prdecessor’ field, the node is considered as “blocker”, otherwise it is considered as a “slow” session waiting for some resource.

The difference between LEAF and LEAF_NW is that LEAF nodes are not waiting for something, while LEAF_NW are not waiting or may be using the CPU



可以看出上面例子中看出

 session  542   2126阻塞了session 1097 44386.


3.在很多情况下如果数据库HANG住则无法登陆sqlplus，这时如果想要对系统进行hanganalyze可以加参数登录sqlplus

具体语法如下：



[oracle@SHDBService01 ~]$ sqlplus -prelim /nolog

SQL*Plus: Release 10.2.0.4.0 - Production on Fri Aug 21 15:42:23 2009

Copyright (c) 1982, 2007, Oracle.  All Rights Reserved.


SQL> conn /as sysdba

Prelim connection established

SQL>

prelim参数只对10g 以后的版本有效。

 10g以前的版本不能登录SQLPLUS时可以使用dbx或则gdb。



查询分区表数据量

 查询分区表记录：


SQL> select * from dinya_test partition(part_01);
select/*+parallel(a 10)*/count(1) from RM_FLOWSET_STATUS partition(RM_FLOWSET_STATUS2013Q3) a;



今天使用了impdp的一个小功能，在做影响分析导数操作应该会用得到，供参考，谢谢。

比如，我们导入生产数据时仅需要表数据、表统计信息、索引统计信息，此时可以使用include功能来实现，如下：

userid='/ as sysdba'
directory=dp_dir
full=y
--TABLE_EXISTS_ACTION=TRUNCATE
include=TABLE_DATA,INDEX_STATISTICS,TABLE_STATISTICS
dumpfile=iocrpt_sj_%U.dmp
logfile=impdp_iocrpt.log
parallel=4
job_name=impdp_iocrpt



提交job语法：

begin
sys.dbms_job.submit(job => :job,
                      what => 'P_CLEAR_PACKBAL;',
                      next_date => to_date('04-08-2008 05:44:09', 'dd-mm-yyyy hh24:mi:ss'),
                      interval => 'sysdate+ 1/360');
commit;
end;
/



－－－－－－－－－－－－－－－－－－－－－－－－－
创建JOB
variable jobno number;
begin
dbms_job.submit(:jobno, 'P_CRED_PLAN;',SYSDATE,'SYSDATE+1/2880',TRUE);
commit;


运行JOB
SQL> begin
         dbms_job.run(:job1);
         end;
         /


删除JOB
SQL> begin
        dbms_job.remove(:job1);
        end;
        /




修改sequence的当前值

declare
  LastValue integer;
begin
  loop
    select SEQ_CONTRACT.currval into LastValue from dual;
    exit when LastValue >= 160 - 1;
    select SEQ_CONTRACT.nextval into LastValue from dual;
  end loop;
end;


重新编译同义词
SELECT 'alter ' || decode(owner,
                          'PUBLIC',
                          'public synonym ',
                          'synonym ' || owner || '.') || object_name ||
       ' compile;'
FROM dba_objects
WHERE object_type = 'SYNONYM'
   AND status = 'INVALID';



或重建sequence


导出序列

SELECT ' CREATE SEQUENCE '||SEQUENCE_owner||'.'||SEQUENCE_NAME|| ' INCREMENT BY '||INCREMENT_BY ||' START WITH '||LAST_NUMBER||' MAXVALUE '||MAX_VALUE ||' CACHE '||CACHE_SIZE||' ORDER NOCYCLE ;'
FROM dba_SEQUENCES
where SEQUENCE_NAME='SEQ_ERROR_ID';

select 'create sequence '||SEQUENCE_owner||'.'||SEQUENCE_NAME||
       ' minvalue '||min_value||
       ' maxvalue '||max_value||
       ' start with '||last_number||
       ' increment by '||increment_by||
        (case when cache_size=0 then ' nocache' else ' cache '||cache_size end) ||
        (case when order_flag='N' then '' else '  order ' end) ||
        (case when cycle_flag='N' then '  NOCYCLE' else '  CYCLE ' end) ||';'
from dba_sequences   where sequence_owner='DBMGR'



属主用户运行：
select dbms_metadata.get_ddl('SEQUENCE',u.object_name) from dba|user_objects u where object_type='SEQUENCE'

数据库需添加临时表空间，否则impdp导入时无法导入，并不提示任何错误信息..


联合主键查询存在

where  (主键a, 主键b)


select a.* from temp.PS_PAIC_EMP_INFO a,
(select /*+  parallel(b 8)*/
 b.emplid, b.paic_out_date
  from SMAPP.PS_PAIC_EMP_INFO b
 where (LAST_NAME not like 'PA%' or NATIONAL_ID not like '1234%' or
       PAIC_MOBILE_PHONE not like '%123456' or PHONE not like '%123456')) b
       where a.emplid = b.emplid
       and a.paic_out_date = b.paic_out_date;



修改sql tuning advisor参数

BEGIN
  DBMS_AUTO_TASK_ADMIN.disable(
    client_name => 'sql tuning advisor',
    operation   => NULL,
    window_name => NULL);
END;
/
BEGIN
  DBMS_AUTO_TASK_ADMIN.disable(
    client_name => 'auto space advisor',
    operation   => NULL,
    window_name => NULL);
END;
/


orapwd file=$ORACLE_HOME/dbs/orasid password=orclsys entries=2

@ /rdbms/admin/catbundle.sql psu apply




 ZT 升级和移植Oracle数据库方法若干 2009-02-03 16:44:50
分类： Oracle
升级数据库和迁移数据库是DBA日常工作中最常见的两种。升级数据库和迁移无非也就是两种方式，一种是从老数据库中exp出,然后在新数据库中导入。另外一种就是使用startup upgrade升级数据库。另外借助于Oracle Rman工具也是能事半功倍的。[@more@]



If you want upgrade your oracle 8i database to 10g, you need make sure upgrade oracle 8i to 8.1.7 frist.

COMPATIBILITY MATRIX
===============================================================
+ Minimum Version of the database that can be directly upgraded to Oracle 10g
Release 2
8.1.7.4 -> 10.2.X.X.X
9.0.1.4 or 9.0.1.5 -> 10.2.X.X.X
9.2.0.4 or higher -> 10.2.X.X.X
10.1.0.2 or higher -> 10.2.X.X.X
+ The following database version will require an indirect upgrade path.
7.3.3 (or lower) -> 7.3.4 -> 8.1.7 -> 8.1.7.4 -> 10.2.X.X.X
7.3.4 -> 8.1.7 -> 8.1.7.4 -> 10.2.X.X.X
8.0.n -> 8.1.7 -> 8.1.7.4 -> 10.2.X.X.X
8.1.n -> 8.1.7 -> 8.1.7.4 -> 10.2.X.X.X


这里介绍一个工作中碰到比较复杂的情况作为例子。

老数据库ORACLE817从HK传过来的
目标数据库是ODC的10.2.0.2,
两者都是在solaris上的，这个过程中不仅需要从命名数据库，而且文件路径不能再现。
其实这是一个迁移的任务。数据库文件有16G，全库EXP文件5G,因此我们选择所以升级数据库，而不是exp/imp.

方法一 先修改控制文件中的文件路径，然后升级，再重命名数据库。

1. parpare 10.2.0.2 oracle software envriment

2. backup this 8i database and shutdown it and it's listner

3. transfer all datafile controlfile redolog to 10g

4. make a new init.ora, specially make sure blow point

a. compatible initalization parameter
b. SGA_AGGREGATE_TARGET >= 150m
C. PGA_AGGREGATE_TARGET >= 120m
D. add "*.undo_tablespace='UNDOTBS1'"

5. modify FULL path of all datafiles and redofiles, it run under 10g

run output sql create by blow sql which is run under in 8i database.

In 8i

SQL>spool adf.sql
select
'alter database rename file '''||df.file_name||''' to '||' ''/oradata/ssz0012dww/noracle/oradata/hkjpcd69/'||substr(df.file_name,instr(df.file_name,'/',-1)+1,100)||''';'
from dba_data_files df;
select
'alter database rename file '''||lf.MEMBER||''' to '||' ''/oradata/ssz0012dww/noracle/oradata/hkjpcd69/'||substr(lf.MEMBER,instr(lf.MEMBER,'/',-1)+1,100)||''';'
from v$logfile lf
spool off;

In 10g
SQL>@adf.sql


6. startup this database in upgrade mode using 10g software

SQL>alter database open upgrade
create SYSAUX and undotbs1 tablespace
CREATE TABLESPACE SYSAUX DATAFILE
'/oradata/ssz0012dww/noracle/oradata/hkjpcd69/_sysaux_4ng5bpdy_.dbf' SIZE 20M
AUTOEXTEND ON NEXT 10M MAXSIZE UNLIMITED
LOGGING
ONLINE
PERMANENT
EXTENT MANAGEMENT LOCAL AUTOALLOCATE
BLOCKSIZE 8K
SEGMENT SPACE MANAGEMENT AUTO
FLASHBACK ON;



SQL>CREATE UNDO TABLESPACE UNDOTBS1 DATAFILE
'/oradata/ssz0012dww/noracle/oradata/hkjpcd69/_undo01.dbf' SIZE 200M AUTOEXTEND ON NEXT 5M MAXSIZE UNLIMITED
ONLINE
RETENTION NOGUARANTEE
BLOCKSIZE 8K
FLASHBACK ON;

alter database open resetlogs upgrade

SQL>spool catelogupgrade.log

@ /rdbms/admin/catupgrd.sql
@ /rdbms/admin/utlrp.sql

@olstrig.sql
运行这个脚本就不会有ora-07445的问题了。



shutdown immediate;
升级过程可能碰到一些错误，可以用 grep "^ORA-" catelogupgrade.log |sore|uniq 来归类察看，我在升级过程中碰到的两个问题，是注意temp和tools表空间是否充足

7. backup this database

8. create a sql script for recreate controlfile
SQL> alter database backup controlfile to trace;
shutdown immediate


9. modify the sql created by step 8 and save it as cc.sql

a.CREATE CONTROLFILE reuse DATABASE NORESETLOGS --> CREATE CONTROLFILE set DATABASE RESETLOGS
b.ALTER DATABASE OPEN; --> ALTER DATABASE OPEN resetlogs;

10. modify databasename in init.ora

11. rename this database by recreate controlfile

SQL>startup nomount
@cc.sql
shutdown immediate
startup


方法二 在热备的方式下直接clone数据，从命名数据库，直接升级。

1. hot backup old database
2. alter database backup controlfile to trace in old database
3. host cp all files to target folder
4. modify file from step 2 and save is as cc.sql, it process renameing database name and alter datafile path.
4. startup nomount newdatabase
5. @cc.sql
6. recover database
7. alter database open resetlogs upgrade

add tempfile
8. @catupgrd.sql and @ utlrp.sql


@ /rdbms/admin/

此种方法主要需要关注的在于 6 步 recover database，9i 和 10g 的archive log 结构上是相同的，所以可以跨版本apply, 8i-->10g的没有测试过。


exp/imp 方式升级8i数据库到10g的例子可以参考 itpub.net上的一篇文章
http://www.itpub.net/thread-1078953-1-1.html


Ref List

Oracle  Database Upgrade Guide 10g Release 2 (10.2)
http://download.oracle.com/docs/cd/B19306_01/server.102/b14238/toc.htm

"migration db to 10g" from metalink.oracle.com
Note:263809.1

感谢我的同事老万在第二方式给于的建议和帮助。








对象统计信息锁定的解决办法
解决办法很明确，就是解锁。
可以从两个层面去处理：
A、解锁Schema

DBMS_STATS.UNLOCK_schema_STATS(user);


B、解锁单个对象
1)先查出被锁定的表select table_name from user_tab_statistics where stattype_locked is not null;
然后再解锁对象
exec dbms_stats.unlock_table_stats(user,'表名');
2)也可直接生成sql脚本
select 'exec dbms_stats.unlock_table_stats('''||user||''','''||table_name||''');' from user_tab_statistics where stattype_locked is not null;
这里不在生成的sql中用动态的user是为了让执行者明确知道到底是解锁哪个schema下的表，防止误操作。

一般而言，这是为了稳定执行计划，因为在Oracle 10g以上，Oracle默认会自动收集统计信息，要想锁住统计信息，请使用LOCK_SCHEMA_STATS、LOCK_TABLE_STATS包。


首选的当然是使用自动管理表空间的方式。

SQL> alter system set undo_tablespace=UNDOTBS scope=spfile;

System altered.

SQL> alter system set undo_management=auto scope=spfile;

System altered.

SQL> shutdown immediate
Database closed.
Database dismounted.
ORACLE instance shut down.
SQL> startup
ORACLE instance started.

Total System Global Area   96468992 bytes
Fixed Size                  1217884 bytes
Variable Size              88083108 bytes
Database Buffers            4194304 bytes
Redo Buffers                2973696 bytes
Database mounted.
Database opened.

select *
From V$Transaction, V$Session
Where Taddr=Addr and
Sid=(select sid from v$mystat where rownum<2);


SQL1:执行此sql会产生事务，why？
select *
  from rv_abbs_pre_sale_detail a

//执行此sql又不会产生事务，why？
select *
  from rv_abbs_pre_sale_detail a
where rownum<10000;
 a.POLICYINFO_ID = '00000000000000406084';


select s.sid,s.serial#,s.sql_hash_value,
   r.segment_name,
   t.xidusn,
   t.xidslot,
   t.xidsqn,t.USED_UBLK
   from v$session s,
   v$transaction t,
   dba_rollback_segs r
   where s.taddr = t.addr
   and t.xidusn = r.segment_id(+) and s.sid=570;

ORA-01555: snapshot too old: rollback segment number 3 with name "_SYSSMU3$" too small
空闲空间很大，有可能segment许多已被offline：
1、增大回滚段表空间。

或
2、更改表空间


Oracle undo释放表空间中的操作步骤

查看各表空间名称
select name from v$tablespace

查看某个表空间信息
select file_name,bytes/1024/1024 from dba_data_files where tablespace_name like 'undoTBS1';

查看回滚段的使用情况，哪个用户正在使用回滚段的资源，如果有用户最好更换时间（特别是生产环境）。
select s.username, u.name from v$transaction t,v$rollstat r, v$rollname u,v$session s  where s.taddr=t.addr and t.xidusn=r.usn and r.usn=u.usn order by s.username;

检查undo Segment状态
select usn,xacts,rssize/1024/1024/1024,hwmsize/1024/1024/1024,shrinks from v$rollstat order by rssize; 创建新的undo表空间，并设置自动扩展参数；

create undo tablespace undotbs2 datafile 'D:\Oracle \PRODUCT\10.1.0\ORADATA\ORCL\undoTBS02.DBF' size 10m reuse autoextend on next 100m maxsize unlimited; 动态更改spfile配置文件；

alter system set  undo _tablespace=undotbs2 scope=both; 等待原UNDO表空间所有Oracle UNDO SEGMENT OFFLINE；

select usn,xacts,status,rssize/1024/1024/1024,hwmsize/1024/1024/1024,shrinks from v$rollstat order by rssize; 再执行看UNDO表空间所有UNDO SEGMENT ONLINE；

select usn,xacts,status,rssize/1024/1024/1024,hwmsize/1024/1024/1024,shrinks from v$rollstat order by rssize; 删除原有的UNDO表空间；

drop tablespace undotbs1 including contents; 确认删除是否成功；

select name from v$tablespace;


再烦，也别忘微笑；再急，也要注意语气: 再苦，也别忘坚持；再累，也要爱自己

关于 分布式Oracle中 database link
在做分布式数据库时难免用到dblink，但关于dblink的资料很少，很多书上提到了，但不详细。

数据库链接定义从一个Oracle数据库到另一个数据库的单行通信通道。
建立链接前要先有到远程数据库的命名服务（连接字符串），就是tnsnames.ora中描述的那个，如'oradXP'
先测试一下：$tnsping oradxp
Attemping to contact(...) OK(30毫秒).
说明对远程数据库oradxp可访问。


创建数据库链接的语法为：
CREATE PUBLIC DATABASE LINK oradxp.cug.edu.cn USING 'oradxp';
其中 oradxp.cug.edu.cn 必须是远程数据库的全局名(SID),'oradxp'就是到远程的连接字符串。远程数据库的全局名可以通过登陆远程机，
SELECT * FROM global_name;
得到。
现在你就可以用链接oradxp.cug.edu.cn访问远程数据库了
如
SELECT * FROM global_name@oradxp.cug.edu.cn;
看看得到的是不是远程机的全局名。
所有SELECT 语句后面跟上链接名都是对远程机的访问。
注意：登陆名口令就是当前登陆本机的用户名和口令。也就是如果你用的是public链接，那么在远程就要有一个和本机相同的用户/口令才行。如：你以aaa/aaa登录本机，然后执行
SELECT * FROM BBB.bbb@oradxp.cug.edu.cn;
那么对远程数据BBB.bbb的访问用户为aaa口令为aaa
也就是在本机和远程机上都有用户aaa口令都为aaa才能执行成功！
关于私有链接：
CREATE DATABASE LINK oradxp.cug.edu.cn CONNECT TO system IDENTIFIED BY aaa;
这就建立了system的私有链接。
私有链接和public链接的差别就是登录名口令的限制。也就是

你不管用什么用户登录本机，执行
SELECT * FROM BBB.bbb@oradxp.cug.edu.cn;
访问远程机数据BBB.bbb的用户和口令都为system/aaa
建好的数据链接放在系统表SYS.link$表中
通过OEM控制台的 分布-〉数据库链接可以查看所有的链接。
要删除public link 可以
drop public database link linkname;
对于私有链接先以相应用户登陆，如上述system/aaa
然后drop database link linkname;
当然，直接删除SYS.link$表中的记录一样可行。

---------------------------------------------

不放心的dblink--手工关闭dblink [REF]  db_link
在csdn里看用户问道了有关dblink的关闭问题，本人一直对这个dblink持保留态度，如果不用最好不用。
在我们使用dblink对远程的oracle数据库进行操作时，这个dblink的访问会单独创建到远程的一次会话，这个到远程数据库的session，并不会在你建立的以后就自动的关闭和远程服务器建立的session，所以这是很可怕的，如果一个不断查询会产生很多个到远程的数据库session，如果session太多，造成查询失败，所以只要一点，笔者一直对这个dblink这个技术保持着保留态度，能不去使用她，尽量不去使用她。
不过如果使用dblink，我们需要及时显示的关闭dblink。以下提供两种方式
1.
alter sesssion close database link <dblink_name>;
2.
dbms_session.close_database_link(<dblink_name>);
如果是每个连接之后，还要用户去commit，以及手工的去colse一下。实在是痛苦之至呀。

------------------------------------------

如果Oracle数据库是以read only模式打开的，则无法通过db link访问远程数据库。因为只要通过db link，即使只执行select，oracle也是要开启分布式事务支持的，事务需要分配回滚段，而read only模式下是没有online的回滚段的：

SQL>select 1 from dual@lnk_db1;

select 1 from dual@lnk_db1

*

ERROR at line 1: ORA-16000: database open for read-only access

在一个read write的库上做个测试，可以看到通过db link的查询确实开启了事务，并且分配了回滚段。

SQL>select sid from v$mystat where rownum=1;

       SID
----------
      1270

SQL>select 1 from dual@lnk_db1;

         1
----------
         1

SQL>select s.sid,s.serial#,s.sql_hash_value,
  2   r.segment_name,
  3   t.xidusn,
  4   t.xidslot,
  5   t.xidsqn
  6   from v$session s,
  7   v$transaction t,
  8   dba_rollback_segs r
  9   where s.taddr = t.addr
 10   and t.xidusn = r.segment_id(+);

       SID    SERIAL# SQL_HASH_VALUE SEGMENT_NA     XIDUSN    XIDSLOT     XIDSQN
---------- ---------- -------------- ---------- ---------- ---------- ----------
      1270      37655              0 _SYSSMU10$         10         45    2042124
可以看到session 1270虽然只执行了一条select语句，但是由于使用了db link，确实开启了一个活动事务，并且分配了一个回滚段_SYSSMU10$。

Update：七公提醒了一下，实际上还是有办法绕过这个问题的。Oracle提供了read only的事务，是无须用到回滚段的。

SQL>select 1 from dual@lnk_db1;
select 1 from dual@lnk_db1
              *
ERROR at line 1:
ORA-16000: database open for read-only access

SQL>set transaction read only;

Transaction set.

SQL>select 1 from dual@lnk_db1;

         1
----------
         1
49.关闭dblink
50.
51.在csdn里看用户问道了有关dblink的关闭问题，本人一直对这个dblink持保留态度，如果不用最好不用。
52.在我们使用dblink对远程的oracle数据库进行操作时，这个dblink的访问会单独创建到远程的一次会话，这个到远程数据库的session，并不会在你建立的以后就自动的关闭和远程服务器建立的session，所以这是很可怕的，如果一个不断查询会产生很多个到远程的数据库session，如果session太多，造成查询失败，所以只要一点，笔者一直对这个dblink这个技术保持着保留态度，能不去使用她，尽量不去使用她。
53.不过如果使用dblink，我们需要及时显示的关闭dblink。以下提供两种方式
54.1.alter sesssion close database link <dblink_name>;
55.2.dbms_session.close_database_link(<dblink_name>);
56.如果是每个连接之后，还要用户去commit，以及手工的去colse一下。实在是痛苦之至呀




另外，我们也可以继续沿用老的手动管理回滚段的方式。

SQL> create rollback segment rbs01;

Rollback segment created.

SQL> alter rollback segment rbs01 online;

Rollback segment altered.

SQL> select segment_name, tablespace_name, status from dba_rollback_segs;



使用drop database link 命令是无法删除其他schema下的dblink的，是否还有其他办法呢？下面是从网上找到的两个方法：
方法一、使用下面的脚本，使用job方式删除dblink
begin
  dbms_scheduler.create_job(
    job_name=>'&owner..drop_database_link',
    job_type=>'PLSQL_BLOCK',
    job_action=>'BEGIN execute immediate ''drop database link &db_link'';END;'
  );
  dbms_scheduler.run_job('&owner..drop_database_link',false);
  dbms_lock.sleep(2);
  dbms_scheduler.drop_job('&owner..drop_database_link');
end;
/
输入变量需要使用大写。
SQL> begin
  2    dbms_scheduler.create_job(
  3      job_name=>'&owner..drop_database_link',
  4      job_type=>'PLSQL_BLOCK',
  5      job_action=>'BEGIN execute immediate ''drop database link &db_link'';END;'
  6    );
  7    dbms_scheduler.run_job('&owner..drop_database_link',false);
  8    dbms_lock.sleep(2);
  9    dbms_scheduler.drop_job('&owner..drop_database_link');
 10  end;
 11  /
Enter value for owner: LIUTYA
old   3:     job_name=>'&owner..drop_database_link',
new   3:     job_name=>'LIUTYA.drop_database_link',
Enter value for db_link: LECCTEST
old   5:     job_action=>'BEGIN execute immediate ''drop database link &db_link'';END;'
new   5:     job_action=>'BEGIN execute immediate ''drop database link LECCTEST'';END;'
Enter value for owner: LIUTYA
old   7:   dbms_scheduler.run_job('&owner..drop_database_link',false);
new   7:   dbms_scheduler.run_job('LIUTYA.drop_database_link',false);
Enter value for owner: LIUTYA
old   9:   dbms_scheduler.drop_job('&owner..drop_database_link');
new   9:   dbms_scheduler.drop_job('LIUTYA.drop_database_link');

PL/SQL procedure successfully completed.

SQL> select * from dba_db_links;
no rows selected
测试成功。
重建测试环境

方法二、使用下面的存储过程
Create or replace procedure Drop_DbLink(schemaName varchar2, dbLink varchar2 ) is
            plsql   varchar2(1000);
            cur     number;
            uid     number;
            rc      number;
    begin
            select
                    u.user_id into uid
           from    dba_users u
           where   u.username = schemaName;
             plsql := 'drop database link "'||dbLink||'"';
             cur := SYS.DBMS_SYS_SQL.open_cursor;
             SYS.DBMS_SYS_SQL.parse_as_user(
                   c => cur,
                   statement => plsql,
                   language_flag => DBMS_SQL.native,
                   userID => uid
          );
             rc := SYS.DBMS_SYS_SQL.execute(cur);


             SYS.DBMS_SYS_SQL.close_cursor(cur);
   end;
   /
 SQL> Create or replace procedure Drop_DbLink(schemaName varchar2, dbLink varchar2 ) is
  2              plsql   varchar2(1000);
  3              cur     number;
  4              uid     number;
  5              rc      number;
  6      begin
  7              select
  8                      u.user_id into uid
  9             from    dba_users u
 10             where   u.username = schemaName;
 11               plsql := 'drop database link "'||dbLink||'"';
 12               cur := SYS.DBMS_SYS_SQL.open_cursor;
 13               SYS.DBMS_SYS_SQL.parse_as_user(
 14                     c => cur,
 15                     statement => plsql,
 16                     language_flag => DBMS_SQL.native,
 17                     userID => uid
 18            );
 19               rc := SYS.DBMS_SYS_SQL.execute(cur);
 20
 21               SYS.DBMS_SYS_SQL.close_cursor(cur);
 22     end;
 23     /

Procedure created.
注意输入参数全部为大写。
SQL> exec drop_dblink('LIUTYA','LECCTEST');
PL/SQL procedure successfully completed.

SQL> select * from dba_db_links;
no rows selected

SQL> drop procedure drop_dblink;
Procedure dropped.

C) Create a procedure as below from “SYS” user.

SQL>  Create or replace procedure Drop_DbLink(schemaName varchar2, dbLink varchar2 ) is
            plsql   varchar2(1000);
            cur     number;
            uid     number;
            rc      number;
    begin
            select
                    u.user_id into uid
           from    dba_users u
           where   u.username = schemaName;
             plsql := 'drop database link "'||dbLink||'"';
             cur := SYS.DBMS_SYS_SQL.open_cursor;
             SYS.DBMS_SYS_SQL.parse_as_user(
                   c => cur,
                   statement => plsql,
                   language_flag => DBMS_SQL.native,
                   userID => uid
          );
             rc := SYS.DBMS_SYS_SQL.execute(cur);

             SYS.DBMS_SYS_SQL.close_cursor(cur);
   end;
   /
Procedure created.
SQL>D) Now drop one DB_LINK of a Private user

SQL> exec Drop_DbLink( 'CKPT', 'DEVWEBSTORE10G_IC.CKPT.COM' );
PL/SQL procedure successfully completed.
SQL>
SQL> select db_link,owner from dba_db_links where owner='CKPT' and db_link='DEVWEBSTORE10G_IC.CKPT.COM';
no rows selected
SQL>Here No DB_LINK exists with the above name after Executing Procedure.

Step 2:- How to DROP ALL DB_LINKS of a “PRIVATE” schema from “SYS” user

This procedure is an extended for the above procedure “Drop_DbLink”, Create a procedure named “Dropschema_dblinks”

create or replace procedure DropSchema_DbLinks(schemaName varchar2 ) is
    begin
            for link in(
                    select
                            l.db_link
                    from    dba_db_links l
                    where   l.owner = schemaName
            ) loop
                    Drop_DbLink(
                           schemaName => schemaName,
                           dbLink => link.db_link
                   );
           end loop;
   end;
   /
Procedure created.
SQL>

SQL> select owner, db_link from dba_db_links where owner ='CKPT';
 OWNER                          DB_LINK
------------------------------ ------------------------------
CKPT                            DEVWEBSTORE9I_IC.CKPT.COM
CKPT                            DEVWEBSTORE9I_IC.WORLD
CKPT                            INTER_EDI_RO.CKPT.COM
CKPT                            ORDERSHIPPING.CKPT.COM
CKPT                            ORDERSHIPPING.WORLD
CKPT                            SVC_IW.CKPT.COM
6 rows selected.

SQL> exec dropschema_dblinks('CKPT');
 PL/SQL procedure successfully completed.
SQL>

SQL> select owner, db_link from dba_db_links where owner ='CKPT';
no rows selected
SQL>


可以给私有DBLINK用户下创建个简单的存储过程，过程中调用DBLINK来验证。

举例：
CREATE OR REPLACE PROCEDURE owner.procedure_name
AS
p_int NUMBER(10);
BEGIN
  SELECT 1 INTO p_int FROM test@db_link;
  DBMS_OUTPUT.PUT_LINE(p_int);
EXCEPTION
  WHEN OTHERS THEN
    DBMS_OUTPUT.PUT_LINE(‘error.’);
END;

然后使用sys执行这个过程，如果打印输出“1”那说明dblink是有效的。如果到异常中，那说明dblink无效。




开trace
ALTER SESSION SET SQL_TRACE = TRUE;

ORA-12519和ORA-12514问题解决记录 .
是说processes设置过小导致的



数据库版本是10.2.0.4,在执行expdp导出时，按ctrl+c结束，再次执行expdp，报错：

UDI-00008: operation generated ORACLE error 31623
ORA-31623: a job is not attached to this session via the specified handle
ORA-06512: at "SYS.DBMS_DATAPUMP", line 2772
ORA-06512: at "SYS.DBMS_DATAPUMP", line 3886
ORA-06512: at line 1

查看metalink，发现如下解释：

Applies to:
Oracle Server - Enterprise Edition - Version: 10.2.0.1 to 10.2.0.4
This problem can occur on any platform.

Symptoms
An export or import operation using DataPump fails with the following errors:

UDI-00008: operation generated ORACLE error 31623
ORA-31623: a job is not attached to this session via the specified handle
ORA-06512: at "SYS.DBMS_DATAPUMP", line 2772
ORA-06512: at "SYS.DBMS_DATAPUMP", line 3886
ORA-06512: at line 1

and the alert log file of the database shows the error:

ORA-00600: internal error code, arguments: [kwqbgqc: bad state], [1], [1], [], [], [], [], []



Cause
A Datapump queue is invalid.

This can happen after reruning the catpatch.sql or utlrp.sql scripts


Solution
1. Shutdown the database cleanly:

     SQL> shutdown immediate
     SQL> startup restrict

2. Drop the queue table.

    SQL> exec dbms_aqadm.drop_queue_table(queue_table=>'SYS.KUPC$DATAPUMP_QUETAB',force=>TRUE);

NOTE:
- If the ORA-4020 error is reported, wait some minutes and try again
- If an ORA-24* error is reported, it could be necessary to perform. a manual cleanup
See Note 203225.1 "How to Manually Cleanup Advanced Queuing Tables"

3. Recreate the queue
    The SQL is in the Note 361025.1 or you can pull it from the catdpb.sql script. in $ORACLE_HOME/rdbms/admin directory.

-- Create our queue table.
BEGIN
dbms_aqadm.create_queue_table(queue_table => 'SYS.KUPC$DATAPUMP_QUETAB',
multiple_consumers => TRUE,
queue_payload_type =>'SYS.KUPC$_MESSAGE',
comment => 'DataPump Queue Table',
compatible=>'8.1.3');
EXCEPTION
WHEN OTHERS THEN
IF SQLCODE = -24001 THEN NULL;
ELSE RAISE;
END IF;
END;
/

4. Run utlrp.sql to recompile all the database objects..

5. Retry the DataPump operation


References
Note 203225.1 - How to Manually Cleanup Advanced Queuing Tables
Note 361025.1 - Invalid Objects After Installing a 10.2 Patchset

Keywords
QUEUE_TABLE ; DATAPUMP ; DBMS_DATAPUMP ;

按照这个文档提供的解决方法进行操作，问题得到解决。



UDI-31623: operation generated ORACLE error 31623
ORA-31623: a job is not attached to this session via the specified handle
ORA-06512: at "SYS.DBMS_DATAPUMP", line 3326
ORA-06512: at "SYS.DBMS_DATAPUMP", line 4551
ORA-06512: at line 1

执行@ /rdbms/admin/catproc.sql



清除stoped impdp/expdp job的方法 2008-09-11 12:07:47
分类： Linux
stoped impdp/expdp job会在dba_datapump_jobs中留下一条记录，显示为not running.
清除stopped job分两种情况：
1) job能够attach
如果job能够attach, 则可以attach后再kill job.
如：expdp system/**** attach=SYS_EXPORT_TABLE_01
        kill_job

2) job无法attach
如果job无法attach, 则需要删除连接DataPump的用户下的master table.
如：conn system/*****
        drop table SYS_EXPORT_TABLE_01　(master table名称一般与job name相同)

以上的用户名和job name都可以从dba_datapump_jobs中得到。




最近调整了一下一个服务器ORALCE（11G）的内存，结果原来做的一个自动数据泵备份不好使了，手动在CMD下执行EXPDP命令，出现错误：

ORA-31236: 作业没有通过指定的句柄连接到此会话

ORA-06512: at "SYS.DBMS_DATAPUMP", line 2772
ORA-06512: at "SYS.DBMS_DATAPUMP", line 3886
ORA-06512: at line 1



在网上查了一下，总结了以下步骤来解决：

1、看看streams_pool_size的大小,我的ORACLE出问题前没设置，默认是0，我给设置了512M,貌似数据泵备份要用到这个玩意

  alter system set streams_pool_size=512M;

2、接下来这个是一个牛人整的，我抄过来了，不过他说要关闭数据库再重启，我没理他，直接执行:

  exec dbms_aqadm.drop_queue_table(queue_table=>'SYS.KUPC$DATAPUMP_QUETAB',force=>TRUE);

  --再重建

  -- Create our queue table.
BEGIN
dbms_aqadm.create_queue_table(queue_table => 'SYS.KUPC$DATAPUMP_QUETAB',
multiple_consumers => TRUE,
queue_payload_type =>'SYS.KUPC$_MESSAGE',
comment => 'DataPump Queue Table',
compatible=>'8.1.3');
EXCEPTION
WHEN OTHERS THEN
IF SQLCODE = -24001 THEN NULL;
ELSE RAISE;
END IF;
END;
/

3、在$ORACLE_HOME/RDBMS/ADMIN下有个utlrp.sql,执行一下，OK，然后在进行数据泵备份，没问题了！



查找进程对应的sql/

select /*+rule*/s.SID,
       s.SERIAL#,
       s.USERNAME,
       p.SPID,
       w.EVENT,
       to_char(s.LOGON_TIME, 'yyyy-mm-dd hh24:mi:ss') as LOGON_TIME,
       r.job,
       j.WHAT,
       r.LAST_DATE,r.THIS_DATE
  from v$process p, v$session s, dba_jobs_running r,dba_jobs j, v$session_wait w
 where p.ADDR = s.PADDR
 and s.sid=r.SID(+)
 and s.SID=w.SID(+)
 and r.JOB=j.JOB(+)
   and p.SPID in (4651, 4670, 5607, 5609, 6731, 19990, 25339);




SET SERVEROUTPUT ON SIZE 10000000

只要在BEGIN下面加一行dbms_output.enable(10000000);，一切问题全部搞定。具体脚本见附件！

ERROR at line 1:
ORA-20000: ORU-10027: buffer overflow, limit of 2000 bytes
ORA-06512: at "SYS.DBMS_OUTPUT", line 35
ORA-06512: at "SYS.DBMS_OUTPUT", line 198
ORA-06512: at "SYS.DBMS_OUTPUT", line 139
ORA-06512: at line 429


ORA-20000: 是因为overflow，一般方法为设置值大一些。

set long 10000;
set linesize 10000;
set serverout on size 10000;



下面是可能出现的几种情况。

1  ORU-10027:buffer overflow limit of 2000 bytes；

方法1：set serveroutput on size 10000000 //设置大点,默认为2000 bytes

方法2：exec dbms_output.enable(999999999999999999999); //默认为2000 bytes

2  ORU-10028:line length overflow,limit of 255 chars per line ;

oracle 10g release2中取消了255个字节的限制。之前的版本，会有255字节的限制。

上面的设置调整都不起作用。在10.2前的版本，对于不太长的内容，可以使用SUBSTR函数来解决这个问题。不确定长度的，目前还没找到解决办法。


两表关联更新

update TA a set(name, remark)=(select b.name, b.remark from TB b where b.id=a.id);

update TA a set(name, remark)=(select b.name, b.remark from TB b where b.id=a.id)
where exists(select 1 from TB b where b.id=a.id)

update TA a set(name, remark)=(select b.name, b.remark from TB b where b.id=a.id)
where exists(select 1 from TB b where b.id=a.id)
注意如果不添加后面的exists语句，TA关联不到的行name, remark栏位将被更新为NULL值， 如果name, remark栏位不允许为null，则报错。 这不是我们希望看到的。

SQL/Oracle 两表关联更新 .
分类： SQL Server Oracle 2011-11-18 10:09 4098人阅读 评论(0) 收藏 举报
nulltableinsertoraclejoin脚本
   有TA, TB两表，假设均有三个栏位id, name, remark. 现在需要把TB表的name, remark两个栏位通过id关联，更新到TA表的对应栏位。

建表脚本：


[sql] view plaincopyprint 
01.drop table TA;
02.create table TA
03.(
04.id number not null,
05.name varchar(10) not null,
06.remark varchar(10) not null
07.);
08.
09.drop table TB;
10.create table TB
11.(
12.id number not null,
13.name varchar(10) not null,
14.remark varchar(10) not null
15.);
16.
17.truncate table TA;
18.insert into TA values(1, 'Aname1', 'Aremak1');
19.insert into TA values(2, 'Aname2', 'Aremak2');
20.commit;
21.
22.truncate table TB;
23.insert into TB values(1, 'Bname1', 'Bremak1');
24.insert into TB values(3, 'Bname3', 'Bremak3');
25.commit;
26.
27.select * from TA;
28.select * from TB;
drop table TA;
create table TA
(
id number not null,
name varchar(10) not null,
remark varchar(10) not null
);

drop table TB;
create table TB
(
id number not null,
name varchar(10) not null,
remark varchar(10) not null
);

truncate table TA;
insert into TA values(1, 'Aname1', 'Aremak1');
insert into TA values(2, 'Aname2', 'Aremak2');
commit;

truncate table TB;
insert into TB values(1, 'Bname1', 'Bremak1');
insert into TB values(3, 'Bname3', 'Bremak3');
commit;

select * from TA;
select * from TB;

SQLServer/Oracle版本的Update写法分别如下：

1. SQLServer


[sql] view plaincopyprint 
01.update TA set name=b.name, remark=b.remark from TA a inner join TB b on a.id = b.id
update TA set name=b.name, remark=b.remark from TA a inner join TB b on a.id = b.id或者

[sql] view plaincopyprint 
01.update TA set name=b.name, remark=b.remark from TA a, TB b where a.id = b.id
update TA set name=b.name, remark=b.remark from TA a, TB b where a.id = b.id
注意不要在被更新表的的栏位前面加别名前缀，否则语法静态检查没问题，实际执行会报错。

Msg 4104, Level 16, State 1, Line 1
The multi-part identifier "a.name" could not be bound.

2. Oracle


[sql] view plaincopyprint 
01.update TA a set(name, remark)=(select b.name, b.remark from TB b where b.id=a.id)
02.where exists(select 1 from TB b where b.id=a.id)
update TA a set(name, remark)=(select b.name, b.remark from TB b where b.id=a.id)
where exists(select 1 from TB b where b.id=a.id)注意如果不添加后面的exists语句，TA关联不到的行name, remark栏位将被更新为NULL值， 如果name, remark栏位不允许为null，则报错。 这不是我们希望看到的。


[sql] view plaincopyprint 
01.--when name, remark is not null, cause error.
02.--if allow null, rows in TA not matched will be update to null.
03.update TA a set(name, remark)=(select b.name, b.remark from TB b where b.id=a.id);
--when name, remark is not null, cause error.
--if allow null, rows in TA not matched will be update to null.
update TA a set(name, remark)=(select b.name, b.remark from TB b where b.id=a.id);
可考虑的替代方法：


[sql] view plaincopyprint 
01.update TA a set name= nvl((select b.name from TB b where b.id=a.id), a.name);
02.update TA a set remark= nvl((select b.remark from TB b where b.id=a.id), a.remark);
update TA a set name= nvl((select b.name from TB b where b.id=a.id), a.name);
update TA a set remark= nvl((select b.remark from TB b where b.id=a.id), a.remark);
如果TA.id, TB.id是unique index或primary key

可以使用视图更新的语法：


[sql] view plaincopyprint 
01.ALTER TABLE TA ADD CONSTRAINT TA_PK
02.  PRIMARY KEY (
03.  ID
04.)
05. ENABLE
06. VALIDATE
07.;
08.
09.ALTER TABLE TB ADD CONSTRAINT TB_PK
10.  PRIMARY KEY (
11.  ID
12.)
13. ENABLE
14. VALIDATE
15.;
16.
17.update (select a.name, b.name as newname,
18.a.remark, b.remark as newremark from TA a, TB b where a.id=b.id)
19.set name=newname, remark=newremark;



Oracle没有update from语法，可以通过两种实现方式：
1、利用子查询：
     update    A
     SET    字段1=（select    字段表达式    from    B    WHERE    ...）,
       字段2=（select    字段表达式    from    B    WHERE    ...）
     WHERE    逻辑表达式

   UPDATE多个字段两种写法：


写法一：

UPDATE table_1 a
   SET col_x1 = (SELECT b.col_y1, b.col_y2 FROM table_2 b WHERE b.col_n = a.col_m),
       col_x2 = (SELECT b.col_y2 FROM table_2 b WHERE b.col_n = a.col_m)
WHERE EXISTS (SELECT * FROM table_2 b WHERE b.col_n = a.col_m)

或

UPDATE table_1 a
   SET col_x1 = (SELECT b.col_y1, b.col_y2 FROM table_2 b WHERE b.col_n = a.col_m),
       col_x2 = (SELECT b.col_y2 FROM table_2 b WHERE b.col_n = a.col_m)
WHERE a.col_m=(SELECT b.col_n FROM table_2 b WHERE b.col_n = a.col_m)


写法二：

UPDATE table_1 a
   SET (col_x1, col_x2) = (SELECT b.col_y1, b.col_y2 FROM table_2 b WHERE b.col_n = a.col_m)
WHERE EXISTS (SELECT * FROM table_2 b WHERE b.col_n = a.col_m);

或

UPDATE table_1 a
   SET (col_x1, col_x2) = (SELECT b.col_y1, b.col_y2 FROM table_2 b WHERE b.col_n = a.col_m)
WHERE a.col_m=(SELECT b.col_n FROM table_2 b WHERE b.col_n = a.col_m)


注意：

 1. 对于子查询的值只能是一个唯一值，不能是多值。
        2. 子查询在绝大多数情况下，最后面的where EXISTS子句是重要的，否则将得到错误的结果。且where EXISTS子句可用另一方法代替，如上。最后的子句是对a表被更新记录的限制，如无此句，对于a表中某记录，如在b表中关联不到对应的记录,则该记录被更新字段将被更新为null。where EXISTS子句就是排除对a表中该情况的记录进行更新。

2、利用视图：


UPDATE (SELECT A.NAME ANAME,B.NAME BNAME FROM A,B WHERE A.ID=B.ID)
SET ANAME=BNAME;

   注意：

    1. 对于视图更新的限制：
    如果视图基于多个表的连接，那么用户更新（update）视图记录的能力将受到限制。除非update只涉及一个表且视图列中包含了被更新的表的整个主键，否则不能更新视图的基表。


另外，Oracle中的Delete的from子句也没有多表联接的功能，只能通过子查询的方式来做：
delete from 表A where exists (select * from 表B where 表A.empid=表B.empid)
delete from 表A where 表A.empid in (select empid from 表B)


三、oracle视图多表更新

在oracle中通常如果视图的数据源来自单表则该视图可以进行更新。而如果视图数据源来自两个以上表时这个视图是不可更新的。但有时候为了操作的方便我们更希望能够对多表视图也进行更新。

这时候我们可以通过建立更新触发器来替代该视图原有更新以达到多表更新的效果

例如：

3.1 创建测试数据表
--===================================================
--创建测试表
--===================================================
Drop Table t1;
Drop Table t2;
create table t1
( t11 numeric(28),t12 varchar2(20));
create table t2
( t11 numeric(28),t22 varchar2(20));

3.2 多表视图范例
--===================================================
--创建测试视图
--===================================================
create Or Replace view t as
   select T1.t11 f1 ,T1.t12 f2 ,T2.t22 f3
      from T1,T2
      Where T1.t11=T2.t11;

3.3 多表视图触发器范例
--===================================================
--创建视图的替代触发器
--===================================================
Create Or Replace Trigger Trg_InsUpdDel_t
Instead Of Insert or update or delete
on t
for each row
Declare
begin
   If Inserting Then
      Insert Into t1 (t11,t12) Values (:New.f1,:New.f2);
      Insert Into t2 (t11,t22) Values (:New.f1,:New.f3);
   elsif Updating Then
      Update t1 set t11=:New.f1,t12=:New.f2 where t11=:New.f1;
      Update t2 set t11=:New.f1,t22=:New.f3 where t11=:New.f1;
   elsif Deleting then
      Delete from t1 where t11=:Old.f1;
      Delete from t2 where t11=:Old.f1;
   End if;
end;
如此即实现多表可更新视图的定义工作 。



ERROR at line 1:
ORA-28365: wallet is not open


可以看到，因为数据库重启后，加密钱夹处于关闭状态，这时只要查询到加密的列，会提示加密钱夹没有打开。

如果用户想打开钱夹，必须具有alter system权限。

下面打开wallet：
SQL> conn / as sysdba
Connected.
SQL> alter system set wallet open identified by "ppppp";




确定文件和快ID的查询

select segment_name, file_id, block_id from dba_extents where owner='OE' and segment_name like 'ORDERS%';


select header_file,header_block from dba_segments where segment_name ='PERSONS';

接着，可以使用相应的文件和块号
alter system dump datafile 397 block 32811;

到trc文件中找到转储信息中的obj#,
执行以下查询
select  name from sys.obj$ where obj#='4916681';

设定sqlplus 提示符

set sqlprompt "_user'@'_connect_identifier >"

call 和exec 区别

call 调用过程时必须加括号()，即使没有参数
而exec不用.

9i
select '&'||'#'||'&'||hash_value||'&'||'#'||'&     '||sql_text||';' from dbmgr.my_sqltext_new
where upper(sql_text) like '%%'


1.10、11g抓取sql以及导出
     运维DBA执行SPA抓取SQL脚本, 详细如下：

  ---------------------------------------------------
  --Step1: 创建名称为STS_NAME_ZY_1030的SQL_SET.
---------------------------------------------------
BEGIN
DBMS_SQLTUNE.CREATE_SQLSET(SQLSET_NAME => 'STS_NAME_dkf_0225',
          DESCRIPTION => 'COMPLETE APPLICATION WORKLOAD',
          SQLSET_OWNER =>'DBMGR');
END;
/
---------------------------------------------------
--Step2: 初始加载当前数据库中的SQL.
---------------------------------------------------
DECLARE
   STSCUR   DBMS_SQLTUNE.SQLSET_CURSOR;
   v_cnt    NUMBER;
BEGIN
   OPEN STSCUR FOR
      SELECT VALUE (P)
        FROM TABLE (
        DBMS_SQLTUNE.SELECT_CURSOR_CACHE (
        '( sql_text LIKE ''%SALES_PRODUCT_MAIN%'' or sql_text LIKE ''%SALES_INFORMATION_MAIN%'') and PARSING_SCHEMA_NAME <> ''SYS''',
          'ALL')) P;
   -- POPULATE THE SQLSET
   DBMS_SQLTUNE.LOAD_SQLSET (SQLSET_NAME       => 'STS_NAME_ZY_1030',
                             POPULATE_CURSOR   => STSCUR,
                             commit_rows       => 100,
                             SQLSET_OWNER      => 'DBMGR');
   CLOSE STSCUR;
   COMMIT;
EXCEPTION
   WHEN OTHERS
   THEN
      RAISE;
END;
/
---------------------------------------------------
--Step3: 增量抓取数据库中的SQL, 会连续抓取一天,每小时抓取一次，在后台执行
---------------------------------------------------
BEGIN
 	DBMS_SQLTUNE.CAPTURE_CURSOR_CACHE_SQLSET(SQLSET_NAME=>'STS_NAME_ZY_1030',
  	TIME_LIMIT=> 86400,
  	REPEAT_INTERVAL=>3600,
  	CAPTURE_OPTION=>'MERGE',
  	CAPTURE_MODE =>DBMS_SQLTUNE.MODE_ACCUMULATE_STATS,
  	BASIC_FILTER=>
  	'( sql_text LIKE ''%SALES_PRODUCT_MAIN%''
 	or sql_text LIKE ''%SALES_INFORMATION_MAIN%''
 	)
  	and PARSING_SCHEMA_NAME <> ''SYS''' ,
  	SQLSET_OWNER => 'DBMGR');
    END;
    /

--step1:
EXEC DBMS_SQLTUNE.CREATE_STGTAB_SQLSET('STGTAB_DKF0225','DBMGR');

--step2:
EXEC DBMS_SQLTUNE.PACK_STGTAB_SQLSET('STS_NAME_DKF_0225','DBMGR','STGTAB_DKF0225','DBMGR');

--step3:
--导出DBMGR.STGTAB_SQLSET_ZY表

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

2.archive  已满 清理 archive log 清理archive  清理归档

SQL> show parameter log_archive_dest; 看看archiv log所在位置
SQL> archive log list;一般VALUE为空时，可以用archive log list;检查一下归档目录和log sequence
SQL> select * from V$FLASH_RECOVERY_AREA_USAGE;检查flash recovery area的使用情况,
SQL> select sum(percent_space_used)*3/100 from v$flash_recovery_area_usage;计算flash recovery area已经占用的空间
SQL> show parameter recover;找到recovery目录,
转移或清除对应的归档日志, 删除一些不用的日期目录的文件，注意保留最后几个文件（比如360以后的）
rman target /
RMAN> crosscheck archivelog all;检查一些无用的archivelog
RMAN> delete expired archivelog all; 删除过期的归档
RMAN> delete archivelog until time 'sysdate-9' ; 删除截止到前一天的所有archivelog
SQL> select * from V$FLASH_RECOVERY_AREA_USAGE;再次查询，发现使用率正常
其它有用的Command:
----------------------------------
如果archive log模式下不能正常startup,则先恢复成noarchive log,startup成功后，再shutdown;
shutdown immediate;
startup mount;
alter database noarchivelog;
alter database open;
shutdown immediate;

再次startup以archive log模式
shutdown immediate;
startup mount;
show parameter log_archive_dest;
alter database archivelog;
archive log list;
alter database open;

如果还不行，则删除一些archlog log
SQL> select group#,sequence# from v$log;

    GROUP# SEQUENCE#
---------- ----------
         1         62
         3         64
         2         63
原来是日志组一的一个日志不能归档
SQL> alter database clear unarchived logfile group 1;
最后，也可以指定位置Arch Log, 请按照如下配置
select name from v$datafile;
alter system set log_archive_dest='/opt/app/oracle/oradata/usagedb/arch' scope=spfile
SQL> alter system set db_recovery_file_dest_size=3G scope=both;


登陆测试数据库，此时由于磁盘满，无法登陆数据库，通过数据库启动初始化文件或者pfile、spfile文件查找确定数据库归档文件存放路径。

根据数据库启动访问参数文件的顺序spfile<sid>.ora，spfile.ora，init<sid>.ora，init.ora，相信下面大家会知道应该查看哪个文件的内容。

E查找到*.log_archive_dest的配置路径

[oracle@dev2_180db dbs]$ cd /u02/oradata/center/archive

2。删除指定1天前的归档文件

[oracle@dev2_180db archive]$ find /u02/oradata/center/archive -mtime +1 -name "*.dbf" -exec rm -rf {} \;

E当手工删除了归档日志以后，Rman备份会检测到日志缺失从而无法进一步继续执行。
所以此时需要手工执行crosscheck过程，之后Rman备份可以恢复正常。

3。通过rman进行Crosscheck日志


[oracle@dev2_180db archive]$ rman target /

Recovery Manager: Release 10.2.0.1.0 - Production on Thu Jan 12 00:45:38 2012

Copyright (c) 1982, 2005, Oracle.  All rights reserved.

connected to target database: CENTER (DBID=4195036994)

RMAN> crosscheck archivelog all;

released channel: ORA_DISK_1
allocated channel: ORA_DISK_1
channel ORA_DISK_1: sid=1028 devtype=DISK
validation failed for archived log
archive log filename=/u02/oradata/center/archive/1_1_766187842.dbf recid=1 stamp=766189358
Crosschecked 1 objects

4。使用delete expired archivelog all 命令删除所有过期归档日志:

RMAN> delete expired archivelog all;

released channel: ORA_DISK_1
allocated channel: ORA_DISK_1
channel ORA_DISK_1: sid=1028 devtype=DISK

List of Archived Log Copies
Key     Thrd Seq     S Low Time  Name
------- ---- ------- - --------- ----
1       1    1       X 02-NOV-11 /u02/oradata/center/archive/1_1_766187842.dbf

Do you really want to delete the above objects (enter YES or NO)  Y
deleted archive log
archive log filename=/u02/oradata/center/archive/1_1_766187842.dbf recid=1 stamp=766189358
Deleted 1 EXPIRED objects

5。简要介绍一下report obsolete命令

使用report obsolete命令报告过期备份

RMAN> report obsolete;


6。使用delete obsolete命令删除过期备份:
RMAN> delete obsolete;


7。再次crosscheck 日志，看返回信息判断是否数据库已经正常
RMAN> crosscheck archivelog all;

released channel: ORA_DISK_1
allocated channel: ORA_DISK_1
channel ORA_DISK_1: sid=1028 devtype=DISK
specification does not match any archive log in the recovery catalog

如果有看到specification does not match any archive log in the recovery catalog返回信息，那说明数据库已经正常了。

8。退出rman，登陆oracle数据库改归档模式为到非归档模式

RMAN> exit

SQL>shutdown immediate;

SQL>start mount;

SQL>alter database noarchivelog;

SQL>alter database open;

Oracle数据库可以运行在2种模式下:归档模式(archivelog)和非归档模式(noarchivelog)
归档模式可以提高Oracle数据库的可恢复性，生产数据库都应该运行在此模式下，归档模式应该和相应的备份策略相结合，只有归档模式没有相应的备份策略只会带来麻烦。

本文简单介绍如何启用和关闭数据库的归档模式。

1.shutdown normal或shutdown immediate关闭数据库
[oracle@jumper oracle]$ sqlplus "/ as sysdba"

SQL*Plus: Release 9.2.0.4.0 - Production on Sat Oct 15 15:48:36 2005

Copyright (c) 1982, 2002, Oracle Corporation.  All rights reserved.


Connected to:
Oracle9i Enterprise Edition Release 9.2.0.4.0 - Production
With the Partitioning option
JServer Release 9.2.0.4.0 - Production

SQL> shutdown immediate;
Database closed.
Database dismounted.
ORACLE instance shut down.


2.启动数据库到mount状态
SQL> startup mount;
ORACLE instance started.

Total System Global Area  101782828 bytes
Fixed Size                   451884 bytes
Variable Size              37748736 bytes
Database Buffers           62914560 bytes
Redo Buffers                 667648 bytes
Database mounted.

3.启用或停止归档模式
如果要启用归档模式，此处使用
alter database archivelog 命令。
SQL> alter database archivelog;
Database altered.

SQL> alter database open;

Database altered.

SQL> archive log list;
Database log mode              Archive Mode
Automatic archival             Enabled
Archive destination            /opt/oracle/oradata/conner/archive
Oldest online log sequence     148
Next log sequence to archive   151
Current log sequence           151

如果需要停止归档模式，此处使用：
alter database noarchivelog 命令。
SQL> shutdown immediate;
Database closed.
Database dismounted.
ORACLE instance shut down.
SQL> startup mount;
ORACLE instance started.

Total System Global Area  101782828 bytes
Fixed Size                   451884 bytes
Variable Size              37748736 bytes
Database Buffers           62914560 bytes
Redo Buffers                 667648 bytes
Database mounted.
SQL> alter database noarchivelog;

Database altered.

SQL> alter database open;

Database altered.

SQL> archive log list;
Database log mode              No Archive Mode
Automatic archival             Enabled
Archive destination            /opt/oracle/oradata/conner/archive
Oldest online log sequence     149
Current log sequence           152

4.修改相应的初始化参数
Oracle10g之前，你还需要修改初始化参数使数据库处于自动归档模式。
在pfile/spfile中设置如下参数：

log_archive_start = true

重启数据库此参数生效，此时数据库处于自动归档模式。
也可以在数据库启动过程中，手工执行：

archive log start

使数据库启用自动归档，但是重启后数据库仍然处于手工归档模式。

从Oracle10g开始，log_archive_start参数已经废除，请参考：Oracle10g已经废弃log_archive_start参数.



SQL> select CAPTURE_NAME, QUEUE_NAME, START_SCN, STATUS, FIRST_SCN from dba_capture;

CAPTURE_NAME   QUEUE_NAME    START_SCN  STATUS   FIRST_SCN

-------------- ------------- ---------- -------- --------

CAPTURE_PROD   DEMODB_QUEUE  7586391    DISABLED 7586391

CAPTURE_DEMODB DEMODB_QUEUE  7592351    ENABLED  7592351

发现配置了二个Capture进程，其中一个状态为DISABLE，一直未启用，是一个错误配置的进程，删除此Capture进程。

SQL> exec dbms_capture_adm.drop_capture('capture_prod');



PL/SQL procedure successfully completed

再次执行，Archivelog文件顺利删除。

RMAN> delete archivelog all;

dataGuarad的primary库，rman中使用backup archivelog all delete input 命令删除已经归档并且已经成功传送到备库并且在standby上应用的日志是遇到
RMAN-08137: WARNING: archive log not deleted as it is still needed
archive log filename=/ora03/oraflsh/RMANCCB/1_3740_580667843.dbf thread=1 sequence=3740
主库和备库的alter日志里面也会出现 标记为APPLIED='NO'的归档日志初始化失败。此时尽管日志已经备份了，但是由于不能删除导致磁盘空间被占满最终会导致数据库hang住，因为不能产生任何的归档日志了。
在主库上执行如下语句，最少有一个archivelog 的APPLIED的值为NO:
alter session set nls_date_format='dd-mon-rr hh24:mi:ss';
select recid, dest_id, thread#, sequence#, first_time, completion_time, creator, registrar, archived, applied, deleted, status
from v$archived_log where standby_dest='YES' and status='A';


     遇到此类问题的原因是因为主库的日志虽然传送到了备库并且成功应用，但是对应的在主库上的日志条目 在v$archived_log.applied并没有被更新为‘YES’正是由于该字段的值为NO ,当使用rman 执行delete input 操作时，rman认为该日志没有归档且没有被备库应用。知道此问题的原因，我们可以使用如下方法解决：
1 检查备库和主库是否有日志的中断，如果有，则解决该中断问题！再次在主库执行上述sql 语句查看是否依然有 applied='NO'的日志条目
2 如果还有归档日志 标记为applied='NO' 并且此日志已经被备库应用，主备库之间没有gap，我们可以使用os 命令删除那些归档日志，然后执行：
RMAN>crosscheck archivelog all;
RMAN>delete expired archivelog all;


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
3 . set unused的用法


一、问题
alter table1 drop (column1,column2); 或者alter table1 drop column column1;
和alter table1 drop column column2;  的话，需要执行很长时间，这期间该表被锁，会影响到其它应用。
解决方法  使用set unused，等系统空闲时再drop unused。
alter table table1 set unused (column1,column2);
或者
alter table table1 set unused column column1;
alter table table2 set unused column column2;
alter table drop unused columns checkpoint 1000;
知识点（set unused的用法）
原理：清楚掉字典信息（撤消存储空间），不可恢复。
   可以使用 SET UNUSED 选项标记一列或者多列不可用。
   使用DROP SET UNUSED 选项删除被被标记为不可用的列。
语法：

   ALTER TABLE table SET UNUSED (COLlist多个) 或者 ALTER TABLE table SET UNUSED COLUMN col单个;

   ALTER TABLE table DROP UNUSED COLUMNS [checkpoint 1000];
set unused不会真地删除字段。
除了alter table drop field外，也可以
alter table set   unused field;
alter table drop unused;
set unused系统开销比较小，速度较快，所以可以先set unuased，然后在系统负载较小时，再drop。如系统负载不大，也可以直接drop。
不管用何种方法，都不会收回空间。
如果你有这个需求，要删除某一个表格上的某些栏位，但是由於这个表格拥有非常大量的资料，如果你在尖峰时间直接执行 ALTER TABLE ABC DROP （COLUMN）；可能会收到 ORA-01562 - failed to extend rollback segment number string，
这是因为在这个删除栏位的过程中你可能会消耗光整个RBS，造成这样的错误出现，因此这样的做法并不是一个好方法，就算你拼命的加大RBS空间来应付这个问题，也不会是个好主意。
        我的建议做法：
        CREATE TABLE T1 （A NUMBER，B NUMBER）；
        SQL> begin 2 for i in 1 .. 100000 3 loop 4 insert into t1 values （i，100）；5 end loop；6 commit；7 end；
        SQL> select count（*） from t1；
        SQL> ALTER TABLE T1 SET UNUSED COLUMN A CASCADE CONSTRAINTS；
        不要马上drop column，应该先set unused让column无法使用，避开系统尖峰时间再来处理删除栏位里的资料，要注意的是一但你set unused column，这个栏位是无法再回复使用的。
        重点来了，若你的栏位有一百万笔资料，我们应该避免一次写入那么多的\ log，所以我准备每删除一千笔资料就commit一次。
        SQL> alter table t1 drop unused columns checkpoint 1000；
        在离峰的时间进行这样的动作，应该可以避免 ORA-01562 的错误发生。
刚才有个人问我如何修复被设置为UNUSED的字段，我考虑了一下，以下的方法可以恢复（以下步骤执行前要做好备份），没有经验的DBA不要轻易尝试。
创建实验表TTTA
SQL> CREATE TABLE TTTA ( A INTEGER,B INTEGER,C VARCHAR2(10),D INTEGER);
SQL> INSERT INTO TTTA VALUES (1,2,'3',4);
SQL> INSERT INTO TTTA VALUES (2,3,'4',5);
SQL> COMMIT;
ALTER TABLE TTTA SET UNUSED COLUMN C;
以下进行恢复
SQL> SELECT OBJ# FROM OBJ$ WHERE NAME='TTTA';
      OBJ#
----------
     32067
SELECT COL#,INTCOL#,NAME FROM COL$ WHERE OBJ#=32067;
      COL#    INTCOL# NAME
---------- ---------- ------------------------------
         1          1 A
         2          2 B
         0          3 SYS_C00003_08031720:09:55$   被UNUSED的字段
         3          4 D
SQL> SELECT COLS FROM TAB$ WHERE OBJ#=32067;
      COLS
----------
         3      ------字段数变为3了
SQL> UPDATE COL$ SET COL#=INTCOL# WHERE OBJ#=32067;
SQL> UPDATE TAB$ SET COLS=COLS+1 WHERE OBJ#=32067;
UPDATE COL$ SET NAME='C' WHERE OBJ#=32067 AND COL#=3;
UPDATE COL$ SET PROPERTY=0 WHERE OBJ#=32067;
SQL> COMMIT;
3、重启数据库
SQL> SELECT * FROM SCOTT.TTTA;
         A          B C                   D
---------- ---------- ---------- ----------
         1          2 3                   4
         2          3 4                   5
恢复完成

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
4  根据spid查找数据中的sql语句和执行计划
execute dbms_job.interval(6,'TRUNC(SYSDATE+1)+6/24');
select * from v$process where spid=24213
select * from v$session where paddr = 'C000000952278FF0';
select * from v$sql where hash_value = '4278407967';
select * from v$sql where hash_value = '1586036868';
select * from table(dbms_xplan.display_cursor('9b3cwxd70jxmr'));

sid----
declare
  -- Local variables here
  i integer:=1;
  DRAWBATCHNO VARCHAR2(32);
  V_BUSINESSTYPEID VARCHAR2(10):='LBS03';
  V_PAYTYPE VARCHAR2(1):='C';
  V_BANKID VARCHAR2(8):='10529002';--A0229002
  V_BRANCH VARCHAR2(11):='2150000';--2150000，2150500
  V_DSTACCOUNT VARCHAR2(128):='2960399980100555181';--6222980061307460
  V_DSTACCOUNTNAME VARCHAR2(150):='王一';--平安测试20070
  V_AMOUNT NUMBER(16,2):= 100;
  V_CURRENCY VARCHAR2(3):='RMB';
  V_SYSTEMID VARCHAR2(10):='122';
  V_KIND VARCHAR2(4):='0';
  V_BANK_NAME VARCHAR2(60):='';
  V_URGENT VARCHAR2(10):='N';
  V_REMARK VARCHAR2(200):='';
BEGIN
  DRAWBATCHNO:= cmscde.CMS_BUSINESS_SYSTEM_PACKAGE.GETDRAWID('LBS');
    for idx in 1..i loop
INSERT INTO TDRAWDATA
  (DRAWID,
   BUSINESSNO,
   BUSINESSTYPEID,
   PAYTYPE,
   BANKID,
   BRANCH,
   DSTACCOUNT,
   DSTACCOUNTNAME,
   CITY,
   PROVINCE,
   REGION_CODE,
   DRAWPERSON,
   DRAWDATE,
   AMOUNT,
   IDTYPE,
   ID,
   STATUSID,
   CURRENCY,
   SYSTEMID,
   VOUCHERNO,
   RCPTNO,
   TOCMS,
   KIND,
   BUSINESSDATE,
   BANK_NAME,
   AREA_CODE,
   URGENT,
   REMARK,
   CMSDRAWPERSON,
   DRAWBATCHNO,
   CASH_FLAG,
   SRC_ACCOUNT,
   ACCOUNT_TYPE,
   CREDIT_CARD_VALID_DATE,
   CREDIT_CARD_CVV2_CODE,
   SIGNATURE,
   BIZ_UNIQUE_SEQUENCE)
  SELECT cmscde.CMS_BUSINESS_SYSTEM_PACKAGE.GETDRAWID(NULL),
         'TEST'||TO_CHAR(SYSDATE,'YYYYMMDDHHmiSS')||idx,
         V_BUSINESSTYPEID,
         V_PAYTYPE,
         V_BANKID,
         V_BRANCH,
         V_DSTACCOUNT,
         V_DSTACCOUNTNAME,
         NULL,
         NULL,
         NULL,
         'HUAHAIJIE001',
         SYSDATE,
         V_AMOUNT,
         1,
         TO_CHAR(SYSDATE,'YYYYMMDDHHMM'),
         'bat-0000',
         V_CURRENCY,
         V_SYSTEMID,
         NULL,
         NULL,
         SYSDATE AS TOCMS,
         V_KIND,
         NULL,
         V_BANK_NAME,
         NULL,
         V_URGENT,--紧急标志
         V_REMARK,
         'HUAHAIJIE001',
         DRAWBATCHNO,
         NULL,
         NULL,
         NULL,
         NULL,
         NULL,
         pub_sys_package.md5(lower(V_DSTACCOUNT || V_DSTACCOUNTNAME || to_char(V_AMOUNT) || 'www.pingan.com/cms')),
         NULL--cmscde.pub_sys_package.md5('YKTESTLZD'||idx)
    FROM DUAL;
    end loop;
end;


pid---

select  sql_text from v$sql where hash_value =(select sql_hash_value from v$session where paddr = (select addr from v$process where spid=***));


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
5.10046跟踪

-如果要准确的性能指标，需要先清理shared_pool和buffer_cache

alter system flush shared_pool;
alter system flush buffer_cache;
alter session set tracefile_identifier='ddddddd';
alter session set trace on;
--开启session级10046 event trace
alter session set events '10046 trace name context forever, level 12';
--执行你的SQL
<sql_text>
--关闭session级10046 event trace
alter session set events '10046 trace name context off';



--获取trace文件的路径
select d.value || '/' || lower(rtrim(i.instance, chr(0))) || '_ora_' ||p.spid|| '.trc' trace_file_name
         from (select p.spid
              from v$mystat m, v$session s, v$process p
             where m.statistic# = 1
               and s.sid = m.sid
               and p.addr = s.paddr) p,
           (select t.instance
              from v$thread t, v$parameter v
            where v.name = 'thread'
              and (v.value = 0 or t.thread# = to_number(v.value))) i,
          (select value from v$parameter where name = 'user_dump_dest') d;

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
6.top 10 sql   top10  top 10  topsql

SELECT   *
    FROM (SELECT   b.username username,
                     a.disk_reads
                   / DECODE (a.executions, 0, 1, a.executions) rds_exec_ratio,
                   a.sql_text STATEMENT
              FROM v$sqlarea a, dba_users b
             WHERE a.parsing_user_id = b.user_id AND b.username = 'ZYK'
          ORDER BY rds_exec_ratio DESC)
   WHERE ROWNUM < 11
ORDER BY rds_exec_ratio DESC

识别’低效执行’的SQL语句
用下列SQL工具找出低效SQL:
SELECT EXECUTIONS , DISK_READS, BUFFER_GETS,
        ROUND((BUFFER_GETS-DISK_READS)/BUFFER_GETS,2) Hit_radio,
        ROUND(DISK_READS/EXECUTIONS,2) Reads_per_run,
        SQL_TEXT
FROM   V$SQLAREA
WHERE  EXECUTIONS>0
AND     BUFFER_GETS > 0
AND (BUFFER_GETS-DISK_READS)/BUFFER_GETS < 0.8
ORDER BY 4 DESC;

查找单条语句的内存占用率
alter system set pga_aggregate_target=10m
alter system set workarea_size_policy=auto;
select distinct * from a where rownum<500000;

select sql_text,operation_type,policy,(last_memory_used/1024/1024),
last_execution,last_tempseg_size
from v$sql i,v$sql_workarea a
where i.hash_value=a.hash_value
and sql_text='select distinct * from a where rownum<500000';


Top 10 by Buffer Gets:

set linesize 100
set pagesize 100
SELECT * FROM
(SELECT substr(sql_text,1,40) sql,
buffer_gets, executions, buffer_gets/executions "Gets/Exec",
hash_value,address
FROM V$SQLAREA
WHERE buffer_gets > 10000
ORDER BY buffer_gets DESC)
WHERE rownum <= 10
;

Top 10 by Physical Reads:

set linesize 100
set pagesize 100
SELECT * FROM
(SELECT substr(sql_text,1,40) sql,
disk_reads, executions, disk_reads/executions "Reads/Exec",
hash_value,address
FROM V$SQLAREA
WHERE disk_reads > 1000
ORDER BY disk_reads DESC)
WHERE rownum <= 10
;

Top 10 by Executions:

set linesize 100
set pagesize 100
SELECT * FROM
(SELECT substr(sql_text,1,40) sql,
executions, rows_processed, rows_processed/executions "Rows/Exec",
hash_value,address
FROM V$SQLAREA
WHERE executions > 100
ORDER BY executions DESC)
WHERE rownum <= 10
;

Top 10 by Parse Calls:

set linesize 100
set pagesize 100
SELECT * FROM
(SELECT substr(sql_text,1,40) sql,
parse_calls, executions, hash_value,address
FROM V$SQLAREA
WHERE parse_calls > 1000
ORDER BY parse_calls DESC)
WHERE rownum <= 10
;

Top 10 by Sharable Memory:

set linesize 100
set pagesize 100
SELECT * FROM
(SELECT substr(sql_text,1,40) sql,
sharable_mem, executions, hash_value,address
FROM V$SQLAREA
WHERE sharable_mem > 1048576
ORDER BY sharable_mem DESC)
WHERE rownum <= 10
;

Top 10 by Version Count:

set linesize 100
set pagesize 100
SELECT * FROM
(SELECT substr(sql_text,1,40) sql,
version_count, executions, hash_value,address
FROM V$SQLAREA
WHERE version_count > 20
ORDER BY version_count DESC)
WHERE rownum <= 10

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
7.【oracle】统计信息的导入导出
创建测试表
SQL> create table test_stat as select * from dba_objects;
查看测试是否有统计信息：
SQL> select A.TABLE_NAME,A.NUM_ROWS,A.BLOCKS,A.LAST_ANALYZED from dba_tables a where a.table_name='TEST_STAT';
上步结果没有，故收集下统计信息：
SQL> execute dbms_stats.gather_table_stats(ownname => 'DANGHB',tabname => 'TEST_STAT',estimate_percent => 20,degree => 5,no_invalidate => false);
再次查看统计信息：
SQL> select A.TABLE_NAME,A.NUM_ROWS,A.BLOCKS,A.LAST_ANALYZED from dba_tables a where a.table_name='TEST_STAT';
创建存放统计信息的表：
SQL> execute dbms_stats.create_stat_table(ownname => 'DANGHB',stattab => 'STAT_TABLE');
导出统计信息：
SQL> execute dbms_stats.export_table_stats(ownname => 'DANGHB',tabname => 'TEST_STAT',stattab => 'STAT_TABLE');
查看存放统计信息的表是否有内容：
SQL> select count(*) from stat_table;
删除测试表的统计信息：
SQL> execute dbms_stats.delete_table_stats(ownname => 'DANGHB',tabname => 'TEST_STAT');
确实是否删除：
SQL> select A.TABLE_NAME,A.NUM_ROWS,A.BLOCKS,A.LAST_ANALYZED from dba_tables a where a.table_name='TEST_STAT';
导入统计信息：
SQL> execute dbms_stats.import_table_stats(ownname => 'DANGHB',tabname => 'TEST_STAT',stattab => 'STAT_TABLE');
查看是否导入成功：
SQL> select A.TABLE_NAME,A.NUM_ROWS,A.BLOCKS,A.LAST_ANALYZED from dba_tables a where a.table_name='TEST_STAT';

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
8.表空间的利用率-表空间使用率  表空间大小

SELECT A.TABLESPACE_NAME,A.BYTES TOTAL,B.BYTES USED, C.BYTES FREE,
(B.BYTES*100)/A.BYTES "% USED",(C.BYTES*100)/A.BYTES "% FREE"
FROM SYS.SM$TS_AVAIL A,SYS.SM$TS_USED B,SYS.SM$TS_FREE C
WHERE A.TABLESPACE_NAME=B.TABLESPACE_NAME AND A.TABLESPACE_NAME=C.TABLESPACE_NAME;


SELECT a.tablespace_name 表空间名,
       total 表空间大小,
       free 表空间剩余大小,
       (total - free) 表空间使用大小,
       ROUND((total - free) / total, 4) * 100 使用率
  FROM (SELECT tablespace_name, ROUND(SUM(bytes) / (1024 * 1024), 4) free
          FROM DBA_FREE_SPACE
         GROUP BY tablespace_name) a,
       (SELECT tablespace_name, ROUND(SUM(bytes) / (1024 * 1024), 4) total
          FROM DBA_DATA_FILES
         GROUP BY tablespace_name) b
 WHERE a.tablespace_name = b.tablespace_name
 
 
 
OR Lcntr IN REVERSE 1..15
LOOP
     LCalc := Lcntr * 31;
END LOOP;

采样表中的数据量。抽样  随机取样
SELECT * FROM (select * from myob  SAMPLE(0.01)) where rownum<=20;
利用ORACLE实现数据抽样
2013-04-18      0 个评论    来源：jingyun的BLOG   收藏     我要投稿
利用ORACLE实现数据抽样

做数据分析的,免不了碰到记录数据量很大，怎么办？
做全面分析是不现实也没有必要。
介绍一下抽样方法及实现
几种常用的抽样方法：
1.简单随机抽样（simple random sampling）
将所有调查总体编号，再用抽签法或随机数字表随机抽取部分观察数据组成样本。
优点：操作简单，均数、率及相应的标准误计算简单。
缺点：总体较大时，难以一一编号。
2.系统抽样（systematic sampling）
又称机械抽样、等距抽样，即先将总体的观察单位按某一顺序号分成n个部分，再从第一部分随机抽取第k号观察单位，依次用相等间距从每一部分各抽取一个观察单位组成样本。
优点：易于理解、简便易行。
缺点：总体有周期或增减趋势时，易产生偏性。
3.整群抽样(cluster sampling)
先将总体依照一种或几种特征分为几个子总体（类．群），每一个子总体称为一层，然后从每一层中随机抽取一个子样本，将它们合在一起，即为总体的样本，称为分层样本
优点：便于组织、节省经费。
缺点：抽样误差大于单纯随机抽样。
4.分层抽样（stratified sampling）
将总体样本按其属性特征分成若干类型或层，然后在类型或层中随机抽取样本单位，合起来组成样本。有按比例分配和最优分配（过度抽样是否就是最优分配方法？）两种方案。
特点：由于通过划类分层，增大了各类型中单位间的共同性，容易抽出具有代表性的调查样本。该方法适用于总体情况复杂，各类别之间差异较大（比如金融客户风险/非风险样本的差异），类别较多的情况。
优点：样本代表性好，抽样误差减少。

我们需要使用抽样的方法从总量用户中随机抽取100W个样本记录。
down到本机然后进行sas抽样，不可能！
直接sas联机抽样，更不可能！
直接提交服务器进行抽样，然后链接到本机进行分析
现在介绍一下ORACLE抽样方法：
Oracle取随机数据实现
随机查看前N条记录
SELECT * FROM (SELECT * FROM TB_PHONE_NO ORDER BY SYS_GUID())
WHERE ROWNUM < 10;
SELECT * FROM (SELECT * FROM chifan  ORDER BY dbms_random.random) WHERE ROWNUM<=5
SQL> SELECT * FROM (SELECT * FROM A SAMPLE(0.01)) WHERE ROWNUM<=1;
注意每次取得的值都不同。
SAMPLE 是随机抽样，后面的数值是采样百分比。
以下是oracle 中随机取数据的方法的详细讲解：
1.快速随机取数据（推荐使用）：
select * from MEMBER sample(1) where rownum <= 10
2.随机取数据，较慢
select * from (
  select * from MEMBER order by dbms_random.value
) where rownum<=10
========原文========
最近在做系统时用到了随机抽取记录的问题；
     上网上查找了很多相关资料，发现了不同的方法及其差异。都是基于ORACLE的方法哦
      首先第一个是随机抽取6个
      select * from  (select * from tablename order by order by dbms_random.value) where  rownum＜7
      这个方法的原理我认为应该是把表中的数据全部查询出来按照随机数进行排列后在从查询出来的数据中查询中6条记录，这个方法我在使用的过程中发现，如果记录一多的话查询的速度有一点点的慢，测试时是7000条，如果几万几十万的话可能就更慢了；
     第二个是利用oracle的sample()或sample block方法
     select * from tablename sample ( 50 ) where  rownum＜6
      这个稍稍介绍一下sample
     Oracle访问数据的基本方法有:
     1.全表扫描
     2.采样表扫描
     全表扫描(Full table Scan)
     全表扫描返回表中所有的记录。
     执行全表扫描，Oracle读表中的所有记录，考查每一行是否满足WHERE条件。Oracle顺序的读分配给该表的每一个数据块，这样全表扫描能够受益于多块读.
      每个数据块Oracle只读一次.
     采样表扫描(sample table scan)
     采样表扫描返回表中随机采样数据。
     这种访问方式需要在FROM语句中包含SAMPLE选项或者SAMPLE BLOCK选项.
     SAMPLE选项:
     当按行采样来执行一个采样表扫描时，Oracle从表中读取特定百分比的记录，并判断是否满足WHERE子句以返回结果。
     SAMPLE BLOCK选项:
     使用此选项时，Oracle读取特定百分比的BLOCK，考查结果集是否满足WHERE条件以返回满足条件的纪录.
      Sample_Percent:
      Sample_Percent是一个数字，定义结果集中包含记录占总记录数量的百分比。
      Sample值应该在[0.000001,99.999999]之间。
      主要注意以下几点:
      1.sample只对单表生效，不能用于表连接和远程表
      2.sample会使SQL自动使用CBO
PS：虽然这样可以获取一定随机的数据，不过，输出的顺序却还是顺序的，不知道是不是Oracle的机制就是这样，还是菜鸟暂时也找不出啥原因，不过这个也算是解决了随机的需求，暂时就这样了~~2015/6/26


select * from  sys.sm$ts_free

SET SERVEROUTPUT ON
SET PAGESIZE 1000
SET LINESIZE 255
SET FEEDBACK OFF
SELECT * FROM SYS.SM$TS_AVAIL T; -- 分配空间
SELECT * FROM SYS.SM$TS_USED T;  -- 已用空间
SELECT * FROM SYS.SM$TS_FREE T;  -- 剩余空间
-- 表空间的利用率
SELECT Substr(df.tablespace_name,1,20) "Tablespace Name",
       Substr(df.file_name,1,40) "File Name",
       Round(df.bytes/1024/1024,2) "Size (M)",
       Round(e.used_bytes/1024/1024,2) "Used (M)",
       Round(f.free_bytes/1024/1024,2) "Free (M)",
       Rpad(' '|| Rpad ('X',Round(e.used_bytes*10/df.bytes,0), 'X'),11,'-') "% Used"
FROM   DBA_DATA_FILES DF,
       (SELECT file_id,
               Sum(Decode(bytes,NULL,0,bytes)) used_bytes
        FROM dba_extents
        GROUP by file_id) E,
       (SELECT Max(bytes) free_bytes,
               file_id
        FROM dba_free_space
        GROUP BY file_id) f
WHERE  e.file_id (+) = df.file_id
AND    df.file_id  = f.file_id (+)
ORDER BY df.tablespace_name,
         df.file_name;

PROMPT
SET FEEDBACK ON
SET PAGESIZE 18
-- 表空间总大小与剩余大小
select a.*, b.free_MB
  from (select tablespace_name, sum(bytes) / 1024 / 1024 total_MB
          from dba_data_files
         group by tablespace_name) a,
       (select tablespace_name, sum(bytes) / 1024 / 1024 free_MB
          from dba_free_space
         group by tablespace_name) b
 where a.tablespace_name = b.tablespace_name;

prompt --'查询表空间使用情况';
col tablespace_name for a25;
col total for a20;
col free for a20;
col "%pct_used" for a20;
select tb.tbs_name,
       tb.TOTAL_GB,
       tb.ALLOTED_GB,
       nvl(ta.used_gb, 0) as used_gb,
       round(nvl(ta.used_gb, 0) / tb.TOTAL_GB * 100, 4) || ' %' as pct_used
  from (select t.TABLESPACE as tbs_name,
               round(sum(t.BLOCKS) *
                     (select value
                        from v$parameter s
                       where s.name = 'db_block_size') / 1024 / 1024 / 1024,
                     4) as USED_GB
          from v$tempseg_usage t
         group by t.TABLESPACE) ta,
       (select t1.tablespace_name as tbs_name,
               round(sum(t1.bytes) / 1024 / 1024 / 1024, 4) as ALLOTED_GB,
               round(sum(decode(t1.maxbytes, 0, t1.bytes, t1.maxbytes)) / 1024 / 1024 / 1024,
                     4) as TOTAL_GB
          from dba_temp_files t1
         where t1.tablespace_name <> 'I3_ORCL_TMP'
         group by t1.tablespace_name) tb
 where ta.tbs_name(+) = tb.tbs_name
/
prompt
prompt --查询temp表空间占数据库的空间比例
SELECT (select round(sum(decode(t.autoextensible,
                                'YES',
                                t.maxbytes,
                                t.bytes)) / 1024 / 1024 / 1024,
                     2)
          from dba_temp_files t
         where tablespace_name not in ('I3_ORCL_TMP')) as temp_size_gb,
       (select round(sum(bytes) / 1024 / 1024 / 1024, 2)
          from dba_data_files) as db_size_gb,
       round(100 * (select sum(decode(t.autoextensible,
                                      'YES',
                                      t.maxbytes,
                                      t.bytes))
                      from dba_temp_files t
                     where tablespace_name not in ('I3_ORCL_TMP')) /
             (select sum(bytes) from dba_data_files),
             2) as "TEMP/DB"
  from dual;

@tempuser

 -------临时表空间的使用率
 select t1."Tablespace" "Tablespace",
t1."Total (G)" "Total (G)",
nvl(t2."Used (G)", 0) "Used(G)",
t1."Total (G)" - nvl(t2."Used (G)", 0) "Free (G)"
from(select tablespace_name "Tablespace", to_char((sum(bytes/1024/1024/1024)),'99,999,990.900') "Total (G)"
from dba_temp_files
group by tablespace_name
union
select tablespace_name "Tablespace", to_char((sum(bytes/1024/1024/1024)),'99,999,990.900') "Total (G)"
from dba_data_files
where tablespace_name like 'TEMP%'
group by tablespace_name) t1,
(select tablespace, round(sum(blocks)*8/1024) "Used (G)" from v$sort_usage
group by tablespace) t2
where t1."Tablespace"=t2.tablespace(+)


 ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
9.不校验历史数据禁用主外键 主键 外键  约束

drop table EPCISUDWR.POLICY_VEHICLE_INFO cascade constraints ;


alter table dept add constraint dept_pk primary key(deptno) rely enable novalidate;
alter table table_name enable novalidate constraint constraint_name;
alter table LIFEDATA.CHS_SPECIAL_LIMIT  disable constraint FK_CHS_AUTOCHECK_LIMIT_LT ;
 alter trigger AWBSTRG.MONEY_RISK_LEVEL_ELIS_BI disable;
  select * from dba_constraints where r_constraint_name='PK_ROLE_RPT_ID';
  SELECT 'alter table '||owner||'.'||table_name||' disable constraint '||constraint_name||';'
  FROM dba_constraints
 WHERE     TABLE_NAME IN
('XIT_TH_APPLY_INFO',
'XIT_BK_APPLY_INFO',
'XIT_TH_CUSTOMER_INFO',
'XIT_BK_CUSTOMER_INFO',
'XIT_LIST_BIS_INFO',
'XIT_LIST_ELITE_LOG_INFO',
'RSUPPORT_CONNECT_REPORT',
'RSUPPORT_CHAT_REPORT',
'XIX_DD_COUNTY_INFO',
'XIX_TH_INTRODUCER_INFO',
'XIX_BK_INTRODUCER_INFO',
'XIX_SYNC_LIST_INFO')
       AND OWNER = 'PA18ODSDATA'
       and constraint_type='R' ;

 ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
10. 查看持有锁的sid. library cache
 SELECT a.SID,
       a.username,
       a.serial#
  FROM v$session a, x$kglpn b
 WHERE a.saddr = b.kglpnuse
   AND b.kglpnmod <> 0
   AND b.kglpnhdl IN
       (SELECT p1raw FROM v$session_wait WHERE event LIKE 'library%');


   ORA-20000: Unable to analyze TABLE , insufficient privileges or does not exist

grant ANALYZE ANY to DEPLOYOP;

：
开发库执行如下脚本报错ORA-00900：



    "DFS lock handle"这一event是在RAC环境中，会话等待获取一个全局锁的句柄时产生的。在RAC中，全局锁的句柄是由DLM（Distributed Lock Manager 分布式锁管理器）所管理和分配的。大量发生这一event说明全局锁句柄资源不够分配了。决定DLM锁数量的参数是_lm_locks，9i以后，它是一个隐含参数，默认值是12000。没有特殊情况，这一值对于一个OLTP系统来说是足够的。我们不能盲目地直接增加资源，而是需要找到导致资源紧张的根本原因。锁资源紧张，说明存在大量事务获取了锁，但是事务没有提交、回滚。那么，又是什么导致了这些事务不结束呢？应用程序代码不完善，没有提交事务？或者那些事务还在等待别的资源？分析到此，我们暂时先放下这一event，看下top event中的另外一个异常event。

    "enq: US - contention"，这个event说明事务在队列中等待UNDO Segment，通常是由于UNDO空间不足导致的。结合对前一event的分析，初步判断正是因为大量事务在等待队列中等待UNDO资源，导致全局锁没有释放。为了验证这一判断，我分别查询发生这2个events的对象是那些。
先看"DFS lock handle"的wait对象：

01.select o.object_id, o.owner, o.object_name, o.subobject_name, o.object_type, s.cnt
02.from dba_objects o,
03.     (select current_obj#, count(*) cnt from dba_hist_active_sess_history
04.      where snap_id between 14315 and 14338
05.      and event='DFS lock handle'
06.      group by current_obj#) s
07.where object_id = s.current_obj#
08.order by cnt desc;
09.
10.
11. OBJECT_ID OWNER              OBJECT_NAME              SUBOBJECT_NAME    OBJECT_TYPE    CNT
12.---------- ------------------ ------------------------ ----------------- -------------- ----------
13.    121517 CS2_PARTY_OWNER    PARKING_LOT_TXN_PK                         INDEX          1524
14.    121525 CS2_PARTY_OWNER    PARKING_LOT_SHMT_IDX2                      INDEX          1074
15.    121518 CS2_PARTY_OWNER    PARKING_LOT_TXN_IDX1                       INDEX          984
16.    121430 CS2_PARTY_OWNER    PARKING_LOT_TXN                            TABLE          664
17.    121524 CS2_PARTY_OWNER    PARKING_LOT_SHMT_IDX1                      INDEX          606
18.    121516 CS2_PARTY_OWNER    PARKING_LOT_IDX3                           INDEX          594
19.    121523 CS2_PARTY_OWNER    PARKING_LOT_SHMT_PK                        INDEX          524
首先，我想到一个可能是UNDO_RETENTION时间太长、且UNDO表空间被设置为GUARANTEE了。这样的话，会导致许多已经结束的事务的UNDO数据被保护起来不被使用，UNDO_RETENTION的时间越长，这些数据占用的UNDO空间就越多，这样就很容易导致"enq: US - contention"问题。从Awr report中看到，UNDO_RETENTION的时间设置得确实比较长：7200秒。再看一下表空间是否被GUARANTEE了：

SQL代码
01.select tablespace_name, retention from dba_tablespaces where tablespace_name like 'UNDO%';
02.
03.TABLESPACE_NAME            RETENTION
04.------------------------------ -----------
05.UNDOTBS1               NOGUARANTEE
06.UNDOTBS2               NOGUARANTEE
07.UNDOTBS3               NOGUARANTEE
结果发现表空间并没有做retension guarantee，这一可能性被排除。

    那我们再看一下到底是那些事务占用了UNDO空间，结果出乎意料：

SQL代码
01.SELECT a.sid, a.username, b.xidusn, b.used_urec, b.used_ublk, sq.sql_text
02.FROM v$session a, v$transaction b, v$sqlarea sq
03.WHERE a.saddr = b.ses_addr
04.a.sql_address = sq.address(+);
05.
06.       SID USERNAME    XIDUSN     USED_UREC  USED_UBLK  SQL_TEXT
07.---------- ----------- ---------- ---------- ---------- -----------
08.      1511 CS2_PARTY   1          9          1
我们在该节点上并没有找到大量占用UNDO空间的事务的。那UNDO空间的实际使用情况到底是怎样的呢？

SQL代码
01.SELECT SEGMENT_NAME, TABLESPACE_NAME, BYTES, BLOCKS, EXTENTS, SEGMENT_TYPE
02.   FROM DBA_SEGMENTS
03.   WHERE SEGMENT_TYPE LIKE chr(37)||'UNDO'||chr(37)
04.order by TABLESPACE_NAME, bytes desc;
05.
06.SEGMENT_NAME   TABLESPACE_NAME BYTES      BLOCKS   EXTENTS    SEGMENT_TYPE
07.-------------- --------------- ---------- -------- ---------- ------------------
08._SYSSMU69$     UNDOTBS1        2.0709E+10 2528008  4615       TYPE2 UNDO
09._SYSSMU123$    UNDOTBS1        11141120   1360     170        TYPE2 UNDO
10._SYSSMU34$     UNDOTBS1        11010048   1344     168        TYPE2 UNDO
11.... ...
    找到症结了。_SYSSMU69$这个回滚段占据了19.3G的空间！再看看这个回滚段中的扩展段（extent）的状态：

SQL代码
01.select status, sum(blocks)
02.  from dba_undo_extents
03.where segment_name='_SYSSMU69$'
04.group by status;
05.
06.STATUS    SUM(BLOCKS)
07.--------- -----------
08.ACTIVE        2528008
    全部扩展段都是active的，正常的话，说明有事务正在使用该回滚段的所有扩展段。但实际上却找不到这样的事务：

SQL代码
01.select
02.   r.name       "RBS name",
03.   t.start_time,
04.   t.used_ublk  "Undo blocks",
05.   t.used_urec  "Undo recs"
06. from
07.   gv$transaction t,
08.   v$rollname r
09.where r.usn  = t.xidusn
10.and r.name = '_SYSSMU69$';
11.
12.no rows selected
    这一点不正常。最大的可能性就是当初使用该回滚段的事务被异常终止了，导致资源没释放。这一点，通过与生产支持的同事确认，得到一个这样的事实：

那我们再查一下该回滚段是在什么时间开始激增的：

SQL代码
01.select begin_time,end_time,undotsn,undoblks,txncount,activeblks,unexpiredblks,expiredblks from v$undostat;
02.
03.2009-09-01 05:19:01 2009-09-01 05:29:01   1  1268     7993    2529896     30048    48
04.2009-09-01 05:09:01 2009-09-01 05:19:01   1  1779     8916    2529896     30024    72
05.2009-09-01 04:59:01 2009-09-01 05:09:01   1  5745     14819   2529896     30024    72
06.2009-09-01 04:49:01 2009-09-01 04:59:01   1  78200    5120    2451832     104448   3712
07.2009-09-01 04:39:01 2009-09-01 04:49:01   1  114524   5213    2339672     115840   99360
08.2009-09-01 04:29:01 2009-09-01 04:39:01   1  102563   6448    2236904     123264   193680
09.2009-09-01 04:19:01 2009-09-01 04:29:01   1  144123   7370    2095304     189056   275632
10.2009-09-01 04:09:01 2009-09-01 04:19:01   1  110936   20206   1989672     308864   261456
11.2009-09-01 03:59:01 2009-09-01 04:09:01   1  80127    13635   1911464     367360   273744
12.2009-09-01 03:49:01 2009-09-01 03:59:01   1  107125   11822   1807576     499840   252576
 可以看到，正是在4:00左右开始急剧增长的。基本上我们可以确认正是这一异常操作导致大量的回滚段被占用也没被释放！

    由于该回滚段的状态处于ONLINE状态，且其所有扩展段都是ACTIVE的，所以我们不能DROP或SHRINK它。现在，我们有两个方案来解决该问题：

1.由于对于的事务已经不存在了，我们无法通过提交或回滚事务来是否回滚段资源。那么，最直接的方法就是重启实例，重置回滚段；
2.临时解决方案就是增加或者新建一个UNDO表空间，使其它事务能正常运行。
    第一个方案会影响到其它模块，只能到周末downtime的时候实施。于是采用第二个方案：临时增加了为UNDOTBS1增加了10g空间。在杀掉一些由于这些等待被彻底hung住的会话后，整个数据库恢复了正常。


ORA-17629: Cannot connect to the remote database server
RMAN-03002: failure of backup command at 11/06/2014 17:55:53
RMAN-06403: could not obtain a fully authorized session
RMAN-04006: error from auxiliary database: ORA-01034: ORACLE not available
ORA-27101: shared memory realm does not exist
Linux-x86_64 Error: 2: No such file or directory

如果继续对比这两部分的登录方式，问题最有可能出现在前一部分，因为使用的是默认行为方式；另外后半部分是天衣无缝的。最终的原因的确出在这里，在使用Oracle的Active Database Duplicate功能创建物理DataGuard的过程中，连接target数据库必须“显式地指定密码”，即使是使用操作系统认证方式登录。


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
11. 查看数据文件的文件号，数据文件是否一致 数据文件一致
select hxfil file#,fhsta status,fhscn scn ,fhrba_seq seq# from x$kcvfh;

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
12. 查看正在执行的impdp或expdp的运行情况.
select * from dba_datapump_jobs t where t.owner_name like 'SYS' and t.state='EXECUTING';

insert into nv values('刘㫞','刘㫞');


中文表名
在cmd窗口导入

oracle exp/imp 详解

导入/导出是ORACLE幸存的最古老的两个命令行工具，其实我从来不认为Exp/Imp是一种好的备份方式，
正确的说法是Exp/Imp只能是一个好的转储工具，特别是在小型数据库的转储，表空间的迁移，表的抽取，
检测逻辑和物理冲突等中有不小的功劳。当然，我们也可以把它作为小型数据库的物理备份后的一个逻
辑辅助备份，也是不错的建议。对于越来越大的数据库，特别是TB级数据库和越来越多数据仓库的出现，
EXP/IMP越来越力不从心了，这个时候，数据库的备份都转向了RMAN和第三方工具。下面说明一下EXP/IMP的使用。
如何使exp的帮助以不同的字符集显示：set nls_lang=simplified chinese_china.zhs16gbk
通过设置环境变量，可以让exp的帮助以中文显示，如果set nls_lang=American_america.字符集，
那么帮助就是英文的了

EXP的所有参数（括号中为参数的默认值）：
USERID                  用户名/口令      如： USERID=duanl/duanl
FULL                    导出整个数据库 (N)
BUFFER                  数据缓冲区的大小
OWNER                   所有者用户名列表,你希望导出哪个用户的对象，就用owner=username
FILE                    输出文件 (EXPDAT.DMP)
TABLES                  表名列表 ,指定导出的table名称，如：TABLES=table1,table2

RECORDLENGTH            IO 记录的长度
GRANTS                  导出权限 (Y)
INCTYPE                 增量导出类型
INDEXES                 导出索引 (Y)
RECORD                  跟踪增量导出 (Y)
ROWS                    导出数据行 (Y)
PARFILE                 参数文件名,如果你exp的参数很多，可以存成参数文件.
CONSTRAINTS             导出约束 (Y)
CONSISTENT              交叉表一致性
LOG                     屏幕输出的日志文件
STATISTICS              分析对象 (ESTIMATE)
DIRECT                  直接路径 (N)
TRIGGERS                导出触发器 (Y)
FEEDBACK                显示每 x 行 (0) 的进度
FILESIZE                各转储文件的最大尺寸
QUERY                   选定导出表子集的子句

下列关键字仅用于可传输的表空间
TRANSPORT_TABLESPACE    导出可传输的表空间元数据 (N)
TABLESPACES             将传输的表空间列表
    IMP的所有参数（括号中为参数的默认值）：
USERID                  用户名/口令
FULL                    导入整个文件 (N)
BUFFER                  数据缓冲区大小
FROMUSER      				  所有人用户名列表
FILE      						  输入文件 (EXPDAT.DMP)
TOUSER        				  用户名列表
SHOW      						  只列出文件内容 (N)
TABLES       					  表名列表
IGNORE    						  忽略创建错误 (N)
RECORDLENGTH   				  IO 记录的长度
GRANTS   							  导入权限 (Y)
INCTYPE       				  增量导入类型
INDEXES 							  导入索引 (Y)
COMMIT        				  提交数组插入 (N)
ROWS     							  导入数据行 (Y)
PARFILE       				  参数文件名
LOG       						  屏幕输出的日志文件
CONSTRAINTS   				  导入限制 (Y)
DESTROY   						  覆盖表空间数据文件 (N)
INDEXFILE 						  将表/索引信息写入指定的文件
SKIP_UNUSABLE_INDEXES   跳过不可用索引的维护 (N)
ANALYZE   						  执行转储文件中的 ANALYZE 语句 (Y)
FEEDBACK 							  显示每 x 行 (0) 的进度
TOID_NOVALIDATE   		  跳过指定类型 id 的校验
FILESIZE 							  各转储文件的最大尺寸
RECALCULATE_STATISTICS  重新计算统计值 (N)

下列关键字仅用于可传输的表空间
TRANSPORT_TABLESPACE   导入可传输的表空间元数据 (N)
TABLESPACES 					 将要传输到数据库的表空间
DATAFILES 						 将要传输到数据库的数据文件
TTS_OWNERS             拥有可传输表空间集中数据的用户

关于增量参数的说明：exp/imp的增量并不是真正意义上的增量，所以最好不要使用。


EXP常用选项
1.FULL，这个用于导出整个数据库，在ROWS=N一起使用时，可以导出整个数据库的结构。例如：
exp userid=test/test file=./db_str.dmp log=./db_str.log full=y rows=n compress=y direct=y

2.OWNER和TABLE，这两个选项用于定义EXP的对象。OWNER定义导出指定用户的对象；TABLE指定EXP的table名称，例如：
exp userid=test/test file=./db_str.dmp log=./db_str.log owner=duanl
exp userid=test/test file=./db_str.dmp log=./db_str.log table=nc_data,fi_arap

3.BUFFER和FEEDBACK，在导出比较多的数据时，我会考虑设置这两个参数。例如：
exp userid=test/test file=yw97_2003.dmp log=yw97_2003_3.log feedback=10000 buffer=100000000 tables=WO4,OK_YT
feedback;没一万行显示一次进度。

4.FILE和LOG，这两个参数分别指定备份的DMP名称和LOG名称，包括文件名和目录，例子见上面。

5.COMPRESS参数不压缩导出数据的内容。用来控制导出对象的storage语句如何产生。默认值为Y，使用默认值，对象的存储语句的init extent等于当前导出对象的extent的总和。推荐使用COMPRESS＝N。

6.FILESIZE该选项在8i中可用。如果导出的dmp文件过大时，最好使用FILESIZE参数，限制文件大小不要超过2G。如：
exp userid=duanl/duanl file=f1,f2,f3,f4,f5 filesize=2G owner=scott
这样将创建f1.dmp, f2.dmp等一系列文件，每个大小都为2G，如果导出的总量小于10G,EXP不必创建f5.bmp.


IMP常用选项
1、FROMUSER和TOUSER,使用它们实现将数据从一个SCHEMA中导入到另外一个SCHEMA中。例如：假设我们做exp时导出的为test的对象,现在我们想把对象导入用户：
imp userid=test1/test1 file=expdat.dmp fromuser=test1 touser=test1

2、IGNORE、GRANTS和INDEXES，其中IGNORE参数将忽略表的存在，继续导入，这个对于需要调整表的存储参数时很有用，我们可以先根据实际情况用合理的存储参数建好表，然后直接导入数据。而GRANTS和INDEXES则表示是否导入授权和索引，如果想使用新的存储参数重建索引，或者为了加快到入速度，我们可以考虑将INDEXES设为N，而GRANTS一般都是Y。例如：imp userid=test1/test1 file=expdat.dmp fromuser=test1 touser=test1 indexes=N


表空间传输
表空间传输是8i新增加的一种快速在数据库间移动数据的一种办法，是把一个数据库上的格式数据文件附加到另外一个数据库中，而不是把数据导出成Dmp文件，这在有些时候是非常管用的，因为传输表空间移动数据就象复制文件一样快。

关于传输表空间有一些规则，即：
1.源数据库和目标数据库必须运行在相同的硬件平台上。
2.源数据库与目标数据库必须使用相同的字符集。
3.源数据库与目标数据库一定要有相同大小的数据块
4.目标数据库不能有与迁移表空间同名的表空间
5.SYS的对象不能迁移
6.必须传输自包含的对象集
7.有一些对象，如物化视图，基于函数的索引等不能被传输

可以用以下的方法来检测一个表空间或一套表空间是否符合传输标准：
exec sys.dbms_tts.transport_set_check('tablespace_name',true);
select * from sys.transport_set_violation;
如果没有行选择，表示该表空间只包含表数据，并且是自包含的。对于有些非自包含的表空间，如数据表空间和索引表空间，可以一起传输。

以下为简要使用步骤，如果想参考详细使用方法，也可以参考ORACLE联机帮助。
1.设置表空间为只读（假定表空间名字为APP_Data 和APP_Index）
alter tablespace app_data read only;
alter tablespace app_index read only;
2.发出EXP命令
SQL>host exp userid=”””sys/password as sysdba””” transport_tablespace=y tablespace=(app_data, app_index)
以上需要注意的是
a.为了在SQL中执行EXP，USERID必须用三个引号，在UNIX中也必须注意避免“/”的使用
b.在816和以后，必须使用sysdba才能操作
c.这个命令在SQL中必须放置在一行

3.拷贝数据文件到另一个地点，即目标数据库,可以是cp(unix)或copy(windows)或通过ftp传输文件（一定要在bin方式）
4.把本地的表空间设置为读写
5.在目标数据库附加该数据文件
imp file=expdat.dmp userid=”””sys/password as sysdba””” transport_tablespace=y “datafile=(c:\temp\app_data,c:\temp\app_index)”
6.设置目标数据库表空间为读写
alter tablespace app_data read write;
alter tablespace app_index read write;


优化EXP/IMP的方法：
     当需要exp/imp的数据量比较大时，这个过程需要的时间是比较长的，我们可以用一些方法来优化exp/imp的操作。

exp:使用直接路径 direct=y
    oracle会避开sql语句处理引擎,直接从数据库文件中读取数据,然后写入导出文件.
    可以在导出日志中观察到: exp-00067: table xxx will be exported in conventional path
    如果没有使用直接路径,必须保证buffer参数的值足够大.
    有一些参数于direct=y不兼容,无法用直接路径导出可移动的tablespace,或者用query参数导出数据库子集.
    当导入导出的数据库运行在不同的os下时,必须保证recordlength参数的值一致(RECORDLENGTH:I/O记录的长度).

imp:通过以下几个途径优化
  1.避免磁盘排序
		将sort_area_size设置为一个较大的值,比如100M
	2.避免日志切换等待
		增加重做日志组的数量,增大日志文件大小.
	3.优化日志缓冲区
		比如将log_buffer容量扩大10倍(最大不要超过5M)
	4.使用阵列插入与提交
		commit = y
		注意:阵列方式不能处理包含LOB和LONG类型的表,对于这样的table,如果使用commit = y,每插入一行,就会执行一次提交.
	5.使用NOLOGGING方式减小重做日志大小
		在导入时指定参数indexes=n,只导入数据而忽略index,在导完数据后在通过脚本创建index,指定 NOLOGGING选项


导出/导入与字符集
    进行数据的导入导出时，我们要注意关于字符集的问题。在EXP/IMP过程中我们需要注意四个字符集的参数：导出端的客户端字符集，导出端数据库字符集，导入端的客户端字符集，导入端数据库字符集。
我们首先需要查看这四个字符集参数。
查看数据库的字符集的信息：
SQL> select * from nls_database_parameters;
PARAMETER                       VALUE
------------------------------ ------------------------------------------
NLS_LANGUAGE                    AMERICAN
NLS_TERRITORY                    AMERICA
NLS_CURRENCY                    $
NLS_ISO_CURRENCY                AMERICA
NLS_NUMERIC_CHARACTERS          .,
NLS_CHARACTERSET                ZHS16GBK
NLS_CALENDAR                    GREGORIAN
NLS_DATE_FORMAT                 DD-MON-RR
NLS_DATE_LANGUAGE               AMERICAN
NLS_SORT                          BINARY
NLS_TIME_FORMAT                 HH.MI.SSXFF AM
NLS_TIMESTAMP_FORMAT            DD-MON-RR HH.MI.SSXFF AM
NLS_TIME_TZ_FORMAT              HH.MI.SSXFF AM TZH:TZM
NLS_TIMESTAMP_TZ_FORMAT         DD-MON-RR HH.MI.SSXFF AM TZH:TZM
NLS_DUAL_CURRENCY               $
NLS_COMP                        BINARY
NLS_NCHAR_CHARACTERSET          ZHS16GBK
NLS_RDBMS_VERSION               8.1.7.4.1

NLS_CHARACTERSET：ZHS16GBK是当前数据库的字符集。

我们再来查看客户端的字符集信息：
客户端字符集的参数NLS_LANG=_< territory >.
language：指定oracle消息使用的语言,日期中日和月的显示。
Territory：指定货币和数字的格式，地区和计算星期及日期的习惯。
Characterset：控制客户端应用程序使用的字符集。通常设置或等于客户端的代码页。或者对于unicode应用设为UTF8。
在windows中，查询和修改NLS_LANG可在注册表中进行：
HKEY_LOCAL_MACHINE\SOFTWARE\Oracle\HOMExx\
xx指存在多个Oracle_Home时的系统编号。
在unix中：
$ env|grep NLS_LANG
NLS_LANG=simplified chinese_china.ZHS16GBK
修改可用：
$ export NLS_LANG=AMERICAN_AMERICA.UTF8

通常在导出时最好把客户端字符集设置得和数据库端相同。当进行数据导入时，主要有以下两种情况：
		1.源数据库和目标数据库具有相同的字符集设置。
			这时,只需设置导出和导入端的客户端NLS_LANG等于数据库字符集即可。
		2.源数据库和目标数据库字符集不同。
      先将导出端客户端的NLS_LANG设置成和导出端的数据库字符集一致，导出数据，然后将导入端客户端的NLS_LANG设置成和导出端一致，导入数据，这样转换只发生在数据库端，而且只发生一次。
      这种情况下，只有当导入端数据库字符集为导出端数据库字符集的严格超集时，数据才能完全导成功，否则，可能会有数据不一致或乱码出现。

不同版本的EXP/IMP问题
   	一般来说，从低版本导入到高版本问题不大，麻烦的是将高版本的数据导入到低版本中，在Oracle9i之前，不同版本Oracle之间的EXP/IMP可以通过下面的方法来解决：
		1、在高版本数据库上运行底版本的catexp.sql；
		2、使用低版本的EXP来导出高版本的数据；
		3、使用低版本的IMP将数据库导入到低版本数据库中；
		4、在高版本数据库上重新运行高版本的catexp.sql脚本。

但在9i中，上面的方法并不能解决问题。如果直接使用低版本EXP/IMP会出现如下错误：
EXP-00008: orACLE error %lu encountered
orA-00904: invalid column name
这已经是一个公布的BUG，需要等到Oracle10.0才能解决，BUG号为2261722，你可以到METALINK上去查看有关此BUG的详细信息。
BUG归BUG，我们的工作还是要做，在没有Oracle的支持之前，我们就自己解决。在Oracle9i中执行下面的SQL重建exu81rls视图即可。

Create or REPLACE view exu81rls
(objown,objnam,policy,polown,polsch,polfun,stmts,chkopt,enabled,spolicy)
AS select u.name, o.name, r.pname, r.pfschma, r.ppname, r.pfname,
decode(bitand(r.stmt_type,1), 0,'', 'Select,')
|| decode(bitand(r.stmt_type,2), 0,'', 'Insert,')
|| decode(bitand(r.stmt_type,4), 0,'', 'Update,')
|| decode(bitand(r.stmt_type,8), 0,'', 'Delete,'),
r.check_opt, r.enable_flag,
DECODE(BITAND(r.stmt_type, 16), 0, 0, 1)
from user$ u, obj$ o, rls$ r
where u.user# = o.owner#
and r.obj# = o.obj#
and (uid = 0 or
uid = o.owner# or
exists ( select * from session_roles where role='Select_CATALOG_ROLE')
)
/
grant select on sys.exu81rls to public;
/

可以跨版本的使用EXP/IMP，但必须正确地使用EXP和IMP的版本：
1、总是使用IMP的版本匹配数据库的版本，如：要导入到817中，使用817的IMP工具。
2、总是使用EXP的版本匹配两个数据库中最低的版本，如：从9201往817中导入，则使用817版本的EXP工具。

示例：

1.exp的条件导出

userid='/ as sysdba '
file=(exp01.dmp,exp02.dmp,exp03.dmp,exp04.dmp,exp05.dmp,exp06.dmp,exp07.dmp,exp08.dmp,exp09.dmp,
exp10.dmp,exp11.dmp,exp12.dmp,exp13.dmp,exp14.dmp,exp15.dmp,exp16.dmp,exp17.dmp,exp18.dmp,exp19.dmp,
exp20.dmp,exp21.dmp,exp22.dmp,exp23.dmp,exp24.dmp,exp25.dmp,exp26.dmp,exp27.dmp,exp28.dmp,exp29.dmp,
exp30.dmp,exp31.dmp,exp32.dmp,exp33.dmp,exp34.dmp,exp35.dmp,exp36.dmp,exp37.dmp,exp38.dmp,exp39.dmp)
filesize=4000m
log=exp.log
tables=(
CSPIDATA.cspi_cms_call_record
)
buffer=40000000
recordlength=65535
RESUMABLE=y
RESUMABLE_NAME=exp_byrnes
RESUMABLE_TIMEOUT=99999
QUERY="where GL_DATE in('20100930','20101031','20101130')"

2.imp导入

userid='/ as sysdba '
file=exp01.dmp
buffer=40000000
fromuser=RISKREPT
touser=aud_riskmd
tables=(
cspi_cms_call_record
)
ignore=y
rows=y
log=imp.log
RESUMABLE=y
RESUMABLE_NAME=imp_byrnes
RESUMABLE_TIMEOUT=99999
commit=y

3.expdp导出

create directory dtpump_egis as '..................';

userid=audmgr/paic1234
directory=dtpump_egis
dumpfile=expdp_egis%U.dmp
parallel=4
tables=
(
EGISDATA.POLICY_APPLICATION
EGISDATA.UNDERWRITING
EGISDATA.QUOTATION_RESULT
EGISDATA.QUOTATE_UNDERWRITER_OPINION

)
content=all
LOGFILE=impdp_gbs4.log
JOB_NAME=job_egis
REMAP_SCHEMA=EGISDATA:aud_gbs
REMAP_TABLESPACE=EGISDATA:ludata
TABLE_EXISTS_ACTION=REPLACE
EXCLUDE=constraint, ref_constraint, grant,index,trigger

4.impd导入

create directory dtpump_egis as '.............';

userid=audmgr/paic1234
directory=dtpump_egis
dumpfile=expdp_egis%U.dmp
parallel=4
tables=
(
EGISDATA.POLICY_APPLICATION
EGISDATA.UNDERWRITING
EGISDATA.QUOTATION_RESULT
EGISDATA.QUOTATE_UNDERWRITER_OPINION
)
content=all
LOGFILE=impdp_gbs5_idx.log
JOB_NAME=zyjob_gbs5_idx
REMAP_SCHEMA=EGISDATA:aud_gbs
REMAP_TABLESPACE=EGISDATA:luidx,EGISIDX:luidx
TABLE_EXISTS_ACTION=REPLACE
INCLUDE=index

5.expdp只导表结构

userid='/ as sysdba'
DIRECTORY=rik_expimpdp_dest
dumpfile=expdp%U.dmp
filesize=3000m
parallel=5
SCHEMAS=IMSFPDATA
content=METADATA_ONLY
LOGFILE=expdp_csb.log
JOB_NAME=expdp_rik_job1

6.expdp条件导出

userid='/ as sysdba'
DIRECTORY=rik_imp_1
dumpfile=expdp_1%U.dmp
parallel=5
tables=
(
ISBDATA. OF_GENERAL_HIS
RPTDATA. TIN_CORE_GENERAL
)
content=all
LOGFILE=expdp_rik_1.log
JOB_NAME=expdp_rik_job1
QUERY="where GL_DATE in('20100930','20101031','20101130')"


7.11g中IMPDP重命名导入表

userid='/ as sysdba '
directory=dtpump
dumpfile=expdp%U.dmp
parallel=4
REMAP_TABLE=ECDATA.TRS_PROJECT_ITEM:ECDATA.TRS_PROJECT_ITEM_BAK
content=all
LOGFILE=impdp.log
JOB_NAME=riky_imp
REMAP_SCHEMA=ECDATA:ECDATA
TABLE_EXISTS_ACTION=REPLACE


Tom Kyte suggests you always set them unusable instead
(and alter session set skip_unusable_indexes = true),
 because if you drop and later forget,
 applications run very slow,
 while if they're disabled,
 the application may throw an error,
 which reminds you.



设置当前用户要生效的角色
(注：角色的生效是一个什么概念呢？假设用户a有b1,b2,b3三个角色，那么如果b1未生效，则b1所包含的权限对于a来讲是不拥有的，只有角色生效了，角色内的权限才作用于用户，最大可生效角色数由参数MAX_ENABLED_ROLES设定；在用户登录后，oracle将所有直接赋给用户的权限和用户默认角色中的权限赋给用户。）
sql>set role role1;//使role1生效
sql>set role role,role2;//使role1,role2生效
sql>set role role1 identified by password1;//使用带有口令的role1生效
sql>set role all;//使用该用户的所有角色生效
sql>set role none;//设置所有角色失效
sql>set role all except role1;//除role1外的该用户的所有其它角色生效。
sql>select * from SESSION_ROLES;//查看当前用户的生效的角色。


8.修改指定用户，设置其默认角色
sql>alter user user1 default role role1;
sql>alter user user1 default role all except role1;




------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
13.查询数据的整个大小

select ceil(a.tempfile_size + b.datafile_size +c.logfile_size)  "databse size(GB)" from
(select sum(bytes)/1024/1024/1024 tempfile_size from dba_temp_files) a,
(select sum(bytes)/1024/1024/1024 datafile_size from dba_data_files) B,
(select sum(bytes)/1024/1024/1024 logfile_size from v$log)c;

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
14.查找存储过程OPERATIONDATA_IMP被哪些session锁住而无法编译   存储过程解锁 解锁存储过程 解锁过程
select *  FROM dba_ddl_locks where name =upper('OPERATIONDATA_IMP');
从而得到session_id，然后通过
select t.sid,t.serial# from v$session t where t.sid=&session_id;
得到sid和serial#最后用
alter system kill session 'sid,serial#';


GRANT SELECT_CATALOG_ROLE TO clmbbquery;  
 set role SELECT_CATALOG_ROLE;
 select any dictionary与select_catalog_role
相同之处，有了这两个中的一个，基本就可以查询数据字典
不同之处：
1、select any dictionary是一种系统权限（system privilege），而select_catalog_role 是一种角色（a role）。
2、角色的话需要重新登录或者显式的set role 来生效，而赋予系统权限是立即生效的。（P.S. 同样revoke权限也是立即生效）
3、select_catalog_role可以查看一些数据字典的视图·(可以看role的定义)，如dba_之类的，而select any dictionary可以查看sys的表，select_catalog_role看不到。
下面具体验证一下：
2、角色的话需要重新登录或者显式的set role 来生效，而赋予系统权限是立即生效的。（P.S. 同样revoke权限也是立即生效）
select any dictionary立即生效
同时开两个会话，查看情况。从上至下，按顺序。
 sys@test10gr2> select * from dba_role_privs where grantee = 'TEST_USER';
GRANTEE                        GRANTED_ROLE                   ADM DEF
------------------------------ ------------------------------ --- ---
TEST_USER                    CONNECT                        NO  YES
TEST_USER                    RESOURCE                       NO  YES
1、TEST_USER 只有最基本的CONNECT和RESOURCE  角色，其它的表权限也没有。
 
 	
TEST_USER@test10gr2> select count(*) from v$session;    
select count(*) from v$session
                     *
ERROR at line 1:
ORA-00942: table or view does not exist
2、此时看不到 v$session

sys@test10gr2> GRANT SELECT ANY DICTIONARY TO TEST_USER; 
Grant succeeded.
3、赋予SELECT ANY DICTIONARY系统权限
 
 	
 TEST_USER@test10gr2>  select count(*) from v$session;  
  COUNT(*)
----------
        73
4、立即生效，可以查看到v$session
 sys@test10gr2> REVOKE SELECT ANY DICTIONARY  FROM TEST_USER;
Revoke succeeded.
5、收回SELECT ANY DICTIONARY系统权限
 
 	
 TEST_USER@test10gr2>  select count(*) from v$session; 
 select count(*) from v$session
                      *
ERROR at line 1:
ORA-00942: table or view does not exist
6、立即生效，无法查看到v$session
select_catalog_role 无法立即生效
 sys@test10gr2> GRANT SELECT_CATALOG_ROLE TO TEST_USER;   
Grant succeeded.
1、赋予SELECT ANY DICTIONARY角色
 
 	
TEST_USER@test10gr2>  select count(*) from v$session; 
 select count(*) from v$session
                      *
ERROR at line 1:
ORA-00942: table or view does not exist
2、无法立即生效，使用set role即可，
revoke role也相同，不即时生效。

TEST_USER@test10gr2> set role SELECT_CATALOG_ROLE;
Role set.
TEST_USER@test10gr2>  select count(*) from v$session;
  COUNT(*)
----------
        74 
3、select_catalog_role可以查看一些数据字典的视图·，如dba_之类的，而select any dictionary可以查看sys的表。
select any dictionary 可以看到 SYS.ACCESS$表
 test_user@test10gr2> select * from dba_sys_privs where grantee = 'TEST_USER';
GRANTEE                        PRIVILEGE                                ADM
------------------------------ ---------------------------------------- ---
TEST_USER                     UNLIMITED TABLESPACE                     NO
TEST_USER                     SELECT ANY DICTIONARY                    NO

test_user@test10gr2>  select * from dba_role_privs where grantee = 'TEST_USER';
GRANTEE                        GRANTED_ROLE                   ADM DEF
------------------------------ ------------------------------ --- ---
TEST_USER                      CONNECT                        NO  YES
TEST_USER                     RESOURCE                       NO  YES
 
test_user@test10gr2> desc SYS.ACCESS$
 Name                                                  Null?    Type
 ----------------------------------------------------- -------- ------------------------------------
 D_OBJ#                                                NOT NULL NUMBER
 ORDER#                                                NOT NULL NUMBER
 COLUMNS                                                        RAW(126)
 TYPES                                                 NOT NULL NUMBER
select_catalog_role 看不到
 test_user@test10gr2> select * from dba_sys_privs where grantee = 'TEST_USER';
GRANTEE                        PRIVILEGE                                ADM
------------------------------ ---------------------------------------- ---
TEST_USER                     UNLIMITED TABLESPACE                     NO
test_user@test10gr2>  select * from dba_role_privs where grantee = 'TEST_USER';
GRANTEE                        GRANTED_ROLE                   ADM DEF
------------------------------ ------------------------------ --- ---
TEST_USER                    CONNECT                        NO  YES
TEST_USER                    RESOURCE                       NO  YES
TEST_USER                    SELECT_CATALOG_ROLE            NO  YES
test_user@test10gr2>  desc SYS.ACCESS$
ERROR:
ORA-04043: object SYS.ACCESS$ does not exist
 


ORA-12801  ORA-01652
增大表空间大小

Applies to:
Oracle Database - Enterprise Edition - Version 11.2.0.3 to 11.2.0.3 [Release 11.2]
Information in this document applies to any platform.

Symptoms
Temporary tablespace space allocation fails in RAC even when there is still free temp space.



ORA-12801: error signaled in parallel query server P017
ORA-01652: unable to extend temp segment by 640 in tablespace XY_TEMP


Cause
Unbalanced temp space distribution in RAC.  One instance seems to consume and cache most of the temp space, causing another instance to hit the ora-1652.

SQL> select inst_id, tablespace_name, round((total_blocks*8192)/(1024*1024*1024),2) "Space(GB)"
2 from gv$sort_segment
3 where tablespace_name='XY_TEMP'
4 order by 1;

INST_ID  TABLESPACE_NAME        Space(GB)
---------- ------------------------------ ----------
1           XY_TEMP                           33.39
2           XY_TEMP                           33.77
3           XY_TEMP                           34.16
4           XY_TEMP                           33.39
5           XY_TEMP                           33.46
6           XY_TEMP                       1118.79   <<<<very unbalanced
7           XY_TEMP                           33.28
8           XY_TEMP                           34.26

This is reported in Bug 14383007 - sort runs out of temp space on 2 nodes even when temp space is available
This bug will be fixed in 11.2.0.4 (future release). Refer < Document 14383007.8> for more details.

Useful queries for debugging:

Collect the information every few seconds:
1. select  * from gv$sort_segment
2. select sum(bytes), owner from gv$temp_extent_map group by owner;
3. select inst_id, blocks_cached, blocks_used, extents_cached, extents_used from GV$TEMP_EXTENT_POOL;

Solution
Workaround is:
Retry the operation.

One-off patch 14383007 has been provided for certain platform, please check My Oracle Support for patch detail.





--***************************
-- Oracle 彻底 kill session
--***************************

  kill session 是DBA经常碰到的事情之一。如果kill 掉了不该kill 的session，则具有破坏性，因此尽可能的避免这样的错误发生。同时也应当注意，
如果kill 的session属于Oracle 后台进程，则容易导致数据库实例宕机。
  通常情况下，并不需要从操作系统级别杀掉Oracle会话进程，但并非总是如此，下面的描述中给出了在Oracle级别杀掉会话以及操作系统级别杀掉进程。

一、获得需要kill session的信息(使用V$SESSION 和 GV$SESSION视图)

  SET LINESIZE 180
  COLUMN spid FORMAT A10
  COLUMN username FORMAT A10
  COLUMN program FORMAT A40

  SELECT s.inst_id,
         s.sid,
         s.serial#,
         p.spid,
         s.username,
         s.program,
         s.paddr,
         s.STATUS
  FROM   gv$session s
         JOIN gv$process p ON p.addr = s.paddr AND p.inst_id = s.inst_id
  WHERE  s.type != 'BACKGROUND';

          INST_ID        SID    SERIAL# SPID       USERNAME   PROGRAM                                       PADDR    STATUS

        ---------- ---------- ---------- ---------- ---------- --------------------------------------------- -------- --------
           1        146         23 27573      TEST       sqlplus@oracle10g (TNS V1-V3)                 4C621950 INACTIVE

           1        160         17 27610      SYS        sqlplus@oracle10g (TNS V1-V3)                 4C624174 ACTIVE

           1        144         42 27641      SCOTT      sqlplus@oracle10g (TNS V1-V3)                 4C624730 INACTIVE


二、使用ALTER SYSTEM KILL SESSION 命令实现
  语法：
      SQL> ALTER SYSTEM KILL SESSION 'sid,serial#';
      SQL> ALTER SYSTEM KILL SESSION 'sid,serial#' IMMEDIATE;

    对于RAC环境下的kill session ,需要搞清楚需要kill 的session 位于哪个节点，可以查询GV$SESSION视图获得。
    kill session 的时候仅仅是将会话杀掉。在有些时候，由于较大的事务或需要运行较长的SQL语句将导致需要kill的session并不能立即杀掉。对于这种情
    况将收到 "marked for kill"提示(如下)，一旦会话当前事务或操作完成，该会话被立即杀掉。

    alter system kill session '4730,39171'
    *
    ERROR at line 1:
    ORA-00031: session marked for kill

  在下面的操作中将杀掉会话146，144
    sys@AUSTIN> alter system kill session '146,23';
    System altered.

    sys@AUSTIN> alter system kill session '144,42';
    System altered.
    sys@AUSTIN> select inst_id,saddr,sid,serial#,paddr,username,status,program from gv$session where username is not null;

       INST_ID SADDR           SID    SERIAL# PADDR    USERNAME   STATUS   PROGRAM

    ---------- -------- ---------- ---------- -------- ---------- -------- ---------------------------------------------
             1 4C70BF04        144         42 4C6545A0 SCOTT      KILLED   sqlplus@oracle10g (TNS V1-V3)

             1 4C70E6B4        146         23 4C6545A0 TEST       KILLED   sqlplus@oracle10g (TNS V1-V3)

             1 4C71FC84        160         17 4C624174 SYS        ACTIVE   sqlplus@oracle10g (TNS V1-V3)

     注意：在查询中可以看到被杀掉的会话的PADDR地址发生了变化，参照查询结果中的红色字体。如果多个session被kill 掉，则多个session的PADDR

     被改为相同的进程地址。


  通过下面的语句来找回被kill 掉的ADDR先前的地址
    SELECT s.username,s.status,

    x.ADDR,x.KSLLAPSC,x.KSLLAPSN,x.KSLLASPO,x.KSLLID1R,x.KSLLRTYP,

    decode(bitand (x.ksuprflg,2),0,null,1)

    FROM x$ksupr x,v$session s

    WHERE s.paddr(+)=x.addr

    and bitand(ksspaflg,1)!=0;

     USERNAME   STATUS   ADDR       KSLLAPSC   KSLLAPSN KSLLASPO       KSLLID1R KS D

    ---------- -------- -------- ---------- ---------- ------------ ---------- -- -
               ACTIVE   4C623BB8         99          4 27468               275 EV 1
               ACTIVE   4C623040          9         24 27444                 0    1
               ACTIVE   4C622A84        101          4 27480               274 EV 1
               ACTIVE   4C6224C8          1         48 27450                 0    1
               ACTIVE   4C621F0C          1         48 27450                 0    1
               ACTIVE   4C6235FC          2          4 27468                 0    1
    SYS        ACTIVE   4C624174          2         15 27442                 0
               ACTIVE   4C62081C          1         48 27440                 0    1
               ACTIVE   4C621394          1         48 27440                 0    1
               ACTIVE   4C620DD8         11         24 27476                 0    1
               ACTIVE   4C61F6E8         15          4 27610                 0    1
               ACTIVE   4C620260        222         24 27450                 0    1
               ACTIVE   4C61FCA4          7         25 27573                 0    1
               ACTIVE   4C61F12C          6         25 27573                 0    1
               ACTIVE   4C61EB70          4         24 27458                 0    1
               ACTIVE   4C61E5B4          1         48 27440                 0    1
               ACTIVE   4C61DFF8          2         24 27444                 0    1
                        4C624730          0          0                       0
                        4C621950          0          0                       0
                        4C61DA3C          0          0                       0


  或者根据下面的语句来获得发生变化的addr

    sys@AUSTIN> select p.addr from v$process p where pid <> 1
      2  minus
      3  select s.paddr from v$session s;

    ADDR

    --------
    4C621950

    4C624730

三、在操作系统级别杀掉会话
  寻找会话对应的操作系统的进程ID

    sys@AUSTIN> select SPID from  v$process where ADDR in ('4C621950','4C624730') ;

    SPID
    ----------
    27573
    27641

  使用kill 命令来杀掉操作系统级别进程ID

    kill session -9 27573
    kill session -9 27641

四、获得当前会话的SID

  SQL> select userenv('sid') from dual;

  USERENV('SID')
  --------------
             627

五、多个会话需要kill 的处理办法
  1.根据给定的SID(用户名)查找需要杀掉会话的信息，包括位于哪一个实例
    set linesize 160
    col program format a35
    col username format a18
    select inst_id,saddr,sid,serial#,paddr,username,status,program from gv$session
    where sid in ('2731','2734','2720','2678','2685')
    and username='CTICUST'
    order by inst_id;

       INST_ID SADDR                   SID    SERIAL# PADDR            USERNAME           STATUS   PROGRAM

    ---------- ---------------- ---------- ---------- ---------------- ------------------ -------- ---------------------------
             1 00000003DAF8F870       2678       8265 00000003DBC6CA08 MSS4USR            INACTIVE JDBC Thin Client

             1 00000003DAF98E48       2685         83 00000003DBC08510 MSS4USR            ACTIVE   JDBC Thin Client

             1 00000003DAFC7B80       2720          5 00000003DBBEDA20 MSS4USR            INACTIVE JDBC Thin Client

             1 00000003DAFD66F8       2731          3 00000003DBBE9AE0 SYS                ACTIVE  racgimon@svdg0028(TNS V1-V3)

             1 00000003DAFDA730       2734         15 00000003DBBEC268 MSS4USR            INACTIVE JDBC Thin Client

             2 00000003DAFD66F8       2731          1 00000003DBBE92F8                    ACTIVE   oracle@svdg0029 (ARC0)

    上面的查询中有一个SID为2731的位于节点2上。
    也可以通过下面的方式来获得RAC的节点信息，便于确定需要kill 的session究竟位于哪一个节点。
      set linesize 160
      col HOST_NAME format a25

      SQL> select INSTANCE_NUMBER,INSTANCE_NAME,HOST_NAME,VERSION,STATUS from gv$instance order by 1;

      INSTANCE_NUMBER INSTANCE_NAME    HOST_NAME                 VERSION           STATUS

      --------------- ---------------- ------------------------- ----------------- ------------
                    1 O02WMT1A         svd0051                  10.2.0.4.0        OPEN
                    2 O02WMT1B         svd0052                  10.2.0.4.0        OPEN
                    3 O02WMT1C         svd0053                  10.2.0.4.0        OPEN

  2.使用下面查询来生成kill session 的语句
    select 'alter system kill session '''|| sid ||',' ||SERIAL# ||''''||';'  from  gv$session
    where sid in ('2731','2734','2720','2678','2685')
    order by inst_id;

获得下列kill session的语句，根据要求由于此次需要杀掉的session全部位于节点1，因此登录到节点节点1执行下面的语句
alter system kill session '2678,8265';
alter system kill session '2685,83';
alter system kill session '2720,5';
alter system kill session '2731,3';
alter system kill session '2734,15';
alter system kill session '2731,1';    --此条命令不需要执行，该session位于节点2。





如果提示没有这个视图，可以在sys用户下执行$ORACLE_HOME/rdbms/admin/catblock.sql脚本进行创建（这个脚本还包含其他一些非常有意义的锁相关视图）
sys@ora10g> conn / as sysdba
Connected.
sys@ora10g> @ /rdbms/admin/catblock.sql

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
15. 分段提交示例
declare   ---
  cursor cur is
    select rowid
      from pub_test.c_obd_common_info;
  t_rid        dbms_sql.Urowid_Table;
  batchrows    number := 2000;
  v_last_rowid urowid;
  v_file_name  varchar2(100);
  v_sqlcode    varchar2(100);
  v_sqlerr     varchar2(500);
begin
  open cur;
  loop
    fetch cur bulk collect
      into t_rid limit batchrows;
    exit when t_rid.count = 0;
    forall i in t_rid.first .. t_rid.last
       update  pub_test.c_obd_common_info a
    set a.CUSTOMER_NAME =null,
        a.CUSTOMER_SEX=null,
        a.CUSTOMER_AGE=null,
        a.CONTACT_TEL=null,
        a.FAMILY_TEL=null,
        a.MOBILE=null,
        a.CONTACT_ADDR=null,
        a.FAMILY_ADDR=null,
        a.CONTACT_POSTCODE=null,
        a.FAMILY_POSTCODE=null
       where rowid = t_rid(i);
    commit;
  end loop;
  close cur;
  commit;
exception
  when others then
    rollback;
end;
/



分段提交
declare
  cursor c_pol_main is
    select  a.* from ABBSDATA.abbs_sale_detail_t5egisss a  ;
  v_pol_main c_pol_main%rowtype;
begin
  open c_pol_main;
  loop
    fetch c_pol_main
      into v_pol_main;
    exit when c_pol_main%notfound;
   insert into     ABBSDATA.abbs_sale_detail
   values (v_pol_main.ABBS_BATCHNO,
v_pol_main.POLNO,
v_pol_main.CERTNO,
v_pol_main.BILLNO,
v_pol_main.AGENCYNO,
v_pol_main.TOT_PREM,
v_pol_main.CERT_STS,
v_pol_main.DESTINATION,
v_pol_main.EFF_DATE,
v_pol_main.UNDWRT_DATE,
v_pol_main.REVOKE_DATE,
v_pol_main.PRODUCTNO);
    if mod(c_pol_main%rowcount, 5000) = 0 then
      commit;
    end if;
  end loop;
  commit;
  close c_pol_main;
exception
  when others then
    close c_pol_main;
    dbms_output.put_line(substr(sqlerrm, 1, 200));
    dbms_output.put_line(v_pol_main.polno || '出错！');
end;
/


分段提交：


DECLARE
  V_COUNT        NUMBER(10) := 0;
  V_COMMIT_COUNT NUMBER(10) := 10000;
  V_C_ID         QUESTION.ID %TYPE;
  CURSOR C_ID IS
    SELECT ID FROM QUESTION;
BEGIN

  OPEN C_ID;

  LOOP

    FETCH C_ID
      INTO V_C_ID;

    EXIT WHEN C_ID%NOTFOUND;
    UPDATE QUESTION Q SET Q.TEXT = 'HOW ARE YOU ' WHERE Q.ID = V_C_ID;

    V_COUNT := V_COUNT + 1;

    /* 分段提交 */
    IF V_COUNT = V_COMMIT_COUNT THEN
      COMMIT;
      V_COUNT := 0;
    END IF;

  END LOOP;

  COMMIT;

END;


分段提交示例2
/*
背景假设：
1.修改表pos_accept中IS_POSTED字段，修改条件是：ACCEPT_DATE在2011年1月1日之前的数据,而且IS_POSTED为空。
2.假设需要修改的数据，随ACCEPT_DATE字段分布比较均匀
3.修改量超过50万，需要分段提交。

*/


/*
  分段提交实现如下：
  1.根据ACCEPT_DATE进行分段提交
  2.可以实现断点续作，当已经commit之后的数据，IS_POSTED不再为空，在脚本中查询数据量时会跳过已经修改过的数据。
*/

declare
	v_max              e_letter_repository.operation_date%type;
	v_min              e_letter_repository.operation_date%type;
	v_interval         number:=0;
	v_step             number:=0;
	v_sql              varchar2(300);
	v_count            number:=0;
	v_insert_count     number:=0;

begin
	--查询需要修改的数据量
	v_sql:='select  max(ACCEPT_DATE),min(ACCEPT_DATE),max(ACCEPT_DATE)- min(ACCEPT_DATE),count(*) from pos_accept;
	execute immediate v_sql into v_max,v_min,v_interval,v_count;

  --计算分段的时间间隔
	v_step:=round(v_interval/(v_count/500000));

	loop
	  --锁定记录
	  select * from pos_accept
      where ACCEPT_DATE >= v_min
			 	and ACCEPT_DATE <least(v_min+v_step,v_end_date) and IS_POSTED is null for update;

		--插入到备份表
		INSERT INTO dmlbak.pos_accept_bu
     SELECT rowid bak_rowid, t.*, null  from pos_accept t
       where ACCEPT_DATE >= v_min
			 	 and ACCEPT_DATE <least(v_min+v_step,v_end_date) and IS_POSTED is null;

    --关联备份表修改源表
    update  pos_accept
      set IS_POSTED='Y'
    where rowid in (select  bak_rowid from  dmlbak.pos_accept_bu where  date_dml_flag is null);

    --设置标志位
    update dmlbak.pos_accept_bu set date_dml_flag=systimestamp where date_dml_flag is null;

    commit;

	  v_min :=v_min+v_step;
		if v_min > v_max then
			exit;
		end if;
	end loop;
	commit;
end;
/





0 6 * * * $HOME/for_crontab/createTomorrowTables >> $HOME/for_crontab/mylog.log 2>&1



------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
15.更改默认临时表空间并查询使用率
--create TMP---------------------------------------------
step 1)
CREATE TEMPORARY TABLESPACE TMP
TEMPFILE
  '/paic/d0fls/data01/oradata/d0fls/tmp01.dbf' SIZE 10M
AUTOEXTEND on next 1M MAXSIZE 1000M;
step 2)
alter database default temporary tablespace TMP;
step 3)
drop tablespace  TEMP  including  contents and datafiles ;
--ReCreate TEMP-----------------------------------------
step 1)
CREATE TEMPORARY TABLESPACE TEMP
TEMPFILE
  '/paic/d0fls/data01/oradata/d0fls/temp01.dbf' SIZE 500M
AUTOEXTEND ON NEXT 10M MAXSIZE 1000M;
step 2)
alter database default temporary tablespace TEMP;
step 3)
drop tablespace  TMP  including  contents and datafiles ;
----------------------------------------------------------

select Total.Tname "表空间",
       Total.Total_Size "大小",
       Total.Total_Size - Used.free_size as "已使用",
       Used.Free_size as 表空间剩余大小,
       Round((Total.Total_Size - Used.free_size) / Total.Total_Size, 4) * 100 || '%'
  from (
        -- 表空间数据文件的大小
        select tablespace_name as TName,
                round(sum(user_bytes) / (1024 * 1024), 1) as Total_size
          from dba_data_files
         group by tablespace_name) Total,
       (
        -- 表空间剩余的大小
        select tablespace_name as TName,
                round(sum(bytes) / (1024 * 1024), 1) as Free_size
          from dba_free_space
         group by tablespace_name) Used
 where Total.TName = Used.TName(+);

 ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
16.查询数据定义
  select dbms_metadata.get_ddl('PACKAGE', 'PKG_TRUNCATE', 'APPMGR') from dual;

 ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
17.使用10046 的level 1及sql trace都可以，其实这两者些时是相等的。
设时间统计为true
SQL> show parameter timed_statistics
设置sql_trace为true,打开跟踪
SQL> alter session set sql_trace=true;
跟踪别的session，首先要找到它的sid的serial#,然后如下操作
打开：SQL>execute dbms_system.SET_SQL_TRACE_IN_SESSION(sid,serial#,true);
关闭: SQL>execute dbms_system.SET_SQL_TRACE_IN_SESSION(sid,serial#,false);
或
打开：SQL>execute dbms_system.SET_EV(sid,serial#,10046,1'');
关闭: SQL>execute dbms_system.SET_EV(sid,serial#,0,0,'');
随便执行一些sql
SQL> select * from ee;
SQL> select * from tab;
关闭sql_trace
SQL> alter session set sql_trace=false;
查找生成的trace文件
SQL> show user
USER is "SYS"
SQL> select sid,paddr from v$session where username='HR'
SQL> /
SQL> select spid from v$process where addr='51A00BD8';
用tkprof解析一下,sys=no是关掉系统视图查找的显示
oracle@yang:/opt/oracle/admin/ocm1/udump> tkprof ocm1_ora_6321.trc 1.txt sys=no

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
18.收缩空闲表空间 收缩表空间 shrink
首先，如果没有分配的空间不足100M，则不考虑收缩。
收缩目标：当前数据文件大小 － （没分配空间－ 100M）×0.8

select /*+ ordered use_hash(a,c) */
  'alter database datafile '''||a.file_name||''' resize '
   ||round(a.filesize - (a.filesize - c.hwmsize-100) *0.8)||'M;'
from
(
select file_id,file_name,round(bytes/1024/1024) filesize from dba_data_files
) a,
(
select file_id,round(max(block_id)*8/1024) HWMsize from dba_extents
group by file_id) c
where a.file_id = c.file_id
  and a.filesize - c.hwmsize > 100;


select /*+ ordered use_hash(a,c) */
  'alter database datafile '''||a.file_name||''' resize '
   ||round(a.filesize - (a.filesize - c.hwmsize-100) *0.8)||'M;',
  a.filesize,
  c.hwmsize
from
(
select file_id,file_name,round(bytes/1024/1024) filesize from dba_data_files
) a,
(
select file_id,round(max(block_id)*8/1024) HWMsize from dba_extents
group by file_id) c
where a.file_id = c.file_id
  and a.filesize - c.hwmsize > 100


  select 'alter database datafile '||file_id||' resize '||resize_g||'G;' from (
select file_id,file_name,total_g,free_g,ceil(total_g - free_g +1)  resize_g from (
select a.file_id,a.file_name,a.bytes/1024/1024/1024 total_g,c.free_g from dba_data_files a,
(select b.file_id,sum(bytes)/1024/1024/1024 free_g from dba_free_space b group by file_id) c
where a.file_id = c.file_id )
where free_g>=5)

如果只是想对某个表个间的datafile resize,可采用:

SQL> select a.file#,a.name,a.bytes/1024/1024 CurrentMB,
       ceil(HWM * a.block_size)/1024/1024 ResizeTo,
       (a.bytes - HWM * a.block_size)/1024/1024 ReleaseMB,
       'alter database datafile '''||a.name||''' resize '||
       ceil(HWM * a.block_size/1024/1024) || 'M;' ResizeCMD
from v$datafile a,
     (select file_id,max(block_id+blocks-1) HWM
       from dba_extents where file_id in
              (select b.file#  From v$tablespace a ,v$datafile b
                where a.ts#=b.ts# and a.name='TEST')
       group by file_id) b
where a.file# = b.file_id(+)
and (a.bytes - HWM *block_size)>0
order by 5
;
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
19.Oracle的锁表与解锁表

SELECT /*+ rule */ s.username,
decode(l.type,'TM','TABLE LOCK',
'TX','ROW LOCK',
NULL) LOCK_LEVEL,
o.owner,o.object_name,o.object_type,
s.sid,s.serial#,s.terminal,s.machine,s.program,s.osuser
FROM v$session s,v$lock l,dba_objects o
WHERE l.sid = s.sid
AND l.id1 = o.object_id(+)
AND s.username is NOT Null

SELECT /*+ rule */ s.username,
decode(l.type,'TM','TABLE LOCK',
'TX','ROW LOCK',
NULL) LOCK_LEVEL,
o.owner,o.object_name,o.object_type,
s.sid,s.serial#,s.terminal,s.machine,s.program,s.osuser
FROM v$session s,v$lock l,dba_objects o
WHERE l.sid = s.sid
AND l.id1 = o.object_id(+)
AND s.username is NOT Null

--kill session语句
alter system kill session'50,492';
--以下几个为相关表
SELECT * FROM v$lock;
SELECT * FROM v$sqlarea;
SELECT * FROM v$session;
SELECT * FROM v$process ;
SELECT * FROM v$locked_object;
SELECT * FROM all_objects;
SELECT * FROM v$session_wait;
查出锁定object的session的信息以及被锁定的object名
SELECT l.session_id sid, s.serial#, l.locked_mode,l.oracle_username,
l.os_user_name,s.machine, s.terminal, o.object_name, s.logon_time
FROM v$locked_object l, all_objects o, v$session s
WHERE l.object_id = o.object_id
AND l.session_id = s.sid
ORDER BY sid, s.serial# ;
查出锁定表的session的sid, serial#,os_user_name, machine name, terminal和执行的语句
--比上面那段多出sql_text和action
SELECT l.session_id sid, s.serial#, l.locked_mode, l.oracle_username, s.user#,
l.os_user_name,s.machine, s.terminal,a.sql_text, a.action
FROM v$sqlarea a,v$session s, v$locked_object l
WHERE l.session_id = s.sid
AND s.prev_sql_addr = a.address
ORDER BY sid, s.serial#;
查出锁定表的sid, serial#,os_user_name, machine_name, terminal，锁的type,mode
SELECT s.sid, s.serial#, s.username, s.schemaname, s.osuser, s.process, s.machine,
s.terminal, s.logon_time, l.type
FROM v$session s, v$lock l
WHERE s.sid = l.sid
AND s.username IS NOT NULL
ORDER BY sid;

这个语句将查找到数据库中所有的DML语句产生的锁，还可以发现，
任何DML语句其实产生了两个锁，一个是表锁，一个是行锁。
杀锁命令
alter system kill session 'sid,serial#'
SELECT /*+ rule */ s.username,
decode(l.type,'TM','TABLE LOCK',
'TX','ROW LOCK',
NULL) LOCK_LEVEL,
o.owner,o.object_name,o.object_type,
s.sid,s.serial#,s.terminal,s.machine,s.program,s.osuser
FROM v$session s,v$lock l,dba_objects o
WHERE l.sid = s.sid
AND l.id1 = o.object_id(+)
AND s.username is NOT NULL
如果发生了锁等待，我们可能更想知道是谁锁了表而引起谁的等待
以下的语句可以查询到谁锁了表，而谁在等待。
以上查询结果是一个树状结构，如果有子节点，则表示有等待发生。
如果想知道锁用了哪个回滚段，还可以关联到V$rollname，其中xidusn就是回滚段的USN

select username,v$lock.sid, trunc(id1/power(2,16)) rbs,
bitand(id1,to_number('ffff','xxxx'))+0 slot,
id2 seq,
lmode,
request from v$lock,v$session where v$lock.type='TX'
and v$lock.sid=v$session.sid
and v$session.username=user;


开发测试主机，Oracle grid卷满了；帮忙安排清理一下。

[root@cnsh230234 root]# su - grid
[grid@cnsh230234 ~]$ ORACLE_SID=+ASM1
[grid@cnsh230234 ~]$ export ORACLE_SID
[grid@cnsh230234 ~]$ sqlplus '/as sysdba'

SQL*Plus: Release 11.2.0.3.0 Production on Tue Jul 1 08:49:25 2014

Copyright (c) 1982, 2011, Oracle.  All rights reserved.

ERROR:
ORA-09817: Write to audit file failed.
Linux-x86_64 Error: 28: No space left on device
Additional information: 12
ORA-01075: you are currently logged on


Enter user-name:
[grid@cnsh230234 ~]$
[grid@cnsh230234 ~]$ df -h | grep 100
                       50G   48G     0 100% /oracle_grid
                       25G   24G     0 100% /paic/hq/heps/data
                       50G   47G     0 100% /paic/mymon/data
                     1008G  793G  164G  83% /paic/db/oradata01




col checkpoint_change# for 999999999999999999999999999999
col user_name format a10
col owner format a10
col object_name format a10
col object_type format a10
SELECT /*+ rule */ lpad(' ',decode(l.xidusn ,0,3,0))||l.oracle_username User_name,
o.owner,o.object_name,o.object_type,s.sid,s.serial#
FROM v$locked_object l,dba_objects o,v$session s
WHERE l.object_id=o.object_id
AND l.session_id=s.sid
ORDER BY o.object_id,xidusn DESC

SELECT sn.username,
       m.SID,
       sn.SERIAL#,
       m.TYPE,
       DECODE(m.lmode, 0, 'None', 1, 'Null',  2, 'Row Share',3, 'Row Excl.',   4,  'Share',  5,  'S/Row Excl.',   6,  'Exclusive',  lmode,
              LTRIM(TO_CHAR(lmode, '990'))) lmode,
       DECODE(m.request,
              0, 'None',   1, 'Null', 2,  'Row Share', 3, 'Row Excl.',  4, 'Share', 5,'S/Row Excl.', 6, 'Exclusive', request,
              LTRIM(TO_CHAR(m.request, '990'))) request,
       m.id1,       m.id2
  FROM v$session sn, v$lock m
 WHERE (sn.SID = m.SID AND m.request != 0) --存在锁请求，即被阻塞
    OR (sn.SID = m.SID --不存在锁请求，但是锁定的对象被其他会话请求锁定
       AND m.request = 0 AND lmode != 4 AND
       (id1, id2) IN (SELECT s.id1, s.id2
                         FROM v$lock s
                        WHERE request != 0
                          AND s.id1 = m.id1
                          AND s.id2 = m.id2))
 ORDER BY id1, id2, m.request;


    oracle用户登录审计
 Oracle中可以按照如下方式对用户登陆失败进行审计：
    1、确认sys.aud$ 是否存在？

    desc sys.aud$

    2、观察user$表中lcount为非0的用户，如果包含被锁账户，则可以判定很有可能是该用户登陆尝试失败过多

    造成了账户被锁：

    select name,lcount from sys.user$;

    3、修改audit参数： audit_trail=none

    alter system set audit_trail=db scope=spfile;

    重启数据库。参数生效。

    4、开启tb登陆失败审计：

    AUDIT SESSION WHENEVER NOT SUCCESSFUL;

    5、登陆失败尝试。

    sqlplus w/错误密码

    6、检查审计记录

    select * from sys.aud$;

    里面有会话基本信息和机器名，用户名等。

    解锁用户

    alter user atest account unlock;

    解除由于密码连续错误而锁定用户

    alter profile default limit failed_login_attempts unlimited;



exec dbms_fga.enable_policy(object_schema=>'TOADATA', object_name=> 'TOA_CUSTOMER', policy_name=> 'check_test_tab');

exec dbms_fga.disable_policy(object_schema=>'TOADATA', object_name=> 'TOA_CUSTOMER', policy_name=> 'check_test_tab',statement_types => 'INSERT, UPDATE, DELETE, SELECT');



对表开启精细审计
    exec dbms_fga.disable_policy(object_schema=>'DBMGR', object_name=> 'TEST', policy_name=> 'check_test_tab',
    statement_types => 'INSERT, UPDATE, DELETE, SELECT');
    exec dbms_fga.enable_policy(object_schema=>'DBMGR', object_name=> 'TEST', policy_name=> 'check_test_tab');
                   SQL> select db_user,sql_text from dba_fga_audit_trail;

                   DB_USER                                                      SQL_TEXT
                   ------------------------------------------------------------ ----------------------------------------
                   DBMGR                                                        INSERT INTO TEST VALUES(1)
                   DBMGR                                                        update test set id = 2
                   DBMGR                                                        delete from test

 begin
      dbms_fga.add_policy(object_schema=>'TOADATA',
                           object_name=>'TOA_CUSTOMER',
                            policy_name=>'check_test_tab',
                            enable=>TRUE,
                            statement_types=>'SELECT,INSERT,UPDATE,DELETE'
                             );
        end;
/


  1 .查看AUD$和FGA_LOG$所在表空间
SELECT table_name, tablespace_name FROM dba_tables WHERE table_name IN ('AUD$', 'FGA_LOG$') ORDER BY table_name;
2.查看AUD$和FGA_LOG$数据量
select segment_name,bytes/1024/1024 size_in_megabytes from dba_segments where segment_name in ('AUD$','FGA_LOG$');
3.创建audit_tbs表空间
create tablespace audit_tbs datafile '/u01/app/oracle/oradata/prod/audit_tbs01.dbf' size 100M autoextend on;
4.move AUD$和FGA_LOG$
SQL> BEGIN
 DBMS_AUDIT_MGMT.set_audit_trail_location(
 audit_trail_type => DBMS_AUDIT_MGMT.AUDIT_TRAIL_AUD_STD,--this moves table AUD$
 audit_trail_location_value => 'AUDIT_TBS');
END;
/
SQL> BEGIN
 DBMS_AUDIT_MGMT.set_audit_trail_location(
 audit_trail_type => DBMS_AUDIT_MGMT.AUDIT_TRAIL_FGA_STD,--this moves table FGA_LOG$
 audit_trail_location_value => 'AUDIT_TBS');
END;
/
5.查看move后的AUD$和FGA_LOG$所在表空间
SELECT table_name, tablespace_name FROM dba_tables WHERE table_name IN ('AUD$', 'FGA_LOG$') ORDER BY table_name;


Create Index  lifedata.yinhw_index On lifedata.POS_CCS_CB_CASE_INFO(REGION_CODE,SPECIAL_CODE,PROBLEM_TYPE,CASE_STATUS,CHANNEL)
Parallel 12;
Alter Index lifedata.yinhw_index Noparallel;



sqlplus "/ as sysdba" 连不上，报ora-01031:insufficient privileges解决方法

 注意文件权限  network/admin/*

注意多个数据库实例时候，set　ORACLE_SID='',

1、检查sqlnet.ora（WINDOWS下位于%ORACLE_HOME%NETWORKADMIN目录）是否包含这句：
SQLNET.AUTHENTICATION_SERVICES=(NTS)，没有的话加上



2、检查登陆windows的用户(administrator或安装oracle时候使用的用户)是不是在包含在ORA_DBA组中，域用户没有连上域服务器时就可能出现这种现象。

3. 要保证 remote_login_passwordfile 参数 = EXCLUSIVE .

4. 看看是否需要使用orapassw生成口令文件 .


一种解决方法案例：

1、检查系统参数：
SQL> show parameter password

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
remote_login_passwordfile            string      EXCLUSIVE
2、
select * from v$pwfile_users;
SQL>
为空

3、
SQL> grant sysdba to sys;
grant sysdba to sys
*
ERROR at line 1:
ORA-01994: GRANT failed: password file missing or disabled
4、建立password文件
D:/>orapwd file="D:/oracle/product/10g/db_1/database/PWDoratest.ora" password=gp
oswong entries=10
5、
SQL> select * from v$pwfile_users;

USERNAME                       SYSDB SYSOP
------------------------------ ----- -----
SYS                            TRUE  TRUE
SYS正常显示出来。
6、重新在远程以SYSDBA登录，可正常使用。


如果口令文件创建的有问题，也是会报如下的错误：

ora-01031:insufficient privileges

口令文件的命名格式应为orapwsid，并且sid是区分大小写的。由于Target Database连接Auxiliary Database时需要验证口令，
如果违反了以上规则，将会提示ORA-01031: insufficient privileges。


我在用linux创建duplicate数据库的时候 就是因为口令文件创建的路径和名称不对才遇到这个错误


-----end-------


 对Oracle数据库UNDO表空间的监控和管理是我们日常最重要的工作之一，UNDO表空间通常都是Oracle自动化管理（通过undo_management初始化参数确定）；UNDO表空间是用于存储DML操作的前镜像数据，它是实例恢复，数据回滚，一致性查询功能的重要组件；我们常常会忽略对它的监控，这会导致UNDO表空间可能出现以下问题：
1).空间使用率100%，导致DML操作无法进行。
2).告警日志中出现大量的ORA-01555告警错误。
3).实例恢复失败，数据库无法正常打开。

一.对Oracle自动化管理UNDO进行干预。

   由于UNDO是自动化管理，可干预的地方非常的少，更多的是监控，通过以下几个地方可对UNDO表空间实施一定的干预：

1).初始化参数

undo_management=AUTO     表示实例自动化管理UNDO表空间，从Oracle 9i开始，Oracle引进了AUM（Automatic Undo Management）。
undo_retention=900              事务提交后，相应的UNDO数据保留的时间，单位：秒。
undo_tablespace=UNDOTBS1 活动的UNDO表空间。
_smu_debug_mode=33554432
_undo_autotune=TRUE

2).Automatic UNDO Retention

    Automatic UNDO Retention这是10g的新特性，没有参数能控制该特性，在10g这个特性是默认启用的。
    在Oracle Database 10g中当自动undo管理被启用，总是存在一个当前的undo retention，Oracle Database尝试至少保留旧的undo信息到该时间。数据库收集使用情况统计信息，基于这些统计信息和UNDO表空间大小来调整undo retention的时间。
    Oracle Database基于undo表空间大小和系统活动自动调整undo retention，通过设置UNDO_RETENTION初始化参数指定undo retention的最小值。

调整UNDO RETENTION的当前值可以通过以下查询获得：
SELECT TO_CHAR(BEGIN_TIME, 'MM/DD/YYYY HH24:MI:SS') BEGIN_TIME,
    TUNED_UNDORETENTION FROM V$UNDOSTAT;

    针对自动扩展的UNDO表空间，系统至少保留UNDO到参数指定的时间，自动调整UNDO RETENTION以满足查询对UNDO的要求，这可能导致UNDO急剧扩张，可以考虑不设置UNDO RETENTION值。

    针对固定的UNDO表空间，系统根据最大可能的undo retention进行自动调整，参考基于UNDO表空间大小和使用历史进行调整，这将忽略UNDO_RETENTION,除非表空间启用了RETENTION GUARANTEE。

自动调整undo retention不支持LOB，因为不能在undo表空间中存储任何有关LOBs事务的UNDO信息。

可以通过设置_undo_autotune=FALSE显示的关闭Automatic UNDO Retention功能。

3).TUNED_UNDORETENTION计算的值很大导致UNDO表空间增长很快？

    当使用的UNDO表空间非自动增长，tuned_undoretention是基于UNDO表空间大小的使用率计算出来的，在一些情况下，特别是较大的UNDO表空间时，这将计算出较大的值。

为了解决此行为，设置以下的实例参数：
_smu_debug_mode=33554432

设置该参数，TUNED_UNDORETENTION就不基于undo表空间大小的使用率计算，代替的是设置(MAXQUERYLEN +300)和UNDO_RETENTION的最大值。

4).UNDO表空间数据文件自动扩展

    如果UNDO表空间是一个自动扩展的表空间，那么很有可能UNDO表空间状态为EXPIRED的EXTENT不会被使用（这是为了减少报ORA-01555错误的几率），这将导致UNDO表空间变得很大；如果将UNDO表空间设置为非自动扩展，那么状态为EXPIRED的EXTENT就能被利用，这样可以一定程度控制UNDO表空间的大小，但这样会增加ORA-01555报错和UNDO空间不足报错的风险。合理的非自动扩展的UNDO表空间大小，以及合理的UNDO_RETENTION设置可以确保稳定的UNDO空间使用。

5).UNDO表空间guarantee属性

    如果UNDO表空间是noguarantee状态，Oracle不确保提交后的事务对应的UNDO表空间中的数据会保留UNDO_RETENTION指定的时长，如果UNDO表空间不足，其他事务将可能偷盗相应的未过期的空间；将UNDO表空间设置为guarantee能够确保提交后的事务对应UNDO表空间中的数据在任何情况下都将保留UNDO_RETENTION指定的时长。

SQL> SELECT tablespace_name, retention FROM dba_tablespaces where tablespace_name='UNDOTBS1';

TABLESPACE_NAME                                              RETENTION
------------------------------------------------------------ ----------------------
UNDOTBS1                                                     NOGUARANTEE

SQL> alter tablespace undotbs1 retention guarantee;

表空间已更改。

SQL> SELECT tablespace_name, retention FROM dba_tablespaces where tablespace_name='UNDOTBS1';

TABLESPACE_NAME                                              RETENTION
------------------------------------------------------------ ----------------------
UNDOTBS1                                                     GUARANTEE

6).UNDO表空间大小

   针对不同类型的业务系统，需要有充足的UNDO表空间，确保系统能够正常的运行。UNDO空间的大小跟业务系统有关系，也跟UNDO_RETENTION和UNDO表空间的GUARANTEE属性有关系，通常我们可以通过V$UNDOSTAT的统计信息估算出需要的UNDO表空间大小。

二.监控UNDO表空间使用情况。

   作为管理员来说，针对UNDO表空间更重要的是日常的监控工作，监控常用到以下的视图：
a).DBA_ROLLBACK_SEGS
DBA_ROLLBACK_SEGS describes rollback segments.

b).V$ROLLSTAT
V$ROLLSTAT contains rollback segment statistics.

c).V$TRANSACTION
V$TRANSACTION lists the active transactions in the system.

d).V$UNDOSTAT
V$UNDOSTAT displays a histogram of statistical data to show how well the system is working. The available statistics include undo space consumption, transaction concurrency, and length of queries executed in the instance. You can use this view to estimate the amount of undo space required for the current workload. Oracle uses this view to tune undo usage in the system. The view returns NULL values if the system is in manual undo management mode.

Each row in the view keeps statistics collected in the instance for a 10-minute interval. The rows are in descending order by the BEGIN_TIME column value. Each row belongs to the time interval marked by (BEGIN_TIME, END_TIME). Each column represents the data collected for the particular statistic in that time interval. The first row of the view contains statistics for the (partial) current time period. The view contains a total of 576 rows, spanning a 4 day cycle.

e).DBA_UNDO_EXTENTS
DBA_UNDO_EXTENTS describes the extents comprising the segments in all undo tablespaces in the database.  This view shows the status and size of each extent in the undo tablespace.

DBA_UNDO_EXTENTS.STATUS有三个值：
ACTIVE      表示未提交事务还在使用的UNDO EXTENT，该值对应的UNDO SEGMENT的DBA_ROLL_SEGMENTS.STATUS一定是ONLINE或PENDING OFFLINE状态，一旦没有活动的事务在使用UNDO SEGMENT，那么对应的UNDO SEGMENT就变成OFFLINE状态。
EXPIRED     表示已经提交且超过了UNDO_RETENTION指定时间的UNDO EXTENT。
UNEXPIRED 表示已经提交但是还没有超过UNDO_RETENTION指定时间的UNDO EXTENT。

   Oracle重复使用UNDO EXTENT的原则如下：
1).ACTIVE状态的EXTENT在任何情况下都不会被占用。
2).如果是自动扩展的UNDO表空间，Oracle会保证EXTENT至少保留UNDO_RETENTION指定的时间。
3).如果自动扩展空间不足或者UNDO表空间是非自动扩展，Oracle会尝试重复使用同一个段下面EXPIRED状态的EXTENT，如果本段中没有这样的EXTENT，就会去偷别的段下面EXPIRED状态的EXTENT，如果依然没有这样的EXTENT，就会使用本段UNEXPIRED的EXTENT，如果还是没有，那么会去偷别的段的UNEXPIRED的EXTENT，这个都没有，就会报错。

1.UNDO表空间空间使用情况。

1).UNDO表空间总大小。
   UNDO表空间下也以段的形式存储数据，每个事务对应一个段，这种类型的段通常被称为回滚段，或者UNDO段。默认情况下，数据库实例会初始化10个UNDO段，这主要是为了避免新生成的事务对UNDO段的争用。
UNDO表空间的总大小就是UNDO表空间下的所有数据文件大小的总和：
SQL> select tablespace_name,contents from dba_tablespaces where tablespace_name='UNDOTBS1';

TABLESPACE_NAME                                              CONTENTS
------------------------------------------------------------ ------------------
UNDOTBS1                                                     UNDO

SQL> select tablespace_name,sum(bytes)/1024/1024 mb from dba_data_files where tablespace_name='UNDOTBS1'  group by tablespace_name;

TABLESPACE_NAME                                                      MB
------------------------------------------------------------ ----------
UNDOTBS1                                                             90

2).查看UNDO表空间的使用情况。
    该使用情况可以通过两个视图来查看：
SQL> select owner,segment_name,bytes/1024/1024 mb from dba_segments where tablespace_name='UNDOTBS1';


OWNER      SEGMENT_NAME                           MB
---------- ------------------------------ ----------
SYS        _SYSSMU12_2867006942$                .125
SYS        _SYSSMU11_3120896088$                .125
SYS        _SYSSMU10_1735367849$               2.125
SYS        _SYSSMU9_3051513041$                2.125
SYS        _SYSSMU8_2280151962$                2.125
SYS        _SYSSMU7_825858386$                 .9375
SYS        _SYSSMU6_2597279618$                3.125
SYS        _SYSSMU5_247215464$                 3.125
SYS        _SYSSMU4_437228663$                 2.125
SYS        _SYSSMU3_3104504842$                5.125
SYS        _SYSSMU2_2464850095$                2.125
SYS        _SYSSMU1_2523538120$                3.125

已选择12行。

SQL>  select segment_name, v.rssize/1024/1024 mb
  2    From dba_rollback_segs r, v$rollstat v
  3    Where r.segment_id = v.usn(+)
  4    order by segment_name ;

SEGMENT_NAME                           MB
------------------------------ ----------
SYSTEM                           .3671875
_SYSSMU10_1735367849$           2.1171875
_SYSSMU11_3120896088$
_SYSSMU12_2867006942$
_SYSSMU1_2523538120$            3.1171875
_SYSSMU2_2464850095$            2.1171875
_SYSSMU3_3104504842$            5.1171875
_SYSSMU4_437228663$             2.1171875
_SYSSMU5_247215464$             3.1171875
_SYSSMU6_2597279618$            3.1171875
_SYSSMU7_825858386$              .9296875
_SYSSMU8_2280151962$            2.1171875
_SYSSMU9_3051513041$            2.1171875

已选择13行。

    通过上面的两个查询可以看出，两个视图查询的值几乎一致，通常在巡检的时候，我们习惯查询dba_segments视图来确定UNDO表空间的使用情况，但查询V$ROLLSTAT数据更加准确。

3).查询事务使用的UNDO段及大小。
    很多客户想知道，我的UNDO表空间超过了90%，是哪些会话的事务占用了这些空间：
SQL>  select s.sid,s.serial#,s.sql_id,v.usn,segment_name,r.status, v.rssize/1024/1024 mb
  2    From dba_rollback_segs r, v$rollstat v,v$transaction t,v$session s
  3    Where r.segment_id = v.usn and v.usn=t.xidusn and t.addr=s.taddr
  4    order by segment_name ;


       SID    SERIAL# SQL_ID                            USN SEGMENT_NAME                                         STATUS                                   MB
---------- ---------- -------------------------- ---------- ------------------------------------------------------------ -------------------------------- ----------
         8        163                                     5 _SYSSMU5_247215464$                                  ONLINE                            3.1171875

    通过这个SQL语句可以查询到会话对应的活动事务使用的UNDO段名称，以及该段占用的UNDO空间大小，对于非活动事务占用了UNDO空间是由Oracle实例根据参数配置自动化管理的。

2.根据Oracle对UNDO表空间的统计信息调整UNDO参数及大小。

    最后我们要谈谈V$UNDOSTAT视图，该视图的作用是用于指导管理员调整UNDO表空间的参数及表空间大小，每行表示的是10分钟的数据，最多可保留576行，4天一个周期，如果该视图没有数据，那么UNDO可能是手动管理方式。下面对该视图字段的含义进行说明：
BEGIN_TIME  DATE  Identifies the beginning of the time interval  时间间隔开始时间。
END_TIME  DATE  Identifies the end of the time interval    时间间隔结束时间。
UNDOTSN NUMBER  Represents the last active undo tablespace in the duration of time. The tablespace ID of the active undo tablespace is returned in this column. If more than one undo tablespace was active in that period, the active undo tablespace that was active at the end of the period is reported.  时间间隔活动的UNDO表空间个数，返回的是活动UNDO表空间的ID号，如果大于1个活动的UNDO表空间，将报告在时间间隔最后被激活的UNDO表空间ID号。
UNDOBLKS  NUMBER  Represents the total number of undo blocks consumed. You can use this column to obtain the consumption rate of undo blocks, and thereby estimate the size of the undo tablespace needed to handle the workload on your system.  表示总共消费的UNDO块数，可以使用这个字段获得undo块的消费比率，由此来估算处理系统负载需要的UNDO表空间大小。
TXNCOUNT  NUMBER  Identifies the total number of transactions executed within the period  在这个时期内总共执行的事务数。
MAXQUERYLEN NUMBER  Identifies the length of the longest query (in seconds) executed in the instance during the period. You can use this statistic to estimate the proper setting of the UNDO_RETENTION initialization parameter. The length of a query is measured from the cursor open time to the last fetch/execute time of the cursor. Only the length of those cursors that have been fetched/executed during the period are reflected in the view.  在这个时期该实例执行的最长查询时间（单位：秒），可以使用这个统计信息估算UNDO_RETENTION初始化参数的大概值。查询的时间精确到从游标打开到最后提取/执行时间。只有当这些游标的查询时间在这个时期被提取/执行才能被反映到该视图。
MAXQUERYID  VARCHAR2(13)  SQL identifier of the longest running SQL statement in the period  在这个时期运行最长时间的SQL语句标识符。
MAXCONCURRENCY  NUMBER  Identifies the highest number of transactions executed concurrently within the period  在这个时期并行执行的最大事务数。
UNXPSTEALCNT  NUMBER  Number of attempts to obtain undo space by stealing unexpired extents from other transactions  尝试从其他事务通过偷盗的方式获得的未过期的undo空间区间数。
UNXPBLKRELCNT NUMBER  Number of unexpired blocks removed from certain undo segments so they can be used by other transactions  从某些UNDO段移除未过期的块数，他们被用于其它事务。
UNXPBLKREUCNT NUMBER  Number of unexpired undo blocks reused by transactions  事务重新使用未过期的undo块数。
EXPSTEALCNT NUMBER  Number of attempts to steal expired undo blocks from other undo segments  尝试从其他UNDO段偷盗过期的UNDO块数。
EXPBLKRELCNT  NUMBER  Number of expired undo blocks stolen from other undo segments  从其他UNDO段偷盗的过期的UNDO块数。
EXPBLKREUCNT  NUMBER  Number of expired undo blocks reused within the same undo segments  在相同UNDO段重新使用的过期的UNDO块数。
SSOLDERRCNT NUMBER  Identifies the number of times the error ORA-01555 occurred. You can use this statistic to decide whether or not the UNDO_RETENTION initialization parameter is set properly given the size of the undo tablespace. Increasing the value of UNDO_RETENTION can reduce the occurrence of this error.  标识ORA-01555错误发生的次数，可以使用这个统计信息决定针对给定的UNDO表空间是否设置UNDO_RETENTION初始化参数。增加UNDO_RETENTION的值可以减少这个错误的发生。
NOSPACEERRCNT NUMBER  Identifies the number of times space was requested in the undo tablespace and there was no free space available. That is, all of the space in the undo tablespace was in use by active transactions. The corrective action is to add more space to the undo tablespace.  在UNDO表空间没有自由空间活动的情况下，空间请求的次数，所有UNDO表空间的空间被活动的事务使用，这需要添加更多的空间到UNDO表空间。
ACTIVEBLKS  NUMBER  Total number of blocks in the active extents of the undo tablespace for the instance at the sampled time in the period  在时间间隔，针对该实例，UNDO表空间活动区间的块个数。
UNEXPIREDBLKS NUMBER  Total number of blocks in the unexpired extents of the undo tablespace for the instance at the sampled time in the period  在时间间隔，针对该实例，UNDO表空间未过期的块个数。
EXPIREDBLKS NUMBER  Total number of blocks in the expired extents of the undo tablespace for the instance at the sampled time in the period  在时间间隔，针对该实例，UNDO表空间过期区间的块个数。
TUNED_UNDORETENTION NUMBER  Amount of time (in seconds) for which undo will not be recycled from the time it was committed. At any point in time, the latest value of TUNED_UNDORETENTION is used to determine whether data committed at a particular time in the past can be recycled.  提交之后UNDO不能被回收的总时间（单位：秒）。
下面是查询V$UNDOSTAT的例子：

SELECT TO_CHAR(BEGIN_TIME, 'MM/DD/YYYY HH24:MI:SS') BEGIN_TIME,
  TO_CHAR(END_TIME, 'MM/DD/YYYY HH24:MI:SS') END_TIME,
  UNDOTSN, UNDOBLKS, TXNCOUNT, MAXCONCURRENCY AS "MAXCON",
  MAXQUERYLEN, TUNED_UNDORETENTION
  FROM v$UNDOSTAT;

通常当字段UNXPSTEALCNT和EXPBLKREUCNT是非零值，表示有空间压力。
如果字段SSOLDERRCNT是非零值，表示UNDO_RETENTION设置不合理。
如果字段NOSPACEERRCNT是非零值，表示有一系列空间问题。
在10g DBA_HIST_UNDOSTAT视图包括了V$UNDOSTAT快照统计信息。
注意：如果参数_undo_autotune=FALSE,X$KTUSMST2将没有数据生成，该表示DBA_HIST_UNDOSTATS视图的源表。


三.释放UNDO表空间。

    UNDO表空间被撑得过大，有些时候我们需要释放这些空间，通常的做法是新建一个UNDO，然后设置使用新建的UNDO表空间，最后DROP原有UNDO表空间。下面通过一个例子来演示这个过程：
SQL> col segment_name format a30
SQL> col tablespace_name format a30
SQL>
SQL> select segment_name, tablespace_name, r.status,
  2    (initial_extent/1024) InitialExtent,(next_extent/1024) NextExtent,
  3    max_extents, v.curext CurExtent
  4    From dba_rollback_segs r, v$rollstat v
  5    Where r.segment_id = v.usn(+)
  6    order by segment_name ;

SEGMENT_NAME                   TABLESPACE_NAME                STATUS                           INITIALEXTENT NEXTEXTENT MAX_EXTENTS  CUREXTENT
------------------------------ ------------------------------ -------------------------------- ------------- ---------- ----------- ----------
SYSTEM                         SYSTEM                         ONLINE                                  112            56       32765          4
_SYSSMU10_1735367849$          UNDOTBS1                       ONLINE                                  128            64       32765          2
_SYSSMU11_3120896088$          UNDOTBS1                       OFFLINE                                 128            64       32765
_SYSSMU12_2867006942$          UNDOTBS1                       OFFLINE                                 128            64       32765
_SYSSMU1_2523538120$           UNDOTBS1                       ONLINE                                  128            64       32765          2
_SYSSMU2_2464850095$           UNDOTBS1                       ONLINE                                  128            64       32765          2
_SYSSMU3_3104504842$           UNDOTBS1                       ONLINE                                  128            64       32765          2
_SYSSMU4_437228663$            UNDOTBS1                       ONLINE                                  128            64       32765          2
_SYSSMU5_247215464$            UNDOTBS1                       ONLINE                                  128            64       32765          3
_SYSSMU6_2597279618$           UNDOTBS1                       ONLINE                                  128            64       32765          3
_SYSSMU7_825858386$            UNDOTBS1                       ONLINE                                  128            64       32765          9
_SYSSMU8_2280151962$           UNDOTBS1                       ONLINE                                  128            64       32765          3
_SYSSMU9_3051513041$           UNDOTBS1                       ONLINE                                  128            64       32765          2

已选择13行。

当前所有的回滚段在属于UNDOTBS1表空间。

SQL> create undo tablespace undotbs2 datafile 'E:\APP\ORADATA\ORCL3\undotbs02.dbf' size 20m autoextend on next 100m;

表空间已创建。

SQL> show parameter undo

NAME                                 TYPE                   VALUE
------------------------------------ ---------------------- ------------------------------
undo_management                      string                 AUTO
undo_retention                       integer                900
undo_tablespace                      string                 UNDOTBS1
SQL> alter system set undo_tablespace='UNDOTBS2';

系统已更改。

SQL> show parameter undo

NAME                                 TYPE                   VALUE
------------------------------------ ---------------------- ------------------------------
undo_management                      string                 AUTO
undo_retention                       integer                900
undo_tablespace                      string                 UNDOTBS2

SQL> select segment_name, tablespace_name, r.status,
  2    (initial_extent/1024) InitialExtent,(next_extent/1024) NextExtent,
  3    max_extents, v.curext CurExtent
  4    From dba_rollback_segs r, v$rollstat v
  5    Where r.segment_id = v.usn(+)
  6    order by segment_name ;

SEGMENT_NAME                   TABLESPACE_NAME                STATUS                           INITIALEXTENT NEXTEXTENT MAX_EXTENTS  CUREXTENT
------------------------------ ------------------------------ -------------------------------- ------------- ---------- ----------- ----------
SYSTEM                         SYSTEM                         ONLINE                                  112            56       32765          5
_SYSSMU10_1735367849$          UNDOTBS1                       OFFLINE                                 128            64       32765
_SYSSMU11_3120896088$          UNDOTBS1                       OFFLINE                                 128            64       32765
_SYSSMU12_2867006942$          UNDOTBS1                       OFFLINE                                 128            64       32765
_SYSSMU13_3398750080$          UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU14_3208386744$          UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU15_2082453576$          UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU16_2746861185$          UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU17_3752120760$          UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU18_3475721077$          UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU19_1407063349$          UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU1_2523538120$           UNDOTBS1                       OFFLINE                                 128            64       32765
_SYSSMU20_910603223$           UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU21_1261247597$          UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU22_1117177365$          UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU2_2464850095$           UNDOTBS1                       OFFLINE                                 128            64       32765
_SYSSMU3_3104504842$           UNDOTBS1                       OFFLINE                                 128            64       32765
_SYSSMU4_437228663$            UNDOTBS1                       OFFLINE                                 128            64       32765
_SYSSMU5_247215464$            UNDOTBS1                       OFFLINE                                 128            64       32765
_SYSSMU6_2597279618$           UNDOTBS1                       OFFLINE                                 128            64       32765
_SYSSMU7_825858386$            UNDOTBS1                       ONLINE                                  128            64       32765          9
_SYSSMU8_2280151962$           UNDOTBS1                       OFFLINE                                 128            64       32765
_SYSSMU9_3051513041$           UNDOTBS1                       OFFLINE                                 128            64       32765

已选择23行。
    虽然将数据库实例使用的UNDO表空间指向了新表空间，但是依然有过去的事务在使用UNDOTBS1表空间下面的段，这个时候不能直接DROP UNDOTBS1（执行DROP命令也会报错），必须等待UNDOTBS1表空间下的所有段状态变成OFFLINE才能DROP。

SQL> r
  1  select segment_name, tablespace_name, r.status,
  2    (initial_extent/1024) InitialExtent,(next_extent/1024) NextExtent,
  3    max_extents, v.curext CurExtent
  4    From dba_rollback_segs r, v$rollstat v
  5    Where r.segment_id = v.usn(+)
  6*   order by segment_name


SEGMENT_NAME                   TABLESPACE_NAME                STATUS                           INITIALEXTENT NEXTEXTENT MAX_EXTENTS  CUREXTENT
------------------------------ ------------------------------ -------------------------------- ------------- ---------- ----------- ----------
SYSTEM                         SYSTEM                         ONLINE                                  112            56       32765          5
_SYSSMU10_1735367849$          UNDOTBS1                       OFFLINE                                 128            64       32765
_SYSSMU11_3120896088$          UNDOTBS1                       OFFLINE                                 128            64       32765
_SYSSMU12_2867006942$          UNDOTBS1                       OFFLINE                                 128            64       32765
_SYSSMU13_3398750080$          UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU14_3208386744$          UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU15_2082453576$          UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU16_2746861185$          UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU17_3752120760$          UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU18_3475721077$          UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU19_1407063349$          UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU1_2523538120$           UNDOTBS1                       OFFLINE                                 128            64       32765
_SYSSMU20_910603223$           UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU21_1261247597$          UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU22_1117177365$          UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU2_2464850095$           UNDOTBS1                       OFFLINE                                 128            64       32765
_SYSSMU3_3104504842$           UNDOTBS1                       OFFLINE                                 128            64       32765
_SYSSMU4_437228663$            UNDOTBS1                       OFFLINE                                 128            64       32765
_SYSSMU5_247215464$            UNDOTBS1                       OFFLINE                                 128            64       32765
_SYSSMU6_2597279618$           UNDOTBS1                       OFFLINE                                 128            64       32765
_SYSSMU7_825858386$            UNDOTBS1                       OFFLINE                                 128            64       32765
_SYSSMU8_2280151962$           UNDOTBS1                       OFFLINE                                 128            64       32765
_SYSSMU9_3051513041$           UNDOTBS1                       OFFLINE                                 128            64       32765

已选择23行。

    UNDOTBS1表空间下的所有段状态都变成了OFFLINE，这个时候可以DROP UNDOTBS1来释放空间。

SQL> drop tablespace undotbs1 including contents and datafiles;

表空间已删除。

    虽然能DROP，只是说明没有事务在使用旧的UNDO表空间，这并不表示所有的UNDO EXTENT已经过期（DBA_UNDO_EXTENTS.STATUS），如果有某些查询需要用到这些存储在旧UNDO表空间上过期或未过期的EXTENT时，将收到ORA-01555的报错。

SQL> select segment_name, tablespace_name, r.status,
  2    (initial_extent/1024) InitialExtent,(next_extent/1024) NextExtent,
  3    max_extents, v.curext CurExtent
  4    From dba_rollback_segs r, v$rollstat v
  5    Where r.segment_id = v.usn(+)
  6    order by segment_name ;


SEGMENT_NAME                   TABLESPACE_NAME                STATUS                           INITIALEXTENT NEXTEXTENT MAX_EXTENTS  CUREXTENT
------------------------------ ------------------------------ -------------------------------- ------------- ---------- ----------- ----------
SYSTEM                         SYSTEM                         ONLINE                                  112            56       32765          5
_SYSSMU13_3398750080$          UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU14_3208386744$          UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU15_2082453576$          UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU16_2746861185$          UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU17_3752120760$          UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU18_3475721077$          UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU19_1407063349$          UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU20_910603223$           UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU21_1261247597$          UNDOTBS2                       ONLINE                                  128            64       32765          0
_SYSSMU22_1117177365$          UNDOTBS2                       ONLINE                                  128            64       32765          0

已选择11行。

    有关AUM更多详细的信息，请参考文章：
   《FAQ – Automatic Undo Management (AUM) / System Managed Undo (SMU) (文档 ID 461480.1)》
   《AUM 常用分析/诊断脚本 (文档 ID 1526122.1)》

--end--




-bash: /bin/rm: Argument list too long
用xargs命令 删除数量比较多的文件：

 find . -name '*.aud' -print0 | xargs -0 rm            ---ok
find . -name '*.trm' -print0 | xargs -0 rm

ls -l *.aud| xargs -n 50 rm -fr
2个方法：
1）find
find . -name *.aud -exec rm {}\;

2) 管道
ls -l |awk '{print $9}'|rm

find . -name '*.aud' -print0 | xargs -0 rm


To work around this you can get the list of filenames using find and pipe it to xargs which in turn invokes rm for every single file. There is no limit on the size of a pipe (or at least none that I am aware of for this practical purpose). Here’s the full command:

find . -name 'spam*' -print0 | xargs -0 rm

This differs from similar commands you might find in the -print0 and -0 arguments: These are needed in case you have spaces in your filenames.

For an in-depth explanation of both the 128K buffer and the spaces in filenames issue you may also want to read the May 2004 update in this blog post. (See, I told you it’s not really new.)


DML语句要用到并行度，就必须先做alter session enable parallel dml; 这样参数调整设置才可以生效！

Oracle关于日志文件基本操作
1.查询系统使用的是哪一组日志文件：
select * from v$log;

2.查询正在使用的组所对应的日志文件：
select * from v$logfile;

3.强制日志切换：
alter system switch logfile;

4.查询历史日志：
select * from v$log_history;

5.查询日志的归档模式：
select dbid,name,created,log_mode from v$database;

6.查询归档日志的信息：
select recid,stamp,thread#,sequence#,name from v$archived_log;

7.增加与删除日志文件组
alter database add logfile group 1 ('/home1/Oracle/oradata/ora8i/log1a.log'),'/home2/oracle/oradata/ora8i/log1b.log') size 100M;

alter database drop logfile group 1;

8.增加与删除日志成员
alter database add logfile member '/home1/oracle/oradata/ora8i/log1a.log' to group 1,'/home1/oracle/oradata/ora8i/log2a.log' to group 2;

alter database drop logfile member '/home1/oracle/oradata/ora8i/log1a.log' ;

9.日志文件移动
alter database rename file '/home1/oracle/oradata/ora8i/log1a.log' to '/home2/oracle/oradata/ora8i/log1a.log';
执行该命令之前必须保证该日志文件物理上已经移动到新目录

10.清除日志文件
alter database clear logfile '/home1/oracle/oradata/ora8i/log1a.log';
该命令用于不能用删除组及组成员命令删除日志时使用

8.查看归档日志占用空间：
SELECT space_limit/1024/1024/1024 AS "Quota_G",space_used/1024/1024 AS "Used_M",space_used/space_limit*100 "Used_%",space_reclaimable AS reclaimable,number_of_files AS files FROM v$recovery_file_dest ;

9.修改归档日志空间大小
alter system set DB_RECOVERY_FILE_DEST_SIZE=40g;

10.查看归档日志列表
RMAN> list archivelog all;
删除归档日志
RMAN> delete archivelog until time 'sysdate-1' ;
双机下也可以用
delete obsolete;
crosscheck archivelog all;
delete expired archivelog all;

11. 用list expired看看是否有失效的archive log,证明没有失效的archive log:
RMAN> list expired archivelog all;



当ORACLE 归档日志满了后，将无法正常登入ORACLE，需要删除一部分归档日志才能正常登入ORACLE。



一、首先删除归档日志物理文件，归档日志一般都是位于archive目录下，AIX系统下文件格式为“1_17884_667758186.dbf”，建议操作前先对数据库进行备份，删除时至少保留最近几天的日志用于数据库恢复。



二、把归档日志的物理文件删除后，我们就可以正常登入ORACLE了，但是还没完全把归档日志删除干净，ORACLE的controlfile中仍 然记录着这些archivelog的信息，在oracle的OEM管理器中有可视化的日志展现出，当我们手工清除archive目录下的文件后，这些记录 并没有被我们从controlfile中清除掉，接下去我们要做的就是这个工作。

我们利用RMAN进行删除操作，操作步骤如下：(window客户端系统为例)

1.指定数据库实例

C:/Documents and Settings/Administrator>SET ORACLE_SID =orcl

2.连接数据库

C:/Documents and Settings/Administrator>RMAN TARGET SYS/sysadmin@orcl

3.查看归档日志的状态

RMAN> list archivelog all;

4.手工删除归档日志文件

RMAN> DELETE ARCHIVELOG ALL COMPLETED BEFORE 'SYSDATE-7';

 说明：
 SYSDATA-7，表明当前的系统时间7天前，before关键字表示在7天前的归档日志，如果使用了闪回功能，也会删除闪回的数据。
同样道理，也可以删除从7天前到现在的全部日志，不过这个命令要考虑清楚，做完这个删除，最好马上进行全备份数据库
DELETE ARCHIVELOG from TIME 'SYSDATE-7'; 删除从7天前到现在的全部日志,慎用
UNIX/LINUX下也可以通过FIND找到7天前的归档数据，使用EXEC子操作删除
find /oraarchive -xdev -mtime +7 -name "*.dbf" -exec rm -f {} ;
这样做仍然会在RMAN里留下未管理的归档文件
仍需要在RMAN里执行下面2条命令
crosscheck archivelog all;
delete expired archivelog all;
所以还不如上面的方法好用，不过用FIND的好处就是，可以在条件上，和EXEC子项上做很多操作，实现更复杂的功能

5.退出rman

RMAN> exit

select s.SID, round(t.used_ublk * p.value/1024/1024, 2) undo_M
  2    from v$transaction t, v$session s, v$parameter   p
  3   where t.ADDR = s.TADDR
  4   and   p.name = 'db_block_size'
  5   and   s.SID  =
  6  1521;




2012-09-21 13:20 Oracle异常ORA-01502: 索引或这类索引的分区处于不可用状态
原因： 出现这个问题，可能有人move过表，或者disable 过索引。
1. alter table xxxxxx move tablespace xxxxxxx 命令后，索引就会失效。
2. alter index index_name  unusable，命令使索引失效。

解决办法：
1. 重建索引才是解决这类问题的完全的方法。
     alter index index_name rebuild (online);

     或者alter index index_name rebuild;
2. 如果是分区索引只需要重建那个失效的分区 。
     alter index index_name rebuild partition partition_name (online);

     或者alter index index_name rebuild partition partition_name ;

3. 或者改变当前索引的名字。

说明：
1. alter session set skip_unusable_indexes=true;就可以在session级别跳过无效索引作查询。
2. 分区索引应适用user_ind_partitions。
3. 状态分4种：
    N/A说明这个是分区索引需要查user_ind_partitions或者user_ind_subpartitions来确定每个分区是否可用；
    VAILD说明这个索引可用；
    UNUSABLE说明这个索引不可用；
    USABLE 说明这个索引的分区是可用的。

4. 查询当前索引的状态：select distinct status from user_indexes;

5. 查询那个索引无效：select index_name from  user_indexes where status <> 'valid';



------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
20.最高效删除重复记录的方法，使用伪例rowid  删除重复
DELETE FROM EMP E WHERE E.ROWID > (SELECT MIN(X.ROWID) FROM EMP X WHERE X.EMP_NO = E.EMP_NO);
     a、查找表中多余的重复记录，重复记录是根据单个字段（peopleId）来判断
　　select * from people
　　where peopleId in (select   peopleId from   people group by   peopleId having count(peopleId) > 1)
　　b、删除表中多余的重复记录，重复记录是根据单个字段（peopleId）来判断，只留有 rowid最小的记录
　　delete from people
　　where peopleId in (select   peopleId from people group by   peopleId   having count(peopleId) > 1)
　　and rowid not in (select min(rowid) from   people group by peopleId having count(peopleId )>1)
　　注:rowid为Oracle自带不用该.....
　　c、查找表中多余的重复记录（多个字段）
　　select * from vitae a
　　where (a.peopleId,a.seq) in   (select peopleId,seq from vitae group by peopleId,seq having count(*) > 1)
　　d、删除表中多余的重复记录（多个字段），只留有rowid最小的记录
　　delete from vitae a
　　where (a.peopleId,a.seq) in   (select peopleId,seq from vitae group by peopleId,seq having count(*) > 1)
　　and rowid not in (select min(rowid) from vitae group by peopleId,seq having count(*)>1)
　　e、查找表中多余的重复记录（多个字段），不包含rowid最小的记录
　　select * from vitae a
　　where (a.peopleId,a.seq) in   (select peopleId,seq from vitae group by peopleId,seq having count(*) > 1)
　　and rowid not in (select min(rowid) from vitae group by peopleId,seq having count(*)>1)
　　(二)
　　比方说
　　在A表中存在一个字段“name”，
　　而且不同记录之间的“name”值有可能会相同，
　　现在就是需要查询出在该表中的各记录之间，“name”值存在重复的项；
　　Select Name,Count(*) From A Group By Name Having Count(*) > 1
　　如果还查性别也相同大则如下:
　　Select Name,sex,Count(*) From A Group By Name,sex Having Count(*) > 1

 ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
21.copy命令语法
copy语法：
usage: COPY FROM <db> TO <db> <opt> <table> { (<cols>) } USING <sel>
  <db>   : database string, e.g., hr/your_password@d:chicago-mktg
  <opt>  : ONE of the keywords: APPEND, CREATE, INSERT or REPLACE
  <table>: name of the destination table
  <cols> : a comma-separated list of destination column aliases
  <sel>  : any valid SQL SELECT statement

set arraysize 200
set linesize 400
set copycommit 500
set long 400
copy from dbaqry/kai123fa456dba789@liferpt to dbmgr/duan5lzh@lolapstg insert LOLAPDATA.sub_lmd_add_pol_analysis using select * from LOLAPDATA.sub_lmd_add_pol_analysis where CALC_DATE >= date '2012-05-01' and CALC_DATE < date '2012-06-01' and DEPTNO like '104%';
copy from dbaqry/kai123fa456dba789@liferpt to dbmgr/duan5lzh@lolapstg insert LOLAPDATA.sub_lmd_primary_pol_analysis using select * from LOLAPDATA.sub_lmd_primary_pol_analysis where CALC_DATE >= date '2012-05-01' and CALC_DATE < date '2012-06-01' and DEPTNO like '104%';
copy from dbaqry/kai123fa456dba789@liferpt to dbmgr/duan5lzh@lolapstg insert LOLAPDATA.PUB_LBS_PRE_APP_PREM  using select COUNT(1) from LOLAPDATA.PUB_LBS_PRE_APP_PREM where DEPTNO like '104%' and APP_DATE >= date '2012-05-01' and APP_DATE < date '2012-06-01';

 ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
22.exp语法
userid='/ as sysdba'
filesize=10000m
file=
(
exp_09_01.dmp,exp_09_02.dmp,exp_09_03.dmp,exp_09_04.dmp,exp_09_05.dmp,exp_09_06.dmp,exp_09_07.dmp,exp_09_08.dmp,exp_09_09.dmp,exp_09_10.dmp,
exp_09_11.dmp, exp_09_12.dmp, exp_09_13.dmp, exp_09_14.dmp, exp_09_15.dmp, exp_09_16.dmp, exp_09_17.dmp, exp_09_18.dmp, exp_09_19.dmp, exp_09_20.dmp
)
log=exp_09_.log
buffer=140000000
recordlength=65535
direct=y
RESUMABLE=y
RESUMABLE_NAME=exp_09__xl1
RESUMABLE_TIMEOUT=99999
tables=(
PA18DATA.FINANCE_OPERATION_LOG_INFO,
PA18DATA.PA18_CLIENT_INFORMATION)

 ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
23.listener配置
t0csms =
  (DESCRIPTION_LIST =
    (DESCRIPTION =
      (ADDRESS_LIST =
        (ADDRESS = (PROTOCOL = TCP)(HOST =t0csms.dbstg.paic.com.cn)(PORT = 1522))
      )
    )
  )

SID_LIST_t0csms=
  (SID_LIST =
    (SID_DESC =
      (ORACLE_HOME =/paic/t0csms/rdbms/oracle/product/11.2.0)
      (SID_NAME = bsbocp)
    )
  )


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
24.拼接statsqltext 拼接sql
  declare
  cursor cur is select distinct hash_value as hash_value from stats$sqltext where sql_text like '%CIT_JOURNAL_INTERFACE%';
  temp_sql clob;
  temp_hashvalue number(20);
  begin
   open cur;
   loop
    fetch cur into temp_hashvalue;
    exit when cur%notfound;
      select replace(wm_concat(sql_text), ',', '') || ';' into temp_sql from stats$sqltext  where hash_value =temp_hashvalue;
      insert into test values(temp_sql);
      temp_sql := '';
    end loop;
    commit;
    close cur;
  end;

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
25.压缩dmp文件  EXP直接导出压缩问津，IMP直接导入压缩文件的方法 .
在10G之前
exp导出
gzip压缩
gzip解压
imp导入
EXP导出：$ mknod p p
$ gzip < p > test.dmp.gz & exp system/xxxx tables=TEST buffer=31457280 CONSISTENT=Y COMPRESS=N file=p
$ rm -rf p
IMP导入：
$ mknod p p
$ gunzip < test.dmp.gz > p & imp system/xxx file=p full=y buffer=31457280


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
26.　Oracle的死锁　　查询数据库 死锁：
select t2.username||'　 '||t2.sid||'
'||t2.serial#||'　 '||t2.logon_time||'
'||t3.sql_text
from v$locked_object t1,v$session t2,v$sqltext t3
where t1.session_id=t2.sid
and t2.sql_address=t3.address
order by t2.logon_time;

查找死锁的进程：
sqlplus "/as sysdba"　 (sys/change_on_install)
SELECT s.username,l.OBJECT_ID,l.SESSION_ID,s.SERIAL#,
l.ORACLE_USERNAME,l.OS_USER_NAME,l.PROCESS
FROM V$LOCKED_OBJECT l,V$SESSION S WHERE l.SESSION_ID=S.SID;

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
27.　查询是table锁还是行锁
select   /*+ rule */ s.username,s.SID,s.SERIAL#,
decode(l.type,'TM','TABLE LOCK',
              'TX','ROW LOCK',
              NULL) LOCK_LEVEL,
o.owner,o.object_name,o.object_type,
s.sid,s.serial#,s.terminal,s.machine,s.program,s.osuser
FROM v$session s,v$lock l,dba_objects o
WHERE l.sid = s.sid
AND l.id1 = o.object_id(+)
AND s.username is NOT NULL;

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
28.　-----临时表空间使用情况


查看临时表空间的实际占用情况：
select blocks*块大小　from v$sort_usage ;


 select t.*
from (SELECT D.TABLESPACE_NAME,
SPACE "SUM_SPACE(M)",
BLOCKS SUM_BLOCKS,
SPACE - NVL(FREE_SPACE, 0) "USED_SPACE(M)",
ROUND((1 - NVL(FREE_SPACE, 0) / SPACE) * 100, 2) "USED_RATE(%)",
FREE_SPACE "FREE_SPACE(M)"
FROM (SELECT TABLESPACE_NAME,
ROUND(SUM(BYTES) / (1024 * 1024), 2) SPACE,
SUM(BLOCKS) BLOCKS
FROM DBA_DATA_FILES
GROUP BY TABLESPACE_NAME) D,
(SELECT TABLESPACE_NAME,
ROUND(SUM(BYTES) / (1024 * 1024), 2) FREE_SPACE
FROM DBA_FREE_SPACE
GROUP BY TABLESPACE_NAME) F
WHERE D.TABLESPACE_NAME = F.TABLESPACE_NAME(+)
UNION ALL --if have tempfile
SELECT D.TABLESPACE_NAME,
SPACE "SUM_SPACE(M)",
BLOCKS SUM_BLOCKS,
USED_SPACE "USED_SPACE(M)",
ROUND(NVL(USED_SPACE, 0) / SPACE * 100, 2) "USED_RATE(%)",
SPACE - USED_SPACE "FREE_SPACE(M)"
FROM (SELECT TABLESPACE_NAME,
ROUND(SUM(BYTES) / (1024 * 1024), 2) SPACE,
SUM(BLOCKS) BLOCKS
FROM DBA_TEMP_FILES
GROUP BY TABLESPACE_NAME) D,
(SELECT TABLESPACE,
ROUND(SUM(BLOCKS * 8192) / (1024 * 1024), 2) USED_SPACE
FROM V$SORT_USAGE
GROUP BY TABLESPACE) F
WHERE D.TABLESPACE_NAME = F.TABLESPACE(+)) t
order by "USED_RATE(%)" desc;


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
29.　授权debug权限
原因是用户权限不够，使用以下命令授予权限：

GRANT debug any procedure, debug connect session TO username
GRANT alter  any procedure TO pub_test

plsqlDev调试功能是利用包dbms_debug包实现的，

dbms_debug包的安装，以sys用户登录后运行: sql> @ /rdbms/admin/prvtpb.plb

在利用plsqlDevIDE做调试时，有时会发生失去响应，此时可执行alter system flush shared_pool试试，

如果还不行，建议改用TOAD来调试。plsqlDev在调试这一块做的不完善。



CPUs=8     Cores=8     Sockdets=2

NUM_CPUS 8   表示逻辑CPU数量(Oracle数据库中表现出来的初始参数 cpu_count)
NUM_CPU_CORES 8    对应CPU Cores数量
NUM_CPU_SOCKETS 2  CPU Sockets数量

-        stat_name = NUM_CPUS. This value should correspond to the number of logical CPUs. For systems with CMT or
hyper-threaded processors, this value should correspond to the total number of hardware threads.  For systems with
multi-core processors, this value should correspond to the total number of hardware threads across all cores in the
system.  NUM_CPUS should be greater than or equal to NUM_CPU_CORES and NUM_CPU_SOCKETS.
对应逻辑CPU数量，
对于CPU多线程或超线程，值应该指hardware threads总数。
对于多核处理器，值应该对应于系统中所有核的hardware threads总数。
NUM_CPUS值大于等于NUM_CPU_CORES and NUM_CPU_SOCKETS
那么也就是说，如果CPU物理个数为2，那么Sockets=2 (初略理解为插槽)     每颗 CPU 采用4核，每核4线程 ,  那么处理器（CMT）
能够支持16个并发执行的硬线程， 对应到 NUM_CPUS 是不是等于 2 * 4 * 4 = 32 (根据第二句红色语句)      NUM_CPU_CORES=2*4 =8   

CPUs：逻辑cpu数量可以从oracle数据库初始化参数cpu_count查看（show parameter cpu_count）。
Cores：cpu核数。
Sockets：CPU插槽（CPU插槽主要分为Socket、Slot这两种。就是用于安装CPU的插座。）



AWR内创建基线，定义为某个范围内的快照，可以用来与其它快照进行比较。

创建基线：

exec dbms_workload_repository.create_baseline (start_snap_id=>1109, end_snap_id=>1111, baseline_name=>'EOM Baseline');

查看基线：

select baseline_id, baseline_name, start_snap_id, end_snap_id from dba_hist_baseline;

删除基线：

exec dbms_workload_repository.drop_baseline(baseline_name=>'EOM Baseline', Cascade=>FALSE);

参数Cascade如果设置为true，就会删除所有相关的快照，此处会删除1109和1111这两个相关的快照。否则AWR自动进程会自动清除这些快照。

关于调试权限

Debug当前schema的过程，则必须给当前shema对应的用户授如下权限：

例如soctt要调试scott.myfunction
则以sys执行grant debug connect session to SCOTT;

Debug其它schema的过程，可以加debug any procedure 权限调试

或是

只针对单个被调试的过程授权 grant debug on “过程” to “调试用户”;



特别注意：

将存储过程编译成调试状态，才可以执行单步调试。

示例：将函数DAY编译成调试状态：

ALTER FUNCTION DAY COMPILE DEBUG

去除函数DAY的调试信息，执行ALTER FUNCTION DAY COMPILE。

查看某对象是否处于调试状态：

SELECT DEBUGINFO
  FROM SYS.ALL_PROBE_OBJECTS PO
 WHERE PO.OWNER = 'DBO'
   AND PO.OBJECT_NAME = 'DAY'
   AND PO.OBJECT_TYPE = 'FUNCTION';



---审计结果,也可以直接查询sys.aud$表
select  *  from  DBA_AUDIT_TRAIL  ---查看审计记录,调用的sys.aud$表
select  *  from  DBA_AUDIT_OBJECT   where (obj_name ='UMS_MENU_ROLE_RELATION' or obj_name ='UMS_MENU_INFO' )---查看对象审计记录
select  *  from  DBA_AUDIT_SESSION  -- session审计记录
select  *  from  DBA_AUDIT_STATEMENT   -- 查看语句审计记录
select  *  from  DBA_AUDIT_EXISTS    -- 使用BY AUDIT NOT EXISTS选项的审计
select  *  from  DBA_AUDIT_POLICIES    -- 审计POLICIES
select  *  from  DBA_COMMON_AUDIT_TRAIL  -- 标准审计+精细审计记录
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
30.增加aud$所在的表空间，无论空闲多大。。
While connecting to the database using sqlplus the following errors occur:
ERROR:
ORA-00604: error occurred at recursive SQL level 3
ORA-08243: recursive audit operation attempted
ORA-08243: recursive audit operation attempted
ORA-02002: error while writing to audit trail
ORA-00604: error occurred at recursive SQL level 3
ORA-08243: recursive audit operation attempted
ORA-08243: recursive audit operation attemptedCause
This issue was reported to development in Bug 11742155 - ORA-2002 and ORA-08243 when the audit tablespace is full
The errors are caused by the fact that we are purging the recyclebin while writing the audit record. This automatic purge is triggered by the fact that there is no free space in the tablespace. Development concluded that there is no way to avoid this automatic purge operation.
Solution
1.) Make sure that at any time there is sufficient free space in the tablespace of the AUD$ table. Tablespace utilization can be monitored with Enterprise Manager or by running the following query:
select sum(bytes)/1024/1024 from dba_free_space where tablespace_name ='<TABLESPACE>';

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
31

数据库大小使用下面sql：
select ceil(a.tempfile_size + b.datafile_size +c.logfile_size) GB from
(select sum(bytes)/1024/1024/1024 tempfile_size from dba_temp_files) a,
(select sum(bytes)/1024/1024/1024 datafile_size from dba_data_files) B,
(select sum(bytes)/1024/1024/1024 logfile_size from v$log)c;

select ceil(a.tempfile_size + b.datafile_size +c.logfile_size) GB from
(select sum(bytes)/1024/1024/1024 tempfile_size from v$tempfile) a,
(select sum(bytes)/1024/1024/1024 datafile_size from v$datafile) B,
(select sum(bytes)/1024/1024/1024 logfile_size from v$log)c;


select round(sum(s.bytes / 1024 / 1024 / 1024), 2) Sum_G,
       round(sum(s.UsedSpace / 1024 / 1024 / 1024), 2) Used_G,
       round(sum(s.FreeSpace / 1024 / 1024 / 1024), 2) Free_G,
       round(sum(s.UsedSpace) / sum(s.bytes), 2) PTUSED
  from (select b.file_id,
               b.tablespace_name,
               b.bytes,
               (b.bytes - sum(nvl(a.bytes, 0))) UsedSpace,
               sum(nvl(a.bytes, 0)) FreeSpace
          from sys.dba_free_space a, sys.dba_data_files b
         where a.file_id(+) = b.file_id
         group by b.file_id, b.tablespace_name, b.bytes
         order by b.tablespace_name) s;



请先回滚到flash_point1，然后删除flash_point1

三、回滚回保证回滚点：

1、停库：

alter system switch logfile;

alter system archive log current;

shutdown immediate;

2、回滚到回滚点：

Startup mount;

FLASHBACK DATABASE TO RESTORE POINT flash_point1;

3、起库：

alter database open resetlogs;

四、清理环境：

drop restore point flash_point1;

select * from v$restore_point;

shutdown immediate

startup mount

alter database noarchivelog;

alter database flashback on;

alter database open;

flashback 回滚数据库
startup mount;
select guarantee_flashback_database,to_char(time,'yyyymmdd hh24:mi:ss'),name from v$restore_point;  +++FCR_TEST_RP
flashback database to restore point FCR_TEST_RP;
alter database open resetlogs;
shutdown immediate

创建一个guarantee restore point

SQL> create restore point flash_point guarantee flashback database;
创建一个普通的restore point

SQL> create restore point b;
flashback dtaase to restore point:(必须在guarantee restore point for flashback database的情况)

删除还原点

SQL> drop RESTORE POINT restore2;

Flashback Restore Point（闪回还原点）

闪回还原点分两种，一种是Normal Restore Points（正常还原点），另一种是Guaranteed Restore Points（担保还原点）

正常还原点和担保还原点的信息都是保存在控制文件，区别在于正常还原点的信息如果不手动删除控制文件也会自动维护管理删除，而担保还原点如果不手动删除，控制文件是不会自动删除的，也就说只要设立了担保还原点没有手动删除，数据库就一定能恢复到那个还原点状态。如果担保还原点和Flashback Database一起使用，那么数据库就能闪回到担保还原点起和之后的任何时间点。

The database can retain up to 2048 restore point. Restore points are retained in the database for at least the number of days specified for the CONTROL_FILE_RECORD_KEEP_TIME initialization parameter. The default value of that parameter is 7 days. Guaranteed restore points are retained in the database until explicitly dropped by the user.


设置回滚点、库还原的操作步骤如下，请先设置回滚点（步骤一、二），谢谢
该库版本10.2.0.5
相关参数：
alter system set db_recovery_file_dest_size=30g scope=both;
db_recovery_file_dest_size big integer 600G
db_flashback_retention_target integer 1440
相关参数与版本是支持flashback database的。
SQL> select name,current_scn,flashback_on from v$database;
NAME CURRENT_SCN FLASHBACK_ON
--------- ----------- ------------------
T1PADM 9.3696E+12 NO
SQL> archive log list;
Database log mode No Archive Mode
Automatic archival Disabled
Archive destination USE_DB_RECOVERY_FILE_DEST
Oldest online log sequence 328
Current log sequence 339
一、调整数据库环境：
shutdown immediate
Startup nomount
alter database archivelog
alter database flashback on
alter database open;
select FLASHBACK_ON from v$database;
二、创建保证回滚点：
1、创建保证回滚点：
shutdown immediate;
startup mount;
create restore point flash_point2 guarantee flashback database;
2、复核该回滚点是否设置正确：
select name from v$restore_point;
3、启动数据库：
Alter database open;
三、回滚回保证回滚点：
1、停库：
alter system switch logfile;
alter system archive log current;
shutdown immediate;
2、回滚到回滚点：
Startup mount;
FLASHBACK DATABASE TO RESTORE POINT flash_point;
3、起库：
alter database open resetlogs;
四、清理环境：
drop restore point flash_point1;
select * from v$restore_point;
shutdown immediate
startup mount
alter database noarchivelog;
alter database flashback off;
alter database open;


正常还原点的使用

 创建正常还原点

SQL> CREATE RESTORE POINT restore1;

查看flashback模式

SQL> select flashback_on from v$database;

FLASHBACK_ON
------------------
NO

执行闪回还原点

SQL> FLASHBACK database TO RESTORE POINT restore1；  --mount状态下执行

删除还原点

SQL> drop restore point restore1;

Restore point dropped.





担保还原点的使用

创建担保还原点

SQL> CREATE RESTORE POINT restore2 GUARANTEE FLASHBACK DATABASE;

查询flashback模式

SQL> select flashback_on from v$database;

FLASHBACK_ON
------------------
RESTORE POINT ONLY        --没开启Flashback Database模式下

执行闪回还原点

SQL> FLASHBACK database TO RESTORE POINT restore2;    --mount状态下执行

删除还原点

SQL> drop RESTORE POINT restore2;





11g还可以指定过去的scn或timestamp

CREATE RESTORE POINT res1 AS OF SCN 1229570;
CREATE RESTORE POINT res2 AS OF TIMESTAMP to_date('2013-10-10 23:12:12','YYYY-MM-DD HH24:MI');



用戶 下有table   TabA
A1 用戶建立view (V_TabA) , view中是引用A 用戶下的TabA .
A2 用戶要 select  A1 用户下的这个view .

采用直接赋予权限的方式，很可能会碰到错误  ORA-01720: grant option does not exist for  ......

一般采取的方法是 ：
1.    以基表用户A 登入(如果多个基表，那么多次运行)
sql >  connect    A/A
sql >  grant  select   on   TabA   to    A1  with  grant  option ;
2.  以view 的拥有用户登入
sql>  connect   A1/A1
sql>  grant   select   on   A1.V_TabA    to   A2  ;
3.  OK,  以 A2 登入即可以访问view了
sql >  connect  A2/A2
sql>  select    *   from   A1.V_TabA     ;

字符集
导出/导入与字符集
    进行数据的导入导出时，我们要注意关于字符集的问题。在EXP/IMP过程中我们需要注意四个字符集的参数：导出端的客户端字符集，导出端数据库字符集，导入端的客户端字符集，导入端数据库字符集。
我们首先需要查看这四个字符集参数。
查看数据库的字符集的信息：
SQL> select * from nls_database_parameters;
PARAMETER                      VALUE
------------------------------ --------------------------------------------------------------------------------
NLS_LANGUAGE                   AMERICAN
NLS_TERRITORY                   AMERICA
NLS_CURRENCY                   $
NLS_ISO_CURRENCY               AMERICA
NLS_NUMERIC_CHARACTERS         .,
NLS_CHARACTERSET               ZHS16GBK
...
NLS_COMP                       BINARY
NLS_NCHAR_CHARACTERSET         ZHS16GBK
NLS_RDBMS_VERSION              8.1.7.4.1
NLS_CHARACTERSET：ZHS16GBK是当前数据库的字符集。

我们再来查看客户端的字符集信息：
客户端字符集的参数NLS_LANG=_< territory >.
language：指定oracle消息使用的语言，日期中日和月的显示。
Territory：指定货币和数字的格式，地区和计算星期及日期的习惯。
Characterset：控制客户端应用程序使用的字符集。通常设置或等于客户端的代码页。或者对于unicode应用设为UTF8。
在windows中，查询和修改NLS_LANG可在注册表中进行：
HKEY_LOCAL_MACHINE\SOFTWARE\Oracle\HOMExx\
xx指存在多个Oracle_HOME时的系统编号。

在unix中：
$ env|grep NLS_LANG
NLS_LANG=simplified chinese_china.ZHS16GBK

修改可用：
$ export NLS_LANG=AMERICAN_AMERICA.UTF8

通常在导出时最好把客户端字符集设置得和数据库端相同。当进行数据导入时，主要有以下两种情况：
(1)    源数据库和目标数据库具有相同的字符集设置。
这时，只需设置导出和导入端的客户端NLS_LANG等于数据库字符集即可。
(2)    源数据库和目标数据库字符集不同。
    先将导出端客户端的NLS_LANG设置成和导出端的数据库字符集一致，导出数据，然后将导入端客户端的NLS_LANG设置成和导出端一致，导入数据，这样转换只发生在数据库端，而且只发生一次。
    这种情况下，只有当导入端数据库字符集为导出端数据库字符集的严格超集时，数据才能完全导成功，否则，可能会有数据不一致或乱码出现


package中表或视图不存在

调用者调用package是以属主.package中属主的身份运行package，即需要package中属主访问到的表或视图来判断，并不是以调用者的权限来判断是否有权限访问..



在备库上执行alter database recover managed standby database using current logfile disconnect;开启RTA，成功 。
在主库上已有的表中插入几条数据并commit。
在备库上执行alter database recover managed standby database cancel;
alter database open read only。
再执行select那个表数据，发现记录数还是没变。为什么呢？不是实时传吗？
lnsr开启监听

SQL> alter database open resetlogs;
alter database open resetlogs
*
ERROR at line 1:
ORA-01139: RESETLOGS option only valid after an incomplete database recovery

解决办法：

SQL> recover database until cancel;
Media recovery complete.
Elapsed: 00:00:00.00
SQL> alter database open resetlogs;
 Database altered

或是日志已经恢复完毕，直接open就可以了
[oracle@DB2 dbs]$ oerr ora 1403
01403, 00000, "no data found"
// *Cause:
// *Action:
[oracle@DB2 dbs]$ oerr ora 01139
01139, 00000, "RESETLOGS option only valid after an incomplete database recovery"
// *Cause: The RESETLOGS option was given in ALTER DATABASE OPEN, but there
//        has been no incomplete recovery session.
// *Action: Retry the ALTER DATABASE OPEN without specifying RESETLOGS

SQL>alter database open;

oracle同义词的一个特点 同义词失效

2011-02-09 16:27:29|  分类： oracle |举报|字号 订阅
总结：当对原对象进行ddl操作后，同义词的状态会变成INVALID；当再次引用这个同义词时，同义词会自动编译，状态会变成VALID，无需人工干预，当然前提是不改变原对象的名称。

su - dbcom
cd /etc/paic/shell/db_info.txt

资源组  主备切换
/oracle_grid/11.2.0/grid/crs/public/

cnsh281003:t2ipm2 > cp -r t0caiku testk
cnsh281003:t2ipm2 > sed -i "s/t0caiku/testk/g" `ls`      ----将所有脚本中含有字符串t0caiku 改为 testk.
cnsh281003:t2ipm2 > grep testk *.ksh


cnsz181002:d0ptos > grep -i "ORACLE_HOME=" *.ksh
act_db.ksh:export ORACLE_HOME=`awk -F: '{if ($1 == "'$ORACLE_SID'") {print $2; exit}}' /etc/paic/shell/db_info.txt`
act_lsnr.ksh:export ORACLE_HOME=`awk -F: '{if ($1 == "'$ORACLE_SID'") {print $2; exit}}' /etc/paic/shell/db_info.txt`
act_rgb.ksh:export ORACLE_HOME=`awk -F: '{if ($1 == "'$ORACLE_SID'") {print $2; exit}}' /etc/paic/shell/db_info.txt`
act_rgh.ksh:export ORACLE_HOME=`awk -F: '{if ($1 == "'$ORACLE_SID'") {print $2; exit}}' /etc/paic/shell/db_info.txt`

cnsz181002:d0ptos > cat /etc/paic/network/tnsnames.ora|grep d0ptos
d0ptos = (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=10.25.18.47)(PORT=1555))(CONNECT_DATA=(sid=d0ptos)))


reset数据库的默认值
alter system reset db_recovery_file_dest_size scope=spfile sid='*';

删除pfile 或spfile中的对应列



psu 升级  Oracle 升级
 @ /rdbms/admin/catbundle.sql psu apply

  @ /rdbms/admin/utlrp.sql


-- 修复ORA-04023报错
sqlplus / as sysdba
drop table PUIU$DBUA;

spool upgrade.log
@ /rdbms/admin/catupgrd.sql

vi  sqlnet.ora
SQLNET.EXPIRE_TIME=10


删除数据库

若是10g以上版本，可执行下面操作删除：
sqlplus '/as sysdba'

startup nomount;

alter database mount exclusive;

alter system enable restricted session;

drop database;

 注意：

请保留库文件删除前后该卷的大小对比，并回复到该步骤里面。以便后面存储组可以看出下线库的数据文件确实被删除了。

替换变量    替换目录  变量   sed

olive:~/tmp> cat some.txt
some other output lines
some other output lines
olive:~/tmp> echo $a
555
olive:~/tmp> sed -e 's/other/'$a'/' some.txt
some 555 output lines
some 555 output lines
olive:~/tmp>




Select distinct b.Text, c.Is_Correct, c.Text Atext
  From Test_Question a, Question b, Response_Value c, Response_Type d
 Where b.Text Like '%在SGA中的有%'
    And
   a.Question_Id = b.Id
   And b.Id = d.Question_Id
   And d.Id = c.Response_Type_Id order by text;

敏感信息屏蔽生产脚本

declare
v_sys   sensitive_info_shield.sys_name%type;
v_owner sensitive_info_shield.owner%type;
v_table_name   sensitive_info_shield.table_name%type;
v_col_name  sensitive_info_shield.column_name%type;
v_updateby_col  sensitive_info_shield.updateby_col%type;
v_updateby_clause  sensitive_info_shield.updateby_clause%type;
v_shield_item sensitive_info_shield.shield_item%type;
v_shield_sql  sensitive_info_shield_rule.shield_sql%type;
v_update_col_sql varchar2(200);
v_temp_sql varchar2(2000):='';
v_sql  varchar2(4000):='';
v_batch_num number:=20000;
v_pre_sql varchar2(4000):='';
v_pre_sql_mid varchar2(4000):='';
v_pre_sql_foot varchar2(4000):='';
cursor cur_tab is select distinct sys_name,owner,table_name
                   from sensitive_info_shield
          --         where UPDATEBY_CLAUSE is not null
                    order by table_name asc;
cursor cur_shield is select owner,table_name,column_name,updateby_col,updateby_clause,shield_item
                      from sensitive_info_shield
                     where sys_name=v_sys and owner=v_owner and table_name=v_table_name;
begin
open cur_tab;
loop
fetch cur_tab into v_sys,v_owner,v_table_name;
v_temp_sql:='';
exit when cur_tab%notfound;
  open cur_shield;
  loop
   fetch cur_shield into v_owner,v_table_name,v_col_name,v_updateby_col,v_updateby_clause,v_shield_item;
   exit when cur_shield%notfound;
   select shield_sql into v_shield_sql from sensitive_info_shield_rule where shield_item =v_shield_item;
   v_shield_sql:=replace(v_shield_sql,'col',v_col_name);
   v_update_col_sql:=v_col_name||'='||v_shield_sql;
   if v_temp_sql is null then
   v_temp_sql:=v_update_col_sql;
  else
    v_temp_sql:=v_temp_sql||','||v_update_col_sql;
    end if;
  end loop;
   close cur_shield;
   v_pre_sql:='declare  n integer;'||chr(10)||
               'begin'||chr(10)||
               --'select count(*) into n from all_tables where owner||'''.'''||table_name=upper('''||v_owner||'.'||v_table_name||''');'||chr(10)||
              -- 'if n=0 then'||chr(10)||
                  --raise_application_error(-20001, 'ELISDATA.ECIF_CLIENT_INFO not exitst, or is not a TABLE');
               --'end if;'||chr(10)||
               'select count(*) into n from user_tables where table_name=''STG_DATA_MASK_FOOTPRINT'';'||chr(10)||
               'if n=0 then'||chr(10)||
                  'execute immediate ''create table stg_data_mask_footprint( table_name varchar2(50), last_rowid urowid)'';'||chr(10)||
               'end if;'||chr(10)||
               'select count(*) into n from user_tables where table_name=''STG_DATA_MASK_LOG'';'||chr(10)||
               'if n=0 then'||chr(10)||
                  'execute immediate ''create table STG_DATA_MASK_LOG(no number(32), info varchar2(300), log_time date default sysdate)'';'||chr(10)||
               'end if;'||chr(10)||
               'select count(*) into n from dba_tables where OWNER||''.''||TABLE_NAME=upper('''||v_owner||'.'||v_table_name||'_r'');'||chr(10)||
               'if n=0 then ' ;-- create the rowid table;
if length(v_table_name)>28 then
      v_pre_sql_mid:= 'execute immediate ''create table '||v_owner||'.'||substr(v_table_name,1,28)||'_r nologging as select rowid rid from '||v_owner||'.'||
v_table_name||' order by rowid'';';
 else
      v_pre_sql_mid:='execute immediate ''create table '||v_owner||'.'||v_table_name||'_r nologging as select rowid rid from '||v_owner||'.'||v_table_name||' order by rowid'';';
end if;
 v_pre_sql_foot:='end if;'||chr(10)||
               'end;'||chr(10)||
               '/';
 v_pre_sql:=v_pre_sql||chr(10)||v_pre_sql_mid||chr(10)||v_pre_sql_foot;
   if length(v_table_name)>28 then
      v_sql:='declare cursor cur(p_last_rowid urowid) is  select rid from '||v_owner||'.'||substr(v_table_name,1,28)||'_r where rid>=p_last_rowid;'||chr(10)||
          't_rid dbms_sql.Urowid_Table;'||chr(10)||
          'batchrows number:='||v_batch_num||';'||chr(10)||
          'v_last_rowid urowid;'||chr(10)||
          'loopno number;'||chr(10)||
          'v_file_name varchar2(100);'||chr(10)|| --脚本名，用于异常处理
          'v_sqlcode varchar2(100);'||chr(10)||--脚本名，用于异常处理
          'v_sqlerr varchar2(500);'||chr(10)||--脚本名，用于异常处理
          'procedure log(seq number, info varchar2) is'||chr(10)||
          'begin'||chr(10)||
          'insert into stg_data_mask_log values(seq, substrb(info,1,300), sysdate);'||chr(10)||
          'end;'||chr(10)||
          'begin'||chr(10)||
          'log(0, '''||v_owner||'.'||v_table_name||' start'');'||chr(10)||
           'begin'||chr(10)||
            'select last_rowid into v_last_rowid from stg_data_mask_footprint where table_name='''||v_owner||'.'||v_table_name||'''; '||chr(10)||
            'exception'||chr(10)||
            'when no_data_found then'||chr(10)||
            ' select rid into v_last_rowid from '||v_owner||'.'||substr(v_table_name,1,28)||'_r where rownum=1;'||chr(10)||
            ' insert into stg_data_mask_footprint(table_name, last_rowid) values('''||v_owner||'.'||v_table_name||''',v_last_rowid);'||chr(10)||
            'end;'||chr(10)||
            'open cur(v_last_rowid);'||chr(10)||
            'loopno:=1;'||chr(10)||
            'loop'||chr(10)||
            'fetch cur bulk collect into t_rid limit batchrows;'||chr(10)||
            'exit when t_rid.count=0;'||chr(10)||
            'forall i in t_rid.first..t_rid.last'||chr(10)||
            'update '||v_owner||'.'||v_table_name||' set '||v_temp_sql||' where rowid=t_rid(i) ;'||chr(10)||
            'v_last_rowid:=t_rid(t_rid.last);'||chr(10)||
            'update stg_data_mask_footprint set last_rowid=v_last_rowid where table_name='''||v_owner||'.'||v_table_name||''';'||chr(10)||
           'log(loopno, '''||v_table_name||':''||t_rid(t_rid.first)||''-''||v_last_rowid||'':''||t_rid.count);'||chr(10)||
            'loopno:=loopno+1;'||chr(10)||
            'commit;'||chr(10)||
            'end loop;'||chr(10)||
            'close cur;'||chr(10)||
            'log(loopno,'''||v_owner||'.'||v_table_name||' end'');'||chr(10)||
            ' commit;'||chr(10)||
            'exception'||chr(10)||
               'when others then'||chr(10)||
               'rollback;'||chr(10)||
               'v_file_name:= ''06_'||v_table_name||'.sql'';'||chr(10)||
               'v_Sqlcode := To_Char(Sqlcode);'||chr(10)||
               'v_Sqlerr  := Substr(Sqlerrm,1, 500);'||chr(10)||
               'insert into t_error_log values(v_file_name,v_Sqlcode,v_Sqlerr,sysdate);'||chr(10)||
               'commit; '||chr(10)||
                'return;'||chr(10)||
            ' end;'||chr(10)||
            '/';
            else
            v_sql:='declare cursor cur(p_last_rowid urowid) is  select rid from '||v_owner||'.'||v_table_name||'_r where rid>=p_last_rowid;'||chr(10)||
          't_rid dbms_sql.Urowid_Table;'||chr(10)||
          'batchrows number:='||v_batch_num||';'||chr(10)||
          'v_last_rowid urowid;'||chr(10)||
          'loopno number;'||chr(10)||
          'v_file_name varchar2(100);'||chr(10)|| --脚本名，用于异常处理
          'v_sqlcode varchar2(100);'||chr(10)||--脚本名，用于异常处理
          'v_sqlerr varchar2(500);'||chr(10)||--脚本名，用于异常处理
          'procedure log(seq number, info varchar2) is'||chr(10)||
          'begin'||chr(10)||
          'insert into stg_data_mask_log values(seq, substrb(info,1,300), sysdate);'||chr(10)||
          'end;'||chr(10)||
          'begin'||chr(10)||
          'log(0, '''||v_owner||'.'||v_table_name||' start'');'||chr(10)||
           'begin'||chr(10)||
            'select last_rowid into v_last_rowid from stg_data_mask_footprint where table_name='''||v_owner||'.'||v_table_name||'''; '||chr(10)||
            'exception'||chr(10)||
            'when no_data_found then'||chr(10)||
            ' select rid into v_last_rowid from '||v_owner||'.'||v_table_name||'_r where rownum=1;'||chr(10)||
            ' insert into stg_data_mask_footprint(table_name, last_rowid) values('''||v_owner||'.'||v_table_name||''',v_last_rowid);'||chr(10)||
            'end;'||chr(10)||
            'open cur(v_last_rowid);'||chr(10)||
            'loopno:=1;'||chr(10)||
            'loop'||chr(10)||
            'fetch cur bulk collect into t_rid limit batchrows;'||chr(10)||
            'exit when t_rid.count=0;'||chr(10)||
            'forall i in t_rid.first..t_rid.last'||chr(10)||
            'update '||v_owner||'.'||v_table_name||' set '||v_temp_sql||' where rowid=t_rid(i) ;'||chr(10)||
            'v_last_rowid:=t_rid(t_rid.last);'||chr(10)||
            'update stg_data_mask_footprint set last_rowid=v_last_rowid where table_name='''||v_owner||'.'||v_table_name||''';'||chr(10)||
           'log(loopno, '''||v_table_name||':''||t_rid(t_rid.first)||''-''||v_last_rowid||'':''||t_rid.count);'||chr(10)||
            'loopno:=loopno+1;'||chr(10)||
            'commit;'||chr(10)||
            'end loop;'||chr(10)||
            'close cur;'||chr(10)||
            'log(loopno,'''||v_owner||'.'||v_table_name||' end'');'||chr(10)||
            ' commit;'||chr(10)||
            'exception'||chr(10)||
               'when others then'||chr(10)||
               'rollback;'||chr(10)||
               'v_file_name:= ''06_'||v_table_name||'.sql'';'||chr(10)||
               'v_Sqlcode := To_Char(Sqlcode);'||chr(10)||
               'v_Sqlerr  := Substr(Sqlerrm,1, 500);'||chr(10)||
               'insert into t_error_log values(v_file_name,v_Sqlcode,v_Sqlerr,sysdate);'||chr(10)||
               'commit; '||chr(10)||
                'return;'||chr(10)||
            ' end;'||chr(10)||
            '/';
          end if;
            v_sql:=v_pre_sql||chr(10)||v_sql;
          update  sensitive_info_shield  set script =v_sql  where sys_name=v_sys  and owner=v_owner and table_name=v_table_name and rownum=1;
  commit;
end loop;
close cur_tab;
end;
/


改密码   修改密码 秘文
alt_passwd.sql的内容：
set verify off
accept username char prompt 'username:'
accept passwd prompt 'new password of this user: ' hide
alter user &username identified by &passwd;




set NLS_LANG=SIMPLIFIED CHINESE_CHINA.ZHS16GBK
影响分析：
set NLS_LANG=SIMPLIFIED CHINESE_CHINA.ZHS16GBK

set autotrace traceonly;
set pagesize 0 linesize 400;
set timing on ;
set feedback on;
set echo on;
alter system flush shared_pool;
alter system flush buffer_cache;


alter session set events 'immediate trace name flush_cache';--清空数据缓冲区


仅执行计划
 set autot trace exp
仅统计信息
set autot trace stat



使用定时计划执行任务
一、使用exp
(1)脚本内容
@echo off
rem  dbbackup.bat
exp scott/tiger owner=scott  file=D:\DB_backup\laofangkuai_%date:~8,2%%date:~5,2%%date:~0,4%.dmp   log=%date:~8,2%%date:~5,2%%date:~0,4%.log

(2)将此脚本加入任务计划，设置每天凌晨2点执行

--==========================================

二、使用expdp
sqlplus  / as sysdba
SQL> create  directory  backup_dir  as  'd:\db_backup';
SQL> grant  read , write  on  directory  backup_dir  to  scott;

(1)脚本内容
@echo off
rem  dbbackup.bat
expdp scott/tiger directory=backup_dir  schemas=scott dumpfile=laofangkuai_%date:~8,2%% date:~5,2%%date:~0,4%.dmp  logfile=%date:~8,2%%date:~5,2%%date:~0,4%.log
(2)将此脚本加入任务计划，设置每天凌晨2点执行



查询恢复进度

select sid, serial#, context, sofar, totalwork,
       round(sofar/totalwork*100,2) "%_complete"
from v$session_longops
where opname like 'rman%'
and opname not like '%aggregate%'
and totalwork != 0
and sofar <> totalwork;


查询恢复进度
SQL> declare
l_start number;  2
  3  l_end number;
  4  begin
  5  select ktuxesiz into l_start from x$ktuxe where ktuxeusn=10 and ktuxeslt=39;
  6  dbms_lock.sleep(60);
  7  select ktuxesiz into l_end from x$ktuxe where ktuxeusn=10 and ktuxeslt=39;
  8  dbms_output.put_line('time est day: '||round(l_end/(l_start-l_end)/60/24,2));
  9  end;
 10  /




pl sql 执行 暂停任务

07.SQL> conn /as sysdba　　--以SYSDBA身份登陆
08.Connected.
09.SQL> @ /rdbms/admin/dbmslock.sql　--安装系统包
10.
11.Package created.
12.
13.
14.Synonym created.
15.
16.
17.Grant succeeded.
18.
19.SQL> grant execute on dbms_lock to public;　--授权PUBLIC执行权限
20.
21.Grant succeeded.
22.
23.SQL> create table test1(id number,name varchar2(40),time date);   --创建test1临时表
24.
25.Table created.
26.
27.SQL> select * from test1;  --无数据
28.
29.no rows selected
30.
31.
32.SQL> SET TIMING ON  --打开时间显示
33.SQL> begin  --开始执行测试脚本
34.  2    insert into test1(id,name,time) values(1,'Andy',sysdate);
35.  3    DBMS_LOCK.SLEEP(10);  --让程序暂时10秒钟
36.  4    insert into test1(id,name,time) values(2,'Shirley',sysdate);
37.  5    commit;
38.  6  end;
39.  7  /




 1、在linux后台相应目录下面创建一个文件 ,
$ vi  test.sh
2、打开文件，在编辑模式下输入如下文本 。。


sqlplus username/PWD <<EOF      --注： 表示连接 到oracle
set timing on;                       --注：该句在SQLplus下表示打印SQL语句的执行时间

/*
你想要执行的SQL文本
*/

EOF    --注：表示结束  end of file


3、为文件附可执行权限  chmod


4、以如下方式在后台执行
$ nohup sh test.sh &

放到后台执行，并拷贝日志文件到另一个主机

sqlplus dbmgr/duan5lzh@'sid' <<EOF
set timing on;
select sysdate from dual;
select instance_name from v\$instance;
UPDATE epcisbase.clean_table_setup c set c.index_parallel=4 where c.table_name in ('RM_FLOW_STATUS','RM_FLOWSET_STATUS');
commit;

SET SERVEROUTPUT ON;
EXEC APPMGR.PKG_CLEAN_DATA_UTIL.CLEAN_PARTITIOIN_DATA_MAIN('EPCISUDWR','RM_FLOWSET_STATUS','20130906');
EXEC APPMGR.PKG_CLEAN_DATA_UTIL.CLEAN_PARTITIOIN_DATA_MAIN('EPCISUDWR','RM_FLOW_STATUS','20130906');
SET SERVEROUTPUT OFF;

select sysdate from dual;
EOF
scp /paic/cx/epcis/data/osepcis/nohup.out  dongkuifeng611@10.11.108.76:/home/dongkuifeng611/

放后台并记录日志
[padep@cnsz081003 trustdw]$ dscp padba@g3ah1020:/paic/xt/trustdw/data/oradata/trustdw/* padba@z4ah8020:/paic/xt/t0tdw/data/oradata/t0tdw >data.out 2>&1 &
[1] 26051
[padep@cnsz081003 trustdw]$ dscp padba@g3ah1020:/paic/xt/trustdw/data1/oradata/trustdw/* padba@z4ah8020:/paic/xt/t0tdw/data1/oradata/t0tdw >data1.out 2>&1 &
[2] 29306
[padep@cnsz081003 trustdw]$ ls -l
total 12
-rw-r--r-- 1 padep usr03 1679 Jul 16 17:02 data1.out
-rw-r--r-- 1 padep usr03 6160 Jul 16 17:02 data.out



需要先将nohup.out 文件主机的密钥复制到目标主机上：

# ssh-keygen  -t  rsa      ----生成密钥文件

#scp -r id_rsa.pub 10.10.10.17:/root/.ssh/authorized_keys   ----home目录的.ssh下

scp /paic/cx/epcis/data/osepcis/.ssh/id_rsa.pub  dongkuifeng611@10.11.108.76:/home/dongkuifeng611/.ssh/authorized_keys

查看表或索引的并行度

select * from dba_tables  where table_name='JZ_BDL_CUST_INFO';
select degree from user_indexes where index_name='IND_T_CHG_MAIN_F';
这个应该是大于1的

alter index IND_T_CHG_MAIN_F noparallel;

select /*+ no_parallel(t) */  count(1)  from NETSPOCDBA.JZ_BDL_CUST_INFO t;


更改数据文件的位置

SQL> startup mount

SQL> alter database rename file 'D:/ORACLE/DB_CREATE_FILE_DEST/ORCL/DATAFILE/O1_
MF_TEST_5JDZLKB6_.DBF' to 'D:/ORACLE/ORADATA/ORCL/O1_MF_TEST_5JDZLKB6_.DBF';

//此处主要是更改控制文件中的内容
Database altered.

SQL> alter database open;


---快速交付
---批量更改数据文件路径。

第二步：修改数据文件的路径
查看有多少个不同路径需要修改，返回的是旧数据文件的oldpath
select distinct substr(df.name,1,instr(df.name,'/',-1,1)) oldpath from v$datafile df;


第三步：修改日志文件的路径(此步可能会遇到错误，处理方法见右边)：
查看有多少个不同路径需要修改，返回的是旧日志文件的oldpath
select distinct substr(df.MEMBER,1,instr(df.MEMBER,'/',-1,1)) oldpath from v$logfile df;

select distinct substr(df.name,1,instr(df.name,'/',-1,1)) oldpath from v$tempfile df;

检查是否都修改完毕(没返回记录则表示都已修改完了）
select name from v$datafile where upper(name) not like '%/' || trim(upper('新测试库SID')) || '/%';
select member from v$logfile where upper(member) not like '%/' || trim(upper('新测试库SID')) || '/%';



set pagesize 999
set linesize 999
select 'alter database rename file '||''''||member||''''||' to '||chr(39)||replace(member,'/paic/hq/scan/redo/oradata/scan/','/paic/r0scan/redo/oradata/r0scan/')||''';'
from v$logfile  where member like '/paic/hq/scan/redo/oradata/scan/%';

select 'alter database rename file '||''''||name||''''||' to '||chr(39)||replace(name,'/paic/hq/scan/data/oradata/scan/','/paic/r0scan/data/oradata/r0scan/')||''';'
from v$datafile where name like '/paic/hq/scan/data/oradata/scan/%'

select 'alter database rename file '||''''||name||''''||' to '||chr(39)||replace(name,'/paic/hq/scan/data/oradata/scan/','/paic/r0scan/data/oradata/r0scan/')||''';'
from v$tempfile where name like '/paic/hq/scan/data/oradata/scan/%'

col checkpoint_change# for 9999999999999999999999

col title for a111000


alter database rename file '/paic/sx/ics/redo/oradata/ics/redo07.log' to '/paic/t4ics/redo/oradata/ics/redo07.log'
*
ERROR at line 1:
ORA-01511: error in renaming log/data files
ORA-01511: error in renaming log/data files
ORA-00312: online log 7 thread 1: '/paic/sx/ics/redo/oradata/ics/redo07.log'



选取指定行记录

with test as
(
select rownum rn, t.*
from (
 select * from table(dbms_xplan.display_sql_plan_baseline(plan_name=>'OTLN_683446627'))) t)
select plan_table_output from test where rn >= (select rn from test where plan_table_output like '%Id  | Operation%')
and rn <= (select rn from test where plan_table_output like '%Predicate Information%');




SQL> select group#,member from v$logfile where member='/paic/sx/ics/redo/oradata/ics/redo07.log';
         7
/paic/sx/ics/redo/oradata/ics/redo07.log


SQL> ALTER DATABASE CLEAR LOGFILE GROUP 7;
ALTER DATABASE CLEAR LOGFILE GROUP 7
*
ERROR at line 1:
ORA-00344: unable to re-create online log '/paic/sx/ics/redo/oradata/ics/redo07.log'
ORA-27040: file create error, unable to create file
SVR4 Error: 2: No such file or directory
Additional information: 1


SQL> alter database rename file '/paic/sx/ics/redo/oradata/ics/redo07.log' to '/paic/t4ics/redo/oradata/ics/redo07.log';

Database altered.


col name format a30
col 起始SCN值 format 9999999999999999999
col 结束SCN值 format 9999999999999999999

select a.name,a.checkpoint_change# "起始SCN值",b.checkpoint_change# "结束SCN值" from v$datafile_header a,v$datafile b where a.file#=b.file#;

col checkpoint_change# format 9999999999999999999
col checkpoint_change# format 9999999999999999999
select a.name,a.checkpoint_change# ,b.checkpoint_change#  from v$datafile_header a,v$datafile b
where a.file#=b.file#;




----管道与多个文件.
# +---------------------------------------+
# | Make two new pipes (Compress / Split) |
# +---------------------------------------+
mknod compress_pipe p;
mknod export_pipe p;
chmod 666 export_pipe compress_pipe;

# +---------------------------------------+
# | Start both the Split and Compress     |
# | backgroud processes.                  |
# +---------------------------------------+
nohup split -b 1024m < export_pipe &
nohup gzip < compress_pipe > export_pipe &

# +---------------------------------------+
# | Finally, start the export to both     |
# | pipes.                                |
# +---------------------------------------+
nohup exp dbmgr/***** tables=dbmgr.CBO_STATS_BAK file=compress_pipe direct=y buffer=1048576000 log=exp3rdfull.log &


mknod total.pipe p //建立一个管道文件
cat total.pipe | compress > Reddy.`date +%b_%d_%H_%M_%S`.dmp.Z &
exp u/p owner=Reddy(which ever your case) consistent=y file=total.pipe log=reddy.`date +%b_%d_%H_%M_%S.`log indexes=n buffer=10485760


这样做
导出:
mknod exp_pipe p
gzip <exp_pipe >test.dmp.gz &
exp username/passwd file=exp_pipe
导入:
mknod imp_pipe p
gunzip <test.dmp.gz >imp_pipe &
imp username/passwd file=imp_pipe full=y


4.  全库导入的一般步骤
注意：在导出时，需要通过toad或其他工具提取源数据库创建主键和索引的脚本
1.  先全库加 rows=n 把结构导进去
$ imp system/manager file=exp.dmp log=imp.log full=y rows=n indexes=n
2.  使业务用户的触发器失效/删除主键和唯一索引
spool drop_pk_u.sql
select 'alter table '||table_name||' drop constraint '||constraint_name||';'
from user_constraints
where constraint_type in ('P','U');
/
spool off
spool disable_trigger.sql
select 'alter trigger '||trigger_name||' disable;'
from user_triggers;
/
spool off

@drop_pk_u.sql
@disable_trigger.sql

3.  以 ignore=y 全库导入
$ imp system/manager file=exp.dmp log=imp.log full=y ignore=y
4.  通过 toad 或其他工具提取源数据库创建主键和索引的脚本,在目标数据库中创建主键
和索引。使触发器生效。



SQL> column F new_val F
SQL> select to_char(sysdate,'yyyymmddhh24miss')||'.txt' F from dual;
------------------
20050124174926.txt SQL> spool &F


oracle 默认隔离级别

我只能GOOGLE到这个：
http://dba.stackexchange.com/que ... ion-level-in-oracle

Using the query from the SO answer Vincent Malgrat referenced, here is how you can get the transaction isolation level for the transaction in progress:
SELECT s.sid, s.serial#,
   CASE BITAND(t.flag, POWER(2, 28))
      WHEN 0 THEN 'READ COMMITTED'
      ELSE 'SERIALIZABLE'
   END AS isolation_level
FROM v$transaction t
JOIN v$session s ON t.addr = s.taddr AND s.sid = sys_context('USERENV', 'SID');

If you are not already in a transaction you can start one with the following:
declare
   trans_id Varchar2(100);
begin
   trans_id := dbms_transaction.local_transaction_id( TRUE );
end;
/

It seems like there would be an easier way than this. I don't know how to get the default isolation level for the session if that is what you are looking for.



EXP-00091 Exporting questionable statistics


下面我们来解决这个问题，让其不再出现：

第一步：

查看DB中的NLS_CHARACTERSET的值（提供两种方法）：

查询NLS_CHARACTERSET的值：
select * from nls_database_parameters t where t.parameter='NLS_CHARACTERSET'
or
select * from v$nls_parameters  where parameter='NLS_CHARACTERSET';
SQL> select * from v$nls_parameters where parameter='NLS_CHARACTERSET';

PARAMETER　　　　      VALUE
-----------------------　　----------------------------------------------
NLS_CHARACTERSET    ZHT16BIG5

第二步：

根据第一步查出的NLS_CHARACTERSET（ZHT16BIG5）来设定exp的环境变量：


WINNT> set NLS_LANG=AMERICAN_AMERICA.ZHT16BIG5

进行设定后，在环境变量中查看NLS_LANG的值是否一致，如果不一致可在环境变量中手中修改。
LINUX> export NLS_LANG=AMERICAN_AMERICA.ZHT16BIG5

附上exp-00091的oracle error message 解決方案说明：

error exp 91
00091, 00000, "Exporting questionable statistics."
// *Cause:  Export was able export statistics, but the statistics may not be
//          usuable. The statistics are questionable because one or more of
//          the following happened during export: a row error occurred, client
//          character set or NCHARSET does not match with the server, a query
//          clause was specified on export, only certain partitions or
//          subpartitions were exported, or a fatal error occurred while
//          processing a table.
// *Action: To export non-questionable statistics, change the client character
//          set or NCHARSET to match the server, export with no query clause,
//          export complete tables. If desired, import parameters can be
//          supplied so that only non-questionable statistics will be imported,
//          and all questionable statistics will be recalculated.


fuser -cu /paic/hq/t0hsman/data01 /paic/hq/t0hsman/data01

SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_BANK_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CALL_HISTORY_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_COMM_FIELD_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_COMM_SYS_PARM_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TMR_TASK_REMIND_STAT_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_BANK_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CALL_HISTORY_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_COMM_FIELD_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_COMM_SYS_PARM_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TMR_TASK_REMIND_STAT_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'CFS_INTRODUCER_CHANGE_INTF_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'CFS_INTRODUCER_CHANGE_INTF_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'CFS_ORDER_STATUS_MAPPING_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'CFS_ORDER_STATUS_MAPPING_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_ACT_TASK_TEL_RELA_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_ACT_TASK_TEL_RELA_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_AFFICHE_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_AFFICHE_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_ASSIGN_PROCESS_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_ASSIGN_PROCESS_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_ASSIGN_TYPE_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_ASSIGN_TYPE_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_ASSIGNED_MENU_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_ASSIGNED_MENU_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_ASYNC_QUERYQUEUE_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_ASYNC_QUERYQUEUE_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_ASYNC_STATUSINFO_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_ASYNC_STATUSINFO_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_ASYNC_TYPEINFO_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_ASYNC_TYPEINFO_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_AUTO_ASSIGN_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_AUTO_ASSIGN_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_AUTO_DISPATCH_CONTROL_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_AUTO_DISPATCH_CONTROL_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_AWARD_PUNISH_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_AWARD_PUNISH_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_AWARD_PUNISH_STATUS_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_AWARD_PUNISH_STATUS_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_BANK_INFO_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_BANK_INFO_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_BATCH_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_BATCH_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_BIZ_BRANCH_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_BIZ_BRANCH_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_BIZ_DISPLAY_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_BIZ_DISPLAY_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_BIZBRA_ADDRESSLIST_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_BIZBRA_ADDRESSLIST_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_BLUEPRINT_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_BLUEPRINT_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_BRANCH_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_BRANCH_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CAMPAIGN_AUDIT_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CAMPAIGN_AUDIT_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CAMPAIGN_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CAMPAIGN_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CAMPAIGN_STATUS_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CAMPAIGN_STATUS_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CAMPAIGN_TYPE_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CAMPAIGN_TYPE_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CERTIFIY_TYPE_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CERTIFIY_TYPE_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CFS_LSMS_VISIT_FILE_CON_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CFS_LSMS_VISIT_FILE_CON_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CHANNEL_SRC_DETAIL_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CHANNEL_SRC_DETAIL_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CITY_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CITY_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_COMPETING_PRODUCTS_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_COMPETING_PRODUCTS_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CUST_LINKMAN_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CUST_LINKMAN_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CUST_TELEPHONE_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CUST_TELEPHONE_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CUSTLIST_SPLIT_DIMEN_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CUSTLIST_SPLIT_DIMEN_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CUSTLIST_SPLIT_DIMEN_IN_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CUSTLIST_SPLIT_DIMEN_IN_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CUSTLIST_SPLIT_OB_AMOUN_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CUSTLIST_SPLIT_OB_AMOUN_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CUSTOMER_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CUSTOMER_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CUSTTSPLIT_TMRGROUP_REL_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CUSTTSPLIT_TMRGROUP_REL_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_DROPDOWN_ASSOCIATE_DEFI_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_DROPDOWN_ASSOCIATE_DEFI_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_DROPDOWN_LIST_DEFINE_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_DROPDOWN_LIST_DEFINE_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_EMPLOYEE_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_EMPLOYEE_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_EMPLOYEE_INTF_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_EMPLOYEE_INTF_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_FILE_UPLOAD_ERROR_DATA_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_FILE_UPLOAD_ERROR_DATA_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_FILE_UPLOAD_TEMPLET_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_FILE_UPLOAD_TEMPLET_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_FILE_UPLOAD_TEMPLET_TYP_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_FILE_UPLOAD_TEMPLET_TYP_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_FILE_UPLOAD_TEMPORARY_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_FILE_UPLOAD_TEMPORARY_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_GROUP_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_GROUP_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_GROUP_SET_RULE_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_GROUP_SET_RULE_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_IB_PURPOSE_HSITORY_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_IB_PURPOSE_HSITORY_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_LINKMAN_TYPE_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_LINKMAN_TYPE_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_LIST_RECLAIM_SETTING_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_LIST_RECLAIM_SETTING_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_LSMS_SEND_DETAIL_INTF_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_LSMS_SEND_DETAIL_INTF_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_LSMS_STATUS_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_LSMS_STATUS_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_MEDIA_SOURCE_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_MEDIA_SOURCE_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_MEDIA_SOURCE_INTF_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_MEDIA_SOURCE_INTF_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_MENU_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_MENU_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_MOBILE_PRENUMBER_REGION_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_MOBILE_PRENUMBER_REGION_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_ORGANIZATION_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_ORGANIZATION_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_ORGANIZATION_INTF_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_ORGANIZATION_INTF_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_PRODUCT_ORDER_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_PRODUCT_ORDER_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_RECLAIM_RULE_TYPE_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_RECLAIM_RULE_TYPE_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_RECOMMEND_RELAT_TYPE_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_RECOMMEND_RELAT_TYPE_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_REGION_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_REGION_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_REMARK_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_REMARK_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_ROLE_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_ROLE_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_SALE_RESULT_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_SALE_RESULT_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_SALE_RESULT_HISTORY_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_SALE_RESULT_HISTORY_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_SPEECHART_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_SPEECHART_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_SPEECHART_INFO_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_SPEECHART_INFO_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_SPEECHART_MAINFLOW_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_SPEECHART_MAINFLOW_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_SPEECHART_TYPE_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_SPEECHART_TYPE_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_SPLIT_CAMPAIGN_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_SPLIT_CAMPAIGN_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_SYSTEM_WORKDAY_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_SYSTEM_WORKDAY_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_T_CUSTLIST_INTF_ERR_LOG_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_T_CUSTLIST_INTF_ERR_LOG_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TASK_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TASK_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TASK_PHASE_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TASK_PHASE_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TASK_RECLAIM_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TASK_RECLAIM_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TASK_REMIND_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TASK_REMIND_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TASK_REMIND_TYPE_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TASK_REMIND_TYPE_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TASK_STATUS_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TASK_STATUS_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TASK_STATUS_REMIND_MAPP_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TASK_STATUS_REMIND_MAPP_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TASK_UNALLOCATED_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TASK_UNALLOCATED_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TCIMS_BATCH_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TCIMS_BATCH_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TCIMS_CUSTLIST_ETL_INTF_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TCIMS_CUSTLIST_ETL_INTF_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TELAREACODE_CITY_RELATI_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TELAREACODE_CITY_RELATI_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TELEPHONE_TYPE_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TELEPHONE_TYPE_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TMR_AWARD_PUNISH_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TMR_AWARD_PUNISH_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TMR_BIZMODE_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TMR_BIZMODE_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TMR_CALL_STAT_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TMR_CALL_STAT_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TMR_GROUP_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TMR_GROUP_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TMR_GROUP_RELA_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TMR_GROUP_RELA_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TMR_OB_AMOUNT_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TMR_OB_AMOUNT_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TMR_SIGNIN_RULE_SETTING_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TMR_SIGNIN_RULE_SETTING_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TMR_WORKDAY_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TMR_WORKDAY_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_UPLOAD_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_UPLOAD_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_ASS_TYPE_MAPPING_UPL_TE_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_ASS_TYPE_MAPPING_UPL_TE_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CFS_ENROLL_STATUS_MAS_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CFS_ENROLL_STATUS_MAS_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CFS_ENROLL_UPDATE_MAS_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CFS_ENROLL_UPDATE_MAS_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CFS_ENROLL_VISIT_MAS_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CFS_ENROLL_VISIT_MAS_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TASK_REMIND_STAT_CONFIG_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TASK_REMIND_STAT_CONFIG_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TMR_IB_REMIND_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TMR_IB_REMIND_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TASK_EXTRACT_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TASK_EXTRACT_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CFS_CH_MODIFY_MAS_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_CFS_CH_MODIFY_MAS_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_PA18_CUSTLIST_ERR_INTF_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_PA18_CUSTLIST_ERR_INTF_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TCIMS_CUSTLIST_ERR_INTF_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TCIMS_CUSTLIST_ERR_INTF_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TCIMS_RCL_APL_RST_INTF_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TCIMS_RCL_APL_RST_INTF_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TCIMS_RCL_CAL_RST_INTF_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TCIMS_RCL_CAL_RST_INTF_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_RCL_BATCH_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_RCL_BATCH_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'JOB_ERROR_LOG_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'JOB_RUNNING_LOG_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_RCL_RUL_TSK_STAT_RELA_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_RCL_RUL_TSK_STAT_RELA_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TMR_IMP_TASK_REMIND_STA_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TMR_IMP_TASK_REMIND_STA_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_VISIT_VERIFY_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_VISIT_VERIFY_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_PCSFAILOVER_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_PCSFAILOVER_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TCIMS_RCL_CAL_STATISTIC_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_TCIMS_RCL_CAL_STATISTIC_BU',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_RCL_ROWID_BI',schema => 'CGIDATA') ||';'  FROM DUAL
UNION ALL SELECT    dbms_metadata.get_ddl(object_type => 'TRIGGER',name => 'NBZ_RCL_ROWID_BU',schema => 'CGIDATA') ||';'  FROM DUAL ;

保存用户及权限 角色 grant

select 'create user '||username||chr(10)||'identified by values '''||password||''''||chr(10)||
'default tablespace '||default_tablespace||chr(10)||'temporary tablespace '||TEMPORARY_TABLESPACE||chr(10)||
'profile '||PROFILE||';'||chr(10)
 from dba_users where username in
 (
 'EPCISINTF',
'DZRPTOPR',
'DZSYSP3',
'DZCOMMON',
'DZCOMOPR',
'PCISINTF',
'DZCDE',
'P3ETL',
'DEPLOYOP',
'P3JOB',
'DZSYSOPR'
 );

--1.2  tablespace quota
 select 'alter user '||username||' quota unlimited on '||tablespace_name||';' from dba_ts_quotas where username in
 (
 'EPCISINTF',
'DZRPTOPR',
'DZSYSP3',
'DZCOMMON',
'DZCOMOPR',
'PCISINTF',
'DZCDE',
'P3ETL',
'DEPLOYOP',
'P3JOB',
'DZSYSOPR'
 )
 order by username;


 不对用户做表空间限额控制:
    GRANT UNLIMITED TABLESPACE TOuser;
这种方式是全局性的。  或者
    alter user  user  quota unlimited on  user_tablespace;
 这种方式是针对特定的表空间的.
回收表空间限额控制:
    revoke unlimited tablespace from  user;
或者
    alter user  user  quota 0 on  user_tablespace;

--1.3 sys priv
select 'grant '||privilege||' to '||grantee||';' from dba_sys_privs where grantee in
(
'EPCISINTF',
'DZRPTOPR',
'DZSYSP3',
'DZCOMMON',
'DZCOMOPR',
'PCISINTF',
'DZCDE',
'P3ETL',
'DEPLOYOP',
'P3JOB',
'DZSYSOPR'
)
order by grantee;

--1.4 role priv
select 'grant '||granted_role||' to '||grantee||';' from dba_role_privs where grantee
in
(
'EPCISINTF',
'DZRPTOPR',
'DZSYSP3',
'DZCOMMON',
'DZCOMOPR',
'PCISINTF',
'DZCDE',
'P3ETL',
'DEPLOYOP',
'P3JOB',
'DZSYSOPR'
)
order by grantee;


--2 最后还保存 tab priv (BIN$表是已删除表)
select 'grant '||privilege||' on '||owner||'.'||table_name||' to '||grantee||';' from dba_tab_privs
where grantee in
(
'EPCISINTF',
'DZRPTOPR',
'DZSYSP3',
'DZCOMMON',
'DZCOMOPR',
'PCISINTF',
'DZCDE',
'P3ETL',
'DEPLOYOP',
'P3JOB',
'DZSYSOPR'
);


批量添加临时文件 temp
select 'alter tablespace '||a.tablespace_name|| ' add tempfile '''||
substr(b.file_name,1,instr(b.file_name,'system')-1)||lower(a.tablespace_name)||'01.dbf'' size 500M reuse
autoextend off;'
from dba_tablespaces a,dba_data_files b
where
a.contents='TEMPORARY' and a.tablespace_name not in (select distinct tablespace_name from dba_data_files)
and b.file_id=1;


11g有个新特性：表新加字段并赋予default值时，oracle会记录到数据字典中，而不会逐行修改数据。

不过，这个特性有很多限制，使用时需要注意。请看下面的测试：

SQL> select banner from v$version where rownum=1;

BANNER
--------------------------------------------------------------------------------
Oracle Database 11g Enterprise Edition Release 11.2.0.2.0 - 64bit Production

--创建测试表，并初始化数据
SQL> create table t_def as select * from dba_objects;

表已创建。

SQL> insert into t_def select * from t_def;

已创建62116行。

SQL> /

已创建124232行。

SQL> commit;

提交完成。

SQL> select count(*) from t_def;

  COUNT(*)
----------
    248464

SQL> select object_id from user_objects where object_name = 'T_DEF';

OBJECT_ID
----------
    166509

SQL> select bytes/1024/1024, blocks from dba_segments where owner='DBMGR' and segment_name='T_DEF';

BYTES/1024/1024     BLOCKS
--------------- ----------
             29       3712

SQL> set timing on

--default值为常量，并且为not null时，耗时只有0.52s
SQL> alter table t_def add def1 varchar2(10) default 'asdfasdf' not null;

表已更改。

已用时间:  00: 00: 00.52

SQL> select * from sys.ecol$;

   TABOBJ#     COLNUM BINARYDEFVAL
---------- ---------- ------------------------------
    166509         16 6173646661736466

SQL> select column_name, column_id from user_tab_columns where table_name='T_DEF' and column_name='DEF1';

COLUMN_NAME                     COLUMN_ID
------------------------------ ----------
DEF1                                   16

如果做10046 trace，可以看到递归调用的过程。有一条语句如下：
insert into ecol$ values (:1, :2, :3)
END OF STMT
PARSE #47096684507784:c=1000,e=1098,p=0,cr=3,cu=0,mis=1,r=0,dep=1,og=4,plh=0,tim=1346910433235212
BINDS #47096684507784:
Bind#0
  oacdty=02 mxl=22(22) mxlc=00 mal=00 scl=00 pre=00
  oacflg=00 fl2=0001 frm=00 csi=00 siz=48 off=0
  kxsbbbfp=2ad58d0878e0  bln=22  avl=04  flg=05
  value=166509
Bind#1
  oacdty=02 mxl=22(22) mxlc=00 mal=00 scl=00 pre=00
  oacflg=00 fl2=0001 frm=00 csi=00 siz=0 off=24
  kxsbbbfp=2ad58d0878f8  bln=22  avl=02  flg=01
  value=16
Bind#2
  oacdty=113 mxl=4000(4000) mxlc=00 mal=00 scl=00 pre=00
  oacflg=00 fl2=0001 frm=00 csi=00 siz=4000 off=0
  kxsbbbfp=2ad58cb36dc8  bln=4000  avl=4000  flg=05
  value=Unhandled datatype (113) found in kxsbndinf

很明显，oracle将default值记录在ecol$表。

--default值为常量，可以为null时，耗时5.65秒，查看ecol$表，没有记录
SQL> alter table t_def add def2 varchar2(10) default 'asdfasdf';

表已更改。

已用时间:  00: 00: 05.65

SQL> select * from sys.ecol$;

   TABOBJ#     COLNUM BINARYDEFVAL
---------- ---------- ------------------------------
    166509         16 6173646661736466

已用时间:  00: 00: 00.07

--default值为变量，且not null。耗时11.21秒，查看ecol$表，没有记录
SQL> alter table t_def add def3 varchar2(32) default sys_guid() not null;

表已更改。

已用时间:  00: 00: 11.21

SQL> select * from sys.ecol$;

   TABOBJ#     COLNUM BINARYDEFVAL
---------- ---------- ------------------------------
    166509         16 6173646661736466

--dump数据块看看
block_row_dump:
tab 0, row 0, @0x1eed
tl: 147 fb: --H-FL-- lb: 0x3  cc: 18
col  0: [ 3]  53 59 53
col  1: [29]
41 50 50 4c 59 24 5f 43 4f 4e 46 5f 48 44 4c 52 5f 43 4f 4c 55 4d 4e 53 5f
55 4e 51 32
col  2: *NULL*
col  3: [ 3]  c2 08 41
col  4: [ 3]  c2 08 41
col  5: [ 5]  49 4e 44 45 58
col  6: [ 7]  78 6f 06 07 0c 1e 23
col  7: [ 7]  78 6f 06 07 0c 1e 23
col  8: [19]  32 30 31 31 2d 30 36 2d 30 37 3a 31 31 3a 32 39 3a 33 34
col  9: [ 5]  56 41 4c 49 44
col 10: [ 1]  4e
col 11: [ 1]  4e
col 12: [ 1]  4e
col 13: [ 2]  c1 05
col 14: *NULL*
col 15: *NULL*
col 16: [ 8]  61 73 64 66 61 73 64 66
col 17: [32]
43 39 30 33 44 39 45 46 34 44 42 44 43 39 37 45 45 30 34 30 31 46 30 41 41
32 30 39 30 45 36 35

可以看到，前面新增加的col15、col16、col17，后面两列都是有实际数据的。

小结：
1、	oracle文档是这样描述这个特性的：
For some types of tables (for example, tables without LOB columns), if you specify both a NOT NULL constraint and a default value, the database can optimize the column add operation and greatly reduce the amount of time that the table is locked for DML.
表添加字段时，如果新加字段指定了default值，并且该列非空，可以显著减少dml锁的时间。
因为该列可以为空时，oracle无法区分是default值，还是本来就是空值。
2、	当default值为变量时（例如sys_guid()、sysdate），只能将值写入到行中，这也很容易理解。

所以，应用该特性时，一定要注意其局限性，否则语句一执行就悲剧了。


 修改表增加字段默认值default
分类： Oracle 管理 2013-09-27 15:20 2948人阅读 评论(0) 收藏 举报
对个生产库的表增加1个字段.字段类型是INT型, 表数据有2千万条, alter table table_name add xxoo number(4) default  0 ;
因此 不仅要修改字典,还要刷新全部数据.
1） 在ALTER sql中有带缺省值，ORACLE会直接刷新全部的记录。
2） 在ALTER sql中没有带缺省值，ORACLE只会影响到后来的记录。
alter table table_name add xxoo number(4) default null;
Table altered

Executed in 0.062 seconds
带有default null 就可以了
 alter table table_name add xxoo number(4) default 0;

Table altered
Executed in 1.625 seconds
原来的话 要更新所有的行,会导致UNDO段占用
使用语句Alter table a add test number(10) default 0;更新一个大表中字段时，表有四个分区，数据达到几十亿行，增加一个字段竟然要几个小时的时间，修改语句加上Nologging ，怎么没有作用呢？去找是不是哪有锁了呢，使用语句 select * from dba_locks where lock_id1=33784;发现Session_id为14的一直在执行，那么他在执行什么呢！查询一下吧。
使用语句：
select a.sid,a.username,c.SQL_TEXT from v$session a, dba_locks b,v$sqlarea c
  where b.lock_id1=33784 and a.SID=b.session_id
   and a.SQL_ADDRESS=c.ADDRESS;
哦，原来他在Update Test 字段值为0.至此总结到，原来Alter之后做的竟然是Update，也明白了为什么Undo表空间会爆涨。去掉Default 0，呵呵，很快就OK了。
建议没有必要时慎用Default





给一个大表增加一个字段，给怎样操作。
Author： Kewin
Date: 2008-11-7

背景：
有个100万数据的TABLE:
SQL> desc t2
Name                                      Null     Type
----------------------------------------- -------- ----------------------------
OWNER                                     NOT NULL VARCHAR2(30)
OBJECT_NAME                               NOT NULL VARCHAR2(30)
SUBOBJECT_NAME                                     VARCHAR2(30)
OBJECT_ID                                 NOT NULL NUMBER
DATA_OBJECT_ID                                     NUMBER
OBJECT_TYPE                                        VARCHAR2(18)
CREATED                                   NOT NULL DATE
LAST_DDL_TIME                             NOT NULL DATE
TIMESTAMP                                          VARCHAR2(19)
STATUS                                             VARCHAR2(7)
TEMPORARY                                          VARCHAR2(1)
GENERATED                                          VARCHAR2(1)
SECONDARY                                          VARCHAR2(1)
需要添加一个字段（KONG INT DEFAULT 100）
在如何修改，需要注意什么细节。

模拟测试：
如果有事务在TABLE上，那ALTER 语句执行失败。因为DML语句会加共享锁在table上，而ALTER需要排他锁。故alter失败。
SQL> alter table t2 add (kong int );
alter table t2 add (kong int )
*
ERROR at line 1:
ORA-00054: resource busy and acquire with NOWAIT specified


Elapsed: 00:00:00.00
那只能rollback transaction 或者kill session；
直接去添加一个字段，注意没有加上缺省值。
SQL> /

Table altered.

Elapsed: 00:00:00.04
执行的速度很快。在掩耳不及迅雷情况执行完毕。
这时可以DUMP BLOCK，看到数据块中的记录没有新添加的字段。（只是执行DDL，修改table的定义）
那这时删除一个字段呢？
SQL> alter table t2 drop column kong;

Table altered.

Elapsed: 00:00:11.42
可以想象，这是做了一个全表扫描。找到kong 字段，把内容搽去。
如果在ALTER中加上了缺省值，那又会怎样？
来来来，上楼上。一起去看看（易中天的语录）

SQL> alter table t2 add (kong int default 10);

Table altered.

Elapsed: 00:01:34.34
可以看到执行时间是1分钟34秒。而同时其他session执行的sql只能被等待。

SQL> select * from v$lock;

ADDR             KADDR                   SID TY        ID1        ID2      LMODE    REQUEST      CTIME      BLOCK
---------------- ---------------- ---------- -- ---------- ---------- ---------- ---------- ---------- ----------
07000000FDDF5C60 07000000FDDF5DD8          9 TX     458782         60          6          0         25          0
07000000FDC5AB28 07000000FDC5AB50          9 TM       6291          0          6          0         25          0
07000000FB9B8308 07000000FB9B8328         13 CU   32906288  117440513          6          0         21          0

（忽略无关的lock。SID=13， 执行了DDL； SID=9，执行DML）
这里有个问题，SID=9， 拥有 table的锁；sid=13也拥有table的锁；那为什么sid=13 要执行那么长的时间，而sid=9 也要
LONG TIME，但是没有看到相关的阻塞。（这个没有阻塞，没有猜到理由）
在DDL时，ORACLE会当作一个原子来执行，sid=13已经修改了数据表的定义，接着更改block的数据；而SID=9只能等待，等待sid=13执行完毕。在SID=9的session可以看到SID=13执行后的结果：
SQL> select * from t2
  2  where owner='KONG2' AND ROWNUM < 2;

OWNER                          OBJECT_NAME
------------------------------ ------------------------------
SUBOBJECT_NAME                  OBJECT_ID DATA_OBJECT_ID OBJECT_TYPE
------------------------------ ---------- -------------- ------------------
CREATED         LAST_DDL_TIME   TIMESTAMP           STATUS  T G S       KONG
--------------- --------------- ------------------- ------- - - - ----------
KONG2                          T1
                                     6290           6290 TABLE
05-NOV-08       05-NOV-08       2008-11-05:22:15:13 VALID   N N N         10

如果在修改同时，加上缺省值，会阻塞其他session；那如果分来呢？先加字段，再加上缺省值。
SQL> alter table t2 add (kong int );

Table altered.

Elapsed: 00:00:00.03
SQL>
SQL> alter table t2 modify (kong default 2000);

Table altered.

Elapsed: 00:00:00.03
看到速度是很快。。。可是和前一个方法有什么区别吗？难道快就没有缺点？

还是有的：
1） 在ALTER sql中有带缺省值，ORACLE会直接刷新全部的记录。
2） 在ALTER sql中没有带缺省值，ORACLE只会影响到后来的记录。（明白快是有隐秘的秘诀）

在选择哪种方法时，要更加具体的情况来实施：是否有INDEX，是否在应用的高并发阶段，等等。





 Oracle11g新特性 - 快速在线新增not null字段 2011-12-29 18:21:53
分类： Linux
问题：某电信系统业务，其中有一张表有上亿条信息记录，而且很重要；要求在不停库和不锁表的情况下；对该表增加一个新的字段，如何实现。
在11g以前，在表中新增一个NOT NULL字段是件十分痛苦的事情，尤其是在表很大的情况，不但执行速度慢（会产生DDL锁，影响其它用户操作），而且由于数据长度的增加，很容易造成表中大量的行链接情况，影响性能。
在11g中，这种情况得到了彻底的改善，Oracle通过在数据字典（ecol$）中记录DEFAULT值，避免了繁重的更新操作，增加非空字段的时间和增加一个可空字段的时间完全一样。
下面先看10g中的情况：
SQL> select * from v$version where rownum<2;

BANNER
----------------------------------------------------------------
Oracle Database 10g Enterprise Edition Release 10.2.0.4.0 - Prod

SQL> create table test as select * from dba_objects;

Table created.

SQL> select count(*) from test;

  COUNT(*)
----------
     24871
SQL> set timing on
SQL> alter table test add new_col varchar(1000) default 'LARGE COLUMN' not null;

Table altered.

Elapsed: 00:00:20.34

可以看到即使对于只有2万多条数据的表，用了20秒，而且在这20秒期间，该表上有DDL锁，所有在该表的DML操作都会被阻塞。

注意，这里新增的列是非空的，如果没有非空这个限制，在10g中也是很快的：

SQL> alter table test add new_col2 varchar(1000);

Table altered.

Elapsed: 00:00:00.59

下面再看11g中的情况：
SQL> select * from v$version where rownum<2;

BANNER
--------------------------------------------------------------------------------
Oracle Database 11g Enterprise Edition Release 11.2.0.1.0 - Production

SQL> create table test as select * from dba_objects;

Table created.

SQL> select count(*) from dba_objects;

  COUNT(*)
----------
     13617

SQL> set timing on
SQL> alter table test add new_col varchar(1000) default 'LARGE COLUMN' not null;

Table altered.

Elapsed: 00:00:01.34

可以看到在11g中只用了1秒，那么Oracle是采用何种方法实现了如此大的性能提升呢？说起来也简单，在Oracle11g中，当添加一个包含DEFAULT值的NOT NULL字段，Oracle不会去更新现有的数据，仅仅是将默认值以及对应的表信息、列信息一起存储在一个新增数据字典表ecol$中。当Oracle在读取数据时，如果发现某一列为非空，但是实际存储却为空，就会从ECOL$中读取该列的默认值。

这样做的好处是不但减少了执行时间，而且不会产生DDL锁，进而不会影响其它用户的操作。

============

回到最开始的问题，如果数据库版本不是11g，那该怎么办呢，其实可以先新建一个允许空的字段，然后把该字段修改会非空，在对之前的数据进行update操作：
1. 新建一个允许空的字段。
SQL> alter table test add new_col varchar(1000);

Table altered.

Elapsed: 00:00:00.14
2. 修改该字段为非空，该语句只对之后的记录起作用，原有记录的该列还是为空值，因此该操作也很快。
SQL> alter table test modify new_col varchar(1000) default 'LARGE COLUMN';

Table altered.

Elapsed: 00:00:00.48
3. 更新原有的字段为默认值。
SQL> alter session enable parallel dml;
SQL> update /*+ parallel(t 8) */ test set new_col='LARGE COLUMN' where new_col is null;

24871 rows updated.
SQL> alter session disable parallel dml;





Solaris内存监控

Solaris内存主要用在以下几个方面：核心，进程，文件系统缓存。如下是监控内存使用的方法。

可用系统物理内存

分配给Solaris核心的内存数量

文件系统缓存使用的内存数量

进程使用的内存数量

系统剩余的内存数量

Total Physical Memory

使用prtconf命令，察看系统物理内存数量。

prtconf | head -2

System Configuration: Sun Microsystems sun4u

Memory size: 49152 Megabytes

Kernel Memory

使用sar –k察看系统核心占用的内存，如下3个内存池之和即是，单位byte

sar -k 1 1

SunOS lonespappb33 5.8 Generic_117350-13 sun4u 11/28/05

05:39:26 sml_mem alloc fail lg_mem alloc fail ovsz_alloc fail

05:39:28 483386752 202156800 0 4400701440 2886180864 0 656105472 0

File System Caching Memory

文件系统缓存使用系统可用的剩余内存缓存文件。在Solaris上，可用的剩余内存（free memory）大部分情况下总是接近0；Solaris8之前，vmstat 显示的free列表示可用的剩余内存，往往在系统启动（booted）的时候很高，随着系统运行慢慢降低为0，这是正常的，因为文件系统缓存的设计目的就是最大化利用系统可用内存来缓存最经常访问的文件。

在Solaris8中，vmstat 显示的free是系统可用的剩余内存（free memory）和可pageable的文件系统缓存（file system cache memory），man的解释：free size of the free list (Kbytes) 。文件系统缓存也挂在内存Free List上。

vmstat 1 5

procs memory page disk faults cpu

r b w swap free re mf pi po fr de sr s0 s1 s2 s3 in sy cs us sy id

0 1 0 62618064 33156520 5220 0 1144 0 0 0 0 0 1 0 0 8093 47291 1895 9 7 85

如上Solaris 8,vmstat 结果表示，文件系统缓存占用了将近33156520k内存。

Free Memory

由于文件系统缓存总是尽量利用可用的剩余内存缓存文件，因此大部分情况下Free memory总是接近0.

Memory Shortage Detection

系统运行时会不断的page in page out;繁忙的paging操作，可导致Page Scaner运行频繁，因此伴随有较高的scan-rage(sr)和page-out(po);这可以作为系统繁忙paging 的表示。

如果有进程被swap(w>0),则通常表示内存短缺，这时候往往swap设备的IO比较繁忙。

Swap Space

Solaris 交换空间（swap space）有2个重要的状态：保留(swap reservation)和分配(physical swap allocation).

保留(swap reservation)是指Process创建segment的时候，系统分配给Process虚拟的内存地址空间（virtual memory address space）,同时为了保证该segment以后可以被page out到swap,分配给Process与该segment同样大小的虚拟交换空间（virtual swap space）.

例如，process创建一个100M的segment,系统会分配给该process100M的virtual memory address space,但不会分配给process物理内存（physical memory）;同时在Swap space中预先保留(reservation)100M虚拟交换空间（virtual swap space）.

分配(physical swap allocation)是指segment driver给process segment分配物理内存时，预先为swap reservation区分配同样大小的物理交换空间（physical swap space）,用来page-out.

例如，process在已有100M的virtual memory address space基础上,通过trap/page-fault/zero-fill-on-demand分配到10M的物理内存;同时会为预先保留(reservation)的100M虚拟交换空间（virtual swap space）分配10M物理swap space.

Virtual Swap Space

系统虚拟交换空间的数量为物理磁盘交换空间大小（disk swap space）+Solaris在内存中分配的交换空间大小（memory swap space）.使用swap –s察看虚拟交换空间信息。

$ swap -s

total: 929688k bytes allocated + 57408k reserved = 987096k used, 17715000k available

Physical Swap Space

系统物理交换空间的数量为/etc/vfstab中配置的磁盘交换空间大小。使用swap –l察看。

$ swap -l

swapfile dev swaplo blocks free

/dev/vx/dsk/swapvol 230,6 16 25165808 25165808

必须确保swap –s和swap –l 的available & free 非0，否则将无法分配虚拟交换内存或者物理交换内存；

此时，Oracle通常会遇见ORA-4030和ORA-12500错误。

可计算memory swap space: 987,096k+17,715,000k-25165808/2k=6,119,192k

Process Memory Usage , ps, and pmap

进程的内存也可分为2种，虚拟内存使用和物理内存使用。进程虚拟内存是指已经分配给进程的虚拟地址空间（virtual address space）;物理内存是指分配给进程的真实的物理内存（real physical memory pages）数量。

Ps的vsz表示虚拟内存，rss表示物理内存

$ ps -opid,vsz,rss,args

PID VSZ RSS COMMAND

27495 1912 1016 –ksh


 AWR使用

SQL>@ /rdbms/admin/awrrpt.sql

用户也可以使用下面的命令手工采样（手工生成快照）：

BEGIN
DBMS_WORKLOAD_REPOSITORY.CREATE_SNAPSHOT ();
END;
/



 显示STATISTICS_LEVEL的当前值：

SQL> SHOW PARAMETER STATISTICS_LEVEL

SQL语句的执行结果是：
NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
statistics_level                     string      TYPICAL
如果STATISTICS_LEVEL的值为TYPICAL或者 ALL，表示启用AWR；如果STATISTICS_LEVEL的值为BASIC，表示禁用AWR。
*BASIC：awr统计的计算和衍生值关闭.只收集少量的数据库统计信息.
*TYPICAL：默认值．只有部分的统计收集.他们代表需要的典型监控oracle数据库的行为.
*ALL : 所有可能的统计都被捕捉. 并且有操作系统的一些信息.这个级别的捕捉应该在很少的情况下,比如你要更多的sql诊断信息的时候才使用.

--查看快照的频率和保留时间（默认为每1小时采样一次，采样信息保留时间为7天）
 select * from dba_hist_wr_control;
 select DBID, SNAP_INTERVAL, SNAPINT_NUM, RETENTION from wrm$_wr_control;

exec dbms_workload_repository.modify_snapshot_settings(interval=>60, retention=>90*24*60);


--修改 快照的频率和保留时间（单位用分钟）
exec dbms_workload_repository.modify_snapshot_settings(interval=>60, retention=>7*24*60);

用户也可以使用下面的命令手工采样（手工生成快照）：
    BEGIN
    DBMS_WORKLOAD_REPOSITORY.CREATE_SNAPSHOT ();
    END;

手工删除指定范围的快照
  begin
  dbms_workload_repository.drop_snapshot_range(low_snap_id => 3965, high_snap_id => 3966, dbid => 3437504306);
  end;

 --查看有多少个快照
 select count(1) from wrh$_active_session_history;
 select count(1) from dba_hist_active_sess_history;

通过查询视图DBA_HIST_SNAPSHOT，可以知道系统中产生了哪些快照。
select * from DBA_HIST_SNAPSHOT;


当SYSAUX表空间满后，AWR将自动覆盖掉旧的信息，并在警告日志中记录一条相关信息：
ORA-1688: unable to extend table SYS.WRH$_ACTIVE_SESSION_HISTORY partition WRH$_ACTIVE_3533490838_1522 by 128 in                 tablespace SYSAUX

select table_name from dba_tables where table_name like 'WRH$%';


  假定一个名称为 apply_interest 上午 2:00 到 4:00 之间运行，对应快照 ID 4150 到 4151。我们可以为这些快照定义
一个名称为 apply_interest_1 的基准线：

SQL> exec dbms_workload_repository.create_baseline(4150, 4151, 'apply_interest_1');

这一操作将快照从 4150 到 4151 编号，作为上面指定的基准线的一部分。查看现有的基准线：
SQL> select *from dba_hist_baseline;

 DBID      BASELINE_ID  BASELINE_NAME        START_SNAP_ID  START_SNAP_TIME                  END_SNAP_ID END_SNAP_TIME
---------- ----------- -------------------- ------------- --------------------------------  ----------- -------------------------------
3437504306     1        apply_interest_1     4150          07-3月 -11 03.00.47.627 上午       4151        07-3月 -11 04.00.12.567 上午

SQL> select *from wrm$_baseline;

DBID        BASELINE_ID BASELINE_NAME                   START_SNAP_ID  END_SNAP_ID
---------- ----------- ------------------------------  -------------  -----------
3437504306      1       apply_interest_1                 4150             4151


在一些调整步骤之后，我们可以创建另一个基准线 — 假设名称为 apply_interest_2（下午2点到4点），然后只为那些与这两条基准线相关的快照比较量度。
SQL> exec dbms_workload_repository.create_baseline(4162, 4163, 'apply_interest_2');

像这样把快照分隔在仅仅几个集合中有助于研究调整对于性能量度的影响。

4.2 删除基线
    分析之后使用 drop_baseline() 来删除基准线；快照将保留（也可级联删除）。此外，当清除例程开始删除旧的快照时，与基准线相关的快照不会
被清除，从而允许进行进一步的分析。
如果要删除一个基准线:
SQL> exec dbms_workload_repository.drop_baseline(baseline_name=>'apply_interest_1', cascade=>false);

SQL> select *from wrh$_active_session_history where snap_id in (4150,4151);

SNAP_ID  DBID     INSTANCE_NUMBER  SAMPLE_ID SAMPLE_TIME                  SESSION_ID ...
4150 3437504306    1             14900840   07-3月 -11 02.55.02.038 上午   162       ...
4150 3437504306    1             14900200   07-3月 -11 02.44.21.942 上午   165       ...
....
4151 3437504306    1             14901980   07-3月 -11 03.14.02.213 上午  165        ...
4151 3437504306    1             14901790   07-3月 -11 03.10.52.183 上午  165        ...
4151 3437504306    1             14901490   07-3月 -11 03.05.52.138 上午  167        ...

--级联删除（基线与快照一块删）
SQL> exec dbms_workload_repository.drop_baseline(baseline_name=>'apply_interest_2', cascade=>true);

SQL> select *from wrh$_active_session_history where snap_id in (4162,4163);
未选定行

AWR报告，只是产生不同的AWR报告，需要运行不同的脚本。

    --产生整个数据库的AWR报告，运行脚本awrrpt.sql。

   @$ORACLE_HOME/rdbms/admin/awrrpt.sql

    --产生某个实例的AWR报告，运行脚本awrrpti.sql。

   @$ORACLE_HOME/rdbms/admin/awrrpti.sql

    --产生某条SQL语句的AWR报告，运行脚本awrsqrpt.sql。

   @$ORACLE_HOME/rdbms/admin/awrsqrpt.sql

--注： $ORACLE_HOME代表Oracle的主目录。

awr
grant execute on DBMS_WORKLOAD_REPOSITORY to user;


安装statpack：

需要拥有sysdba权限的用户操作，首先创建用户表空间,这需要看我们收集的信息量的大小来设置，一般设置成500M既可


create tablespace perfstat '/home/oracle/perfstat.dbf' size 500m extent management local;  @$ORACLE_HOME/rdbms/admin/spcreate.sql

SPCPKG complete. Please check spcpkg.lis for any errors.需要出现上述语句才算成功，否则请查看.lis文件并执行，进行重建,如果在创建的时候出错，我们可以删除重新建立：

@$ORACLE_HOME/rdbms/admin/spdrop.sql，在重新建立即可
收集系统信息:execute statspack.snap
查看收集统计信息的情况：


SQL> select snap_id,snap_time,startup_time from stats$snapshot;
SNAP_ID SNAP_TIME STARTUP_T
---------- --------- ---------
1 14-AUG-11 14-AUG-11  2 14-AUG-11 14-AUG-11

自动统计系统的情况：@$ORACLE_HOME/rdbms/admin/spauto.sql
移除自动收集：

查看job号：


select job,job_user,priv_user,last_date,next_date,interval from user_jobs;
执行：


execute dbms_jobs.remove('job');
清除统计资料：

---修改job执行时间.
declare
x number;
begin
select job into x from dba_jobs
where schema_user='EPCISJOB' and what='job_package.job_309;' and rownum=1;
sys.dbms_job.change(job => x,
what => 'job_package.job_309;',
next_date => sysdate+10/1440,
interval => 'trunc(sysdate+1) + 14/24');
commit;
SYS.DBMS_OUTPUT.PUT_LINE('Job Number is: ' || to_char(x));
exception when others then
dbms_output.put_line('error');
rollback;
end;
/


scheduled_dbms_jobs.sql
set linesize 250
col log_user      for a10
col job            for 9999999  head 'Job'
col broken        for a1        head 'B'
col failures      for 99        head "fail"
col last_date      for a18      head 'Last|Date'
col this_date      for a18      head 'This|Date'
col next_date      for a18      head 'Next|Date'
col interval      for 9999.000 head 'Run|Interval'
col what          for a60

select j.log_user,
    j.job,
    j.broken,
    j.failures,
    j.last_date||':'||j.last_sec last_date,
    j.this_date||':'||j.this_sec this_date,
    j.next_date||':'||j.next_sec next_date,
    j.next_date - j.last_date interval,
    j.what
from (select dj.LOG_USER, dj.JOB, dj.BROKEN, dj.FAILURES,
            dj.LAST_DATE, dj.LAST_SEC, dj.THIS_DATE, dj.THIS_SEC,
            dj.NEXT_DATE, dj.NEXT_SEC, dj.INTERVAL, dj.WHAT
        from dba_jobs dj) j;



What Jobs are Actually Running

running_jobs.sql

set linesize 250
col sid            for 9999    head 'Session|ID'
col log_user        for a10
col job            for 9999999 head 'Job'
col broken          for a1      head 'B'
col failures        for 99      head "fail"
col last_date      for a18      head 'Last|Date'
col this_date      for a18      head 'This|Date'
col next_date      for a18      head 'Next|Date'
col interval        for 9999.000 head 'Run|Interval'
col what            for a60
select j.sid,
        j.log_user,
        j.job,
        j.broken,
        j.failures,
        j.last_date||':'||j.last_sec last_date,
        j.this_date||':'||j.this_sec this_date,
        j.next_date||':'||j.next_sec next_date,
        j.next_date - j.last_date interval,
        j.what
from (select djr.SID,
                  dj.LOG_USER, dj.JOB, dj.BROKEN, dj.FAILURES,
                  dj.LAST_DATE, dj.LAST_SEC, dj.THIS_DATE, dj.THIS_SEC,
                  dj.NEXT_DATE, dj.NEXT_SEC, dj.INTERVAL, dj.WHAT
          from dba_jobs dj, dba_jobs_running djr
        where dj.job = djr.job ) j;



What Sessions are Running the Jobs
session_jobs.sql

set linesize 250
col sid          for 9999    head 'Session|ID'
col spid                      head 'O/S|Process|ID'
col serial#      for 9999999 head 'Session|Serial#'
col log_user      for a10
col job          for 9999999 head 'Job'
col broken        for a1      head 'B'
col failures      for 99      head "fail"
col last_date    for a18      head 'Last|Date'
col this_date    for a18      head 'This|Date'
col next_date    for a18      head 'Next|Date'
col interval      for 9999.000 head 'Run|Interval'
col what          for a60
select j.sid,
s.spid,
s.serial#,
      j.log_user,
      j.job,
      j.broken,
      j.failures,
      j.last_date||':'||j.last_sec last_date,
      j.this_date||':'||j.this_sec this_date,
      j.next_date||':'||j.next_sec next_date,
      j.next_date - j.last_date interval,
      j.what
from (select djr.SID,
            dj.LOG_USER, dj.JOB, dj.BROKEN, dj.FAILURES,
            dj.LAST_DATE, dj.LAST_SEC, dj.THIS_DATE, dj.THIS_SEC,
            dj.NEXT_DATE, dj.NEXT_SEC, dj.INTERVAL, dj.WHAT
        from dba_jobs dj, dba_jobs_running djr
      where dj.job = djr.job ) j,
    (select p.spid, s.sid, s.serial#
          from v$process p, v$session s
        where p.addr = s.paddr ) s
where j.sid = s.sid;

方法一：

Killing the Oracle DBMS_JOB

Take control of Oracle's queue with a step by step approach to getting rid of those pesky DBMS_JOBs.
Let's face it, Oracle's job scheduling facility is a wonderful tool for scheduling Oracle related jobs without having to maintain a cron job on Unix or an AT job in windows. It is also very robust and reliable. It is that very reliability and robustness that gives many of us our problems.
If you have any form of jobs running on your system, you will at one time or another come across the issue of a run-away job that just doesn't seem to want to end. Or maybe you will try and shutdown the database only to find out that it is waiting to complete a job. I would like to offer some help in the management of those job queues when they just don't seem to want to end or go away.
A while back I needed to find information on how to clear the job queue for jobs running with no apparent end in sight. Some had hung, while others just were taking a bad access path to data. I needed to bring down these jobs, do a bit of tuning and then restart the jobs. Well, to my amazement, there wasn't very much information out on the web that gave good insight into this process. Basically the method suggested was to first break the job and then issue an ALTER SYTEM KILL SESSION command. This method does not always work and unfortunately--never on my system, for the jobs I had. I then called Oracle support and basically got the same answer as I found out on the web. They did give me one added piece of information. They said, if the ALTER SYSTEM KILL SESSION didn't work, I was supposed to bounce my database in order to bring down the job queue processes. First of all, this wasn't an option and when I did get the opportunity to bounce the database box, many of the jobs seemed to come right back as strong as ever.
Before writing this article I did another quick search on the topic of killing dbms_jobs and to my amazement there still wasn't much good information out there. This is why I want to share my method, so that you won't be stuck up against the wall with this problem and nowhere to turn, as I was.
Viewing Scheduled dbms_jobs
When looking at what jobs have been scheduled, there is really only one view that you need to go to. The dba_jobs view contains all of the information you need, to see what has been scheduled, when they were last run, and if they are currently running. Use the following simple script to take a look. Bear with me on the sub-select, I will build on this query as we go on in the presentation.

scheduled_dbms_jobs.sql
set linesize 250
col log_user      for a10
col job            for 9999999  head 'Job'
col broken        for a1        head 'B'
col failures      for 99        head "fail"
col last_date      for a18      head 'Last|Date'
col this_date      for a18      head 'This|Date'
col next_date      for a18      head 'Next|Date'
col interval      for 9999.000 head 'Run|Interval'
col what          for a60

select j.log_user,
    j.job,
    j.broken,
    j.failures,
    j.last_date||':'||j.last_sec last_date,
    j.this_date||':'||j.this_sec this_date,
    j.next_date||':'||j.next_sec next_date,
    j.next_date - j.last_date interval,
    j.what
from (select dj.LOG_USER, dj.JOB, dj.BROKEN, dj.FAILURES,
            dj.LAST_DATE, dj.LAST_SEC, dj.THIS_DATE, dj.THIS_SEC,
            dj.NEXT_DATE, dj.NEXT_SEC, dj.INTERVAL, dj.WHAT
        from dba_jobs dj) j;

What Jobs are Actually Running

A simple join to the dba_jobs_running view will give us a good handle on the scheduled jobs that are actually running at this time. This is done by a simple join through the job number. The new column of interest returned here is the sid which is the identifier of the process that is currently executing the job.

running_jobs.sql

set linesize 250
col sid            for 9999    head 'Session|ID'
col log_user        for a10
col job            for 9999999 head 'Job'
col broken          for a1      head 'B'
col failures        for 99      head "fail"
col last_date      for a18      head 'Last|Date'
col this_date      for a18      head 'This|Date'
col next_date      for a18      head 'Next|Date'
col interval        for 9999.000 head 'Run|Interval'
col what            for a60
select j.sid,
        j.log_user,
        j.job,
        j.broken,
        j.failures,
        j.last_date||':'||j.last_sec last_date,
        j.this_date||':'||j.this_sec this_date,
        j.next_date||':'||j.next_sec next_date,
        j.next_date - j.last_date interval,
        j.what
from (select djr.SID,
                  dj.LOG_USER, dj.JOB, dj.BROKEN, dj.FAILURES,
                  dj.LAST_DATE, dj.LAST_SEC, dj.THIS_DATE, dj.THIS_SEC,
                  dj.NEXT_DATE, dj.NEXT_SEC, dj.INTERVAL, dj.WHAT
          from dba_jobs dj, dba_jobs_running djr
        where dj.job = djr.job ) j;

What Sessions are Running the Jobs

Now that we have determined which jobs are currently running, we need to find which Oracle session and operating system process is accessing them. This is done through first joining v$process to v$session by way of paddr and addr which is the address of the processs that owns the sessions, and then joining the results back to the jobs running through the sid value. The new columns returned in our query are spid which is the operating system process identifier and serial# which is the session serial number.

session_jobs.sql

set linesize 250
col sid          for 9999    head 'Session|ID'
col spid                      head 'O/S|Process|ID'
col serial#      for 9999999 head 'Session|Serial#'
col log_user      for a10
col job          for 9999999 head 'Job'
col broken        for a1      head 'B'
col failures      for 99      head "fail"
col last_date    for a18      head 'Last|Date'
col this_date    for a18      head 'This|Date'
col next_date    for a18      head 'Next|Date'
col interval      for 9999.000 head 'Run|Interval'
col what          for a60
select j.sid,
s.spid,
s.serial#,
      j.log_user,
      j.job,
      j.broken,
      j.failures,
      j.last_date||':'||j.last_sec last_date,
      j.this_date||':'||j.this_sec this_date,
      j.next_date||':'||j.next_sec next_date,
      j.next_date - j.last_date interval,
      j.what
from (select djr.SID,
            dj.LOG_USER, dj.JOB, dj.BROKEN, dj.FAILURES,
            dj.LAST_DATE, dj.LAST_SEC, dj.THIS_DATE, dj.THIS_SEC,
            dj.NEXT_DATE, dj.NEXT_SEC, dj.INTERVAL, dj.WHAT
        from dba_jobs dj, dba_jobs_running djr
      where dj.job = djr.job ) j,
    (select p.spid, s.sid, s.serial#
          from v$process p, v$session s
        where p.addr = s.paddr ) s
where j.sid = s.sid;

Now that we have a good handle on how we can look at the jobs and the key columns involved, let's go through the steps needed to bring down a job. The following is a 5 to 11 step process that should solve all of your problems.


Bringing Down a DBMS_JOB

1. Find the Job You Want to Bring Down

In order to do anything you first need to find the job that is giving you a headache. Go ahead and run the running_jobs.sql. This will give you the prime information, job, sid, serial#, and spid, for the following actions in bringing down the job.

2. Mark the DBMS_JOB as Broken

Use the following command for the job that you have to deal with.

SQL> EXEC DBMS_JOB.BROKEN(job#,TRUE);

All this command does is mark the job so that if we get it to stop, it won't start again. Let's make one thing perfectly clear, after executing this command the job is still running.

As a side note, if you are trying to shut down a database with jobs that run throughout the day, they may hinder your attempts to bring down the database cleanly. This is a wonderful command to make sure no jobs are executing during the shutdown process. Just be aware that you will need to mark the jobs as unbroken when the database comes back up, more on that later.

3. Kill the Oracle Session

Since the job is still running and it isn't going to end soon, you will need to kill the Oracle session that is executing the job. Use the following command for to kill the job.

ALTER SYSTEM KILL SESSION 'sid,serial#';

4. Kill the O/S Process

More often than not the previous step will still leave the job attached to the database and still running. When this happens you will need to go out to the operating system level and get rid of the process that has spawned from the running job. In order to do this you must login to the database box and issue the following command, depending on the type of operating system you have.

For Windows, at the DOS Prompt: orakill sid spid

For UNIX at the command line> kill '9 spid

The orakill is an Oracle command, while kill is a Unix command.

5. Check if the Job is Still Running

Re-run the session_jobs.sql script to see if you have gotten rid of the job. If you have there is no reason to go further. Usually steps 1 through 4 will be sufficient to get rid of a job but when the job is running wild you will have to continue with steps 6 through 11 which describes a process for bouncing the job queue process.

6. Determine the Current Number of Job Queue Processes

SQL> col value for a10
SQL> select name,value from v$parameter where name = 'job_queue_processes';

7. Alter the Job Queue to Zero

SQL> ALTER SYSTEM SET job_queue_processes = 0;

This will bring down the entire job queue processes.

8. Validate that No Processes are Using the Job Queue

Re-run the session_jobs.sql script to see if any jobs are still running. Since we have given a hard stop to the job queue and issued the kill commands, you can now wait until no more jobs are running. After all the jobs have quit running, you can do whatever maintenance or tuning you need to do before proceeding.

9. Mark the DBMS_JOB as Not Broken
You can now reset the broken job to not broken so they can run again. Just issue the command.

SQL>EXEC DBMS_JOB.BROKEN(job#,FALSE):

10. Alter the Job Queue to Original Value
Set the job queue to its' original value so that the jobs can run again.

ALTER SYSTEM SET job_queue_processes = original_value;

11. Validate that DBMS_JOB Is Running
To make sure everything is back to normal, re-run the above scripts to validate that jobs are scheduled, not broken, and are executing with the next and last dates columns changing.

Oracle have given us a great tool for scheduling activities within the database. As with many things inside the database, not everything goes as planned, nor are we given adequate tools to fix some of the problems we encounter. With the eleven steps outlined here, hopefully you will have increased your arsenal to handle those run away jobs that have given the best of us a few tense moments.
--------------------------------------------------------------------------------------------------------------------------
注意：第四步 删除操作系统层次的进程或线程操作，Oracle在Linux/Unix中后台进程是以进程方式运作，在Windows系列操作系统中是以线程方式运作。
对于Windows，启动命令提示符:
orakill sid spid
其中sid是数据库实例的名称，而不是前面脚本中查出来的sid。
可以通过一下命令来得到：
select name from v$database;
select instance_name from v$instance;



方法二：

1、查看所有job;
select * from dba_jobs;
2、查看正在运行的job;
select * from dba_jobs_running;
3、根据sid查出对应的session;
select SID,SERIAL# from V$Session where SID='&SID';
4、kill对应的session;
alter system kill session '&SID,&SERIAL';
5、将job置为broken;
exec dbms_job.broken('&JOB',true);
6、sysdba用户权限删除job;
delete from dba_jobs where JOB='&JOB';





@$ORACLE_HOME/rdbms/admin/sptrunc.sql;

statpack的收集类型：

level级别：控制收集数据的类型。

threshold门限：设置收集的数据的乏值，默认的收集类型是5，我们可以更改她的收集类型；

execute statpack.snap(i_snap_level=>10,i_modify_parameter=>'true');

只修改本次收集方式：execute statpack.snap(i_snap_level=>10);

threshold门限：快照门限只应用于stat$sql_summary表中获取sql语句。

生成系统报告：@$ORACLE_HOME/rdbms/admin/spreport.sql
statspack






=======================================================================

solaris查看内存使用情况命令

1>ps -efo pmem,uid,pid,ppid,pcpu,comm | sort -r
用PS命令的-o选项来实现，这些选项有：user ruser group rgroup uid ruid gid rgid pid ppid pgid sid taskid ctid pri opri pcpu pmem vsz rss osz nice class time etime stime zone zoneid f s c lwp nlwp psr tty addr wchan fname comm args projid project pset
具体的意思可以man ps来查看。

查看solaris内存使用情况，按占用内存大小排序
ps -efo pmem,uid,pid,ppid,pcpu,comm | sort -r

pmem   The ratio of the process's resident  set size  to  the  physical  memory  on
       the machine, expressed as a percentage.

如果你不知道这个命令都带有什么选项， ps help即可。

2> # prtconf -vp | grep Mem
prtconf 命令在/usr/sbin下，这个命令可以得到总内存。其实也不用这么麻烦，top命令看到的信息更多。

3> echo ::memstat | mdb -k
例如：
# echo ::memstat | mdb -k
Page Summary                Pages                MB  %Tot
------------     ----------------  ----------------  ----
Kernel                      75297               588    7%
Anon                       888409              6940   86%
Exec and libs               28196               220    3%
Page cache                  15958               124    2%
Free (cachelist)            17993               140    2%
Free (freelist)              3162                24    0%
Total                     1029015              8039
Physical                  1026087              8016

具体解释：
Kernel: Kernel pages
Anon: anonymous pages (such as stack, heap, shared mem etc)
Exec and libs: executables and libraries
Page cache:  file cache
Free (cachelist) + Free (freelist) = freemem(vmstat 中的free值)
这个命令运行起来时间比较长。

4>prstat -a
 *PID      ：进程的进程 ID。
 *USERNAME ：真实用户（登录）名称或真实用户 ID。
 *SIZE     ：进程的总虚拟内存大小，以 K、M 或 G 为单位。
 *RSS      ：进程的驻留集大小 (RSS)，以 K、M 或 G 为单位。(RSS是进程驻留内存的大小，SIZE是进
             程总共的大小。一般SIZE要大于RSS，至于SIZE大于RSS的部分就放到了SWAP区里了)
 *STATE    ：进程的状态 (cpuN/sleep/wait/run/zombie/stop)。
 *PRI      ：进程的优先级。数字更大表示优先级更高。
 *NICE     ：优先级计算中使用的 nice 值。只有特定调度类中的进程才有 nice 值。
 *TIME     ：进程的累计执行时间。
 *CPU      ：进程使用的当前 CPU 时间的百分比。如果在非全局域中执行并且池设备是活动的，百分比将
             zone绑定的池所使用的处理器集合中处理器的百分比。
 *PROCESS  ：进程的名称（执行文件的名称）。
 *NLWP     ：进程中 lwps 的数量

中间还有个参数：系统平均负载(Load average)在Linux系统中，uptime、w、top等命令都会有系统平均负载load average的输出.
命令输出的最后内容表示在过去的1、5、15分钟内运行队列中的平均进程数量。 只要每个CPU的当前活动进程数不大于3那么系统的性能就是良好的，如果每个CPU的任务数大于5，那么就表示这台机器的性能有严重问题。load average/cpu_num< 3 就是性能不错的。
顺便提一下，多个CPU状态查看命令：mpstat

5>vmstat 3 4
看vmstat的输出时，从第2行开始看，如果sr列数值比较大，就表明内存紧张。


6>top

7>sar -r 5 5
sar -r标示的freemem显示的是空闲的页面数，而不是用k来衡量的，它表示的数值与vmstat差不多。
它们显示的free memory都还包括高速文件缓存占用的的内存，并不是真正没有使用的内存。

比如:vmstat显示的内存有152528k,sar -r显示的是18933个pages，一个page大约8k，用18933乘以8，还是差不多150M.但实际上呢，真正意义上空闲的内存只有6个M（用专门的memtool测量的），而不是152M。




1.top

使用权限：所有使用者

使用方式：top [-] [d delay] [q] [c] [S] [s] [i] [n] [b]

说明：即时显示process的动态

d :改变显示的更新速度，或是在交谈式指令列( interactive command)按s

q :没有任何延迟的显示速度，如果使用者是有superuser的权限，则top将会以最高的优先序执行

c :切换显示模式，共有两种模式，一是只显示执行档的名称，另一种是显示完整的路径与名称S :累积模式，会将己完成或消失的子行程( dead child process )的CPU time累积起来

s :安全模式，将交谈式指令取消,避免潜在的危机

i :不显示任何闲置(idle)或无用(zombie)的行程

n :更新的次数，完成后将会退出top

b :批次档模式，搭配"n"参数一起使用，可以用来将top的结果输出到档案内



范例：

显示更新十次后退出;

top -n 10



使用者将不能利用交谈式指令来对行程下命令:

top -s



将更新显示二次的结果输入到名称为top.log的档案里:

top -n 2 -b < top.log

另附一个命令简介linux traceroutewindows tracert两个命令相当，跟踪网络路由



2.vmstat

正如我们之前讨论的任何系统的性能比较都是基于基线的，并且监控CPU的性能就是以上3点，运行队列、CPU使用率和上下文切换。以下是一些对于CPU很普遍的性能要求：

1.对于每一个CPU来说运行队列不要超过3，例如，如果是双核CPU就不要超过6；

2.如果CPU在满负荷运行，应该符合下列分布，

a) User Time：65%～70%

b) System Time：30%～35%

c) Idle：0%～5%

3. mpstat

对于上下文切换要结合CPU使用率来看，如果CPU使用满足上述分布，大量的上下文切换也是可以接受的。

常用的监视工具有：vmstat, top,dstat和mpstat.

# vmstat 1

procs -----------memory---------- ---swap-- -----io---- --system-- ----cpu----

r b swpd free buff cache si so bi bo in cs us sy id wa

0 0 104300 16800 95328 72200 0 0 5 26 7 14 4 1 95 0

0 0 104300 16800 95328 72200 0 0 0 24 1021 64 1 1 98 0

0 0 104300 16800 95328 72200 0 0 0 0 1009 59 1 1 98 0

r表示运行队列的大小，

b表示由于IO等待而block的线程数量，

in表示中断的数量，

cs表示上下文切换的数量，

us表示用户CPU时间，

sys表示系统CPU时间，

wa表示由于IO等待而是CPU处于idle状态的时间，

id表示CPU处于idle状态的总时间。

dstat可以给出每一个设备产生的中断数：

# dstat -cip 1

----total-cpu-usage---- ----interrupts--- ---procs---

usr sys idl wai hiq siq| 15 169 185 |run blk new

6 1 91 2 0 0| 12 0 13  | 0 0 0

1 0 99 0 0 0| 0    0  6 | 0 0 0

0 0 100 0 0 0| 18 0  2 | 0 0 0

0 0 100 0 0 0| 0    0  3 | 0 0 0

我们可以看到这里有3个设备号15，169和185.设备名和设备号的关系我们可以参考文件/proc/interrupts,这里185代表网卡eth1.

# cat /proc/interrupts

CPU0

0: 1277238713 IO-APIC-edge timer

6: 5 IO-APIC-edge floppy

7: 0 IO-APIC-edge parport0

8: 1 IO-APIC-edge rtc

9: 1 IO-APIC-level acpi

14: 6011913 IO-APIC-edge ide0

15: 15761438 IO-APIC-edge ide1

169: 26 IO-APIC-level Intel 82801BA-ICH2

185: 16785489 IO-APIC-level eth1

193: 0 IO-APIC-level uhci_hcd:usb1

mpstat可以显示每个CPU的运行状况，比如系统有4个CPU。我们可以看到：

# mpstat –P ALL 1

Linux 2.4.21-20.ELsmp (localhost.localdomain) 05/23/2006

05:17:31 PM CPU %user %nice %system %idle intr/s

05:17:32 PM all 0.00 0.00 3.19 96.53 13.27

05:17:32 PM 0 0.00 0.00 0.00 100.00 0.00

05:17:32 PM 1 1.12 0.00 12.73 86.15 13.27

05:17:32 PM 2 0.00 0.00 0.00 100.00 0.00

05:17:32 PM 3 0.00 0.00 0.00 100.00 0.00

总结的说，CPU性能监控包含以下方面：

检查系统的运行队列，确保每一个CPU的运行队列不大于3.

确保CPU使用分布满足70/30原则（用户70%，系统30%）。

如果系统时间过长，可能是因为频繁的调度和改变优先级。

CPU Bound进程总是会被惩罚（降低优先级）而IO Bound进程总会被奖励（提高优先级）。



4.prstat命令

要显示系统上当前运行的进程和项目的各种统计信息，请使用带有-J选项的prstat命令：



%prstat -J

        PID USERNAME SIZE  RSS STATE PRI NICE     TIME CPU PROCESS/NLWP

 21634 jtd     5512K 4848K cpu0   44   0  0:00.00 0.3% prstat/1

  324 root      29M  75M sleep  59   0  0:08.27 0.2% Xsun/1

 15497 jtd       48M  41M sleep  49   0  0:08.26 0.1% adeptedit/1

  328 root    2856K 2600K sleep  58   0  0:00.00 0.0% mibiisa/11

 1979 jtd     1568K 1352K sleep  49   0  0:00.00 0.0% csh/1

 1977 jtd     7256K 5512K sleep  49   0  0:00.00 0.0% dtterm/1

  192 root    3680K 2856K sleep  58   0  0:00.36 0.0% automountd/5

 1845 jtd       24M  22M sleep  49   0  0:00.29 0.0% dtmail/11

 1009 jtd     9864K 8384K sleep  49   0  0:00.59 0.0% dtwm/8

  114 root    1640K 704K sleep  58   0  0:01.16 0.0% in.routed/1

  180 daemon  2704K 1944K sleep  58   0  0:00.00 0.0% statd/4

  145 root    2120K 1520K sleep  58   0  0:00.00 0.0% ypbind/1

  181 root    1864K 1336K sleep  51   0  0:00.00 0.0% lockd/1

  173 root    2584K 2136K sleep  58   0  0:00.00 0.0% inetd/1

  135 root    2960K 1424K sleep   0   0  0:00.00 0.0% keyserv/4

PROJID   NPROC SIZE  RSS MEMORY     TIME CPU PROJECT

   10      52 400M 271M   68%  0:11.45 0.4% booksite

    0      35 113M 129M   32%  0:10.46 0.2% system



Total: 87 processes, 205 lwps, load averages: 0.05, 0.02, 0.02


要显示系统上当前运行的进程和任务的各种统计信息，请使用带有-T选项的prstat命令：



%prstat -T

  PID USERNAME SIZE  RSS STATE PRI NICE     TIME CPU PROCESS/NLWP

 23023 root      26M  20M sleep  59   0  0:03:18 0.6% Xsun/1

 23476 jtd       51M  45M sleep  49   0  0:04:31 0.5% adeptedit/1

 23432 jtd     6928K 5064K sleep  59   0  0:00:00 0.1% dtterm/1

 28959 jtd       26M  18M sleep  49   0  0:00:18 0.0% .netscape.bin/1

 23116 jtd     9232K 8104K sleep  59   0  0:00:27 0.0% dtwm/5

 29010 jtd     5144K 4664K cpu0   59   0  0:00:00 0.0% prstat/1

  200 root    3096K 1024K sleep  59   0  0:00:00 0.0% lpsched/1

  161 root    2120K 1600K sleep  59   0  0:00:00 0.0% lockd/2

  170 root    5888K 4248K sleep  59   0  0:03:10 0.0% automountd/3

  132 root    2120K 1408K sleep  59   0  0:00:00 0.0% ypbind/1

  162 daemon  2504K 1936K sleep  59   0  0:00:00 0.0% statd/2

  146 root    2560K 2008K sleep  59   0  0:00:00 0.0% inetd/1

  122 root    2336K 1264K sleep  59   0  0:00:00 0.0% keyserv/2

  119 root    2336K 1496K sleep  59   0  0:00:02 0.0% rpcbind/1

  104 root    1664K 672K sleep  59   0  0:00:03 0.0% in.rdisc/1

TASKID   NPROC SIZE  RSS MEMORY     TIME CPU PROJECT

  222      30 229M 161M   44%  0:05:54 0.6% group.staff

  223       1  26M  20M  5.3%  0:03:18 0.6% group.staff

   12       1  61M  33M  8.9%  0:00:31 0.0% group.staff

    1      33  85M  53M   14%  0:03:33 0.0% system



Total: 65 processes, 154 lwps, load averages: 0.04, 0.05, 0.06



--------------------------------------------------------------------------------

注–

-J和-T选项不能一起使用。


purge recyclebin;

有几种方法可以手动控制回收站。如果在删除名为 TEST 的特定表之后需要从回收站中清除它，可以执行
 
PURGE TABLE TEST;或者使用其回收站中的名称：
purge table "BIN$04LhcpndanfgMAAAAAANPw==$0";此命令将从回收站中删除表 TEST 及所有相关对象，如索引、约束等，从而节省了空间。但是，如果要从回收站中永久删除索引，则可以使用以下命令来完成工作：
purge index in_test1_01;此命令将仅仅删除索引，而将表的拷贝留在回收站中
在这种情况下，Oracle 自动清除该表空间中属于该用户的对象。
此外，有几种方法可以手动控制回收站。如果在删除名为 TEST 的特定表之后需要从回收站中清除它，可以执行
 
PURGE TABLE TEST;或者使用其回收站中的名称：
PURGE TABLE "BIN$04LhcpndanfgMAAAAAANPw==$0";此命令将从回收站中删除表 TEST 及所有相关对象，如索引、约束等，从而节省了空间。但是，如果要从回收站中永久删除索引，则可以使用以下命令来完成工作：
purge index in_test1_01;此命令将仅仅删除索引，而将表的拷贝留在回收站中。
 有时在更高级别上进行清除可能会有用。例如，您可能希望清除表空间 USERS 的回收站中的所有对象。可以执行：
 
PURGE TABLESPACE USERS;您也许希望只为该表空间中特定用户清空回收站。在数据仓库类型的环境中，用户创建和删除许多临时表，此时这种方法可能会有用。您可以更改上述命令，限定只清除特定的用户：
PURGE TABLESPACE USERS USER SCOTT;诸如 SCOTT 等用户可以使用以下命令来清空自己的回收站
PURGE RECYCLEBIN;DBA 可以使用以下命令清除任何表空间中的所有对象
PURGE DBA_RECYCLEBIN;PURGE DBA_RECYCLEBIN;可以看到，可以通过多种不同方法来管理回收站，以满足特定的需要。

数据库运维常用脚本

目录
 
一、DB 监控脚本
1、监控TEMP使用情况
	关于temp表空间，新建库标准：初始值为数据文件总和的2%，若该值低于2G，则初始设置为2G；最大值不能超过数据文件总和的10%和500G的较小者；如果出现temp表空间不足报警（"ORA-1652: unable to extend temp segment by 64 in tablespace TEMP"）时，可采用下面sql检查temp分配的大小，以及当前temp消耗，对于11g的库也可查询历史时段temp消耗情况。
 	查询temp表空间使用率

 
 	查询temp空间与DB空间分配比例
 	查询temp空间使用较多的session


 
注：当数据库报temp表空间不足时，消耗temp过高的sql因temp资源分配不足而终止，而上述sql仅用于查数据库当前temp消耗情况；对于11g版本的数据库可以通过查
询ASH视图获取temp消耗过高的sql。

 
2、UNDO监控管理
（1）监控undo使用情况
	数据库undo规范：未开自动扩展，占用undo过多的session会有报警提示


（2）kill占用undo的session
对于kill session操作需注意以下几点：
 	Undo使用小于250M需值班组长确认后kill；
 	Undo使用大于250M需升级到主管DBA确认。



（3）查询回滚进度




3、监控redo的使用情况
	数据库最新规范：redo需至少6组redo，大小介于[200,1000]M之间，大批量事物会引发redo资源使用紧张现象；standby redo组数比online redo多一组，大小一致。
 	查询primary端redo使用情况


 	查询redo产生较多的session


 	查询standby端redo使用情况


 	Redo操作
 	常用命令
alter system switch logfile;
alter system archive log current;
alter system checkpoint;

 	add log member to group
alter database add logfile member
'/paic/hq/sales/data/oradata/sales/redo07.log' to group 1,'/paic/hq/sales/data/oradata/sales/redo08.log' to group 2
to group 3;

 	add log group
ALTER DATABASE ADD LOGFILE THREAD 1 GROUP 4 ('/paic/hq/sales/data/oradata/sales/redo08.log', '/paic/hq/sales/data/oradata/sales/redo09.log')
size 500M
-- <reuse> 文件存在的话采用reuse ;

alter database add <standby> logfile thread 1 group 7 ('/paic/mis/bkcst/data/oradata/bkcst/dgredo07.log' size 500M);
--for 11g asm
alter database add <standby> logfile thread 1 group <group#+1> size <bytes>M;

 	rename logfile
alter database rename file
'/paic/hq/sales/data/oradata/sales/redo07.log'  to   '/paic/hq/sales/data/oradata/sales/redo14.log';

 	delete logfile
alter database drop logfile member '/paic/hq/sales/data/oradata/sales/redo07.log';

 	delete log group
alter database drop logfile '/paic/hq/sales/data/oradata/sales/redo08.log';
or
alter database drop logfile group 4;

 	clear logfile
alter database clear logfile '/paic/hq/sales/data/oradata/sales/redo08.log';

4、监控表空间使用情况
	表空间的使用率监控：表空间使用率超过85%则报警，此时需要添加一定数量的数据文件以满足数据量的增长需求。


5、监控产生大量物理读的session


6、FS卷监控处理
	对于FS卷报警处理，关闭该卷上的datafile和tempfile的自动扩展，同时新建相应大小的datafile和tempfile




7、监控active的长连接
	对于不同数据库长连接的定义不同，比如银行库active的session的长连接定义的连接时长很短，而epcis数据库有时需要跑报表则长连接定义的连接时长则很长


8、内存监控
	在日常工作中，数据库内存相关报错（如 ora-4031）属于常见问题，以下可帮助诊断此类问题。

 	硬解析
数据库硬解析过多会导致占用大量的library cache，导致数据库内存不足。


 	查询某个内存区的使用情况



 	Shared pool子池







9、存储io性能监控





二、数据库问题诊断相关
1、等待事件

2、锁
	数据库锁分为对象锁和内存锁（闩latch），如果数据库存在大量锁等待事件，将影响到数据库性能。
 	查询锁等待holder-waiter


 	查询锁等待源头


 	查询对象锁


 	library cache pin等待事件
在后台sys用户下执行：
select s.sid || ',' || s.serial# sid_serial,
       kglpnmod "mode held",
       kglpnreq "request"
  from sys.x$kglpn p, v$session s
 where p.kglpnuse = s.saddr
   and kglpnhdl = (select p1raw
                     from v$session_wait
                    where sid = &SID_IN_LIBRARY_CACHE_PIN);

或者：
select sid Holder ,KGLPNUSE Sesion , KGLPNMOD Held, KGLPNREQ Req
 from x$kglpn , v$session
 where KGLPNHDL in (select p1raw from v$session_wait
 where wait_time=0 and event like 'library%')
 and KGLPNMOD <> 0
 and v$session.saddr=x$kglpn.kglpnuse ;

或者：
 select sql_text from v$sqlarea
  where (v$sqlarea.address,v$sqlarea.hash_value)
      in (select sql_address,sql_hash_value from v$session where sid in (
 select sid
 from x$kglpn , v$session
 where KGLPNHDL in (select p1raw from v$session_wait
 where wait_time=0 and event like 'library%')
 and KGLPNMOD <> 0
 and v$session.saddr=x$kglpn.kglpnuse );
注：
查到held>0 的sid，如果local=no ，请沟通是否可以kill掉这个进程

Wait_time值也有四种含义：
值>0：最后一次等待时间(单位：10ms)，当前未在等待状态。
值=0：session正在等待当前的事件。
值=-1：最后一次等待时间小于1个统计单位，当前未在等待状态。
值=-2：时间统计状态未置为可用，当前未在等待状态。

KGLLKMOD NUMBER ---持有锁的模式(0为no lock/pin held﹐1为null,2为share﹐3为exclusive)
KGLLKREQ NUMBER ---请求锁的模式(0为no lock/pin held﹐1为null,2为share﹐3为exclusive)

 	Cache buffers chains
查询等待事件的类型是否是latch free：
select sw.sid || ',' || s.serial# sids,
       s.username,
       sw.event,
       sw.P1,
       sw.p2,
       sw.p3,
       sw.p1raw,
       sw.wait_time "WAIT",
       sw.state,
       sw.seconds_in_wait sec,
       s.status,
       to_char(s.logon_time, 'dd/hh24:mi:ss') log_time
  from v$session s, v$session_wait sw
 where s.username is not null
   and sw.sid = s.sid
   and sw.event not like '%SQL*Net%'
   and sw.event not like 'PX Deq%'
 order by sw.event;

如果是latch free，则其中p2字段的值表示latch number，据此可以查出是什么原因引起的latch free：
select * from v$latchname where latch#=&P2;

如果等待的latch是cache buffers chains，则需要根据p1raw查出被争用的hot block和segment名称：
--在后台sys用户下执行，查找热块
select /*+ RULE */
       e.owner || '.' || e.segment_name segment_name,
       e.extent_id extent#,
       x.dbablk - e.block_id + 1 block#,
       x.tch,
       l.child#
  from sys.v$latch_children l, sys.x$bh x, sys.dba_extents e
 where x.hladdr = '&P1RAW'
   and e.file_id = x.file#
   and x.hladdr = l.addr
   and x.dbablk between e.block_id and e.block_id + e.blocks - 1
 order by x.tch desc;

column segment_name format a30
select distinct e.owner,e.segment_name,e.segment_type
from dba_extents e,
    (select * from (select addr,ts#,file#,dbarfil,dbablk,tch from x$bh order by tch desc )where rownum<11) b
    where e.relative_fno=b.dbarfil
    and e.block_id<=b.dbablk
    and e.block_id+e.blocks>b.dbablk;

--查找产生热块的sql：
column segment_name format a35
select /*+ rule */ hash_value,sql_text from v$sqltext
where (hash_value,address ) in (
   select a.hash_value,a.address from v$sqltext a ,
   (select distinct e.owner,e.segment_name,e.segment_type
    from dba_extents e,
    (select * from (select addr,ts#,file#,dbarfil,dbablk,tch from x$bh order by tch desc )where rownum<11) b
    where e.relative_fno=b.dbarfil
    and e.block_id<=b.dbablk
    and e.block_id+e.blocks>b.dbablk ) b
    where a.sql_text like '%'||b.segment_name||'%'
    and b.segment_type='TABLE')
    order by hash_value,address,piece;

找到latch holder所在session的sid和serial#，考虑是否可以kill掉，缓解数据库的压力：
--这个latchhold变化得非常快，每刷新一次都会变化
select a.username, a.sid, a.serial#, a.status, b.pid, b.laddr, b.name
  from v$session a, v$latchholder b
 where a.sid = b.sid;

 	Db file sequential read
--db file sequential read等待时间是由于执行对索引，回滚（undo）段，和表（当借助rowid来访问），控制文件和数据文件头的单块读操作SQL语句（用户和递归）引发。
--当等待事件为db file sequential read时，P1对应file_id，P2对应&block_id
--通过下面这个语句可以查询到正在等待什么对象


 	Db file scattered read
--当等待事件是db file scattered read时，用以下语句检查执行计划：
   select hash_value,child_number,
   lpad(' ',2*depth)||operation||' '||options||decode(id,0,substr(optimizer,1,6)||' Cost='||to_char(cost)) operation,
   object_name object,cost,cardinality,round(bytes/1024) kbytes
   from v$sql_plan
   where hash_value in
   (select a.sql_hash_value from v$session a,v$session_wait b
   where a.sid=b.sid
   and b.event='db file scattered read')
   order by hash_value,child_number,id;

3、连接风暴
 	查询数据库连接情况

 	统计session连接数

 	监听日志分析perl脚本及使用说明


4、Trace
	通过以下两种方式获取tracefile的名字。
 	Oradebug
oradebug setmypid/ oradebug setospid 1525
oradebug tracefile_name

 	map_session_to_trace
SELECT s.sid, s.server,
       CASE
         WHEN s.server IN ('DEDICATED', 'SHARED') THEN
          decode(substr(version, 1, 2),
                 '11',
                 i.instance_name,
                 lower(i.instance_name)) || '_' ||
          nvl(lower(pp.server_name), nvl(lower(ss.name), 'ora')) || '_' ||
          p.spid
         ELSE
          NULL
       END || CASE
         WHEN p.traceid IS NOT NULL THEN
          '_' || p.traceid
         ELSE
          ''
       END || '.trc' AS trace_file_name
  FROM v$instance      i,
       v$session       s,
       v$process       p,
       v$px_process    pp,
       v$shared_server ss
 WHERE s.paddr = p.addr
   AND s.sid = pp.sid(+)
   AND s.paddr = ss.paddr(+)
   AND s.type = 'USER'
 ORDER BY s.sid;

三、SQL优化相关
1、执行计划
 	9i版本格式化输出执行计划
	--需输入sql_hash_value
set feedback off
set long 99999
col "ACCESS PREDICATES" for a80
col "FILTER PREDICATES" for a80
undefine hash_value
col "Optimizer Plan:" for a99
select '|   id| Operation                         | PHV/Object Name               |  Rows | Bytes|   Cost |'
as "Optimizer Plan:" from dual
union all
select '|'||decode(ACCESS_PREDICATES, null,' ','*')||decode(FILTER_PREDICATES, null, ' ', '@')||lpad(' ',3-(length(id)))||id||
    rpad('| '||substr(lpad(' ',1*(depth-1))||operation||
     decode(options, null,'',' '||options), 1, 35), 36, ' ')||'|'||
  rpad(decode(id, 0, '------------- '
    , substr(decode(substr(object_name, 1, 7), 'SYS_LE_', null, object_name)
       ||' ',1, 30)), 31, ' ')||'|'||
   lpad(decode(cardinality,null,'  ',
      decode(sign(cardinality-1000), -1, cardinality||' ',
      decode(sign(cardinality-1000000), -1, trunc(cardinality/1000)||'K',
      decode(sign(cardinality-1000000000), -1, trunc(cardinality/1000000)||'M',
      trunc(cardinality/1000000000)||'G')))), 7, ' ') || '|' ||
  lpad(decode(bytes,null,' ',
    decode(sign(bytes-1024), -1, bytes||' ',
    decode(sign(bytes-1048576), -1, trunc(bytes/1024)||'K',
       decode(sign(bytes-1073741824), -1, trunc(bytes/1048576)||'M',
         trunc(bytes/1073741824)||'G')))), 6, ' ') || '|' ||
    lpad(decode(cost,null,' ', decode(sign(cost-10000000), -1, cost||' ',
                decode(sign(cost-1000000000), -1, trunc(cost/1000000)||'M',
                       trunc(cost/1000000000)||'G'))), 8, ' ') || '|' as "Explain plan"
from v$sql_plan sp
where sp.hash_value=&&hash_value
union all
select lpad('-',99,'-') from dual;
select '*'||id||'--'|| ACCESS_PREDICATES as "ACCESS PREDICATES"
from v$sql_plan
where ACCESS_PREDICATES is not null and hash_value=&&hash_value;
select '@'||id||'--'|| FILTER_PREDICATES as "FILTER PREDICATES"
from v$sql_plan
where FILTER_PREDICATES is not null and hash_value=&&hash_value;
set head on
set feedback on
undefine hash_value

 	Explain plan for
	--或者预生成执行计划：表示为以下sql语句生成执行计划,不会执行该语句
	EXPLAIN PLAN set statement_id='MYSQL1' FOR  &SQL语句
	--格式化输出：
	select * from table(dbms_xplan.display('plan_table',null,'serial'));

 	DBMS_XPLAN
	--for 10g or high version
	select * from table(dbms_xplan.display_cursor( <sql_id> , <cursor_child> , <format> ));
	select * from table(dbms_xplan.display_awr( <sql_id> , <plan_hash_value> , <db_id> , <format>));
 	查询绑定变量取值
2、统计信息

使用绑定变量情形下的执行计划

[sql] view plaincopyprint 
01.SQL> variable v_id number;   -->定义绑定变量
02.SQL> exec :v_id:=900;        -->给绑定变量赋值
03.
04.PL/SQL procedure successfully completed.
05.
06.SQL> select sum(object_id) from t where id<:v_id;
07.
08.SUM(OBJECT_ID)
09.--------------
10.        446549
11.
12.SQL> select * from table(dbms_xplan.display_cursor());   -->此时上一条SQL语句走了全表扫描，其SQL_ID 为7qcp6urqh7d2j





3、SQL Cost
 	For 9i
select to_char(sp.snap_time,'YYYY-MM-DD HH24:MI:SS') as snap_time,
       sq.hash_value,
       sq.sorts,
       (sq.executions - lag(sq.executions, 1) over(partition by sq.hash_value order by sq.snap_id))  executions,
       round((sq.disk_reads - lag(sq.disk_reads, 1) over(partition by sq.hash_value order by sq.snap_id))
       / (sq.executions - lag(sq.executions, 1) over(partition by sq.hash_value order by sq.snap_id))) pre_disk_reads,
       round((sq.buffer_gets - lag(sq.buffer_gets, 1) over(partition by sq.hash_value order by sq.snap_id))
       / (sq.executions - lag(sq.executions, 1) over(partition by sq.hash_value order by sq.snap_id))) pre_buffer_gets,
       round((sq.cpu_time - lag(sq.cpu_time, 1) over(partition by sq.hash_value order by sq.snap_id)) / 1000000
       / (sq.executions - lag(sq.executions, 1) over(partition by sq.hash_value order by sq.snap_id))) pre_cpu_time,
       round((sq.elapsed_time - lag(sq.elapsed_time, 1) over(partition by sq.hash_value order by sq.snap_id)) / 1000000
       / (sq.executions - lag(sq.executions, 1) over(partition by sq.hash_value order by sq.snap_id))) pre_elapsed_time
  from STATS$SQL_SUMMARY sq, stats$snapshot sp
 where sq.snap_id = sp.snap_id
   and sp.snap_time between to_date('20120820 10:00:00', 'yyyymmdd hh24:mi:ss') and  to_date('20120831 20:00:00', 'yyyymmdd hh24:mi:ss')
   --and sq.executions> 1000
   and sq.hash_value in ('2600794431')
   order by sp.snap_time;

 	For 10g&11g
select *
  from (select to_char(begin_interval_time, 'yyyy-mm-dd hh24:mi:ss') time,
               s.sql_id,
               (select sql_text
                  from dba_hist_sqltext st
                 where st.sql_id = s.sql_id) sql_text,
               sum(s.executions_delta) executions,
               s.parsing_schema_name,
               round((sum(elapsed_time_delta) / sum(s.executions_delta)) /
                     1000000,
                     0) per_elapsed_time,
               round((sum(s.cpu_time_delta) / sum(s.executions_delta)) /
                     1000000,
                     0) per_cpu_time,
               round(sum(s.disk_reads_delta) / sum(s.executions_delta), 0) per_disk_reads,
               round(sum(s.buffer_gets_delta) / sum(s.executions_delta), 0) per_buffer_gets,
               round(sum(s.parse_calls_delta) / sum(s.executions_delta), 0) per_parse_calls,
               round(sum(s.iowait_delta) / sum(s.executions_delta) / 1000000,
                     0) per_iowait,
               round(sum(s.ccwait_delta) / sum(s.executions_delta) / 1000000,
                     0) per_ccwait,
               sum(elapsed_time_delta) / 1000000 elapsed_time,
               sum(s.cpu_time_delta) / 1000000 cpu_time,
               sum(s.disk_reads_delta) disk_reads,
               sum(s.buffer_gets_delta) buffer_gets,
               sum(s.parse_calls_delta) parse_calls,
               sum(s.iowait_delta) / 1000000 iowait,
               sum(s.ccwait_delta) / 1000000 ccwait
          from dba_hist_snapshot sn, dba_hist_sqlstat s
         where s.snap_id = sn.snap_id
          and s.parsing_schema_name = 'FGLPA'
          and s.sql_id='5ac9j4vppg5kh'
           and s.executions_delta <> 0
           and to_date(to_char(begin_interval_time, 'yyyy-mm-dd hh24:mi:ss'),
                       'yyyy-mm-dd hh24:mi:ss') >=
               to_date('2012-02-15 00:00:00', 'yyyy-mm-dd hh24:mi:ss')
           and to_date(to_char(begin_interval_time, 'yyyy-mm-dd hh24:mi:ss'),
                       'yyyy-mm-dd hh24:mi:ss') <
               to_date('2012-02-17 00:30:00', 'yyyy-mm-dd hh24:mi:ss')
         group by to_char(begin_interval_time, 'yyyy-mm-dd hh24:mi:ss'),
                  s.sql_id,
                  s.parsing_schema_name)
 order by per_buffer_gets desc;

四、CRS常用命令
1、CRS  start or stop
#crsctl start crs   --打开集群CRS命令程序
#crsctl stop crs   --关闭

2、CRS service
	$ crs_start -all --启动所有的crs服务
$ crs_stop -all --停止所有的crs服务
$ crsctl start crs --启动crs服务
$ crsctl stop crs --停止crs服务
$ srvctl start|stop|status nodeapps -n <node_name>   -- start/stop/check所有的nodeapps，比如：VIP, GSD, listener, ONS
$ srvctl stop listener -n host1(host2) --停止某个节点的listener
$ srvctl start|stop|status instance -d <db_name> -i <instance_name>	 -- start/stop/check指定的实例
$ srvctl start|stop|status database -d <db_name> 		 -- start/stop/check所有的实例
$ crs_stop  资源名(ora.ORCL.ORATEST.cs) 停一个资源，此命令可停到资源状态为UNKNOWN的资源

3、CRS manage
	$ srvctl setenv database -d <db_name> -t   --设置全局环境和变量
	$ srvctl remove database -d <db_name>   --从OCR中删除已有的数据库
	$ srvctl add database -d <db_name> -o <oracle_home> --向OCR中添加一个数据库
	$ srvctl add instance -d <db_name> -i <instance_name> -n <node n>   --向OCR中添加一个数据库的实例
	$ srvctl add asm -n <node_name> -i <asm_inst_name> -o <oracle_home>  --向OCR中添加一个ASM实例
	$ srvctl add service -d <db_name>  --添加一个service

4、crs log
$ORA_CRS_HOME/log/节点主机名（rachost01)/racg
$ORA_CRS_HOME/log/节点主机名(rachost01)/crsd
$ORA_CRS_HOME/crs/init
$ORA_CRS_HOME/css/log
$ORA_CRS_HOME/css/init
$ORA_CRS_HOME/evm/log
$ORA_CRS_HOME/evm/init
$ORA_CRS_HOME/srvm/log

五、Dataguard
1、Primary端查询DG步情况
col DEST_NAME for a20;
col RECOVERY_MODE for a15;
select * from v$archive_dest_status
where destination is not null;

2、MRP进程控制
	alter database recover managed standby database cancel;
alter database recover managed standby database disconnect from session;
alter database recover managed standby database parallel 32 disconnect from session;
alter database recover managed standby database parallel 64 disconnect from session;
alter database recover managed standby database using current logfile disconnect;
alter database recover managed standby database delay 1440 disconnect from session;
select PROCESS,STATUS,CLIENT_PROCESS,GROUP#,THREAD#,SEQUENCE# , BLOCK# from  v$managed_standby where process='MRP0';

3、Archivelog注册
	alter database register  or replace logfile '/paic/hq/paces/log/spaces/paces_0000019850.arc';
	--下面sql用于生成注册当前目录下所有文件
	ls -l *.arc | awk "{print \"alter database register or replace logfile '`pwd`/\"\$9\"';\"}">logreg.sql

4、查询recover进度
	select * from v$recovery_progress;
5、DG监控语句
select  a.dg_sid DG_SID,
        to_char(a.stat_date,'MM-DD HH24:MI') mon_time,
        c.db_dba_flag ,
        a.primary_db_status ,
        a.primary_log_seq ,
        a.last_dg_status ,
        a.last_apply_seq ,
        to_char(a.last_apply_time,'MM-DD HH24:MI') apply_time,
        a.apply_time_differ ,
        a.apply_log_differ
from db_dg_stat a , db_dg_info b ,database_info c
where a.dg_id=b.dg_id and b.db_id=c.db_id
      and c.db_dg_flag = 'Y'
      and b.dg_stat_flag='Y'
      and TRUNC(a.stat_date) = TRUNC(SYSDATE)
      AND a.stat_date =(SELECT MAX(stat_date) FROM db_dg_stat d WHERE d.dg_id = a.dg_id)
      and a.dg_sid=upper('&dg_sid')
order by a.apply_time_differ desc,trunc(a.stat_date,'HH'),a.last_dg_status desc,a.apply_log_differ desc;
6、FRA区使用
	prompt –统计FRA区使用率
col sumused for a10;
select sum(PERCENT_SPACE_USED)||'%' as sumused from v$flash_recovery_area_usage;

--查询FRA区使用情况
select b.TOTAL_G,
       b."TOTAL_G" * (1 - a."USED") "FREE_G",
       b."TOTAL_G" * (1 - a."USED" + a."RECLAIMABLE") "free+reclaimable_G",
       round((a."USED" - a."RECLAIMABLE")*100,2)||' %' as pct_used
  from (select sum(xx.PERCENT_SPACE_USED) / 100 "USED",
               sum(xx.PERCENT_SPACE_RECLAIMABLE) / 100 "RECLAIMABLE"
          from v$flash_recovery_area_usage xx) a,
       (select round(value / 1024 / 1024 / 1024) "TOTAL_G"
          from v$parameter
         where name = 'db_recovery_file_dest_size') b;

六、Datadump
1、resume
	在做导出或导入时设定resume参数，可以避免因空间问题报错终止。
userid='/ as sysdba'
OWNER=EIMCDE,EIMDATA,EIMETL,EIMJOB,EIMLOGTMP,EIMMONOPR,EIMOPR
file=/paic/hq/pa18/data2/oradata/tmp/exp_01.dmp  exp_02.dmp  exp_03.dmp exp_04.dmp exp_05.dmp
	 exp_06.dmp exp_07.dmp exp_08.dmp exp_09.dmp exp_10.dmp exp_11.dmp exp_12.dmp exp_13.dmp
	 exp_14.dmp exp_15.dmp exp_16.dmp exp_17.dmp exp_18.dmp exp_19.dmp exp_20.dmp exp_21.dmp
	 exp_22.dmp exp_23.dmp exp_24.dmp exp_25.dmp exp_26.dmp exp_27.dmp exp_28.dmp exp_29.dmp
	 exp_30.dmp exp_31.dmp exp_32.dmp exp_33.dmp exp_34.dmp exp_35.dmp exp_36.dmp exp_37.dmp
	 exp_38.dmp exp_39.dmp exp_40.dmp exp_41.dmp exp_42.dmp exp_43.dmp exp_44.dmp exp_45.dmp
log=/paic/hq/pa18/data2/oradata/tmp/exp.log
filesize=10G
rows=y
resumable=y   ---can not query the process of exp or imp if no the parameter
resumable_timeout=20000000   --set the durning time of resume
通过以下sql可以查询到导数进度


2、compress
	对于11g版本提供了功能强大的导出压缩功能，默认压缩算法可以很大程度上对数据做压缩导出，压缩比例高达80%；而对于10g虽然已提供压缩功能，但是压缩效果很不明显。
3、cross_version
	对于数据泵，从高版本到低版本导入时，需在导出时添加version选项，取值为目标库参数COMPATIBLE的取值。

	version=

4、table_join
	对于存在表连接的数据导出
userid="/ as sysdba"
directory=dp_dir
dumpfile=expdp_0729_%U.dmp
logfile=expdp_0729.log
COMPRESSION=ALL
tables=(
POLAPDATA.NL_T_CHG_RATE,
POLAPDATA.AUTO_POLICY_BASE_INFO,
POLAPDATA.AUTO_POLICY_VEHICLE_INFO,
POLAPDATA.AUTO_CB_TMP_CLAIM_POLICY,
POLAPDATA.DEPARTMENT_DEFINE,
POLAPDATA.BASE_PLAN_DEFINE,
POLAPDATA.BUSINESS_CHANNEL_DEFINE,
POLAPDATA.AUTO_CB_VHL_PARAMETER,
POLAPDATA.STAND_AUTO_EARNED_LJ,
POLAPDATA.WJ_T_CARCASE_PLYRLT_HIS,
POLAPDATA.AUTO_CB_TMP_CLM_PLY_BAK
)
query=(
polapdata.AUTO_POLICY_BASE_INFO:"where (last_begin_date>=to_date('20120101','YYYYMMDD') AND  last_begin_date<to_date('20120730','YYYYMMDD')) OR( last_begin_date>=to_date('20110101','YYYYMMDD') AND  last_begin_date<to_date('20110730','YYYYMMDD')) OR (underwrite_time>=to_date('20120101','YYYYMMDD') AND underwrite_time<to_date('20120730','YYYYMMDD')) OR (underwrite_time>=to_date('20110101','YYYYMMDD') AND underwrite_time<to_date('20110730','YYYYMMDD'))"
POLAPDATA.STAND_AUTO_EARNED_LJ:"where stat_ym like '2009%'"
POLAPDATA.WJ_T_CARCASE_PLYRLT_HIS:"where run_time>=to_date('20090101','yyyymmdd')  and run_time<to_date('20100101','yyyymmdd')"
)
5、muti_where
	在expdp导出时，如果导出多个表，而且条件不同，则可采用下述方式导出。
	userid="/ as sysdba"
directory=lmw
dumpfile=exp_20120216_where_%U.dmp
logfile=exp_20120216_where_.log
COMPRESSION=ALL
tables=(
polapdata.NL_APPLY_BASE_INFO
polapdata.AUTO_APPLY_BASE_INFO
polapdata.AUTO_POLICY_BASE_INFO
polapdata.PMLS_APPLY_BASE_INFO
polapdata.CH_ENDORSE
polapdata.AUTO_UNDERWRITE_INFO
polapdata.CH_POLICY
polapdata.DEP_SUM_WFH_LIST
polapdata.ICSS_PC_NEW_POLICY_INVD
polapdata.KF_CLIENT_VIP
polapdata.KF_DEST_CLIENT_VIP
polapdata.KF_DEST_EFFICIENCY
polapdata.KF_DEST_WORKLOAD
polapdata.KF_DEST_NL_TIME_EFFECT
polapdata.ICSS_T_QUERY_COUNTER
polapdata.KF_CD_QUESTION_DEST
)
query=(
polapdata.NL_APPLY_BASE_INFO:"where EP_CREATED_DATE>=TO_DATE('20120101','YYYYMMDD')"
polapdata.AUTO_APPLY_BASE_INFO:"where EP_CREATED_DATE>=TO_DATE('20120101','YYYYMMDD')"
polapdata.AUTO_POLICY_BASE_INFO:"where  LCD>=TO_DATE('20120101','YYYYMMDD')"
polapdata.PMLS_APPLY_BASE_INFO:"where CREATED_DATE>=TO_DATE('20120101','YYYYMMDD')"
polapdata.CH_ENDORSE:"where  CREATED_DATE>=TO_DATE('20120101','YYYYMMDD')"
polapdata.AUTO_UNDERWRITE_INFO:"where CREATED_DATE>=TO_DATE('20120101','YYYYMMDD')"
polapdata.CH_POLICY:"where CREATED_DATE>=TO_DATE('20120101','YYYYMMDD')"
polapdata.DEP_SUM_WFH_LIST:"where CREATED_DATE>=TO_DATE('20120101','YYYYMMDD')"
polapdata.ICSS_PC_NEW_POLICY_INVD:"where LCD>=TO_DATE('20120101','YYYYMMDD')"
polapdata.KF_CLIENT_VIP:"where LCD>=TO_DATE('20120101','YYYYMMDD')"
polapdata.KF_DEST_CLIENT_VIP:"where LCD>=TO_DATE('20120101','YYYYMMDD')"
polapdata.KF_DEST_EFFICIENCY:"where LCD>=TO_DATE('20120101','YYYYMMDD')"
polapdata.KF_DEST_WORKLOAD:"where LCD>=TO_DATE('20120101','YYYYMMDD')"
polapdata.KF_DEST_NL_TIME_EFFECT:"where LCD>=TO_DATE('20120101','YYYYMMDD')"
polapdata.ICSS_T_QUERY_COUNTER:"where LCD>=TO_DATE('20120101','YYYYMMDD')"
polapdata.KF_CD_QUESTION_DEST:"where LCD>=TO_DATE('20120101','YYYYMMDD')"
)
6、multiuser-multitable
	导出多个用户下的多个表。
userid='/ as sysdba'
directory=dump_dir
dumpfile=expdp_elis_tables_2011115_%U.dmp
filesize=10000M
logfile=expdp_elis_tables_2011115.log
schemas=elisdata,INSDATA
include=table:"in ('POS_USER_OPERATION_RELATION','POS_ROLE_OPERATION_RELATION','POS_USER_OPERATION_RELATION','INSDATA'.'INVESTIGATE_INFO')"
parallel=4
job_name=expdp_elis_tables_2011115

七、Backup&Restore
1、备份检查
 	检查rman备份情况
--该sql是来获取正常的没有报错的rman备份的时间
SELECT /*+ RULE */ OBJECT_TYPE BACKUP_TYPE, (SYSDATE-MAX(END_TIME)) DAYS_SINCE_BACKUP,
 MAX(END_TIME) LAST_SUCCESSFUL_BACKUP
 FROM SYS.V_$RMAN_STATUS  WHERE STATUS = 'COMPLETED' AND OPERATION='BACKUP' GROUP BY OBJECT_TYPE;

--这个sql可以用来确认当前rman的备份情况，可以看到很多是COMPLETED WITH WARNINGS。这个被foglight认为是异常的。
  select a.OBJECT_TYPE,a.end_time,a.status,a.OPERATION,b.recid,b.output from v$rman_status a,v$rman_output b
   where a.OBJECT_TYPE='ARCHIVELOG' and a.recid=b.recid(+) order by 2 desc;
--output 为输出的报错信息，一般为已经备份，导致的异常。
select * from v$archived_log where backup_count=1;  --查看日志的备份情况
select * from v$rman_configuration;                --查看rman的配置情况，也可以登陆到主机连接catlog，show all查询更相信的信息
select OBJECT_TYPE,end_time,status,OPERATION,recid from v$rman_status where OBJECT_TYPE='ARCHIVELOG' order by 2 desc;
--查看rman的记录情况

2、备份 / 恢复
（1）backup database
rman
RMAN> connect target /
RMAN> show all;
RMAN> CONFIGURE DEVICE TYPE DISK BACKUP TYPE TO COMPRESSED BACKUPSET PARALLELISM 4;
RMAN>RUN {
ALLOCATE CHANNEL ch00 TYPE disk;
ALLOCATE CHANNEL ch01 TYPE disk;
ALLOCATE CHANNEL ch02 TYPE disk;
ALLOCATE CHANNEL ch03 TYPE disk;
CONFIGURE DEVICE TYPE DISK BACKUP TYPE TO COMPRESSED BACKUPSET PARALLELISM 4;
CONFIGURE BACKUP OPTIMIZATION ON;
SQL 'ALTER SYSTEM ARCHIVE LOG CURRENT';
BACKUP section size 4096m FILESPERSET 4 FORMAT='<备份目录>/back_%d_%s_%p_%t' DATABASE;
BACKUP CURRENT CONTROLFILE [For standby] FORMAT='<备份目录>/<$ORACLE_SID>_ctl.f';
release channel ch00;
release channel ch01;
release channel ch02;
release channel ch03;
}
RMAN> list backup;
（2）image copy
ORACLE_SID=$ORACLE_SID
export ORACLE_SID
ORACLE_HOME=/stg/oracle/otzj11g/app/oracle/product/11.2.0
export ORACLE_HOME
NLS_DATE_FORMAT='yyyy-mm-dd hh24:mi:ss'
export NLS_DATE_FORMAT

/stg/oracle/otzj11g/app/oracle/product/11.2.0/bin/rman nocatalog target /  <<EOF
run{
allocate channel ch1 type disk;
allocate channel ch2 type disk;
allocate channel ch3 type disk;
allocate channel ch4 type disk;
allocate channel ch5 type disk;
allocate channel ch6 type disk;
allocate channel ch7 type disk;
allocate channel ch8 type disk;
backup as copy database format '+DATA2_DG';
release channel ch1;
release channel ch2;
release channel ch3;
release channel ch4;
release channel ch5;
release channel ch6;
release channel ch7;
release channel ch8;
}
EOF
（3）增备（基于scn）
rman target / <<EOF
run
{
	allocate channel c1 device type disk;
	allocate channel c2 device type disk;
	allocate channel c3  device type disk;
	allocate channel c4  device type disk;
	BACKUP as compressed backupset INCREMENTAL FROM SCN 8775975306547 DATABASE FORMAT '/paic/bank/rptnew/data/osrptnew/wangsj/standby_%U'      tag 'FORSTANDBY';
	backup current controlfile format '/paic/bank/rptnew/data/osrptnew/wangsj/stdctl.ctl';
	release channel c1;
	release channel c2;
	release channel c3;
	release channel c4;
}
exit
EOF

(4) backup datafile for standby
rman target / <<EOF
CONFIGURE DEVICE TYPE DISK BACKUP TYPE TO COMPRESSED BACKUPSET PARALLELISM 4;
run
{
     allocate channel c1 device type disk ;
     allocate channel c2 device type disk ;
     allocate channel c3 device type disk ;
     allocate channel c4 device type disk ;
     CONFIGURE BACKUP OPTIMIZATION OFF;
     BACKUP as compressed backupset full DATABASE FORMAT '/paic/app/oracle/rdbms/os11g/wangsj/bak_full/eps_standby_%U' tag 'EPS_FORSTANDBY' section size 10g;
     backup current controlfile for standby format '/paic/app/oracle/rdbms/os11g/wangsj/bak_full/stdctl.ctl';
     release channel c1;
     release channel c2;
     release channel c3;
     release channel c4;
}
exit
EOF

八、Storage
1、查询asm磁盘使用情况


2、查询 asm disk信息
select d.NAME AS DG_NAME
         ,t.DISK_NUMBER
         ,t.NAME AS DISK_NAME
         ,t.PATH
         ,t.TOTAL_MB
         ,t.FREE_MB
  from v$asm_disk t,v$asm_diskgroup d
  where t.GROUP_NUMBER=d.GROUP_NUMBER
  order by t.GROUP_NUMBER,t.DISK_NUMBER ;

3、查询 asm disk reblance 进度
select * from v$asm_operation;

4、坏块检查定位

asm  controlfile   rman

rman target /

restore controlfile to '+DG1/orcl/controlfile/current.307.724358011' from '+DG1/orcl/controlfile/Current.278.723200291' ;

restore controlfile to '+DG1/orcl/controlfile/current' from '+DG1/orcl/controlfile/Current.278.723200291' ;


用oracle自身的控制文件作为源恢复即可, 相当于复制.


注意:restore后你自己命名的控制文件名如果是asm自动管理,可能名字不会按你命的名字来,在asmcmd中确认下正确的控制文件名,再更新到pfile中.




九、Install & upgrade

$ORACLE_HOME/oui/bin/runInstaller  -invPtrLoc $HOME/../app/oraInst.loc -silent -clone ORACLE_HOME="/paic/bank/kiss/data/app/oracle/product/10.2.0" ORACLE_HOME_NAME="oracle_home_skiss120227"

安装种子软件
解除之前的ORACLE_HOME
./runInstaller -detachHome ORACLE_HOME=<ORACLE_HOME_path>
11g之前版本：
$ORACLE_HOME/oui/bin/runInstaller -invPtrLoc xxxx/oraInst.loc -silent -clone ORACLE_HOME="<ORACLE_HOME>" ORACLE_HOME_NAME="<NAME>"
11g版本(加上指定ORACLE_BASE)
$ORACLE_HOME/oui/bin/runInstaller -invPtrLoc xxxx/oraInst.loc -silent -clone ORACLE_BASE="<ORACLE_BASE>" ORACLE_HOME="<ORACLE_HOME>" ORACLE_HOME_NAME="<NAME>"

查看Patch
$ORACLE_HOME/OPatch/opatch lsinventory -invPtrLoc $HOME/../app/oraInst.loc
$ORACLE_HOME/OPatch/opatch lsinventory -invPtrLoc $ORACLE_HOME/oraInst.loc
opatch 最新版本下载： 68806880

查看PSU
$ORACLE_HOME/OPatch/opatch lsinventory –invPtrLoc   /../oraInst.loc -bugs_fixed | grep -i 'Patch Set Update'

apply & rollback
$ORACLE_HOME/OPatch/opatch apply -invPtrLoc $HOME/../app/oraInst.loc
$ORACLE_HOME/OPatch/opatch rollback -id PATCH_NO -invPtrLoc $HOME/../app/oraInst.loc

RAC — the cluster database(DB_NAME) already exits

出现这个的原因很简单，就是rac 这个数据库的信息没有彻底的从OCR中清除干净。下面我们来清除这些信息。

[oracle@rac1 bin]$ srvctl config   -- 这个命令用来显示保存在SRVM配置文件中的配置信息
Rac
[oracle@rac1 bin]$ srvctl remove database -d rac  -- 删除这个数据库
Remove the database rac  (y/[n]) y
[oracle@rac1 bin]$ srvctl config   -- 再次查看，还存在，很奇怪
rac

[oracle@rac1 bin]$ srvctl remove database -d rac –f  -- 加上-f 参数，强制删除
[oracle@rac1 bin]$ srvctl config    -- 查看，正常，信息已经被删除掉
[oracle@rac1 bin]$


因为之前这个数据库的实例信息我已经删除了，所以rac这个数据库的信息也是不完整的，对于不完整的信息删除，还是要强制删除。



拷贝asm磁盘里的

服务时间代表的是“ CPU used by this session”,是CPU服务会话所花费的所有时间。

实例级：  统计名叫CPU used by this session
注意９i后时间单位是1百万分之1

select  a.value "Total CPU time"
from v$sysstat a
where a.name ='CPU used by this session';

会话级：

select statistic# from v$statname where name ='CPU used by this session';
同样查看统计名CPU used by this session

我们先找到CPU used by this session的统计号

12


再去查v$sesstat
select sid ,a.value "Total CPU time"
from v$sesstat a
where a.statistic#=12;


Service Time　＝　SQL解析时间　＋　递归调用时间　＋　其它时间


SQL/PLSQL等解析时所花的时间，如果解析时间超过总的CPU服务时间２０％，那么需要调优应用程序代码，比如绑定变量、SESSION_CURSOR_CACHE等
Service Time　＝　SQL解析时间　＋　递归调用时间　＋　其它时间
                 -----------
                  不要超过Service Time的20%

查看SQL解析时间呢？


我们也分实例级和会话级
  实例级：
select a.value "Total parse time"
from v$sysstat a
where a.name ='parse time cpu';

会话级：
select name, statistic# from v$statname where name
like '%parse%';
统计名仍然是parse time cpu，统计号是230
然后查询v$sesstat
select sid,a.value "Total parse Cpu time"
from v$sesstat a
where a.statistic#=230;

另外parse count可以判断数据库sql解析的效率。

递归调用时间是用在语义分析阶段查找数据字典或者PLSQL内部包造成的解析所花的CPU时间。
select name,sid,value "Total parse Cpu time"
from v$statname a,v$mystat b
where a.name like '%parse%'
and a.statistic#=b.statistic#;

查看本会话的统计
select name ,statistic# from v$statname where name like '%cpu%';


select a.value "Total recursive Cpu time"
from v$sysstat a
where a.name ='recursive cpu usage'

查找v$sysstat,v$sesstat,我们可以查看到递归调用的时间了

其它CPU时间

其它CPU时间通常占绝大多数，它是执行内存BUFFER搜索，索引和全表扫描涉及的IO操作所占有的CPU.
select a.value "Total CpU",
b.value "parse cpu",
c.value "recursive cpu",
a.value -b.value-c.value "other"
from v$sysstat a, v$sysstat b, v$sysstat c
where a.name='CPU userd by this session'
and b.name ='parse time cpu'
and c.name ='recursive cpu usage';


大部分空闲等待事件都是客户端相关的消息传输事件

我们来查看下数据库的等待事件数据
 select event,time_waited,average_wait from
 v$system_event where
 event not in('pmon timer',
 'smon timer',
 'rdbms ipc message',
 'parallel dequeue wait',
 'virtual circuit',
 'SQL*Net message from client',
 'client message',
 'NULL event')
 order by time_waited desc;

 上例,NOT IN这些空闲事件，可以查看非空闲等待事件的统计信息



找到消耗CPU最高的是最近4小时登陆的，最近半小时有过活动的会话

find sessions with the highest cpu consumption
select s.sid,s.serial#,p.spid as "os pid",
s.username ,s.module,
st.value/100 as "cpu sec"
from v$sesstat st,v$statname sn,v$session s,v$process p
where sn.name ='CPU used by this session
 --cpu
 and st.atatistic#=sn.statistic#
 and st.sid=s.sid
 and s.paddr=p.addr
 and s.last_call_et<1800   ------actie within last 1/2 hour
 and s.logon_time>(sysdate-240/1440) ---sessions logged bon within 4hours
 order by st.value;


查找等待最严重的会话

find sessinos with highest waits of a certain type

select s.sid ,s.serial#,p.spid as "os pid", s.username,s.module,se.time_waited
from v$session_event se,v$session s, v$process p
where se.event='&event_name'
and s.last_call_et<1800  ---active tithin last 1/2 hour
and s.logon_time>(sysdate-240/1440) ---sessions logged on within 4 hour
and se.sid=s.sid
and s.paddr=p.addr
order by se.time_waited;



 我们要来分析会话服务时间，等待时间在总的DB TIME中所占的比例
 一个会话的服务时间占整个数据库DB TIME的比例

10g or higher:find sessions with the highest db time
select  s.sid,s.serial#,p.spid as "OS PID",s.username,s.module,st.value/100 as "db time (sec)"
,stcpu.value/100 as "cpu time(sec)",round（stcpu.value/st.value*100,2) as "% cpu"
from v$sesstat st,v$statname sn,v$session s, v$sesstat stcpu ,v$statname sncpu ,v$process p
where sn.name=DB time' ---cpu
and st.statistic#=sn.statistic#
and st.sid =s.sid
and sncpu.name='CPU used by this session' ---cpu
and stcpu.statistic# = sncpu.statistic#
and stcpu.sid=st.sid
and s.paddr=p.addr
and s.last_call_et <1800  ----active within last 1/2 hour
and s.logon_time >(sysdate-240/1440) ---sessions logged on within 4 hours
and st.value>0;



SQL> alter tablespace OGG read only;
alter tablespace OGG read only
*
ERROR at line 1:
ORA-30514: system trigger cannot modify tablespace being made read only



原因：没有禁用掉goldengate的DDL触发器。
解决办法：禁用掉goldengate的DDL触发器

ALTER TRIGGER sys.GGS_DDL_TRIGGER_BEFORE DISABLE;  –注意该触发器属于SYS

结论：在对安装有OGG的数据库进行升级或者因为某些原因要执行catalog.sql等脚本进行刷新数据字典的行为时需要确保sys.GGS_DDL_TRIGGER_BEFORE是禁用的。


Oracle AWR 手动配置
1.查看当前的AWR保存策略
select * from dba_hist_wr_control;

DBID,SNAP_INTERVAL,RETENTION,TOPNSQL
860524039,+00 01:00:00.000000,+07 00:00:00.000000,DEFAULT
以上结果表示,每小时产生一个SNAPSHOT，保留7天
2.调整AWR配置
AWR配置都是通过dbms_workload_repository包进行配置
2.1调整AWR产生snapshot的频率和保留策略，如：如将收集间隔时间改为30 分钟一次。并且保留5天时间（注：单位都是为分钟）：
exec dbms_workload_repository.modify_snapshot_settings(interval=>30, retention=>5*24*60);
2.2关闭AWR,把interval设为0则关闭自动捕捉快照
2.3手工创建一个快照
exec DBMS_WORKLOAD_REPOSITORY.CREATE_SNAPSHOT ();
2.4 查看快照
select * from sys.wrh$_active_session_history
2.5手工删除指定范围的快照
exec WORKLOAD_REPOSITORY.DROP_SNAPSHOT_RANGE(low_snap_id => 22, high_snap_id => 32, dbid => 3310949047);
2.6创建baseline
exec dbms_workload_repository.create_baseline (56,59,'apply_interest_1')
2.7删除baseline
exec DBMS_WORKLOAD_REPOSITORY.DROP_BASELINE(baseline_name => ' apply_interest_1', cascade => FALSE);

3.生产AWR报告
$ORACLE_HOME/rdbms/admin/awrrpt.sql

4.1 Snapshots( 快照)
　　前面操作报表生成时，snap这个关键字已经出现过多次了，想必你对它充满了疑惑，这个东西是哪来的咋来的谁让它来的呢？事实上，Snap是Snapshot的简写，这正是AWR在自动性方面的体现，虽然你没有创建，但是AWR自动帮你创建了(当然也可以手动创建snapshot)，并且是定时(每小时)创建，定期清除(保留最近7天)。

　　Snapshots 是一组某个时间点时历史数据的集合，这些数据就可被ADDM(Automatic Database Diagnostic Monitor)用来做性能对比。默认情况下，AWR能够自动以每小时一次的频率生成Snapshots性能数据，并保留7天，，如果需要的话，DBA可以通过DBMS_WORKLOAD_REPOSITORY过程手动创建、删除或修改snapshots。

提示：调用DBMS_WORKLOAD_REPOSITORY包需要拥有DBA权限。
4.1.1  手动创建Snapshots
　　手动创建Snapshots，通过DBMS_WORKLOAD_REPOSITORY.CREATE_SNAPSHOT过程，例如：

SQL> exec dbms_workload_repository.create_snapshot();

PL/SQL procedure successfully completed.
　　然后可以通过DBA_HIST_SNAPSHOT 视图查看刚刚创建的Snapshots信息。

4.1.2  手动删除Snapshots
　　删除Snapshots是使用DBMS_WORKLOAD_REPOSITORY包的另一个过程：DROP_SNAPSHOT_RANGE，该过程在执行时可以通过指定snap_id的范围的方式一次删除多个Snapshots，例如：

SQL> select count(0) from dba_hist_snapshot where snap_id between 7509 and 7518;

  COUNT(0)

----------

        10

SQL> begin

  2   dbms_workload_repository.drop_snapshot_range(

  3     low_snap_id => 7509,

  4     high_snap_id => 7518,

  5     dbid => 3812548755);

  6  end;

  7  /

PL/SQL procedure successfully completed.

SQL> select count(0) from dba_hist_snapshot where snap_id between 7509 and 7518;

  COUNT(0)

----------

         0
　　注意当snapshots被删除的话，与其关联的ASH记录也会级联删除。

4.1.3  修改Snapshots设置
　　通过MODIFY_SNAPSHOT_SETTINGS过程，DBA可以调整包括快照收集频率、快照保存时间、以及捕获的SQL数量三个方面的设置。分别对应MODIFY_SNAPSHOT_SETTINGS的三个参数：

 Retention ：设置快照保存的时间，单位是分钟。可设置的值最小为1天，最大为100年。设置该参数值为0的话，就表示永久保留收集的快照信息。
 Interval ：设置快照收集的频率，以分钟为单位。可设置的值最小为10分钟，最大为1年。如果设置该参数值为0，就表示禁用AWR特性。
 Topnsql ：指定收集的比较占用资源的SQL数量，可设置的值最小为30，最大不超过100000000。
　　查看当前快照收集的相关设置，可以通过DBA_HIST_WR_CONTROL视图查看，例如：

SQL> select * from dba_hist_wr_control;



      DBID SNAP_INTERVAL            RETENTION            TOPNSQL

---------- ------------------------ -------------------- ----------

3812548755 +00000 01:00:00.0        +00007 00:00:00.0    DEFAULT
　　又比如通过MODIFY_SNAPSHOT_SETTTINGS过程修改snap_intrval的设置：

SQL> exec dbms_workload_repository.modify_snapshot_settings(interval=>120);

PL/SQL procedure successfully completed.

SQL> select * from dba_hist_wr_control;



      DBID SNAP_INTERVAL            RETENTION            TOPNSQL

---------- ------------------------ -------------------- ----------

3812548755 +00000 02:00:00.0        +00007 00:00:00.0    DEFAULT
4.2 Baselines( 基线)
　　Baseline ，直译的话叫做基线，顾名思义的方式理解，就是用于比较的基本线。因为Baseline中包含指定时间点时的性能数据，因此就可以用来与其它时间点时的状态数据做对比，以分析性能问题。

　　创建Baseline时，Snapshots是做为其中的一个组成部分存在，因此一般来说当AWR自动维护快照时，如果定义过baseline，与baseline相关的快照不会被删除，即使是过期的快照，这样就相当于手动保留了一份统计数据的历史信息，DBA可以在适当的时间将其与现有的快照进行对比，以生成相关的统计报表。

　　用户可以通过DBMS_WORKLOAD_REPOSITORY包中的相关过程，手动的创建或删除Baseline。

4.2.1  创建Baseline
　　创建Baseline使用CREATE_BASELINE过程，执行该过程时分别指定开始和结果的snap_id，然后为该baseline定义一个名称即可，例如：

SQL> BEGIN

  2    DBMS_WORKLOAD_REPOSITORY.CREATE_BASELINE(start_snap_id => 7550,

  3                                             end_snap_id   => 7660,

  4                                             baseline_name => ¨am_baseline¨);

  5  END;

  6  /

PL/SQL procedure successfully completed.

SQL> select dbid,baseline_name,start_snap_id,end_snap_id from dba_hist_baseline;

      DBID BASELINE_NAME        START_SNAP_ID END_SNAP_ID

---------- -------------------- ------------- -----------

3812548755 am_baseline                   7550        7660
4.2.2  删除Baseline
　　删除Baseline使用DROP_BASELINE过程，删除时可以通过cascade参数选择是否将其关联的Snapshots级别进行删除，例如：

SQL> BEGIN

  2    DBMS_WORKLOAD_REPOSITORY.DROP_BASELINE(baseline_name => ¨am_baseline¨,

  3                                           cascade       => true);

  4  END;

  5  /

PL/SQL procedure successfully completed.

SQL> select * from dba_hist_baseline;

no rows selected

SQL> select * from dba_hist_snapshot where snap_id between 7550 and 7660;

no rows selected
　　如上例中所示，删除时指定了cascade参数值为true，对应的snap也被级联删除了。



不管是EM也好，或是前面演示中使用的awr*.sql脚本也好，实质都是访问ORACLE中的部分相关视图来生成统计数据，因此如果DBA对自己的理解能力有足够的自信，也可以直接查询动态性能视图(或相关数据字典)的方式来获取自己想要的那部分性能数据。ORACLE将这部分性能统计数据保存在DBA_HIST开头的数据字典中，要查询当前实例所有能够访问的DBA_HIST字典，可以通过下列语句：

SQL> select * from dict where table_name like ¨DBA_HIST%¨;

TABLE_NAME COMMENTS

------------------------------ --------------------------------------------------------------------------------

DBA_HIST_DATABASE_INSTANCE Database Instance Information

DBA_HIST_SNAPSHOT Snapshot Information

DBA_HIST_SNAP_ERROR Snapshot Error Information

DBA_HIST_BASELINE Baseline Metadata Information

DBA_HIST_WR_CONTROL Workload Repository Control Information

DBA_HIST_DATAFILE Names of Datafiles

DBA_HIST_FILESTATXS Datafile Historical Statistics Information

DBA_HIST_TEMPFILE Names of Temporary Datafiles

DBA_HIST_TEMPSTATXS Temporary Datafile Historical Statistics Information

DBA_HIST_COMP_IOSTAT I/O stats aggregated on component level

DBA_HIST_SQLSTAT SQL Historical Statistics Information

DBA_HIST_SQLTEXT SQL Text

......................

........................
　　ORACLE 数据库中以DBA_HIST命名的视图非常多，下面简单介绍几个，比如说：

 V$ACTIVE_SESSION_HISTORY
　　该视图由ASH自动维护，以每秒一次的频率收集当前系统中活动session的信息。虽然说是记录SESSION的历史记录，不过该视图与V$SESSION还是有差异的。

SQL> desc v$active_session_history;

Name Type Nullable Default Comments

------------------------- ------------ -------- ------- --------

SAMPLE_ID NUMBER Y

SAMPLE_TIME TIMESTAMP(3) Y

SESSION_ID NUMBER Y

SESSION_SERIAL# NUMBER Y

USER_ID NUMBER Y

SQL_ID VARCHAR2(13) Y

SQL_CHILD_NUMBER NUMBER Y

SQL_PLAN_HASH_VALUE NUMBER Y

FORCE_MATCHING_SIGNATURE NUMBER Y

SQL_OPCODE NUMBER Y

PLSQL_ENTRY_OBJECT_ID NUMBER Y

PLSQL_ENTRY_SUBPROGRAM_ID NUMBER Y

PLSQL_OBJECT_ID NUMBER Y

PLSQL_SUBPROGRAM_ID NUMBER Y

SERVICE_HASH NUMBER Y

SESSION_TYPE VARCHAR2(10) Y

SESSION_STATE VARCHAR2(7) Y

QC_SESSION_ID NUMBER Y

QC_INSTANCE_ID NUMBER Y

BLOCKING_SESSION NUMBER Y

BLOCKING_SESSION_STATUS VARCHAR2(11) Y

BLOCKING_SESSION_SERIAL# NUMBER Y

EVENT VARCHAR2(64) Y

EVENT_ID NUMBER Y

EVENT# NUMBER Y

SEQ# NUMBER Y

P1TEXT VARCHAR2(64) Y

P1 NUMBER Y

P2TEXT VARCHAR2(64) Y

P2 NUMBER Y

P3TEXT VARCHAR2(64) Y

P3 NUMBER Y

WAIT_CLASS VARCHAR2(64) Y

WAIT_CLASS_ID NUMBER Y

WAIT_TIME NUMBER Y

TIME_WAITED NUMBER Y

XID RAW(8) Y

CURRENT_OBJ# NUMBER Y

CURRENT_FILE# NUMBER Y

CURRENT_BLOCK# NUMBER Y

PROGRAM VARCHAR2(48) Y

MODULE VARCHAR2(48) Y

ACTION VARCHAR2(32) Y

CLIENT_ID VARCHAR2(64) Y
　　v$session 中与操作相关的列均被收集，除此之外还冗余了部分列，这是为了方便DBA查询V$ACTIVE_SESSION_HISTORY时能够快速获取到自己需要的数据。

 DBA_HIST_ACTIVE_SESS_HISTORY
　　该视图与V$ACTIVE_SESSION_HISTORY的结构灰常灰常灰常的想像，功能也灰常灰常灰常的类似，都是记录活动session的操作记录，所不同点在于，V$ACTIVE_SESSION_HISTORY是ORACLE自动在内存中维护的，受制于其可用内存区限制，并非所有记录都能保存，而DBA_HIST_ACTIVE_SESS_HISTORY视图则是维护到磁盘中的。简单理解的话，就是说通常情况下，DBA_HIST_ACTIVE_SESS_HISTORY视图的数据量要比V$ACTIVE_SESSION_HISTORY的多。

提示：上述结构并不绝对，因为默认情况下DBA_HIST_ACTIVE_SESS_HISTORY字典的数据每10秒收集一次，而V$ACTIVE_SESSION_HISTORY中则是每秒一次，因此也有可能V$ACTIVE_SESSION_HISTORY中记录量更大。不过相对来说，DBA_HIST字典中保存的数据更长久。
 DBA_HIST_DATABASE_INSTANCE
　　该视图用来显示数据库和实例的信息，比如DBID，实例名，数据库版本等等信息，生成报表中第一行表格，就是由该视图生成的。如图：



　　如果你去分析awrrpt.sql脚本的话，会发现其中有如下脚本，上述表格中显示的内容信息，正是来自于下列脚本：

select distinct

(case when cd.dbid = wr.dbid and

cd.name = wr.db_name and

ci.instance_number = wr.instance_number and

ci.instance_name = wr.instance_name

then ¨* ¨

else ¨ ¨

end) || wr.dbid dbbid

, wr.instance_number instt_num

, wr.db_name dbb_name

, wr.instance_name instt_name

, wr.host_name host

from dba_hist_database_instance wr, v$database cd, v$instance ci;
 DBA_HIST_SNAPSHOT
　　该视图用来记录当前数据库收集到的快照信息。相信朋友应该还记得之前使用脚本生成报表时，输入完快照区间后显示的一堆列表，没错，那正是DBA_HIST_SNAPSHOT记录的内容，该段功能对应的代码如下：

select to_char(s.startup_time,¨dd Mon "at" HH24:mi:ss¨) instart_fmt

, di.instance_name inst_name

, di.db_name db_name

, s.snap_id snap_id

, to_char(s.end_interval_time,¨dd Mon YYYY HH24:mi¨) snapdat

, s.snap_level lvl

from dba_hist_snapshot s

, dba_hist_database_instance di

where s.dbid = :dbid

and di.dbid = :dbid

and s.instance_number = :inst_num

and di.instance_number = :inst_num

and di.dbid = s.dbid

and di.instance_number = s.instance_number

and di.startup_time = s.startup_time

and s.end_interval_time >= decode( &num_days

, 0 , to_date(¨31-JAN-9999¨,¨DD-MON-YYYY¨)

, 3.14, s.end_interval_time

, to_date(:max_snap_time,¨dd/mm/yyyy¨) - (&num_days-1))

order by db_name, instance_name, snap_id;






 LRM-112 LRM-113 EXP-19 When Performing Export With WHERE Clause and PARFILE (文档 ID 116258.1) 转到底部


--------------------------------------------------------------------------------

修改时间:2013-7-31类型:PROBLEM


***Checked for relevance on 31-Jul-2013***


Problem Description
-------------------

You are receiving the following errors when doing export with WHERE clause
and PARFILE:

LRM-00112: multiple values not allowed for parameter 'query'
LRM-00113: error when processing file 'hr_exp_refresh_emplid3.par'

EXP-00019: failed to process parameters, type 'EXP HELP=Y' for help
EXP-00000: Export terminated unsuccessfully

When you issue the following commands from command line it works fine:

exp scott/tiger tables=emp query=\"where job=\'SALESMAN\' and sal\<1600\"

or:

exp scott/tiger tables=emp query=\"where ename like \’SMI%\’\"

But if you issue:

exp scott/tiger PARFILE=xyz

where you PARFILE xyz looks like:

tables=emp query=\"where job=\'SALESMAN\' and sal\<1600\"

or:

tables=emp query=\"where ename like \’SMI%\’\"

or:

tables=emp query="where "HIREDATE" < '16-DEC-04'"

you receive the above error messages.


Solution
--------

Your PARFILE should look like:

tables=emp query="where JOB = 'SALESMAN' and salary < 1600"

or:

tables=emp query="where ename like ’SMI%’ "

or:

tables=emp query='where "HIREDATE" < ''16-DEC-04'''

(i.e. double single quotes around the '16-DEC-04' string, and no spaces)

and not:

tables=emp query=\"where job=\'SALESMAN\' and sal\<1600\"

or:

tables=emp query=\"where ename like \’SMI%\’\"

or:

tables=emp query="where "HIREDATE" < '16-DEC-04'"

You do not need the escape character('\') to make some reserved characters
a literal when using parfile.


Solution Explanation
--------------------

Note that the ", ', and < are all UNIX reserved characters (on NT " and ')
and thus need to be escaped when you are using command line.
If you are using a parfile these don't need to be escaped.




XP-00008: ORACLE error 942 encountered
ORA-00942: table or view does not exist
EXP-00024: Export views not installed, please notify your DBA
EXP-00000: Export terminated unsuccessfully

Cause
The export views were not installed during the original installation of the Oracle database environment.

Solution
To install the appropriate export views, have a DBA run the following script. while logged in as sys with sysdba permissions, run: $ORACLE_HOME\rdbms\admin\catexp.sql



'关机脚本
On Error Resume Next
Dim objShell,intReturn,mbFinished,moWindow
Set objShell = CreateObject("Wscript.Shell")
'Set moWindow = WScript.CreateObject("InternetExplorer.Application","IE_")
mbFinished = False

Dim OSVersion
Dim OSCaption
Dim MachineType

MachineType = TestMachineType()

If MachineType = "Laptop" Then
	'笔记本不执行该策略
	WScript.Quit

End If

OSCaption=GetOSCaption()
If (InStr(OSCaption, "Windows XP") Or InStr(OSCaption, "Windows 2000 Professional") Or InStr(OSCaption,"Windows 7")) Then
	Call Main() '操作系统版本为XP，才执行
Else
	intReturn = objShell.Popup("服务器系统，不尝试关机，5秒后自动退出关机程序",5, "服务器系统不进入关机状态......")
	WScript.Quit
	'WScript.Echo "不是Windows XP系统！不修改电源管理方案"
End If

'==================================主程序结束=============================================

Sub Main()
Do
	time1=time

	intReturn = objShell.Popup("系统即将在30分钟后进入关机状态，如需继续使用电脑，请点击【确定】",1805, "系统将在30分钟后进入关机状态......")

	time2=time
	time3=DateDiff("s",time1,time2)
	'if
	If time3>1800 Then
		Go_Sleep()
		Exit do
	Else
		Set moWindow = WScript.CreateObject("InternetExplorer.Application","IE_")
		Call Wait_Sleep()
	End If

Loop
End Sub

'================主程序完成================

Sub Go_Sleep()

Const Shutdown_Mod = 5 'Forced Shutdown (1 + 4)
Set objNet = WScript.CreateObject( "WScript.Network" )
Set objWMIService = GetObject("winmgmts:{impersonationLevel=impersonate," & _
 "(Shutdown)}!\\" & objNet.ComputerName & "\root\cimv2") '获得对象
Set colOSes = objWMIService.ExecQuery("SELECT * FROM Win32_OperatingSystem")
For Each objOS In colOSes '只可能有一个 objOS 在colOSes集合中
  intReturn = objOS.Win32Shutdown(Shutdown_Mod)
  If intReturn <> 0 Then
    msgbox "您有文档未保存，关机操作失败"
  End If
Next

	WScript.Quit

End Sub





Sub Wait_Sleep()
	dim i
	mbFinished = False
	i=0
	'Const wshYes = 6
	'Const wshNo = 7
	'Const wshYesNoDialog = 4
	'Const wshQuestionMark = 32


	'intReturn = objShell.Popup("10分钟后进入关机状态，您是否需要取消今天的关机任务？点击【Yes】将取消关机", _
    	'600, "取消关机", wshYesNoDialog + wshQuestionMark)



	moWindow.Navigate "about:blank"
	With moWindow.Document.ParentWindow.Document
		.Write "<body scroll=no style='background-color:#d4d0c8;font-size:9pt'>10分钟后进入关机状态，您是否需要取消今天的关机任务？<br>点击【加班中，今天不关机了】将取消关机。还剩余<font id='str'>600</font>秒进入关机状态<br><br><div align='center'><input type='submit' value='加班中，今天不关机了' Width='10px' id='btnOK'/>&nbsp;&nbsp;&nbsp;&nbsp;<input type='button' value='1小时后再决定' class='cancel' id='btnCancel'/></div></body>"
        	.Title ="取消关机"
	End With
	moWindow.Document.Close

	With moWindow
		.Toolbar = False
		.Statusbar = False
		.Menubar = False
		.Resizable = False
		.Width =500
		.Height=130
		.left= 350
		.top= 350
		Set .document.all.btnOK.onclick = GetRef("evtOK")
		Set .document.all.btnCancel.onclick = GetRef("evtCancel")
		.Visible = true
	End With


	Do
        	WScript.Sleep 1000
		i=i+1
		if i<600 then
			moWindow.Document.All.str.innerHTML = 600-i
        		If mbFinished Then Exit Do
		else
			Call Go_Sleep()
		end if
	Loop





	'If intReturn = wshYes Then
    		'Wscript.Echo "You clicked the Yes button."
	'    	WScript.Quit
	'ElseIf intReturn = wshNo Then
    		'Wscript.Echo "You clicked the No button."等待30分钟后继续提示
    	'	WScript.Sleep(1800000)
	'Else
    		'WScript.Echo "The popup timed out."
    	'	Call Go_Sleep()
	'End If

End Sub

Sub evtOK
	mbFinished = True
        moWindow.Quit
        Wscript.Quit
End Sub

Sub evtCancel
      	mbFinished = True
	moWindow.Visible = false
        moWindow.Quit
	'WScript.Sleep(5000)
	WScript.Sleep(3600000)
End Sub

Sub IE_onQuit
        mbFinished = True
End Sub


Function GetOSCaption()

	'返回计算机操作系统信息XP/Win2000/Win2003/Server等
	strComputer = "."
	Set objWMIService = GetObject("winmgmts:" _
 		& "{impersonationLevel=impersonate}!\\" & strComputer & "\root\cimv2")

	Set colOSes = objWMIService.ExecQuery("Select * from Win32_OperatingSystem")
	For Each objOS in colOSes
  		GetOSCaption=objOS.Caption '返回操作系统的版本信息
	Next

End function

Function TestMachineType()

	'查询计算机类型：台式机，笔记本等.....
	Dim DevType
	strComputer = "."
	Set objWMIService = GetObject("winmgmts:" _
    	& "{impersonationLevel=impersonate}!\\" & strComputer & "\root\cimv2")
	Set colChassis = objWMIService.ExecQuery _
    	("Select * from Win32_SystemEnclosure")
	For Each objChassis in colChassis
    	For  Each strChassisType in objChassis.ChassisTypes
        	Select Case strChassisType
            	Case 3
               	 	DevType="Desktop"
            	Case 4
                	DevType="Desktop"
            	Case 6
                	DevType="Desktop"
            	Case 7
                	DevType="Desktop"
            	Case 8
                	DevType="Laptop"
            	Case 9
                	DevType="Laptop"
            	Case 10
                	DevType="Laptop"
            	Case 11
                	DevType="Laptop"
            	Case 12
                	DevType="Laptop"
            	Case 13
                	DevType="Laptop"
            	Case 14
                	DevType="Laptop"
            	Case Else
                	DevType="Other"
            	End Select
    	Next
	Next
	TestMachineType =DevType

End Function





SPM演示
一、概念：SQL Plan Management，SQL执行计划管理
存储：SMB,SYSAUX(default:10%/Manual),自动清理

Step1：基于CBO产生最佳执行计划
Step2：在baseline中匹配该执行计划 Best(fixed)>Best(Accepted)>Best(Others)
Step3：如果找到，则使用；否则将该新执行计划放入计划历史中，直到演化测试性能提高或不降低时则转为accepted；
注：第一次执行基于CBO产生最佳执行计划，第二次执行时生成baseline

二、参数
SQL> show parameter baseline
NAME                                 TYPE        VALUE        备注
------------------------------------ ----------- -------- ----------------------
optimizer_capture_sql_plan_baselines boolean     TRUE      自动捕获并记录计划
optimizer_use_sql_plan_baselines     boolean     TRUE      激活baseline特性

三、属性
EANBLE:
--enable
DECLARE
  l_plans_altered PLS_INTEGER;
BEGIN
  l_plans_altered := DBMS_SPM.alter_sql_plan_baseline(sql_handle      => 'SQL_eb02b83ef37b86b8',
                                                      plan_name       => 'SQL_PLAN_fq0ps7vtrr1ps18935e29',
                                                      attribute_name  => 'enabled',
                                                      attribute_value => 'no');

  DBMS_OUTPUT.put_line('Plans Altered: ' || l_plans_altered);
END;
/

--ACCEPTED:
SELECT dbms_spm.evolve_sql_plan_baseline(
sql_handle => 'SQL_1f40ec92e7275269',
plan_name => NULL,
time_limit => 10,
verify => 'yes',
commit => 'no'
)
FROM dual;

FIXED:
--fixed
DECLARE
  l_plans_altered PLS_INTEGER;
BEGIN
  l_plans_altered := DBMS_SPM.alter_sql_plan_baseline(sql_handle      => 'SQL_eb02b83ef37b86b8',
                                                      plan_name       => 'SQL_PLAN_fq0ps7vtrr1ps18935e29',
                                                      attribute_name  => 'fixed',
                                                      attribute_value => 'no');
  DBMS_OUTPUT.put_line('Plans Altered: ' || l_plans_altered);
END;
/

四、案例
> Load from cache
> Load from AWR
> Load from Other DB
> Migrate from outline


1、创建baseline：内存中获取（使用优化后的sql）
(1) Original
SQL1: 21nhqyt19wvjq
plan_hash:930246749
select /*wangsj0811*/ count(*) from dbmgr.info t where t.finfoid is not null;

SQL2: d5sa7qvvr682c
plan_hash:1292474211
select /*wangsj0811*/ /*+full(t)*/ count(*) from dbmgr.info t where t.finfoid is not null;

SQL3: a7nf6c9q5b8ga
plan_hash:2726757802
select /*wangsj0811*/ /*+index(t pk_info)*/ count(*) from dbmgr.info t where t.finfoid is not null;

Display plan from baseline
select * from table(dbms_xplan.display_sql_plan_baseline(sql_handle => 'SQL_bf79ad3015c0c4eb',plan_name => 'SQL_PLAN_byydd60aw1j7b67e15d79'));

(2) Create baseline for original sql
declare
  l_pls number;
begin
  l_pls := DBMS_SPM.LOAD_PLANS_FROM_CURSOR_CACHE(sql_id          => '21nhqyt19wvjq',
                                                 plan_hash_value => 930246749,
                                                 enabled         => 'NO');
end;
/

--sql_handle: SQL_1f40ec92e7275269

(2) Cureent(Optimized)
sqlid: 37knpcgyja1s5
plan_hashvalue:1316258862
sqltext: select /*wangsj15*/ /*+index(t pk_info)*/ count(*) from dbmgr.info t where t.finfoid=26012
sql_handle: SQL_aea851f7a41d5f8e

(3) Load baseline from cache
declare l_pls number;
begin
  l_pls := DBMS_SPM.load_plans_from_cursor_cache(sql_id          => 'd5sa7qvvr682c', -- hinted_SQL_ID'
                                                 plan_hash_value => 1292474211, --hinted_plan_hash_value
                                                 sql_handle      => 'SQL_1f40ec92e7275269' --sql_handle_for_original
                                                 );
end;
/


declare l_pls number;
begin
  l_pls := DBMS_SPM.load_plans_from_cursor_cache(sql_id          => 'a7nf6c9q5b8ga', -- hinted_SQL_ID'
                                                 plan_hash_value => 2726757802, --hinted_plan_hash_value
                                                 sql_handle      => 'SQL_1f40ec92e7275269' --sql_handle_for_original
                                                 );
end;
/

(4) Drop former plan baseline if need
declare
  l_pls number;
begin
  l_pls := DBMS_SPM.DROP_SQL_PLAN_BASELINE(sql_handle => 'SQL_1f40ec92e7275269', 							 --sql_handle_for_original
                                           plan_name  => 'SQL_PLAN_1yh7ckbmkfnm9a7cb5955'		   --sql_plan_name_for_original
                                           );
end;
/

2、创建baseline：AWR报告中好的执行计划

--Capture plan baseline from AWR
EXEC DBMS_SQLTUNE.CREATE_SQLSET(sqlset_name => 'plan_baseline_wangsj',sqlset_owner => 'DBMGR');
declare
baseline_ref_cursor DBMS_SQLTUNE.SQLSET_CURSOR;
begin
open baseline_ref_cursor for
select VALUE(p) from table(DBMS_SQLTUNE.SELECT_WORKLOAD_REPOSITORY(10464, 10467,'sql_id='||CHR(39)||'a7nf6c9q5b8ga'||CHR(39)||' and plan_hash_value=2726757802',NULL,NULL,NULL,NULL,NULL,NULL,'ALL')) p;
DBMS_SQLTUNE.LOAD_SQLSET('plan_baseline_wangsj', baseline_ref_cursor);
end;
/

--Load plan from sqlset
set serveroutput on
declare
my_integer pls_integer;
begin
my_integer := dbms_spm.load_plans_from_sqlset(sqlset_name => 'plan_baseline_wangsj',sqlset_owner => 'DBMGR',fixed => 'NO',enabled => 'YES');
DBMS_OUTPUT.PUT_line(my_integer);
end;
/

3、创建baseline：从其他库导入
(1) Create baseline for better SQL in DB1
declare
  l_pls number;
begin
  l_pls := DBMS_SPM.LOAD_PLANS_FROM_CURSOR_CACHE(sql_id          => 'a7nf6c9q5b8ga',
                                                 plan_hash_value => 2726757802,
                                                 enabled         => 'NO');
end;
/

--check the baesline
select t.sql_handle,
       t.plan_name,
       t.sql_text,
       t.creator,
       t.origin,
       to_char(t.created, 'yyyy-mm-dd hh24:mi:ss') as created,
       t.enabled,
       t.accepted,
       t.fixed
  from dba_sql_plan_baselines t
 where t.creator = 'DBMGR'
   and t.sql_text like '%wangsj0811%'
   and t.sql_text like  '%/*+index(t pk_info)*/%'
   and t.sql_text not like '%dba_sql_plan_baselines%'
   and t.sql_text not like '%v$sql%'
   and t.created > sysdate - 1 / 24
 order by t.created desc
;

(2) Create stgtab for baseline
exec dbms_spm.create_stgtab_baseline(table_name => 'stgtab_baseline_wangsj',table_owner => 'dbmgr');

(3) Pack baseline into Stgtable
SQL3: a7nf6c9q5b8ga
plan_hash:2726757802
select /*wangsj0811*/ /*+index(t pk_info)*/ count(*) from dbmgr.info t where t.finfoid is not null;
sql_handle:SQL_cd496c73722fbdb9
plan_name:SQL_PLAN_cukbcfdt2zgdt67e15d79

SET SERVEROUTPUT ON
DECLARE
   l_plans_packed  PLS_INTEGER;
BEGIN
   l_plans_packed := DBMS_SPM.pack_stgtab_baseline(
    table_name      => 'stgtab_baseline_wangsj',
    table_owner     => 'DBMGR',
    sql_handle => 'SQL_cd496c73722fbdb9',
    plan_name => 'SQL_PLAN_cukbcfdt2zgdt67e15d79');

   DBMS_OUTPUT.put_line('Plans Packed: ' || l_plans_packed);
END;
/

(4) imp/impdp stgtab into the Target DB from DB1
--exp
userid='/ as sysdba'
tables=dbmgr.stgtab_baseline_wangsj
file=/paic/cx/epcis/data/osepcis/wangsj/exp/exp_stg_01.dmp
log=/paic/cx/epcis/data/osepcis/wangsj/exp/exp_stg.log
filesize=1G

--Environment Init
declare
  l_pls number;
begin
  l_pls := DBMS_SPM.DROP_SQL_PLAN_BASELINE(sql_handle => 'SQL_cd496c73722fbdb9', 							 --sql_handle_for_original
                                           plan_name  => 'SQL_PLAN_cukbcfdt2zgdt67e15d79'		   --sql_plan_name_for_original

                                           );
end;
/

drop table dbmgr.stgtab_baseline_wangsj;

--imp stgtab
userid='/ as sysdba'
tables=stgtab_baseline_wangsj
fromuser=dbmgr
touser=dbmgr
file=/paic/stg/oracle/11g/otzj11g/wangsj/exp/exp_stg_01.dmp
log=/paic/stg/oracle/11g/otzj11g/wangsj/exp/imp_stg.log
resumable=y
resumable_timeout=20000000

(5) Unpacked stgtab
SET SERVEROUTPUT ON
DECLARE
   l_plans_unpacked  PLS_INTEGER;
BEGIN
   l_plans_unpacked := DBMS_SPM.unpack_stgtab_baseline(
    table_name      => 'stgtab_baseline_wangsj',
    table_owner     => 'DBMGR',
    sql_handle => 'SQL_cd496c73722fbdb9',
    plan_name => 'SQL_PLAN_cukbcfdt2zgdt67e15d79');
   DBMS_OUTPUT.put_line('Plans Unpacked: ' || l_plans_unpacked);
END;
/

4、Migrate from outline
(1) Source DB
SQL_hashvalue: 3534787754
SELECT /*wangsj0815_spm*/ count(*)  from dbmgr.info t
pa18stg=(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.31.22.199)(PORT=1583))(connect_data =(sid = pa18stg)))

(2) Create outline for original sql on the special category
CREATE OR REPLACE OUTLINE idx_spm_wangsj for category spm ON
SELECT /*wangsj0815_spm*/ count(*)  from dbmgr.info t
;

exec dbms_outln.update_signatures;
alter system set use_stored_outlines=spm;

(3) Create outline for Hinted sql
CREATE OR REPLACE OUTLINE full_spm_wangsj for category spm ON
SELECT /*wangsj0815_spm*/ /*+full(t)*/ count(*)  from dbmgr.info t
;

(4) Exchange
UPDATE OUTLN.OL$HINTS
SET OL_NAME=DECODE(OL_NAME,'IDX_SPM_WANGSJ','FULL_SPM_WANGSJ','FULL_SPM_WANGSJ','IDX_SPM_WANGSJ')
WHERE OL_NAME IN ('IDX_SPM_WANGSJ','FULL_SPM_WANGSJ');
COMMIT;

(5) Update
drop outline FULL_SPM_WANGSJ;
exec dbms_outln.update_signatures;

(6) Check
SQL> @sql9i
HASH_VALUE     CHILD# PLAN_VALUE   EXEC_CNT FIRST_LOAD_TIME      LAST_LOAD_TIME         DISK_PER BUFFER_PER ROWS_PROCESSED    CPU_PER ELAPSE_PER OUTLINE_CA PARSING_USER   MODULE
---------- ---------- ---------- ---------- -------------------- -------------------- ---------- ---------- -------------- ---------- ---------- ---------- -------------- --------------------------------------------------
3534787754          0 3647386531          1 2013-08-14/17:53:30  2013-08-14/17:53:30       84751      85000              1          5          9 SPM        DBMGR          PL/SQL Developer

SQL> @plan9i

Optimizer Plan:
---------------------------------------------------------------------------------------------------
|   id| Operation                         | PHV/Object Name               |  Rows | Bytes|   Cost |
|    0| SELECT STATEMENT                  |-------------                  |       |      |   8192 |
|    1| SORT AGGREGATE                    |                               |     1 |      |        |
|    2|  TABLE ACCESS FULL                |INFO                           |   215K|      |   8192 |
---------------------------------------------------------------------------------------------------

--The result indicated that this SQL have used the outline(Full table )

(7) exp outline
userid="outln/outln"
tables=(outln.ol$,outln.ol$hints,outln.ol$nodes)
file=outln_20130815.dmp
query="WHERE ol_name='IDX_SPM_WANGSJ'"
STATISTICS=NONE


(8) Migrate outline to baseline
variable report clob;
exec :report:=DBMS_SPM.MIGRATE_STORED_OUTLINE( attribute_name=>'CATEGORY',attribute_value => 'SPM');






SQL> set echo on---------------------------------------------------设置运行命令是是否显示语句
SQL> set feedback on----------------------------------------------设置显示“已选择XX行”
SQL> set colsep | ---------------------------------------------------设置列与列之间的分割符号
SQL> set pagesize 10-----------------------------------------------设置每一页的行数
SQL> SET SERVEROUTPUT ON-------------------------------设置允许显示输出类似dbms_output
SQL> set heading on------------------------------------------------设置显示列名
SQL> set timing on--------------------------------------------------设置显示“已用时间：XXXX”
SQL> set time on-----------------------------------------------------设置显示当前时间
SQL> set autotrace on-----------------------------------------------设置允许对执行的sql进行分析



拼接statssqltext
  declare
  cursor cur is select distinct hash_value as hash_value from stats$sqltext where sql_text like '%CIT_JOURNAL_INTERFACE%';
  temp_sql clob;
  temp_hashvalue number(20);
  begin
   open cur;
   loop
    fetch cur into temp_hashvalue;
    exit when cur%notfound;
      select replace(wm_concat(sql_text), ',', '') || ';' into temp_sql from stats$sqltext  where hash_value =temp_hashvalue;
      insert into test values(temp_sql);
      temp_sql := '';
    end loop;
    commit;
    close cur;
  end;


有些时候因为测试环境需要,我们需要使用生产库的备份集在另外一台新的机器上做恢复(前提是新机器事先安装Oracle软件,版本跟原库一致),下面是恢复过程.

1.在原库上做全备(在原库上操作)
run{
allocate channel c1 device type disk;
allocate channel c2 device type disk;
backup format '/u02/rman_backup/full_backup/full_backup_%T_%s' database;
sql 'alter system archive log current';
backup format '/u02/rman_backup/full_backup/arc_backup_%T_%s' archivelog all;
release channel c1;
release channel c2;
}
2.查看原库的DBID(在原库上操作)
因为在做恢复的过程中需要设定DBID,这里需要找到原库的DBID
SQL> select dbid from v$database;
      DBID
----------
1820932955

-----以下的操作没有特殊说明,全部在目的库上操作-----
3.使用ftp将原库上的备份集拷贝到目的库的目录/u02/ftp/(具体操作省略)

4.在新机器上创建如下目录
mkdir /u02/mydb
mkdir -p /u02/mydb/oracl/{adump,bdump,cdump,dpdump,udump,pfile}
mkdir -p /u02/mydb/oradata/oracl
mkdir -p /u02/mydb/flash_recovery_area

5.创建密码文件
orapwd file=/u01/app/oracle/product/10.2.0/db_1/dbs/orapworacl.ora password=oracle

6.恢复参数文件
[oracle@hxlbak ~]$ rman target /

Recovery Manager: Release 10.2.0.1.0 - Production on Fri Jun 29 06:51:54 2012

Copyright (c) 1982, 2005, Oracle.  All rights reserved.

connected to target database (not started)

RMAN>set dbid 1820932955 -- 这里的dbid需要跟原库保持一致

RMAN> startup nomount

startup failed: ORA-01078: failure in processing system parameters
LRM-00109: could not open parameter file '/u01/app/oracle/product/10.2.0/db_1/dbs/initoracl.ora'

starting Oracle instance without parameter file for retrival of spfile
Oracle instance started

Total System Global Area     159383552 bytes

Fixed Size                     1218268 bytes
Variable Size                 54528292 bytes
Database Buffers             100663296 bytes
Redo Buffers                   2973696 bytes

RMAN> restore spfile to pfile '/u01/app/oracle/product/10.2.0/db_1/dbs/initoracl.ora' from '/u02/ftp/full_backup_20120628_37';

Starting restore at 29-JUN-12
using target database control file instead of recovery catalog
allocated channel: ORA_DISK_1
channel ORA_DISK_1: sid=36 devtype=DISK

channel ORA_DISK_1: autobackup found: /u02/ftp/full_backup_20120628_37
channel ORA_DISK_1: SPFILE restore from autobackup complete
Finished restore at 29-JUN-12


备份集full_backup_20120628_3里7包含了参数文件,我们在备份数据的时候会默认备份参数文件,可以在原库使用list backup查看,list backup输出部分内容如下:

BS Key  Type LV Size       Device Type Elapsed Time Completion Time
------- ---- -- ---------- ----------- ------------ ---------------
35      Full    80.00K     DISK        00:00:01     28-JUN-12
        BP Key: 35   Status: AVAILABLE  Compressed: NO  Tag: TAG20120628T184555
        Piece Name: /u02/rman_backup/full_backup/full_backup_20120628_37
  SPFILE Included: Modification time: 28-JUN-12

恢复了参数文件initoracl.ora后,因为原库和目的库各文件保存的路径不一致,这个时候需要修改参数文件,修改的地方如下,各文件路径指向新目录:

*.audit_file_dest='/u02/mydb/oracl/adump'
*.background_dump_dest='/u02/mydb/oracl/bdump'
*.control_files='/u02/mydb/oradata/oracl/control01.ctl','/u02/mydb/oradata/oracl/control02.ctl','/u02/mydb/oradata/oracl/control03.ctl'
*.core_dump_dest='/u02/mydb/oracl/cdump'
*.db_recovery_file_dest='/u02/mydb/flash_recovery_area'
*.user_dump_dest='/u02/mydb/oracl/udump'

7.使用编辑好的参数文件启动数据库到nomount状态并恢复控制文件

SQL> startup nomount pfile=/u01/app/oracle/product/10.2.0/db_1/dbs/initoracl.ora
ORACLE instance started.

Total System Global Area 1048576000 bytes
Fixed Size                  1223368 bytes
Variable Size             310379832 bytes
Database Buffers          734003200 bytes
Redo Buffers                2969600 bytes
SQL>

恢复控制文件
RMAN> restore controlfile from '/u02/ftp/full_backup_20120628_36';

Starting restore at 29-JUN-12
using target database control file instead of recovery catalog
allocated channel: ORA_DISK_1
channel ORA_DISK_1: sid=155 devtype=DISK

channel ORA_DISK_1: restoring control file
channel ORA_DISK_1: restore complete, elapsed time: 00:00:05
output filename=/u02/mydb/oradata/oracl/control01.ctl
output filename=/u02/mydb/oradata/oracl/control02.ctl
output filename=/u02/mydb/oradata/oracl/control03.ctl
Finished restore at 29-JUN-12

跟参数文件一样,在备份数据的时候会默认备份了控制文件,备份集full_backup_20120628_36中包含了控制文件,同样可以在原库使用list backup查看,list backup输出部分内容如下:

BS Key  Type LV Size       Device Type Elapsed Time Completion Time
------- ---- -- ---------- ----------- ------------ ---------------
34      Full    6.98M      DISK        00:00:02     28-JUN-12
        BP Key: 34   Status: AVAILABLE  Compressed: NO  Tag: TAG20120628T184555
        Piece Name: /u02/rman_backup/full_backup/full_backup_20120628_36
  Control File Included: Ckp SCN: 1545845      Ckp time: 28-JUN-12

8.启动数据库到mount状态并注册备份集
RMAN> alter database mount;

database mounted
released channel: ORA_DISK_1

注册备份集,因为控制文件中的保留的备份信息是原库的,我们这里需要重新注册新库路径下的备份集
RMAN> catalog start with '/u02/ftp/';

Starting implicit crosscheck backup at 29-JUN-12
allocated channel: ORA_DISK_1
channel ORA_DISK_1: sid=155 devtype=DISK
Crosschecked 29 objects
Finished implicit crosscheck backup at 29-JUN-12

Starting implicit crosscheck copy at 29-JUN-12
using channel ORA_DISK_1
Finished implicit crosscheck copy at 29-JUN-12

searching for all files in the recovery area
cataloging files...
no files cataloged

searching for all files that match the pattern /u02/ftp/

List of Files Unknown to the Database
=====================================
File Name: /u02/ftp/full_backup_20120628_35
File Name: /u02/ftp/full_backup_20120628_37
File Name: /u02/ftp/full_backup_20120628_34
File Name: /u02/ftp/arc_backup_20120628_38
File Name: /u02/ftp/arc_backup_20120628_40
File Name: /u02/ftp/full_backup_20120628_36
File Name: /u02/ftp/full_backup_20120628_31
File Name: /u02/ftp/full_backup_20120628_33
File Name: /u02/ftp/arc_backup_20120628_39
File Name: /u02/ftp/full_backup_20120628_32
File Name: /u02/ftp/full_backup_20120628_30

Do you really want to catalog the above files (enter YES or NO)  yes
cataloging files...
cataloging done

List of Cataloged Files
=======================
File Name: /u02/ftp/full_backup_20120628_35
File Name: /u02/ftp/full_backup_20120628_37
File Name: /u02/ftp/full_backup_20120628_34
File Name: /u02/ftp/arc_backup_20120628_38
File Name: /u02/ftp/arc_backup_20120628_40
File Name: /u02/ftp/full_backup_20120628_36
File Name: /u02/ftp/full_backup_20120628_31
File Name: /u02/ftp/full_backup_20120628_33
File Name: /u02/ftp/arc_backup_20120628_39
File Name: /u02/ftp/full_backup_20120628_32
File Name: /u02/ftp/full_backup_20120628_30

9.列出当前的所有数据文件

SQL> column name format a60;
SQL> select file# as "file/grp#", name from v$datafile;
 file/grp# NAME
---------- ------------------------------------------------------------
         1 /u01/app/oracle/oradata/oracl/system01.dbf';
         2 /u01/app/oracle/oradata/oracl/undotbs01.dbf';
         3 /u01/app/oracle/oradata/oracl/sysaux01.dbf';
         4 /u01/app/oracle/oradata/oracl/users01.dbf';
         5 /u01/app/oracle/oradata/oracl/hxl01.dbf';
         6 /u01/app/oracle/oradata/oracl/hxl02.dbf';
         7 /u01/app/oracle/oradata/oracl/hxl03.dbf';
         8 /u01/app/oracle/oradata/oracl/hxl04.dbf';
         9 /u01/app/oracle/oradata/oracl/hxl05.dbf';
        10 /u02/app/oracle/oradata/oracl/hxl06.dbf';
        11 /u02/app/oracle/oradata/oracl/hxl07.dbf';
 file/grp# NAME
---------- ------------------------------------------------------------
        12 /u02/app/oracle/oradata/oracl/hxl08.dbf';
        13 /u02/app/oracle/oradata/oracl/hxl09.dbf';
        14 /u02/app/oracle/oradata/oracl/hxl10.dbf';

可以看到,当前控制文件中记录的数据文件的路径是原来的路径,我们在做恢复的时候需要指向新的路径.

10.恢复数据库
RMAN> run{
set newname for datafile  1 to '/u02/mydb/oradata/oracl/system01.dbf';
set newname for datafile  2 to '/u02/mydb/oradata/oracl/undotbs01.dbf';
set newname for datafile  3 to '/u02/mydb/oradata/oracl/sysaux01.dbf';
set newname for datafile  4 to '/u02/mydb/oradata/oracl/users01.dbf';
set newname for datafile  5 to '/u02/mydb/oradata/oracl/hxl01.dbf';
set newname for datafile  6 to '/u02/mydb/oradata/oracl/hxl02.dbf';
set newname for datafile  7 to '/u02/mydb/oradata/oracl/hxl03.dbf';
set newname for datafile  8 to '/u02/mydb/oradata/oracl/hxl04.dbf';
set newname for datafile  9 to '/u02/mydb/oradata/oracl/hxl05.dbf';
set newname for datafile 10 to '/u02/mydb/oradata/oracl/hxl06.dbf';
set newname for datafile 11 to '/u02/mydb/oradata/oracl/hxl07.dbf';
set newname for datafile 12 to '/u02/mydb/oradata/oracl/hxl08.dbf';
set newname for datafile 13 to '/u02/mydb/oradata/oracl/hxl09.dbf';
set newname for datafile 14 to '/u02/mydb/oradata/oracl/hxl10.dbf';
restore database;
switch datafile all;
recover database;
}

11.打开数据库
alter database open resetlogs;

-- The End --


根据表名搜索SQL语句
STATS$SQLTEXT


这个视图让我很迷惑,stats$sqltext一个hash_value是只对应一个sql语句吗 

1。 stats$sqltext 里有数据

2。需要写一个function 来得到完整SQL_TEXT
PHP code:--------------------------------------------------------------------------------
第一个获取SQLtext from stats$sqltext,只能处理长度 < 4000 的。
CREATE OR REPLACE FUNCTION get_sql_old (
   hash_in   IN   INTEGER
)
   RETURN VARCHAR2
IS
   sql_text    VARCHAR2 (4000);
   CURSOR sql_pieces_cur
   IS
      SELECT   sql_text
          FROM STATS$SQLTEXT
         WHERE  hash_value = hash_in
      ORDER BY piece ASC;
BEGIN
   FOR sql_pieces_rec IN sql_pieces_cur
   LOOP
    if (length(sql_text) +length(sql_pieces_rec.sql_text) >= 4000 )
     then
        RETURN sql_text;
    end if;
      sql_text := sql_text || sql_pieces_rec.sql_text;
   END LOOP;
   RETURN sql_text;
EXCEPTION
    When others then
    return sql_text;
END;
/

第二个，对付长度大于 4000的sqltext
CREATE OR REPLACE procedure get_sql_proc_2 (
hash_in  IN  INTEGER,
sqltext  out varchar2,
sqltext1 out varchar2,
sqltext2 out varchar2,
sqltext3 out varchar2,
sqltext4 out varchar2,
sqltext5 out varchar2,
sqltext6 out varchar2,
sqltext7 out varchar2,
sqltext8 out varchar2,
sqltext9 out varchar2
)
IS
   no number default 1;
   CURSOR sql_pieces_cur
   IS
      SELECT      sql_text
      FROM    stats$sqltext
      WHERE    hash_value = hash_in
      ORDER BY    piece ASC;
BEGIN
   FOR sql_pieces_rec IN sql_pieces_cur
   LOOP
    if (length(sqltext) + length(sql_pieces_rec.sql_text) >= 4000 )
     then
        CASE
            when no = 1 then sqltext1 := sqltext;
            when no = 2 then sqltext2 := sqltext;
            when no = 3 then sqltext3 := sqltext;
            when no = 4 then sqltext4 := sqltext;
            when no = 5 then sqltext5 := sqltext;
            when no = 6 then sqltext6 := sqltext;
        END CASE;
        sqltext := '';
        no := no + 1 ;
    end if;
    if (length(sql_pieces_rec.sql_text) = 64 )then
              sqltext := sqltext || sql_pieces_rec.sql_text;
    else
        sqltext := sqltext ||'
'|| sql_pieces_rec.sql_text;
    end if;
   END LOOP;
END;
/

rollingpig 写的这个脚本怎么好象同一个hash_value会有很多 sqltext似的,谁能帮我解释解释吗 

检查需要恢复的数据文件
--check
select to_char(controlfile_change#),controlfile_time from v$database;
select to_char(checkpoint_change#),checkpoint_time,last_change#,last_time from v$datafile;
select to_char(checkpoint_change#),checkpoint_time from v$datafile_header;

select dbms_flashback.get_system_change_number from dual;

declare v_sql varchar2(100);
 begin
 v_sql := 'grant  insert,update,delete  on  CDMSDATA.FUND_SHARE_REC to  pub_test';
 execute immediate v_sql;
end;
/

shell 创建多个目录
mkdir -p $OBASE/admin/${NEWSID}/{adump,bdump,cdump,udump,dpdump}
echo "inventory_loc=${OBASE}/oraInventory" > ${OBASE}/oraInst.loc
echo "inst_group=dba" >> ${OBASE}/oraInst.loc

--按序列统计大小
 select a.FIRST_TIME,
        a.sequence#,
        a.blocks * a.block_size / 1024 / 1024 log_size_mb
   from v$archived_log a
  where a.FIRST_TIME > sysdate - 1
    and a.dest_id=1
  order by a.FIRST_TIME desc

--按小时查询日志大小
select a.time, trunc(sum(a.log_size_mb), 0) log_size_mb
  from (select to_char(FIRST_TIME, 'yyyy-mm-dd hh24') time,
               aa.blocks * aa.block_size / 1024 / 1024 log_size_mb
          from v$archived_log aa
           where aa.dest_id = 1) a
-- where time < '2011-05-01 16'
--  and time > '2011-05-01 14'
 group by TIME
 order by time desc

--按小时查询归档次数
select a.time, count(a.sequence#) count
  from (select to_char(FIRST_TIME, 'yyyy-mm-dd hh24') time, sequence#
          from v$archived_log
         where dest_id = 1) a
-- where time < '2011-05-01 16'
--  and time > '2011-05-01 14'
 group by TIME
 order by time desc


--按天数统计日志量
 select a.time,sum(a.bytes) / 1024 / 1024/1024
   from (select to_char(FIRST_TIME, 'yyyy-mm-dd') time,
                blocks * block_size bytes
           from v$archived_log where dest_id=1) a
 group by a.time
 order by a.time desc

--查询REDO大于10MB的session
col machine format a20
col osuser format a20
set lines 150
select sysdate,
       se.username,
       se.sid,
       se.serial#,
       se.status,
       se.machine,
       se.osuser,
       round(st.value / 1024 / 1024) redosize,
       sa.sql_text
  from v$session se, v$sesstat st, v$sqlarea sa
 where se.sid = st.sid
   and st.STATISTIC# =
       (select STATISTIC# from v$statname where NAME = 'redo size')
      --and se.username is not null
   and st.value > 10 * 1024 * 1024
   and se.SQL_ADDRESS = sa.ADDRESS
   and se.SQL_HASH_VALUE = sa.HASH_VALUE
 order by redosize;


select trunc(completion_time),sum(mb)/1024 day_gb
from (select name,completion_time,blocks*block_size/1024/1024 Mb
from v$archived_log)
group by trunc(completion_time)  having trunc(completion_time)> trunc(sysdate)-5 ;


oracle如何查询每天归档日志的大小  2007-05-20 18:33:23
分类： Oracle
SELECT trunc(first_time) "Date",
to_char(first_time, 'Dy') "Day",
count(1) "Total",
SUM(decode(to_char(first_time, 'hh24'),'00',1,0)) "h0",
SUM(decode(to_char(first_time, 'hh24'),'01',1,0)) "h1",
SUM(decode(to_char(first_time, 'hh24'),'02',1,0)) "h2",
SUM(decode(to_char(first_time, 'hh24'),'03',1,0)) "h3",
SUM(decode(to_char(first_time, 'hh24'),'04',1,0)) "h4",
SUM(decode(to_char(first_time, 'hh24'),'05',1,0)) "h5",
SUM(decode(to_char(first_time, 'hh24'),'06',1,0)) "h6",
SUM(decode(to_char(first_time, 'hh24'),'07',1,0)) "h7",
SUM(decode(to_char(first_time, 'hh24'),'08',1,0)) "h8",
SUM(decode(to_char(first_time, 'hh24'),'09',1,0)) "h9",
SUM(decode(to_char(first_time, 'hh24'),'10',1,0)) "h10",
SUM(decode(to_char(first_time, 'hh24'),'11',1,0)) "h11",
SUM(decode(to_char(first_time, 'hh24'),'12',1,0)) "h12",
SUM(decode(to_char(first_time, 'hh24'),'13',1,0)) "h13",
SUM(decode(to_char(first_time, 'hh24'),'14',1,0)) "h14",
SUM(decode(to_char(first_time, 'hh24'),'15',1,0)) "h15",
SUM(decode(to_char(first_time, 'hh24'),'16',1,0)) "h16",
SUM(decode(to_char(first_time, 'hh24'),'17',1,0)) "h17",
SUM(decode(to_char(first_time, 'hh24'),'18',1,0)) "h18",
SUM(decode(to_char(first_time, 'hh24'),'19',1,0)) "h19",
SUM(decode(to_char(first_time, 'hh24'),'20',1,0)) "h20",
SUM(decode(to_char(first_time, 'hh24'),'21',1,0)) "h21",
SUM(decode(to_char(first_time, 'hh24'),'22',1,0)) "h22",
SUM(decode(to_char(first_time, 'hh24'),'23',1,0)) "h23"
FROM V$log_history
group by trunc(first_time), to_char(first_time, 'Dy')
Order by 1
SELECT SUM(BLOCKS *BLOCK_SIZE )/1024/1024 AS "Size(M)",TRUNC(completion_time) FROM v$archived_log
GROUP BY TRUNC(completion_time)


通过v$mystat查询 当前 session 的统计信息，同时也可以查得session 的Redo 生成情况：

col name format a30

_selecta.name,b.value

from v$statname a,v$mystat b

where a.statistic#=b.statistic# and a.name='redo size';



NAME                                VALUE
------------------------------ ----------
redo size                           20112





通过v$sysstat 查得全局Redo 的生成量

col value for 9999999999999999

_selectname,value

from v$sysstat

where name='redo size';



NAME                                VALUE
------------------------------ ----------
redo size                      3139476724



从v$sysstat 查得自数据库实例启动以来累积日志生成量，可以根据实例启动时间来

大致估算每天数据库日志生成量：

alter session set nls_date_format='yyyy-mm-dd HH24:mi:ss';



_selectstartup_time from v$instance;



_select(_selectvalue/1024/1024/1024) from v$sysstat where name='redo size')/

(_selectround(sysdate - (_selectstartup_time from v$instance)) from dual) REDO_GB_PER_DAY

from dual;



REDO_GD_PER_DAY
---------------
     .100823532



归档日志生成量，v$archived_log 根据一段时间的归档日志量进行估算：



_selectname,completion_time,blocks*block_size/1024/1024 Mb

from v$archived_log where rownum < 11

and completion_time between trunc(sysdate) - 2 and trunc(sysdate) - 1;



NAME                                          COMPLETION_TIME             MB
--------------------------------------------- ------------------- ----------
/oracle/oradata/archive/1_108_759450376.dbf   2011-09-14 13:00:18 36.9335938
/oracle/oradata/archive/1_109_759450376.dbf   2011-09-14 22:00:23 40.0454102



某日全天日志生成查询计算：



_selecttrunc(completion_time),sum(Mb)/1024 Day_GB

from (_selectname,completion_time,blocks*block_size/1024/1024 Mb

from v$archived_log

where completion_time between trunc(sysdate) - 2 and trunc(sysdate) - 1)

group by trunc(completion_time);



TRUNC(COMPLETION_TI     DAY_GB
------------------- ----------
2011-09-14 00:00:00 .075174809



最近日期的日志生成统计：

_selecttrunc(completion_time),sum(mb)/1024 day_gb

from (_selectname,completion_time,blocks*block_size/1024/1024 Mb

from v$archived_log)

group by trunc(completion_time);



TRUNC(COMPLETION_TI     DAY_GB
------------------- ----------
2011-08-29 00:00:00 .078902245
2011-09-07 00:00:00 .085594654
2011-09-15 00:00:00  .11264801
2011-08-27 00:00:00 .152146816
2011-09-06 00:00:00  .08170557
2011-08-19 00:00:00 .073926926
2011-09-13 00:00:00 .122589588
2011-09-14 00:00:00 .075174809



综述：根据每日归档的生成量，也可以反过来估计每日的数据库活动性及周期性，并决定空间分配问题（网络摘录2011/9/16



分析对比SQL语句在不同执行计划中的执行情况

SELECT st2.SQL_ID,
   st2.PLAN_HASH_VALUE,
   st_long.PLAN_HASH_VALUE l_PLAN_HASH_VALUE,
   st2.CPU_MINS,
   st_long.CPU_MINS l_CPU_MINS,
   st2.ELA_MINS,
   st_long.ELA_MINS l_ELA_MINS,
   st2.EXECUTIONS,   www.2cto.com
   st_long.EXECUTIONS l_EXECUTIONS,
   st2.CROWS,
   st_long.CROWS l_CROWS,
   st2.CPU_MINS_PER_ROW,
   st_long.CPU_MINS_PER_ROW l_CPU_MINS_PER_ROW

FROM
   (SELECT st.SQL_ID,
     st.PLAN_HASH_VALUE,
     SUM(st.EXECUTIONS_DELTA) EXECUTIONS,
     SUM(st.ROWS_PROCESSED_DELTA) CROWS,
     TRUNC(SUM(st.CPU_TIME_DELTA)                                         /1000000/60) CPU_MINS ,   www.2cto.com
     DECODE( SUM(st.ROWS_PROCESSED_DELTA), 0 , 0 , (SUM(st.CPU_TIME_DELTA)/1000000/60)/SUM(st.ROWS_PROCESSED_DELTA) ) CPU_MINS_PER_ROW ,
     TRUNC(SUM(st.ELAPSED_TIME_DELTA)                                     /1000000/60) ELA_MINS

   FROM DBA_HIST_SQLSTAT st
   WHERE 1                     =1
   AND ( st.CPU_TIME_DELTA    !=0
   OR st.ROWS_PROCESSED_DELTA !=0)
   GROUP BY st.SQL_ID,
     st.PLAN_HASH_VALUE
   ) st2,   www.2cto.com
   (SELECT st.SQL_ID,
     st.PLAN_HASH_VALUE,
     SUM(st.EXECUTIONS_DELTA) EXECUTIONS,
     SUM(st.ROWS_PROCESSED_DELTA) CROWS,
     TRUNC(SUM(st.CPU_TIME_DELTA)                                         /1000000/60) CPU_MINS ,

     DECODE( SUM(st.ROWS_PROCESSED_DELTA), 0 , 0 , (SUM
(st.CPU_TIME_DELTA)/1000000/60)/SUM(st.ROWS_PROCESSED_DELTA) ) CPU_MINS_PER_ROW ,
     TRUNC(SUM(st.ELAPSED_TIME_DELTA)                                     /1000000/60) ELA_MINS   www.2cto.com
   FROM DBA_HIST_SQLSTAT st
   WHERE 1                                         =1
   AND ( st.CPU_TIME_DELTA                        !=0
   OR st.ROWS_PROCESSED_DELTA                     !=0)
   HAVING TRUNC(SUM(st.CPU_TIME_DELTA)/1000000/60) > 10
   GROUP BY st.SQL_ID,
     st.PLAN_HASH_VALUE
   ) st_long

WHERE 1                                                                            =1
AND st2.SQL_ID                                                                     = st_long.SQL_ID
AND st_long.CPU_MINS_PER_ROW/DECODE(st2.CPU_MINS_PER_ROW,0,1,st2.CPU_MINS_PER_ROW) > 2   www.2cto.com
ORDER BY l_CPU_MINS DESC,
   st2.SQL_ID,
   st_long.CPU_MINS DESC,
   st2.PLAN_HASH_VALUE;

-- 检查数据库热块
SET LINESIZE 200
SET VERIFY OFF

SELECT *
FROM   (SELECT name,
               addr,
               gets,
               misses,
               sleeps
        FROM   v$latch_children
        WHERE  name = 'cache buffers chains'
        AND    misses > 0
        ORDER BY misses DESC)
WHERE  rownum < 11;

ACCEPT address PROMPT "Enter ADDR: "

COLUMN owner FORMAT A15
COLUMN object_name FORMAT A30
COLUMN subobject_name FORMAT A20

SELECT *
FROM   (SELECT o.owner,
               o.object_name,
               o.subobject_name,
               o.object_type,
               bh.tch,
               bh.obj,
               bh.file#,
               bh.dbablk,
               DECODE(bh.class,1,'data block',
                               2,'sort block',
                               3,'save undo block',
                               4,'segment header',
                               5,'save undo header',
                               6,'free list',
                               7,'extent map',
                               8,'1st level bmb',
                               9,'2nd level bmb',
                               10,'3rd level bmb',
                               11,'bitmap block',
                               12,'bitmap index block',
                               13,'file header block',
                               14,'unused',
                               15,'system undo header',
                               16,'system undo block',
                               17,'undo header',
                               18,'undo block') AS class,
               DECODE(bh.state, 0,'free',
                                1,'xcur',
                                2,'scur',
                                3,'cr',
                                4,'read',
                                5,'mrec',
                                6,'irec',
                                7,'write',
                                8,'pi',
                                9,'memory',
                                10,'mwrite',
                                11,'donated') AS state
        FROM   x$bh bh,
               dba_objects o
        WHERE  o.data_object_id = bh.obj
        AND    hladdr = '&address'
        ORDER BY tch DESC)
WHERE  rownum < 11;




---- 执行计划的信息
set pagesize 1000

-- 查询的是library cache中的真实的执行计划，如果dbms_xplan.display则是显示的plan_table中的，不真实
select * from table(dbms_xplan.display_cursor('&sid_id',null,'Typical'));

select parent_id,
       depth,
       operation,
       options,
       object_owner,
       object_name,
       object_type,
       cost,
       bytes,
       cpu_cost,
       io_cost,
       filter_predicates
  from v$sql_plan_statistics_all
 where sql_id = '&sql_id';


_controlfile_enqueue_timeout

有些时候因为测试环境需要,我们需要使用生产库的备份集在另外一台新的机器上做恢复(前提是新机器事先安装Oracle软件,版本跟原库一致),下面是恢复过程.

1.在原库上做全备(在原库上操作)
run{
allocate channel c1 device type disk;
allocate channel c2 device type disk;
backup format '/u02/rman_backup/full_backup/full_backup_%T_%s' database;
sql 'alter system archive log current';
backup format '/u02/rman_backup/full_backup/arc_backup_%T_%s' archivelog all;
release channel c1;
release channel c2;
}
2.查看原库的DBID(在原库上操作)
因为在做恢复的过程中需要设定DBID,这里需要找到原库的DBID
SQL> select dbid from v$database;
      DBID
----------
1820932955

-----以下的操作没有特殊说明,全部在目的库上操作-----
3.使用ftp将原库上的备份集拷贝到目的库的目录/u02/ftp/(具体操作省略)

4.在新机器上创建如下目录
mkdir /u02/mydb
mkdir -p /u02/mydb/oracl/{adump,bdump,cdump,dpdump,udump,pfile}
mkdir -p /u02/mydb/oradata/oracl
mkdir -p /u02/mydb/flash_recovery_area

5.创建密码文件
orapwd file=/u01/app/oracle/product/10.2.0/db_1/dbs/orapworacl.ora password=oracle

6.恢复参数文件
[oracle@hxlbak ~]$ rman target /

Recovery Manager: Release 10.2.0.1.0 - Production on Fri Jun 29 06:51:54 2012

Copyright (c) 1982, 2005, Oracle.  All rights reserved.

connected to target database (not started)

RMAN>set dbid 1820932955 -- 这里的dbid需要跟原库保持一致

RMAN> startup nomount

startup failed: ORA-01078: failure in processing system parameters
LRM-00109: could not open parameter file '/u01/app/oracle/product/10.2.0/db_1/dbs/initoracl.ora'

starting Oracle instance without parameter file for retrival of spfile
Oracle instance started

Total System Global Area     159383552 bytes

Fixed Size                     1218268 bytes
Variable Size                 54528292 bytes
Database Buffers             100663296 bytes
Redo Buffers                   2973696 bytes

RMAN> restore spfile to pfile '/u01/app/oracle/product/10.2.0/db_1/dbs/initoracl.ora' from '/u02/ftp/full_backup_20120628_37';

Starting restore at 29-JUN-12
using target database control file instead of recovery catalog
allocated channel: ORA_DISK_1
channel ORA_DISK_1: sid=36 devtype=DISK

channel ORA_DISK_1: autobackup found: /u02/ftp/full_backup_20120628_37
channel ORA_DISK_1: SPFILE restore from autobackup complete
Finished restore at 29-JUN-12


备份集full_backup_20120628_3里7包含了参数文件,我们在备份数据的时候会默认备份参数文件,可以在原库使用list backup查看,list backup输出部分内容如下:

BS Key  Type LV Size       Device Type Elapsed Time Completion Time
------- ---- -- ---------- ----------- ------------ ---------------
35      Full    80.00K     DISK        00:00:01     28-JUN-12
        BP Key: 35   Status: AVAILABLE  Compressed: NO  Tag: TAG20120628T184555
        Piece Name: /u02/rman_backup/full_backup/full_backup_20120628_37
  SPFILE Included: Modification time: 28-JUN-12

恢复了参数文件initoracl.ora后,因为原库和目的库各文件保存的路径不一致,这个时候需要修改参数文件,修改的地方如下,各文件路径指向新目录:

*.audit_file_dest='/u02/mydb/oracl/adump'
*.background_dump_dest='/u02/mydb/oracl/bdump'
*.control_files='/u02/mydb/oradata/oracl/control01.ctl','/u02/mydb/oradata/oracl/control02.ctl','/u02/mydb/oradata/oracl/control03.ctl'
*.core_dump_dest='/u02/mydb/oracl/cdump'
*.db_recovery_file_dest='/u02/mydb/flash_recovery_area'
*.user_dump_dest='/u02/mydb/oracl/udump'

7.使用编辑好的参数文件启动数据库到nomount状态并恢复控制文件

SQL> startup nomount pfile=/u01/app/oracle/product/10.2.0/db_1/dbs/initoracl.ora
ORACLE instance started.

Total System Global Area 1048576000 bytes
Fixed Size                  1223368 bytes
Variable Size             310379832 bytes
Database Buffers          734003200 bytes
Redo Buffers                2969600 bytes
SQL>

恢复控制文件
RMAN> restore controlfile from '/u02/ftp/full_backup_20120628_36';

Starting restore at 29-JUN-12
using target database control file instead of recovery catalog
allocated channel: ORA_DISK_1
channel ORA_DISK_1: sid=155 devtype=DISK

channel ORA_DISK_1: restoring control file
channel ORA_DISK_1: restore complete, elapsed time: 00:00:05
output filename=/u02/mydb/oradata/oracl/control01.ctl
output filename=/u02/mydb/oradata/oracl/control02.ctl
output filename=/u02/mydb/oradata/oracl/control03.ctl
Finished restore at 29-JUN-12

跟参数文件一样,在备份数据的时候会默认备份了控制文件,备份集full_backup_20120628_36中包含了控制文件,同样可以在原库使用list backup查看,list backup输出部分内容如下:

BS Key  Type LV Size       Device Type Elapsed Time Completion Time
------- ---- -- ---------- ----------- ------------ ---------------
34      Full    6.98M      DISK        00:00:02     28-JUN-12
        BP Key: 34   Status: AVAILABLE  Compressed: NO  Tag: TAG20120628T184555
        Piece Name: /u02/rman_backup/full_backup/full_backup_20120628_36
  Control File Included: Ckp SCN: 1545845      Ckp time: 28-JUN-12

8.启动数据库到mount状态并注册备份集
RMAN> alter database mount;

database mounted
released channel: ORA_DISK_1

注册备份集,因为控制文件中的保留的备份信息是原库的,我们这里需要重新注册新库路径下的备份集
RMAN> catalog start with '/u02/ftp/';

Starting implicit crosscheck backup at 29-JUN-12
allocated channel: ORA_DISK_1
channel ORA_DISK_1: sid=155 devtype=DISK
Crosschecked 29 objects
Finished implicit crosscheck backup at 29-JUN-12

Starting implicit crosscheck copy at 29-JUN-12
using channel ORA_DISK_1
Finished implicit crosscheck copy at 29-JUN-12

searching for all files in the recovery area
cataloging files...
no files cataloged

searching for all files that match the pattern /u02/ftp/

List of Files Unknown to the Database
=====================================
File Name: /u02/ftp/full_backup_20120628_35
File Name: /u02/ftp/full_backup_20120628_37
File Name: /u02/ftp/full_backup_20120628_34
File Name: /u02/ftp/arc_backup_20120628_38
File Name: /u02/ftp/arc_backup_20120628_40
File Name: /u02/ftp/full_backup_20120628_36
File Name: /u02/ftp/full_backup_20120628_31
File Name: /u02/ftp/full_backup_20120628_33
File Name: /u02/ftp/arc_backup_20120628_39
File Name: /u02/ftp/full_backup_20120628_32
File Name: /u02/ftp/full_backup_20120628_30

Do you really want to catalog the above files (enter YES or NO)  yes
cataloging files...
cataloging done

List of Cataloged Files
=======================
File Name: /u02/ftp/full_backup_20120628_35
File Name: /u02/ftp/full_backup_20120628_37
File Name: /u02/ftp/full_backup_20120628_34
File Name: /u02/ftp/arc_backup_20120628_38
File Name: /u02/ftp/arc_backup_20120628_40
File Name: /u02/ftp/full_backup_20120628_36
File Name: /u02/ftp/full_backup_20120628_31
File Name: /u02/ftp/full_backup_20120628_33
File Name: /u02/ftp/arc_backup_20120628_39
File Name: /u02/ftp/full_backup_20120628_32
File Name: /u02/ftp/full_backup_20120628_30

9.列出当前的所有数据文件

SQL> column name format a60;
SQL> select file# as "file/grp#", name from v$datafile;
 file/grp# NAME
---------- ------------------------------------------------------------
         1 /u01/app/oracle/oradata/oracl/system01.dbf';
         2 /u01/app/oracle/oradata/oracl/undotbs01.dbf';
         3 /u01/app/oracle/oradata/oracl/sysaux01.dbf';
         4 /u01/app/oracle/oradata/oracl/users01.dbf';
         5 /u01/app/oracle/oradata/oracl/hxl01.dbf';
         6 /u01/app/oracle/oradata/oracl/hxl02.dbf';
         7 /u01/app/oracle/oradata/oracl/hxl03.dbf';
         8 /u01/app/oracle/oradata/oracl/hxl04.dbf';
         9 /u01/app/oracle/oradata/oracl/hxl05.dbf';
        10 /u02/app/oracle/oradata/oracl/hxl06.dbf';
        11 /u02/app/oracle/oradata/oracl/hxl07.dbf';
 file/grp# NAME
---------- ------------------------------------------------------------
        12 /u02/app/oracle/oradata/oracl/hxl08.dbf';
        13 /u02/app/oracle/oradata/oracl/hxl09.dbf';
        14 /u02/app/oracle/oradata/oracl/hxl10.dbf';

可以看到,当前控制文件中记录的数据文件的路径是原来的路径,我们在做恢复的时候需要指向新的路径.

10.恢复数据库
RMAN> run{
set newname for datafile  1 to '/u02/mydb/oradata/oracl/system01.dbf';
set newname for datafile  2 to '/u02/mydb/oradata/oracl/undotbs01.dbf';
set newname for datafile  3 to '/u02/mydb/oradata/oracl/sysaux01.dbf';
set newname for datafile  4 to '/u02/mydb/oradata/oracl/users01.dbf';
set newname for datafile  5 to '/u02/mydb/oradata/oracl/hxl01.dbf';
set newname for datafile  6 to '/u02/mydb/oradata/oracl/hxl02.dbf';
set newname for datafile  7 to '/u02/mydb/oradata/oracl/hxl03.dbf';
set newname for datafile  8 to '/u02/mydb/oradata/oracl/hxl04.dbf';
set newname for datafile  9 to '/u02/mydb/oradata/oracl/hxl05.dbf';
set newname for datafile 10 to '/u02/mydb/oradata/oracl/hxl06.dbf';
set newname for datafile 11 to '/u02/mydb/oradata/oracl/hxl07.dbf';
set newname for datafile 12 to '/u02/mydb/oradata/oracl/hxl08.dbf';
set newname for datafile 13 to '/u02/mydb/oradata/oracl/hxl09.dbf';
set newname for datafile 14 to '/u02/mydb/oradata/oracl/hxl10.dbf';
restore database;
switch datafile all;
recover database;
}

11.打开数据库
alter database open resetlogs;

-- The End --


 --查看数据库是否开启审计，如果value列为DB则开启了数据库级审计，只有数据库开启审计才可以进行审计
1.select name,value from v$parameter2 where name like '%audit_trail%';

--审计目标库用户对目标表进行的dml操作
2.audit update,delete,insert  on ggmgr.t_test_conn_for_gg by session;

--查看目标端的同步表是否已开启审计，开启了哪些审计(delete insert update ...)
3.select * from dba_obj_audit_opts where object_name=upper('t_test_conn_for_gg');

--根据时间查看对象的审计记录
4.select * from dba_audit_object where timestamp>=sysdate-30;

  用全文索引做了一个根据表名查找SQL语句的功能. 在Statspack中有一个表存放了数据库中执行过的SQL, 虽然不是全部, 但也有差不多99.9%了. 只是由于它是分行存贮的, 不能直接用普通的SQL语句(like)来查找, 表名有可能被折分存放在两行中. 解决的方法有两种, 一是写过程, 将多行的串在一起. 二是用全文索引中的主从存贮方式, 建立全文索引来查询. 我选择的是全文索引的方式.

    先将这里面的数据拷出来, 分成两个表, 主表和从表.

CREATE TABLE SQLS AS
  SELECT DISTINCT HASH_VALUE,'X' BODY FROM STATS$SQLTEXT;
ALTER TABLE SQLS ADD PRIMARY KEY (HASH_VALUE);
CREATE TABLE SQL_DETAILS AS
  SELECT HASH_VALUE,PIECE,SQL_TEXT FROM STATS$SQLTEXT;
ALTER TABLE SQL_DETAILS ADD PRIMARY KEY (HASH_VALUE, PIECE);

    创建全文索引的存贮方式及Lexer属性.

begin
ctx_ddl.create_preference('sqltext_pref', 'DETAIL_DATASTORE');
ctx_ddl.set_attribute('sqltext_pref', 'binary', 'true');
ctx_ddl.set_attribute('sqltext_pref', 'detail_table', 'sql_details');
ctx_ddl.set_attribute('sqltext_pref', 'detail_key', 'hash_value');
ctx_ddl.set_attribute('sqltext_pref', 'detail_lineno', 'piece');
ctx_ddl.set_attribute('sqltext_pref', 'detail_text', 'sql_text');
end;
/
begin
ctx_ddl.create_preference('sqltext_lex', 'BASIC_LEXER');
ctx_ddl.set_attribute ('sqltext_lex', 'continuation', '_');
ctx_ddl.set_attribute ('sqltext_lex', 'printjoins', '_');
ctx_ddl.set_attribute ('sqltext_lex', 'index_themes', 'NO');
ctx_ddl.set_attribute ('sqltext_lex', 'index_text', 'YES');
end;
/






解决方法：
昨天在网上找到了以下的文字：
您不能授予执行触发器的权限，因为用户不能执行触发器：Adaptive Server Anywhere 触发它们以响应对数据库执行的操作。不过，触发器确实具有与它所执行的操作关联的权限，并且定义其权限以执行某些操作。
触发器使用定义了这些权限的表的所有者的权限（而不是导致触发器触发的用户的权限，并且不是创建该触发器的用户的权限）执行。
在触发器引用表时，它使用表创建者的组成员资格找到没有指定的显式所有者名称的表。例如，如果 user_1.Table_A 上的触发器引用 Table_B，并且没有指定 Table_B 的所有者，那么，Table_B 就必须已经由 user_1 创建，或者，user_1 必须（直接或间接地）是作为 Table_B 的所有者的某个组的成员。如果这两个条件都不具备，该触发器触发时将出现消息 [没有找到表]。
此外，user_1 必须具有执行该触发器中指定的操作的权限。
所以我们需要b用户给a用户‘table_B’表的操作权限.(如果在a用户的‘table_A’表上的触发器中有对b用户‘table_B’表进行增、删、改的操作,那么就需要b用户给a用户‘table_B’表的增、删、改操作权限).
权限: SELECT（讀）， INSERT（追加）， UPDATE（寫），DELETE

GRANT 权限 ON 表名 TO 用户名;

注意:用这条语句的用户必须是表的所有者.



〖现象(Symptom)   〗
创建触发器时，报告权限不足，具体过程如下。
Step01：system的身份登陆数据库
SQL> connect system@wm
Enter password:
Connected.


Step02：创建触发器trigger_autoadd
SQL> CREATE OR REPLACE TRIGGER trigger_autoadd
 2    before insert
 3      on test.autoadd
 4      for each row
 5 begin
 6    select test.SEQ_id.nextval into :new.id from dual;
 7 end;
 8 /
Warning: Trigger created with compilation errors


SQL> show error
Errors for TRIGGER SYSTEM.TRIGGER_AUTOADD:
LINE/COL ERROR
-------- ------------------------------------------
2/16    PL/SQL: ORA-01031: insufficient privileges
2/4     PL/SQL: SQL Statement ignored
在表autoadd上创建触发器trigger_autoadd。


用户system有角色（role）DBA权限,而DBA已经就有CREATE ANY TRIGGER
的权限,因此，system就有create any trigger的权限。


Step03：system用户也能往表autoadd中也能插入数据库。
SQL> insert into test.autoadd
 2 values(4,'sdfds','sdfsdf');
1 row inserted


Step04：序列也可以正常访问。
SQL> select test.SEQ_id.nextval from dual;


  NEXTVAL
----------
      205


这就非常奇怪，用户system有CREATE ANY TRIGGER的权限，system有访问触发器中所引用的对象（表）上的权限，为什么还报告“权限不足”呢？


〖原理（Cause）   〗
要想创建触发器，必须要有CREATE TRIGGER，CREATE ANY TRIGGER的权限。如：
要想使用户tt有创建触发器的权限，则执行命令：
Grant CREATE TRIGGER to tt;


要想使用户tt有在其他模式(any schema)创建触发器的权限，则执行命令：
Grant CREATE ANY TRIGGER to tt;


本例中，用户system已经有了CREATE ANY TRIGGER和访问任何对象的权限。那么，用户System自然也有访问序列（sequence）seq_id的权限，但是这个权限是从角色（role）DBA继承而来的权限。创建触发器（trigger）时，ORACLE有一个限制，触发器（trigger）的拥有者必须被显示（explicitly）授予访问触发器（trigger）中涉及到的对象的权限(也就是说这些权限不能由角色继承而来)。


〖方法（Action）   〗
Step01：显示（explicitly）授予触发器的拥有者(system)访问序列（sequence）seq_id的权限。
SQL> grant select on test.seq_id to system;
Grant succeeded.


Step02：再次执行创建触发器trigger_autoadd3的脚本。
SQL> CREATE OR REPLACE TRIGGER trigger_autoadd3
 2  before insert
 3       on test.autoadd
 4        for each row
 5   begin
 6      select test.SEQ_id.nextval into :new.id from dual;
 7   end;
 8 /


Trigger created
触发器创建成功。

sed 's/^M//g' dos.txt | cat -v



摘 要 字符集的设置不当是影响ORACLE数据库汉字显示的关键问题。本文从实践经验出发，介绍了ORACLE关于字符集的分类、构成及设定方法，分析了ORACLE数据库汉字显示乱码的常见现象及原因，并针对各种现象及原因提出了行之有效的解决办法。
   关键字 ORACLE 字符集 乱码解决


1 引言
    ORACLE数据库作为业界领先的数据库产品，近年来在国内大中型企业中得到了广泛的应用。虽然ORACLE数据库产品本身在本地化方面已做得相当成熟，但还是有不少用户反应汉字显示乱码的问题。如对同一数据库不同的用户对同一表中的username查询却得出了不同的结果： “ORACLE      ”和“ORACLE中国有限公司”，显然结果中将中文字符显示为乱码，那么为什么呢？字符集的设置不当是影响ORACLE数据库汉字显示的关键问题。
2 关于字符集
    字符集是ORACLE为适应不同语言文字显示而设定的。用于汉字显示的字符集主要有ZHS16CGB231280、ZHS16GBK、US7ASCII和UTF－8等。字符集同时存在于服务器端和客户端。服务器端字符集是在安装ORACLE时指定的，字符集登记信息存储在ORACLE数据库字典的V$NLS_PARAMETERS表中；而客户端字符集是在系统注册表（WINDOWS系统）或在用户的环境变量（UNIX系统）中设定的。
3 字符集的构成与设定
    字符集的构成与设定方式分为客户端与服务器端两种：
    (1)客户端字符集的构成与设定。客户端的字符集是由当前用户的环境变量NLS_LANG设定的。环境变量NLS_LANG的构成：
NLS_LANG=language_territory.charset
其中，
language 指定服务器消息的语言
territory   指定服务器的日期和数字格式
charset    指定字符集
三个成分可以任意组合，例如：
AMERICAN_AMERICA.US7SCII
SIMPLIFIED CHINESE_CHINA.ZHS16GBK
AMERICAN_AMERICA. ZHS16GBK
    客户端字符集的设定方法针对不同操作系统设定方法稍有不同：WINDOWS系统是在注册表项：HKEY_LOCAL_MACHINE\SOFTWARE\ORACLE\HOME0\NLS_LANG中设定；UNIX系统是在当前用户的环境变量中设定，如在当前用户的profile文件中增加一行如下代码：
NLS_LANG=SIMPLIFIED Chinese_CHINA.ZHS16GBK；export NLS_LANG
    (2)服务端字符集的构成与设定。服务端字符集的构成体现在数据字典表V$NLS_PARAMETERS的NLS_LANGUAGE、NLS_TERRITORY、NLS_CHARACTERSET三项取值上，其中NLS_CHARACTERSET的取值就是具体的数据库字符集。如利用查询语句SQL>SELECT * FROM V$NLS_PARAMETERS;
可得到如下结果：
PARAMETER                   VALUE
------------------------------------------------------------
NLS_LANGUAGE           SIMPLIFIED CHINESE
NLS_TERRITORY               CHINA
……
NLS_CHARACTERSET           ZHS16GBK
……
    即当前数据库使用的字符集是ZHS16GBK。
    数据库服务端的字符集是在创建数据时设定的。但可通过如下方法对已设定的字符集进行修改：
    方法一：重建数据库。建立数据库时将数据库的字符集设定为所需字符集。
    方法二：修改SYS.PROPS$表。即用SYS用户登陆ORACLE后，利用下面语句修改相应的字符集并提交：
SQL>UPDATE PROPS$ SET VALUE$=’ZHS16GBK‘
WHERE NAME=’NLS_CHARACTERSET’;
SQL>COMMIT;
    通过此种方法来更改数据库字符集，只对更改后的数据有效，即数据库中原来的数据仍以原字符集被存储。
    另外，有的还利用CREATE DATABASE CHARACTER SET ZHS16GBK命令暂时的修改字符集，当重启数据库后，数据库字符集将恢复原来的字符集。
4 常见的汉字乱码问题及解决方案
    要在客户端正确显示ORACLE数据库中的汉字信息，首先必须使客户端的字符集与服务器端的字符集一致；其次是加载到ORACLE数据库的数据字符集必须与服务器字符集一致。据此，汉字显示乱码的问题大致可以分为以下几种情况：
    (1)客户端字符集与服务器端字符集不同，服务器端字符集与加载数据字符集一致。这种情况是最常见的，只要把客户端的字符集设置正确即可。具体解决方案：
     第一步：查询V$NLS_PARAMETERS得到服务端的字符集：
SQL>SELECT * FROM V$NLS_PARAMETERS;
PARAMETER                       VALUE
-----------------------------------------------------
NLS_LANGUAGE      SIMPLIFIED CHINESE
NLS_TERRITORY                  CHINA
                                        ……………………
NLS_CHARACTERSET          ZHS16GBK
                                         ……………………
    第二步：根据服务端的字符集设定客户端的字符集，设定方法参见客户端的字符集的设定方式。以UNIX系统为例，可在当前用户的profile文件中增加如下两行：
    NLS_LANG=SIMPLIFIED Chinese_CHINA.ZHS16GBK
    export NLS_LANG
    (2)客户端字符集与服务器端字符集相同，服务器端字符集与加载数据字符集不一致。这种情况一般发生在ORACLE版本升级或重新安装数据库时选择了与原来数据库不同的字符集，而恢复加载的备份数据仍是按原字符集卸出的场合。另一种情况是加载从其它使用不同字符集的ORACLE数据库卸出的数据。在这两种情况中，不管客户端字符集与服务器端字符集是否一致都无法正确显示汉字。具体解决方案：
    方案一：按服务端字符集的修改方法修改服务端字符集与加载数据字符集一致，然后导入数据。
    方案二：利用数据格式转储，避开字符集带来的问题。即先将加载数据倒入到与其字符集一致的数据库中，然后再将数据要么按文本格式导出（数据量较小的情况下），要么通过第三方工具（如POWER BUILDER，ACCESS，FOXPRO等）倒出数据，最后将倒出的数据导入到目标数据库中。
    (3)客户端字符集与服务器端字符集不同，服务端字符集与输入数据字符集不同。这种情况是在客户端字符集与服务器端字符集不一致时，从客户端输入了汉字信息。输入的这些信息即便是把客户端字符集更改正确，也无法显示汉字。解决方案：修改客户端字符集与服务端字符集一致后，重新输入数据。
5 结束语
    根据ORACLE官方文档的说明，一旦数据库创建后，数据库的字符集是不能改变的。因此，提前考虑自己的数据库将选用哪一种字符集是十分重要的。数据库字符集选择的一般规则是将数据库字符集设定为操作系统本地字符集的一个超集，同时数据库字符集也应该是所有客户字符集的超集。如同样是中文环境，在选择ZHS16CGB231280还是ZHS16GBK时，我们更多的情况是选择ZHS16GBK，因为它包含了ZHS16CGB231280字符集。










    接下来创建全文索引.

CREATE INDEX SQL_CTX on SQLS(body) indextype is ctxsys.context
parameters('datastore sqltext_pref LEXER sqltext_lex');
    接下来就可以查询了.

SELECT HASH_VALUE FROM SQLS WHERE CONTAINS(BODY,'tablename and ...') > 0
    接下来要好好用用这个功能了.

oracle的体系
oracle的体系很庞大，要学习它，首先要了解oracle的框架。在这里，简要的讲一下oracle的架构，让初学者对oracle有一个整体的认识。

1、物理结构（由控制文件、数据文件、重做日志文件、参数文件、归档文件、密码文件组成）
控制文件：包含维护和验证数据库完整性的必要信息、例如，控制文件用于识别数据文件和重做日志文件，一个数据库至少需要一个控制文件
数据文件：存储数据的文件
重做日志文件：含对数据库所做的更改记录，这样万一出现故障可以启用数据恢复。一个数据库至少需要两个重做日志文件
参数文件：定义Oracle 例程的特性，例如它包含调整SGA 中一些内存结构大小的参数
归档文件：是重做日志文件的脱机副本，这些副本可能对于从介质失败中进行恢复很必要。
密码文件：认证哪些用户有权限启动和关闭Oracle例程

2、逻辑结构（表空间、段、区、块）
表空间：是数据库中的基本逻辑结构，一系列数据文件的集合。
段：是对象在数据库中占用的空间
区：是为数据一次性预留的一个较大的存储空间
块：ORACLE最基本的存储单位，在建立数据库的时候指定

3、内存分配（SGA和PGA）
SGA：是用于存储数据库信息的内存区，该信息为数据库进程所共享。它包含Oracle 服务器的数据和控制信息, 它是在Oracle 服务器所驻留的计算机的实际内存中得以分配，如果实际内存不够再往虚拟内存中写。
PGA：包含单个服务器进程或单个后台进程的数据和控制信息，与几个进程共享的SGA 正相反PGA 是只被一个进程使用的区域，PGA 在创建进程时分配在终止进程时回收

4、后台进程（数据写进程、日志写进程、系统监控、进程监控、检查点进程、归档进程、服务进程、用户进程）
数据写进程：负责将更改的数据从数据库缓冲区高速缓存写入数据文件
日志写进程：将重做日志缓冲区中的更改写入在线重做日志文件
系统监控：检查数据库的一致性如有必要还会在数据库打开时启动数据库的恢复
进程监控：负责在一个Oracle 进程失败时清理资源
检查点进程：负责在每当缓冲区高速缓存中的更改永久地记录在数据库中时,更新控制文件和数据文件中的数据库状态信息。
归档进程：在每次日志切换时把已满的日志组进行备份或归档
服务进程：用户进程服务。
用户进程：在客户端，负责将用户的SQL 语句传递给服务进程，并从服务器段拿回查询数据。

5、oracle例程：Oracle 例程由SGA 内存结构和用于管理数据库的后台进程组成。例程一次只能打开和使用一个数据库。

6、SCN(System Change Number)：系统改变号，一个由系统内部维护的序列号。当系统需要更新的时候自动增加，他是系统中维持数据的一致性和顺序恢复的重要标志。

深入学习
管理：可以考OCP证书，对oracle先有一个系统的学习，然后看Oracle Concepts、oracle online document,对oracle的原理会有更深入的了解，同时可以开始进行一些专题的研究如：RMAN、RAS、STATSPACT、DATAGUARD、TUNING、BACKUP&RECOVER等等。

开发：对于想做Oracle开发的，在了解完Oracle基本的体系结构之后，可以重点关注PL/SQL及Oracle的开发工具这一部分。 PL/SQL主要是包括怎么写SQL语句，怎么使用Oracle本身的函数，怎么写存储过程、存储函数、触发器等。 Oracle的开发工具主要就是Oracle自己的Developer Suite（Oracle Forms Developer and Reports Developer这些），学会如何熟练使用这些工具。
介绍几本oracle入门的好书

oracle官方文档：《concept》上面讲了oracle的体系和概念，很适合初学者看。

OCP的教学用书，也就是STUDY GUIDE(SG)。
Oracle8i 备份恢复手册
Oracle8高级管理与优化
Oracle8i PLSQL程序设计
Oracle8数据库管理员手册
以上书本都是机械工业出版社出版。

介绍几个网站
http://tahiti.oracle.com oracle的官方文档
现在http://www.oracle.com.cn/onlinedoc/index.htm也有官方文档，速度奇快
http://metalink.oracle.com/ oracle的技术支持网站。需要购买Oracle服务才能有一个帐号，才能登陆，有大量的Knowledge Base，大量问题解决经验。
http://www.oracle.com oracle的官方网站，可以在这里down oracle的软件、官方文档和获得最新的消息
http://www.dbazine.com/ Oracle的杂志
http://asktom.oracle.com
http://www.orafaq.net/
http://www.ixora.com.au/
http://www.oracle-base.com
http://www.dba-oracle.com/oracle_links.htm



oracle10g的sysaux空间暴增与空间回收



在Oracle10中表空间SYSAUX引入，oracle把统计信息存储在这里，这也是为了更好的优化system表空间，我们可以用视图V$SYSAUX_OCCUPANTS 查看，oracle有哪些数据存贮在SYSAUX中。

SELECT occupant_name, space_usage_kbytes FROM V$SYSAUX_OCCUPANTS;



oracle的SM/AWR, SM/ADVISOR, SM/OPTSTAT and SM/OTHER的统计信息都存储在SYSAUX中，这里重点介绍SM/OPTSTAT。

SM/OPTSTAT：用于存储老版本的优化统计信息，在oracle10g中，在我们手动或自动更新统计信息使oracle选择了错误的执行计划。oracle10g是可以恢复旧版本的统计信息，这个统计信息默认保存31天



查询当前SM/OPTSTAT的统计信息的保存时间
SQL> select dbms_stats.get_stats_history_retention from dual;

GET_STATS_HISTORY_RETENTION
---------------------------
                         31

修改SM/OPTSTAT的统计信息的保存时间为10天
SQL> exec dbms_stats.alter_stats_history_retention(10);

PL/SQL procedure successfully completed

SQL> select dbms_stats.get_stats_history_retention from dual;

GET_STATS_HISTORY_RETENTION
---------------------------
                         10

SQL>

删除16天前的统计数据
SQL> exec dbms_stats.purge_stats(sysdate-16);

PL/SQL procedure successfully completed

SQL>



查看当前有效的统计数据是到什么时间的
SQL> select DBMS_STATS.GET_STATS_HISTORY_AVAILABILITY from dual;

GET_STATS_HISTORY_AVAILABILITY
--------------------------------------------------------------------------------
12-2月 -12 07.15.49.000000000 下午 +08:00

再删除7天前的统计数据
SQL> exec dbms_stats.purge_stats(sysdate-7);

PL/SQL procedure successfully completed

这个时候发现有效的统计信息时间已经变了
SQL> select DBMS_STATS.GET_STATS_HISTORY_AVAILABILITY from dual;

GET_STATS_HISTORY_AVAILABILITY
--------------------------------------------------------------------------------
14-2月 -12 07.15.57.000000000 下午 +08:00

SQL>

这个时候虽然删除了数据，但空间还没有回收，如何回收空间呢？



没有释放空间是因为“purge_stats”用delete的方式删除数据，虽然数据没了，但是HWM还没降下来，查看OPTSTAT使用哪些表，然后降低其高水位即可。
SQL> SELECT s.object_name from dba_objects s where s.object_name like '%OPTSTAT%' and s.object_type='TABLE'
  2  ;

OBJECT_NAME
--------------------------------------------------------------------------------
WRI$_OPTSTAT_TAB_HISTORY
WRI$_OPTSTAT_IND_HISTORY
WRI$_OPTSTAT_HISTHEAD_HISTORY
WRI$_OPTSTAT_HISTGRM_HISTORY
WRI$_OPTSTAT_AUX_HISTORY
WRI$_OPTSTAT_OPR
OPTSTAT_HIST_CONTROL$

7 rows selected

SQL>



再结合如下sql判断哪个表大，然后就move哪个表
SQL> select a.table_name,a.num_rows from dba_tables a where  a.tablespace_name='SYSAUX' and a.table_name like '%OPTSTAT%'
  2  ;

TABLE_NAME                       NUM_ROWS
------------------------------ ----------
WRI$_OPTSTAT_OPR                      151
WRI$_OPTSTAT_AUX_HISTORY                0
WRI$_OPTSTAT_HISTGRM_HISTORY       139933
WRI$_OPTSTAT_HISTHEAD_HISTORY       14406
WRI$_OPTSTAT_IND_HISTORY             1196
WRI$_OPTSTAT_TAB_HISTORY             1323

6 rows selected

SQL>

再用如下语句查出相关表的索引，因为move表，索引会失效，需要重建索引
SQL> select i.index_name,i.table_name,i.status,i.table_owner
  2   from dba_indexes i,dba_objects s where i.table_name=s.object_name and  s.object_name like '%OPTSTAT%' and s.object_type='TABLE'
  3  ;

INDEX_NAME                     TABLE_NAME                     STATUS   TABLE_OWNER
------------------------------ ------------------------------ -------- ------------------------------
I_WRI$_OPTSTAT_TAB_OBJ#_ST     WRI$_OPTSTAT_TAB_HISTORY       VALID    SYS
I_WRI$_OPTSTAT_TAB_ST          WRI$_OPTSTAT_TAB_HISTORY       VALID    SYS
I_WRI$_OPTSTAT_IND_OBJ#_ST     WRI$_OPTSTAT_IND_HISTORY       VALID    SYS
I_WRI$_OPTSTAT_IND_ST          WRI$_OPTSTAT_IND_HISTORY       VALID    SYS
I_WRI$_OPTSTAT_HH_OBJ_ICOL_ST  WRI$_OPTSTAT_HISTHEAD_HISTORY  VALID    SYS
I_WRI$_OPTSTAT_HH_ST           WRI$_OPTSTAT_HISTHEAD_HISTORY  VALID    SYS
I_WRI$_OPTSTAT_H_OBJ#_ICOL#_ST WRI$_OPTSTAT_HISTGRM_HISTORY   VALID    SYS
I_WRI$_OPTSTAT_H_ST            WRI$_OPTSTAT_HISTGRM_HISTORY   VALID    SYS
I_WRI$_OPTSTAT_AUX_ST          WRI$_OPTSTAT_AUX_HISTORY       VALID    SYS
I_WRI$_OPTSTAT_OPR_STIME       WRI$_OPTSTAT_OPR               VALID    SYS

10 rows selected

SQL>


降低HWM
sql> alter table WRI$_OPTSTAT_TAB_HISTORY move;
sql> alter table WRI$_OPTSTAT_OPR move;
sql> alter table WRI$_OPTSTAT_IND_HISTORY move;
sql> alter table WRI$_OPTSTAT_HISTHEAD_HISTORY move;
sql> alter table WRI$_OPTSTAT_HISTGRM_HISTORY move;
sql> alter table WRI$_OPTSTAT_AUX_HISTORY move;
sql> alter table OPTSTAT_HIST_CONTROL$ move;



重建索引
alter index I_WRI$_OPTSTAT_TAB_OBJ#_ST  rebuild online;
alter index I_WRI$_OPTSTAT_TAB_ST rebuild online;
alter index I_WRI$_OPTSTAT_IND_OBJ#_ST rebuild online;
alter index I_WRI$_OPTSTAT_IND_ST rebuild online;
alter index I_WRI$_OPTSTAT_HH_OBJ_ICOL_ST rebuild online;
alter index I_WRI$_OPTSTAT_HH_ST rebuild online;
alter index I_WRI$_OPTSTAT_H_OBJ#_ICOL#_ST rebuild online;
alter index I_WRI$_OPTSTAT_H_ST rebuild online;
alter index I_WRI$_OPTSTAT_AUX_ST rebuild online;
alter index I_WRI$_OPTSTAT_OPR_STIME rebuild online;



如果索引编译不成功，就要create indexe

用如下语句生成DDL语句
SQL> set long 4000
SQL> select dbms_metadata.get_ddl('INDEX','I_WRI$_OPTSTAT_IND_OBJ#_ST','SYS') from dual;
SQL> select dbms_metadata.get_ddl('INDEX','I_WRI$_OPTSTAT_TAB_ST','SYS') from dual;



如何恢复统计信息



用如下语句查到统计信息的时间点
select TABLE_NAME, STATS_UPDATE_TIME from dba_tab_stats_history；



可以按需要根据时间点恢复统计信息
execute DBMS_STATS.RESTORE_TABLE_STATS ('owner','table',date)
execute DBMS_STATS.RESTORE_DATABASE_STATS(date)
execute DBMS_STATS.RESTORE_DICTIONARY_STATS(date)
execute DBMS_STATS.RESTORE_FIXED_OBJECTS_STATS(date)
execute DBMS_STATS.RESTORE_SCHEMA_STATS('owner',date)
execute DBMS_STATS.RESTORE_SYSTEM_STATS(date)



例如：
SQL> execute dbms_stats.restore_table_stats ('SKATE','BK_ADMIN',sysdate -1);

PL/SQL procedure successfully completed

SQL>



参考文档：[ID 329984.1], [ID 452011.1],[ID 454678.1]



escape与like引发的bug修改ORA-01424
1.	Cursor_share 改成“exact”， 这个办法证实不行，因为我查看了参数，已经是exact了
2.	使用to_char函数，具体把
 LIKE '%渭南\_201012\_N1-N5\_OB-ITS-TB\_P\_A-B-C\_20100909-2\_主力\_2009-2009\_座机%' ESCAPE '\'   改成
LIKE to_char('%渭南\_201012\_N1-N5\_OB-ITS-TB\_P\_A-B-C\_20100909-2\_主力\_2009-2009\_座机%') ESCAPE '\'
该方法经过凌永辉同志测试，bug不再出现。

3.	DBA身份执行如下命令：
 alter system set "_fix_control"='6163564:off';
这个办法我没有验证，因为是系统级的参数，执行了 “select * from v$system_fix_control where bugno='6163564';  ”查到value =1，推测该方法应该可行。


  今天犯了一个非常弱智+傻缺的错误，写在这里，鞭策自己：

$ ./runInstaller
./runInstaller: /data/oinstall/database/install/runInstaller: Execute permission denied.
    查了半天权限，没有问题，后来朋友说让我看看介质是不是错了，我们的OS全都是hp ux ia64的，应该不会错，后来查了半天还是不能运行，于是逐一确认，排查原因，原来我的安装介质真的下载错了。

   如何查看OS的version

   1. uname
  e.g.
   $ uname -m
   ia64

   2.查看java的版本
      $ cd /opt/java1.4/bin
      $ ./java -version
         java version "1.4.2.14"
        Java(TM) 2 Runtime Environment, Standard Edition (build 1.4.2.14-070618-16:24)
        Java HotSpot(TM) Server VM (build 1.4.2 1.4.2.14-070618-18:03-PA_RISC2.0 PA2.0 (aCC_AP), mixed mode)



oracle exp/imp 详解

导入/导出是ORACLE幸存的最古老的两个命令行工具，其实我从来不认为Exp/Imp是一种好的备份方式，正确的说法是Exp/Imp只能是一个好的转储工具，特别是在小型数据库的转储，表空间的迁移，表的抽取，检测逻辑和物理冲突等中有不小的功劳。当然，我们也可以把它作为小型数据库的物理备份后的一个逻辑辅助备份，也是不错的建议。对于越来越大的数据库，特别是TB级数据库和越来越多数据仓库的出现，EXP/IMP越来越力不从心了，这个时候，数据库的备份都转向了RMAN和第三方工具。下面说明一下EXP/IMP的使用。
如何使exp的帮助以不同的字符集显示：set nls_lang=simplified chinese_china.zhs16gbk，通过设置环境变量，可以让exp的帮助以中文显示，如果set nls_lang=American_america.字符集，那么帮助就是英文的了

EXP的所有参数（括号中为参数的默认值）：
USERID                  用户名/口令      如： USERID=duanl/duanl
FULL                    导出整个数据库 (N)
BUFFER                  数据缓冲区的大小
OWNER                   所有者用户名列表,你希望导出哪个用户的对象，就用owner=username
FILE                    输出文件 (EXPDAT.DMP)
TABLES                  表名列表 ,指定导出的table名称，如：TABLES=table1,table2

RECORDLENGTH            IO 记录的长度
GRANTS                  导出权限 (Y)
INCTYPE                 增量导出类型
INDEXES                 导出索引 (Y)
RECORD                  跟踪增量导出 (Y)
ROWS                    导出数据行 (Y)
PARFILE                 参数文件名,如果你exp的参数很多，可以存成参数文件.
CONSTRAINTS             导出约束 (Y)
CONSISTENT              交叉表一致性
LOG                     屏幕输出的日志文件
STATISTICS              分析对象 (ESTIMATE)
DIRECT                  直接路径 (N)
TRIGGERS                导出触发器 (Y)
FEEDBACK                显示每 x 行 (0) 的进度
FILESIZE                各转储文件的最大尺寸
QUERY                   选定导出表子集的子句

下列关键字仅用于可传输的表空间
TRANSPORT_TABLESPACE    导出可传输的表空间元数据 (N)
TABLESPACES             将传输的表空间列表
    IMP的所有参数（括号中为参数的默认值）：
USERID                  用户名/口令
FULL                    导入整个文件 (N)
BUFFER                  数据缓冲区大小
FROMUSER      				  所有人用户名列表
FILE      						  输入文件 (EXPDAT.DMP)
TOUSER        				  用户名列表
SHOW      						  只列出文件内容 (N)
TABLES       					  表名列表
IGNORE    						  忽略创建错误 (N)
RECORDLENGTH   				  IO 记录的长度
GRANTS   							  导入权限 (Y)
INCTYPE       				  增量导入类型
INDEXES 							  导入索引 (Y)
COMMIT        				  提交数组插入 (N)
ROWS     							  导入数据行 (Y)
PARFILE       				  参数文件名
LOG       						  屏幕输出的日志文件
CONSTRAINTS   				  导入限制 (Y)
DESTROY   						  覆盖表空间数据文件 (N)
INDEXFILE 						  将表/索引信息写入指定的文件
SKIP_UNUSABLE_INDEXES   跳过不可用索引的维护 (N)
ANALYZE   						  执行转储文件中的 ANALYZE 语句 (Y)
FEEDBACK 							  显示每 x 行 (0) 的进度
TOID_NOVALIDATE   		  跳过指定类型 id 的校验
FILESIZE 							  各转储文件的最大尺寸
RECALCULATE_STATISTICS  重新计算统计值 (N)

下列关键字仅用于可传输的表空间
TRANSPORT_TABLESPACE   导入可传输的表空间元数据 (N)
TABLESPACES 					 将要传输到数据库的表空间
DATAFILES 						 将要传输到数据库的数据文件
TTS_OWNERS             拥有可传输表空间集中数据的用户

关于增量参数的说明：exp/imp的增量并不是真正意义上的增量，所以最好不要使用。


EXP常用选项
1.FULL，这个用于导出整个数据库，在ROWS=N一起使用时，可以导出整个数据库的结构。例如：
exp userid=test/test file=./db_str.dmp log=./db_str.log full=y rows=n compress=y direct=y

2.OWNER和TABLE，这两个选项用于定义EXP的对象。OWNER定义导出指定用户的对象；TABLE指定EXP的table名称，例如：
exp userid=test/test file=./db_str.dmp log=./db_str.log owner=duanl
exp userid=test/test file=./db_str.dmp log=./db_str.log table=nc_data,fi_arap

3.BUFFER和FEEDBACK，在导出比较多的数据时，我会考虑设置这两个参数。例如：
exp userid=test/test file=yw97_2003.dmp log=yw97_2003_3.log feedback=10000 buffer=100000000 tables=WO4,OK_YT
feedback;每一万行显示一次进度。

4.FILE和LOG，这两个参数分别指定备份的DMP名称和LOG名称，包括文件名和目录，例子见上面。

5.COMPRESS参数不压缩导出数据的内容。用来控制导出对象的storage语句如何产生。默认值为Y，使用默认值，对象的存储语句的init extent等于当前导出对象的extent的总和。推荐使用COMPRESS＝N。

6.FILESIZE该选项在8i中可用。如果导出的dmp文件过大时，最好使用FILESIZE参数，限制文件大小不要超过2G。如：
exp userid=duanl/duanl file=f1,f2,f3,f4,f5 filesize=2G owner=scott
这样将创建f1.dmp, f2.dmp等一系列文件，每个大小都为2G，如果导出的总量小于10G,EXP不必创建f5.bmp.


IMP常用选项
1、FROMUSER和TOUSER,使用它们实现将数据从一个SCHEMA中导入到另外一个SCHEMA中。例如：假设我们做exp时导出的为test的对象,现在我们想把对象导入用户：
imp userid=test1/test1 file=expdat.dmp fromuser=test1 touser=test1

2、IGNORE、GRANTS和INDEXES，其中IGNORE参数将忽略表的存在，继续导入，这个对于需要调整表的存储参数时很有用，我们可以先根据实际情况用合理的存储参数建好表，然后直接导入数据。而GRANTS和INDEXES则表示是否导入授权和索引，如果想使用新的存储参数重建索引，或者为了加快到入速度，我们可以考虑将INDEXES设为N，而GRANTS一般都是Y。例如：imp userid=test1/test1 file=expdat.dmp fromuser=test1 touser=test1 indexes=N


表空间传输
表空间传输是8i新增加的一种快速在数据库间移动数据的一种办法，是把一个数据库上的格式数据文件附加到另外一个数据库中，而不是把数据导出成Dmp文件，这在有些时候是非常管用的，因为传输表空间移动数据就象复制文件一样快。

关于传输表空间有一些规则，即：
1.源数据库和目标数据库必须运行在相同的硬件平台上。
2.源数据库与目标数据库必须使用相同的字符集。
3.源数据库与目标数据库一定要有相同大小的数据块
4.目标数据库不能有与迁移表空间同名的表空间
5.SYS的对象不能迁移
6.必须传输自包含的对象集
7.有一些对象，如物化视图，基于函数的索引等不能被传输

可以用以下的方法来检测一个表空间或一套表空间是否符合传输标准：
exec sys.dbms_tts.transport_set_check('tablespace_name',true);
select * from sys.transport_set_violation;
如果没有行选择，表示该表空间只包含表数据，并且是自包含的。对于有些非自包含的表空间，如数据表空间和索引表空间，可以一起传输。

以下为简要使用步骤，如果想参考详细使用方法，也可以参考ORACLE联机帮助。
1.设置表空间为只读（假定表空间名字为APP_Data 和APP_Index）
alter tablespace app_data read only;
alter tablespace app_index read only;
2.发出EXP命令
SQL>host exp userid=”””sys/password as sysdba””” transport_tablespace=y tablespace=(app_data, app_index)
以上需要注意的是
a.为了在SQL中执行EXP，USERID必须用三个引号，在UNIX中也必须注意避免“/”的使用
b.在816和以后，必须使用sysdba才能操作
c.这个命令在SQL中必须放置在一行

3.拷贝数据文件到另一个地点，即目标数据库,可以是cp(unix)或copy(windows)或通过ftp传输文件（一定要在bin方式）
4.把本地的表空间设置为读写
5.在目标数据库附加该数据文件
imp file=expdat.dmp userid=”””sys/password as sysdba””” transport_tablespace=y “datafile=(c:\temp\app_data,c:\temp\app_index)”
6.设置目标数据库表空间为读写
alter tablespace app_data read write;
alter tablespace app_index read write;


优化EXP/IMP的方法：
     当需要exp/imp的数据量比较大时，这个过程需要的时间是比较长的，我们可以用一些方法来优化exp/imp的操作。

exp:使用直接路径 direct=y
    oracle会避开sql语句处理引擎,直接从数据库文件中读取数据,然后写入导出文件.
    可以在导出日志中观察到: exp-00067: table xxx will be exported in conventional path
    如果没有使用直接路径,必须保证buffer参数的值足够大.
    有一些参数于direct=y不兼容,无法用直接路径导出可移动的tablespace,或者用query参数导出数据库子集.
    当导入导出的数据库运行在不同的os下时,必须保证recordlength参数的值一致(RECORDLENGTH:I/O记录的长度).

imp:通过以下几个途径优化
  1.避免磁盘排序
		将sort_area_size设置为一个较大的值,比如100M
	2.避免日志切换等待
		增加重做日志组的数量,增大日志文件大小.
	3.优化日志缓冲区
		比如将log_buffer容量扩大10倍(最大不要超过5M)
	4.使用阵列插入与提交
		commit = y
		注意:阵列方式不能处理包含LOB和LONG类型的表,对于这样的table,如果使用commit = y,每插入一行,就会执行一次提交.
	5.使用NOLOGGING方式减小重做日志大小
		在导入时指定参数indexes=n,只导入数据而忽略index,在导完数据后在通过脚本创建index,指定 NOLOGGING选项


导出/导入与字符集
    进行数据的导入导出时，我们要注意关于字符集的问题。在EXP/IMP过程中我们需要注意四个字符集的参数：导出端的客户端字符集，导出端数据库字符集，导入端的客户端字符集，导入端数据库字符集。
我们首先需要查看这四个字符集参数。
查看数据库的字符集的信息：
SQL> select * from nls_database_parameters;
PARAMETER                       VALUE
------------------------------ ------------------------------------------
NLS_LANGUAGE                    AMERICAN
NLS_TERRITORY                    AMERICA
NLS_CURRENCY                    $
NLS_ISO_CURRENCY                AMERICA
NLS_NUMERIC_CHARACTERS          .,
NLS_CHARACTERSET                ZHS16GBK
NLS_CALENDAR                    GREGORIAN
NLS_DATE_FORMAT                 DD-MON-RR
NLS_DATE_LANGUAGE               AMERICAN
NLS_SORT                          BINARY
NLS_TIME_FORMAT                 HH.MI.SSXFF AM
NLS_TIMESTAMP_FORMAT            DD-MON-RR HH.MI.SSXFF AM
NLS_TIME_TZ_FORMAT              HH.MI.SSXFF AM TZH:TZM
NLS_TIMESTAMP_TZ_FORMAT         DD-MON-RR HH.MI.SSXFF AM TZH:TZM
NLS_DUAL_CURRENCY               $
NLS_COMP                        BINARY
NLS_NCHAR_CHARACTERSET          ZHS16GBK
NLS_RDBMS_VERSION               8.1.7.4.1

NLS_CHARACTERSET：ZHS16GBK是当前数据库的字符集。

我们再来查看客户端的字符集信息：
客户端字符集的参数NLS_LANG=_< territory >.
language：指定oracle消息使用的语言,日期中日和月的显示。
Territory：指定货币和数字的格式，地区和计算星期及日期的习惯。
Characterset：控制客户端应用程序使用的字符集。通常设置或等于客户端的代码页。或者对于unicode应用设为UTF8。
在windows中，查询和修改NLS_LANG可在注册表中进行：
HKEY_LOCAL_MACHINE\SOFTWARE\Oracle\HOMExx\
xx指存在多个Oracle_HOME时的系统编号。
在unix中：
$ env|grep NLS_LANG
NLS_LANG=simplified chinese_china.ZHS16GBK
修改可用：
$ export NLS_LANG=AMERICAN_AMERICA.UTF8

通常在导出时最好把客户端字符集设置得和数据库端相同。当进行数据导入时，主要有以下两种情况：
		1.源数据库和目标数据库具有相同的字符集设置。
			这时,只需设置导出和导入端的客户端NLS_LANG等于数据库字符集即可。
		2.源数据库和目标数据库字符集不同。
      先将导出端客户端的NLS_LANG设置成和导出端的数据库字符集一致，导出数据，然后将导入端客户端的NLS_LANG设置成和导出端一致，导入数据，这样转换只发生在数据库端，而且只发生一次。
      这种情况下，只有当导入端数据库字符集为导出端数据库字符集的严格超集时，数据才能完全导成功，否则，可能会有数据不一致或乱码出现。

不同版本的EXP/IMP问题
   	一般来说，从低版本导入到高版本问题不大，麻烦的是将高版本的数据导入到低版本中，在Oracle9i之前，不同版本Oracle之间的EXP/IMP可以通过下面的方法来解决：
		1、在高版本数据库上运行底版本的catexp.sql；
		2、使用低版本的EXP来导出高版本的数据；
		3、使用低版本的IMP将数据库导入到低版本数据库中；
		4、在高版本数据库上重新运行高版本的catexp.sql脚本。

但在9i中，上面的方法并不能解决问题。如果直接使用低版本EXP/IMP会出现如下错误：
EXP-00008: orACLE error %lu encountered
orA-00904: invalid column name
这已经是一个公布的BUG，需要等到Oracle10.0才能解决，BUG号为2261722，你可以到METALINK上去查看有关此BUG的详细信息。
BUG归BUG，我们的工作还是要做，在没有Oracle的支持之前，我们就自己解决。在Oracle9i中执行下面的SQL重建exu81rls视图即可。

Create or REPLACE view exu81rls
(objown,objnam,policy,polown,polsch,polfun,stmts,chkopt,enabled,spolicy)
AS select u.name, o.name, r.pname, r.pfschma, r.ppname, r.pfname,
decode(bitand(r.stmt_type,1), 0,'', 'Select,')
|| decode(bitand(r.stmt_type,2), 0,'', 'Insert,')
|| decode(bitand(r.stmt_type,4), 0,'', 'Update,')
|| decode(bitand(r.stmt_type,8), 0,'', 'Delete,'),
r.check_opt, r.enable_flag,
DECODE(BITAND(r.stmt_type, 16), 0, 0, 1)
from user$ u, obj$ o, rls$ r
where u.user# = o.owner#
and r.obj# = o.obj#
and (uid = 0 or
uid = o.owner# or
exists ( select * from session_roles where role='Select_CATALOG_ROLE')
)
/
grant select on sys.exu81rls to public;
/

可以跨版本的使用EXP/IMP，但必须正确地使用EXP和IMP的版本：
1、总是使用IMP的版本匹配数据库的版本，如：要导入到817中，使用817的IMP工具。
2、总是使用EXP的版本匹配两个数据库中最低的版本，如：从9201往817中导入，则使用817版本的EXP工具。

示例：

1.exp的条件导出

userid='/ as sysdba '
file=(exp01.dmp,exp02.dmp,exp03.dmp,exp04.dmp,exp05.dmp,exp06.dmp,exp07.dmp,exp08.dmp,exp09.dmp,
exp10.dmp,exp11.dmp,exp12.dmp,exp13.dmp,exp14.dmp,exp15.dmp,exp16.dmp,exp17.dmp,exp18.dmp,exp19.dmp,
exp20.dmp,exp21.dmp,exp22.dmp,exp23.dmp,exp24.dmp,exp25.dmp,exp26.dmp,exp27.dmp,exp28.dmp,exp29.dmp,
exp30.dmp,exp31.dmp,exp32.dmp,exp33.dmp,exp34.dmp,exp35.dmp,exp36.dmp,exp37.dmp,exp38.dmp,exp39.dmp)
filesize=4000m
log=exp.log
tables=(
CSPIDATA.cspi_cms_call_record
)
buffer=40000000
recordlength=65535
RESUMABLE=y
RESUMABLE_NAME=exp_byrnes
RESUMABLE_TIMEOUT=99999
QUERY="where GL_DATE in('20100930','20101031','20101130')"

2.imp导入

userid='/ as sysdba '
file=exp01.dmp
buffer=40000000
fromuser=RISKREPT
touser=aud_riskmd
tables=(
cspi_cms_call_record
)
ignore=y
rows=y
log=imp.log
RESUMABLE=y
RESUMABLE_NAME=imp_byrnes
RESUMABLE_TIMEOUT=99999
commit=y

3.expdp导出

create directory dtpump_egis as '..................';

userid=audmgr/paic1234
directory=dtpump_egis
dumpfile=expdp_egis%U.dmp
parallel=4
tables=
(
EGISDATA.POLICY_APPLICATION
EGISDATA.UNDERWRITING
EGISDATA.QUOTATION_RESULT
EGISDATA.QUOTATE_UNDERWRITER_OPINION

)
content=all
LOGFILE=impdp_gbs4.log
JOB_NAME=job_egis
REMAP_SCHEMA=EGISDATA:aud_gbs
REMAP_TABLESPACE=EGISDATA:ludata
TABLE_EXISTS_ACTION=REPLACE
EXCLUDE=constraint, ref_constraint, grant,index,trigger

4.impd导入

create directory dtpump_egis as '.............';

userid=audmgr/paic1234
directory=dtpump_egis
dumpfile=expdp_egis%U.dmp
parallel=4
tables=
(
EGISDATA.POLICY_APPLICATION
EGISDATA.UNDERWRITING
EGISDATA.QUOTATION_RESULT
EGISDATA.QUOTATE_UNDERWRITER_OPINION
)
content=all
LOGFILE=impdp_gbs5_idx.log
JOB_NAME=zyjob_gbs5_idx
REMAP_SCHEMA=EGISDATA:aud_gbs
REMAP_TABLESPACE=EGISDATA:luidx,EGISIDX:luidx
TABLE_EXISTS_ACTION=REPLACE
INCLUDE=index

5.expdp只导表结构

userid='/ as sysdba'
DIRECTORY=rik_expimpdp_dest
dumpfile=expdp%U.dmp
filesize=3000m
parallel=5
SCHEMAS=IMSFPDATA
content=METADATA_ONLY
LOGFILE=expdp_csb.log
JOB_NAME=expdp_rik_job1

6.expdp条件导出

userid='/ as sysdba'
DIRECTORY=rik_imp_1
dumpfile=expdp_1%U.dmp
parallel=5
tables=
(
ISBDATA. OF_GENERAL_HIS
RPTDATA. TIN_CORE_GENERAL
)
content=all
LOGFILE=expdp_rik_1.log
JOB_NAME=expdp_rik_job1
QUERY="where GL_DATE in('20100930','20101031','20101130')"


7.11g中IMPDP重命名导入表

userid='/ as sysdba '
directory=dtpump
dumpfile=expdp%U.dmp
parallel=4
REMAP_TABLE=ECDATA.TRS_PROJECT_ITEM:ECDATA.TRS_PROJECT_ITEM_BAK
content=all
LOGFILE=impdp.log
JOB_NAME=riky_imp
REMAP_SCHEMA=ECDATA:ECDATA
TABLE_EXISTS_ACTION=REPLACE

.使用TRANSFORM去掉表空间和存储子句
secooler@secDB /expdp$ impdp sec/sec directory=expdp_dir dumpfile=sec_expdp.dmp sqlfile=sec_expdp.sql TRANSFORM=segment_attributes:n
TRANSFORM=segment_attributes:n

rm -rf *.dmp

mknod exp01.dmp p
mknod exp02.dmp p
mknod exp03.dmp p
mknod exp04.dmp p

gzip -d < exp01.dmp.gz > exp01.dmp &
gzip -d < exp02.dmp.gz > exp02.dmp &
gzip -d < exp03.dmp.gz > exp03.dmp &
gzip -d < exp04.dmp.gz > exp04.dmp &

set NLS_LANG=SIMPLIFIED CHINESE_CHINA.ZHS16GBK
imp  dcppdata/dcpp123  file=exp01.dmp,exp02.dmp,exp03.dmp,exp04.dmp log=0919.log  buffer=40960000 feedback=10000 ignore=y  tables=TFLOW_OBJECT,TFLOW_TASK,TGUARANTY_CONTRACT,TGUARANTY_INFO,TGUARANTY_RELATIVE,TIND_INFO,TCLASSIFY_RECORD,TBUSINESS_TYPE,TBUSINESS_HISTORY,TBUSINESS_DUEBILL

当从linux 64 向 linux32 做数据库迁移时，数据库能正常启动，但是执行一系列操作时会报异常：
ORA-06553: PLS-801: internal error [56319]
同时在跟踪文件还伴随：
*** SESSION ID:(26.44) 2010-12-02 13:36:17.147
Error in executing triggers on connect internal




SQL>
SQL>
SQL>
SQL> select trigger_name from dba_triggers where trigger_name like '%DDL%' and owner='DBMGR';

TRIGGER_NAME
------------------------------
DBTR_DDL_AUDIT
DBTR_DDL_RESTRICTION

SQL> alter trigger DBMGR.DBTR_DDL_RESTRICTION  disable;

Trigger altered.

SQL>


ERROR at line 1:
ORA-00604: error occurred at recursive SQL level 1
ORA-25153: Temporary Tablespace is Empty
ORA-06512: at "DBMGR.PRC_DDL_RESTRICTION", line 10
ORA-06512: at line 2
这个异常可能是由于同平台不同bit引起的，我们需要重新编译对象来消除这个不兼容影响
以下是简单步骤：
1、修改初始化文件,增加 _SYSTEM_TRIG_ENABLED = false参数
2、Stratup nomount
3、从源库备份一个控制文件，在目标库上重新创建控制文件。
4、Shutdown immediate
5、 Startup upgrade
6、@$ORACLE_HOME/rdbms/admin/utlirp.sql;
7、Shutdown immediate
8、Startup
9、@$ORACLE_HOME/rdbms/admin/utlrp.sql;
10、Shutdown immediate
11、再次修改初始化参数文件,删除参数 _SYSTEM_TRIG_ENABLED = false
12、Startup

转换完成(当时是照网上一个文档做的，现在仔细看来1、2、3、4、11这些步骤貌似都不需要的，最最主要的就是使用utlirp来把相关内容全部在32位平台下编译一遍)，



Long Session监控
select a.sid,a.serial#,a.machine,a.osuser,a.username 用户名,trunc(a.last_call_et/60) 已执行时间_分钟, to_char(a.LOGON_TIME,'yyyymmdd hh24:mi:ss') 登录时间,trunc((sysdate-a.logon_time)*24*60) 登录持续时间_分钟,
        b.sql_text SQL
from v$session a,v$sqltext b
where a.status='ACTIVE' and username not in('SYS')
	and a.last_call_et/60 >= &2
	and a.sql_address=b.address
	and a.username is not null
	order by a.username,a.last_call_et desc,a.sid, b.address,b.piece;


回滚段的使用在正常情况下为循环使用的。但若在当前extent写完后，需要更多的空间时，回滚段的next extent 中存在有活动事务，则实例会试图扩展回滚段。如果回滚段中有长时间 idle 的事务，尽管其占用的回滚段的量很小，但是，由于其一直不释放，将导致回滚段一直增长，直至该事务释放占用的回滚段或是回滚段表空间满。
可通过检查 v$rollstat 来获得回滚段的使用情况，应监控extents 值远大于 optimal 的回滚段，以防其由于有异常的会话而导致回滚段增长过大。

可使用以下查询来获取数据库中异常使用的RBS：
COLUMN   start_uext FORMAT   999
COLUMN   xidusn FORMAT   99
COLUMN   sid FORMAT   9999
COLUMN   username FORMAT   a10
SELECT s.sid, s.serial#, t.start_time, t.xidusn,s.username, t.start_uext, r.curext, s.last_call_et, s.machine, s.username
 FROM V$session s, V$transaction t, V$rollstat r
 WHERE s.saddr=t.ses_addr
 AND t.xidusn=r.usn
 AND ((r.curext=t.start_uext-1) OR
((r.curext=r.extents-1) AND t.start_uext=0));

这个SQL的作用就是查出数据库中RBS的当前extent的next extent被占用的进程、事务的信息。


获取session数量和百分比的sql脚本，内容如下：
set feedback off
set echo off
set trims on
set heading off
conn ovsee/ovsee03@&1
spool out/session_&1..txt
select trunc(a*100/b,2)||':'||a||':'||b  from (select value b from v$parameter where name='processes'), (select cou
nt(*) a from v$session);
spool off




查看DML LOCK情况和锁定的对象情况：
select a.sid,
   decode(a.type,
   'MR', 'Media Recovery',
   'RT', 'Redo Thread',
   'UN', 'User Name',
   'TX', 'Transaction',
   'TM', 'DML',
   'UL', 'PL/SQL User Lock',
   'DX', 'Distributed Xaction',
   'CF', 'Control File',
   'IS', 'Instance State',
   'FS', 'File Set',
   'IR', 'Instance Recovery',
   'ST', 'Disk Space Transaction',
   'IR', 'Instance Recovery',
   'ST', 'Disk Space Transaction',
   'TS', 'Temp Segment',
   'IV', 'Library Cache Invalidation',
   'LS', 'Log Start or Switch',
   'RW', 'Row Wait',
   'SQ', 'Sequence Number',
   'TE', 'Extend Table',
   'TT', 'Temp Table',
   a.type) lock_type,
   decode(a.lmode,
   0, 'None',           /* Mon Lock equivalent */
   1, 'Null',           /* N */
   2, 'Row-S (SS)',     /* L */
   3, 'Row-X (SX)',     /* R */
   4, 'Share',          /* S */
   5, 'S/Row-X (SSX)',  /* C */
   6, 'Exclusive',      /* X */
   to_char(a.lmode)) mode_held,
   decode(a.request,
   0, 'None',           /* Mon Lock equivalent */
   1, 'Null',           /* N */
   2, 'Row-S (SS)',     /* L */
   3, 'Row-X (SX)',     /* R */
   4, 'Share',          /* S */
   5, 'S/Row-X (SSX)',  /* C */
   6, 'Exclusive',      /* X */
   to_char(a.request)) mode_requested,
   a.ctime        lock_time,
   to_char(a.id1) lock_id1,
   c.object_name  lock_object_name,
   c.object_type  lock_object_type,
   to_char(a.id2) lock_id2
from v$lock a,dba_objects c
   where (id1,id2) in
     (select b.id1, b.id2 from v$lock b where b.id1=a.id1 and b.id2=a.id2 )
     and a.type in ('TX','TM')
     and a.id1=c.object_id(+)


2.2.2	查看实时的锁等待情况
1、判断是否存在锁等待，同时查出BLOCKER和WAITER：
SELECT * FROM V$LOCK WHERE BLOCK > 0;    --查出的是BLOCKER的加锁情况
SELECT * FROM V$LOCK WHERE REQUEST > 0;  --查出的是WAITER的等锁情况
--也可以从等待事件入手：
    SELECT * FROM V$SESSION_WAIT WHERE EVENT ='enqueue';


存在多个BLOCKER时，查出源头的BLOCKER：
SELECT *
  FROM V$LOCK
 WHERE SID IN (SELECT SID SESSION_ID
                 FROM V$LOCK
                WHERE BLOCK > 0
               MINUS
               SELECT W.SID SESSION_ID
                 FROM V$SESSION_WAIT W
                WHERE W.EVENT = 'enqueue');
        因为等待'enqueue'的都是WAITER，在V$LOCK过滤了这些WAITER后，剩下的应该都是真正的BLOCKER。


查看BLOCKER对应的SESSION的状态和等待事件：
SELECT S.SID,
       S.USERNAME,
       S.STATUS,
       W.EVENT,
       L.TYPE,
       L.ID1,
       L.ID2,
       L.LMODE,
       L.CTIME,
       L.BLOCK
    FROM V$SESSION S, V$SESSION_WAIT W, V$LOCK L
   WHERE S.SID = W.SID
    AND S.SID = L.SID
    AND L.BLOCK > 0;


查出WAITER等待的记录行：
 --首先查出WAITER等待的资源：
 SELECT ROW_WAIT_OBJ# ,
       ROW_WAIT_FILE# ,
       ROW_WAIT_BLOCK# ,
       ROW_WAIT_ROW#
    FROM V$SESSION
    WHERE SID IN (SELECT DISTINCT SID FROM V$LOCK WHERE REQUEST > 0 )
    AND ROW_WAIT_OBJ# <> -1;
--再根据OBJECT_ID得出具体的对象属主和名称：
SELECT OWNER,OBJECT_NAME,OBJECT_TYPE FROM DBA_OBJECTS WHERE OBJECT_ID=< ROW_WAIT_OBJ#>
--根据以上得到的OBJECT_ID,FILE_ID,BLOCK_ID,ROW#，就构成标准的ROWID，查出记录行：
   SELECT *
  FROM < OWNER > . < OBJECT_NAME >
 WHERE ROWID = DBMS_ROWID.ROWID_CREATE(1,
                                       ROW_WAIT_OBJ#,
                                       ROW_WAIT_FILE#,
                                       ROW_WAIT_BLOCK#,
                                       ROW_WAIT_ROW#);
2.2.3	查看累积的锁和锁等待情况
  --查看INSTANCE级别的enqueue资源使用情况：
  SELECT * FROM V$SYSSTAT WHERE NAME  LIKE '%enqueue%';
  --查看INSTANCE级别的等待enqueue事件的情况：
  SELECT * FROM V$SYSTEM_EVENT WHERE EVENT='enqueue';



expdp ddw/ddw@jiong directory=EXPDIR dumpfile=ddwdump.dmp schemas=ddw include=procedure,table:\"in('SALES','SALES_TMP')\" job_name=zhou logfile=ddwdump.log
只导出SALES和SALES_TMP两张表

table:\"in('SALES','SALES_TMP')\"   双引号要用斜杠转义

expdp ddw/ddw@jiong directory=EXPDIR dumpfile=ddwdump.dmp schemas=ddw include=procedure,table:\"LIKE('AATEST%')\" job_name=zhou logfile=ddwdump.log

刚测试过，成功导出 table:\"LIKE('AATEST%')\"，AATEST开头的三张表都OK的

连接到: Oracle Database 10g Enterprise Edition Release 10.2.0.1.0 - Production
With the Partitioning, OLAP and Data Mining options
自动启用 FLASHBACK 以保持数据库完整性。
启动 "DDW"."ZHOU":  ddw/********@jiong directory=EXPDIR dumpfile=ddwdump.dmp schemas=ddw include=procedure,table:"LIKE('AATEST%')" job_name=zhou logfile=ddwdump.log
正在使用 BLOCKS 方法进行估计...
处理对象类型 SCHEMA_EXPORT/TABLE/TABLE_DATA
使用 BLOCKS 方法的总估计: 192 KB
处理对象类型 SCHEMA_EXPORT/TABLE/TABLE
处理对象类型 SCHEMA_EXPORT/TABLE/INDEX/INDEX
处理对象类型 SCHEMA_EXPORT/TABLE/CONSTRAINT/CONSTRAINT
处理对象类型 SCHEMA_EXPORT/TABLE/INDEX/STATISTICS/INDEX_STATISTICS
处理对象类型 SCHEMA_EXPORT/PROCEDURE/PROCEDURE
处理对象类型 SCHEMA_EXPORT/PROCEDURE/ALTER_PROCEDURE
处理对象类型 SCHEMA_EXPORT/TABLE/STATISTICS/TABLE_STATISTICS
. . 导出了 "DDW"."AATEST"                              6.304 KB       4 行
. . 导出了 "DDW"."AATEST_1"                            6.304 KB       4 行
. . 导出了 "DDW"."AATEST_2"                            6.234 KB       1 行
已成功加载/卸载了主表 "DDW"."ZHOU"
******************************************************************************
DDW.ZHOU 的转储文件集为:
  D:\DDWDUMP.DMP
作业 "DDW"."ZHOU" 已于 21:42:32 成功完成


我发现里面似乎不能用正则表达式。
可以这么搞：
expdp ddw/ddw@jiong directory=EXPDIR dumpfile=ddwdump.dmp schemas=ddw include=table:\"IN(select object_name from dba_objects where owner='DDW' and object_type='TABLE' and \(object_name like 'AATEST%' or object_name like 'SALES%'\)\)\" job_name=zhou logfile=ddwdump.log

结果：
连接到: Oracle Database 10g Enterprise Edition Release 10.2.0.1.0 - Production
With the Partitioning, OLAP and Data Mining options
自动启用 FLASHBACK 以保持数据库完整性。
启动 "DDW"."ZHOU":  ddw/********@jiong directory=EXPDIR dumpfile=ddwdump.dmp schemas=ddw include=table:"IN(select object_name from dba_objects where owner='DDW' and object_type='TABLE' and \(object_name like 'AATEST%' or object_name like 'SALES%'\)\)" job_name=zhou logfile=ddwdump.log
正在使用 BLOCKS 方法进行估计...
处理对象类型 SCHEMA_EXPORT/TABLE/TABLE_DATA
使用 BLOCKS 方法的总估计: 192 KB
处理对象类型 SCHEMA_EXPORT/TABLE/TABLE
处理对象类型 SCHEMA_EXPORT/TABLE/INDEX/INDEX
处理对象类型 SCHEMA_EXPORT/TABLE/CONSTRAINT/CONSTRAINT
处理对象类型 SCHEMA_EXPORT/TABLE/INDEX/STATISTICS/INDEX_STATISTICS
处理对象类型 SCHEMA_EXPORT/TABLE/STATISTICS/TABLE_STATISTICS
. . 导出了 "DDW"."AATEST"                              6.304 KB       4 行
. . 导出了 "DDW"."AATEST_1"                            6.304 KB       4 行
. . 导出了 "DDW"."AATEST_2"                            6.234 KB       1 行
. . 导出了 "DDW"."SALES_IMP"                               0 KB       0 行
. . 导出了 "DDW"."SALES_PAR1"                              0 KB       0 行
. . 导出了 "DDW"."SALES_SMALL"                             0 KB       0 行
已成功加载/卸载了主表 "DDW"."ZHOU"
******************************************************************************
DDW.ZHOU 的转储文件集为:
  D:\DDWDUMP.DMP
作业 "DDW"."ZHOU" 已于 00:02:37 成功完成





INCLUDE=TABLE:"LIKE 'AAA%'",INCLUDE=TABLE:"LIKE 'BBB%'",INCLUDE=TABLE:"LIKE 'CCC%'"



解析并马上执行动态语句 ,或非运行时创建的pl/sql块

1. 不提交dml事务,要显式提交;
execute immediate处理ddl,会提交所以以前改变的数据;

2.不支持多行查询,可以临时表 或者ref cursors

3.执行sql不需语句,执行pl/sql 要加分号;

--0.传入
declare
    i_aac001 number(6):=111;
begin
    execute immediate 'insert into a2(aac001) values(:1)'
    using i_aac001;
end;


insert into a2(aac001) values(1);
insert into a2(aac001) values(2);


--1.传入/传出
declare
    cnt number(6);
begin
    execute immediate 'select 1 from dual where 1=:1' into cnt
    using cnt;
    dbms_output.put_line(cnt);
end;

--2.调用存储过程
declare
    s1 varchar2(10);
    s2 varchar2(10);
begin
    execute immediate 'begin test1(:1,:2); end;'
    using s1,s2;
end;

--3.传值到记录
declare
--类型
--声明
    type type_a is record(str varchar2(10));
    v_a type_a;
    v_b a2%rowtype;
begin
    execute immediate 'select * from a2 where aac001=1742178'
    into v_b;
end;

--4.多行查询 用临时表 或ref cursors
declare
   l_sal    pls_integer := 2000;
begin
   execute immediate 'insert into temp(empno, ename) ' ||
                    '           select empno, ename from emp ' ||
                    '           where   sal > :1'
     using l_sal;
   commit;
end;

http://baiyaoming.iteye.com/blog/1255016


for in  变量声明类型
-------------------------------
declare
cursor cur is select * from a2;
begin
    for c in (select * from a2) loop
        dbms_output.put_line(c.aac002);
    end loop;
end;

insert into a2(aac001) values(1);

declare
    type t_a is table of a2%rowtype;
    type t_b is table of number(10) index by pls_integer;
    v_a t_a;
    v_b t_b;
begin
    select aac001 bulk collect into v_b from a2;
    for i in v_b.first..v_b.last loop
        dbms_output.put_line(v_b(i));
    end loop;
end;




Oracle 从缓存里面查找真实的执行计划
设置autotrace

序号
 命令
 解释

1
 SET AUTOTRACE OFF
 此为默认值，即关闭Autotrace

2
 SET AUTOTRACE ON EXPLAIN
 只显示执行计划

3
 SET AUTOTRACE ON STATISTICS
  只显示执行的统计信息

4
 SET AUTOTRACE ON
  包含2,3两项内容

5
 SET AUTOTRACE TRACEONLY
  与ON相似，但不显示语句的执行结

使用SQL

SQL>EXPLAIN PLAN FOR sql语句;

SQL>SELECT plan_table_output FROM TABLE(DBMS_XPLAN.DISPLAY('PLAN_TABLE'));

一.  查看当前session 的SID
SYS@anqing1(rac1)> SELECT USERENV('SID') FROM DUAL;
USERENV('SID')
--------------
137
SYS@anqing1(rac1)> SELECT SID FROM V$MYSTAT WHERE ROWNUM =1;
SID
----------
137

二.  查看缓存中的Explain Plan
1）根据SID，从v$sql中找到相应SQL的HASH_VALUE和ADDRESS
/* Formatted on 2011/6/20 17:38:20 (QP5 v5.163.1008.3004) */
SELECT a.sql_text, a.address, a.hash_value
FROM v$sql a, v$session b
WHERE a.hash_value = b.sql_hash_value AND b.sid = &sid;

2）根据hash_value和address的值，从v$sql_plan中找到真实的执行计划
/* Formatted on 2011/6/20 17:39:22 (QP5 v5.163.1008.3004) */
SET LINE 200;
COL oper FORMAT a100;
SELECT LPAD (oper, LENGTH (oper) + LEVEL * 2, ' ') oper, cost
FROM (SELECT object_name || ':' || operation || ' ' || options AS oper,
cost,
id,
parent_id
FROM v$sql_plan
WHERE hash_value = '&hash_value' AND address = '&address')
START WITH id = 0
CONNECT BY PRIOR id = parent_id;







 用unzip解压多个压缩文件

法一：用分号隔开(适用于对象较少的时候）
# ls
p2848731_11i_SOLARIS.zip  p2848731_11i_zhs.zip      p4262360_11i_GENERIC.zip
#unzip p2848731_11i_SOLARIS.zip  ;unzip p2848731_11i_zhs.zip   ;unzip p4262360_11i_GENERIC.zip
法二：
#find . -name '*.zip' -exec unzip {} \;
法三：
#ls *.zip | xargs -n1 unzip
法四：（借用一个循环）
# for i in *
> do
> unzip $i
> done




ps显示为uid而不是用户名，是因为用户名超过8个字符。当用户名超过8个字符时，显示时就会用uid代替。
[palog@CNSH041576 procps-3.2.8]$ cat /etc/passwd|grep 2001
mt2s0ylcc:x:2001:5008::/paic/t2s0ylcc/rdbms/mt2s0ylcc:/bin/bash
[palog@CNSH041576 procps-3.2.8]$ cat /etc/passwd|grep 2081
mt3s0ylcc:x:2081:5008::/paic/t3s0ylcc/rdbms/mt3s0ylcc:/bin/bash



 最近PL/SQL包在编译时被hang住，起初以为是所依赖的对象被锁住。结果出乎意料之外。下面直接看代码演示。

1、在SQL*Plus下编译包时被hang住
SQL> alter package bo_syn_data_pkg compile;
alter package bo_syn_data_pkg compile
*
ERROR at line 1:
ORA-01013: user requested cancel of current operation

Elapsed: 00:04:52.65                                  -->强行中断，此时编译时间已经超过4分钟

SQL> alter package bo_syn_data_pkg compile body;      -->编译Body时也被hang住
>alter package bo_syn_data_pkg compile body
*
ERROR at line 1:
ORA-01013: user requested cancel of current operation

Elapsed: 00:06:58.05

SQL> select * from v$mystat where rownum<2;

   SID STATISTIC#      VALUE
------ ---------- ----------
  1056          0          1

Elapsed: 00:00:00.01
SQL> select sid,serial#,username from v$session where sid=1056;

   SID    SERIAL#     Oracle User
------ ---------- ---------------
  1056      57643 GOEX_ADMIN

Elapsed: 00:00:00.01

2、故障分析
-->在session 2中监控，没有任何对象被锁住
SQL> @locks_blocking

no rows selected

-->监控编译的session时发现出现library cache pin事件
SQL> select sid,seq#,event,p3text,wait_class from v$session_wait where event like 'library cache pin';

       SID       SEQ# EVENT                     P3TEXT                                   WAIT_CLASS
---------- ---------- ------------------------- ---------------------------------------- --------------------
      1056         69 library cache pin         100*mode+namespace                       Concurrency

-->来看看library cache pin
-->The library cache pin wait event is associated with library cache concurrency. It occurs when the
-->session tries to pin an object in the library cache to modify or examine it. The session must acquire a
-->pin to make sure that the object is not updated by other sessions at the same time. Oracle posts this
-->event when sessions are compiling or parsing PL/SQL procedures and views.
-->上面的描述即是需要将对象pin到library cache，且此时这个对象没有被其他对象更新或持有。对我们的这个包而言，即此时没有其它对象
-->修改该或者其依赖的对象没有被锁住。而此时出现该等待事件意味着包或其依赖对象一定被其它session所持有。前面的查询没有找到任何
-->锁定对象，看来一定包被其它session所持有。

-->查看当前数据库所有的session的情况
-->发现有一个unknow的session
SQL> @sess_users_active

+----------------------------------------------------+
| Active User Sessions (All)                         |
+----------------------------------------------------+

   SID Serial ID    Status    Oracle User     O/S User  O/S PID Session Program              Terminal   Machine
------ --------- --------- -------------- ------------ -------- -------------------------- ---------- ---------
  1086     59678    ACTIVE     GOEX_ADMIN       oracle   5840   oracle@Dev-DB-04 (J000)      UNKNOWN  Dev-DB-04
  1093     54214    ACTIVE     GOEX_ADMIN       oracle   3847   sqlplus@Dev-DB-04 (TNS V1-      pts/1 Dev-DB-04

-->查询该session运行的SQL语句
-->经验证下面的SQL语句正是所编译包中的一部分
SQL> @sess_query_sql
Enter value for sid: 1086
old   8:   AND s.sid = &&sid
new   8:   AND s.sid = 1086

SQL_TEXT
--------------------------------------------------------------------------------
SELECT BO_SYN_DATA_PKG.GEN_NEW_RECID AS REC_ID, TO_CHAR( GOATOTIMESTAMP, 'yyyymm
dd' ) AS TRADE_DATE, 'DMA' AS TRANS_TYPE, TO_CHAR( GOATOACTIONID ) AS EXEC_KEY,
GOATOGROUPREFNUM AS GRP_REF_NUM, GOATOL1ORDERID AS L1_ORDER_ID, GOATOCLORDID AS
CLORDER_ID, TO_CHAR( GOATOACTION ) AS ACTION, GOATOACTIONSTATUS AS ACTION_STATUS
, GOATOACCNUM AS ACC_NUM, GOATOPLCD AS PL_CD, GOATOTIMESTAMP AS ENTRY_DT, GOATOE
NDTIMESTAMP AS EXEC_TIMESTAMP, GOATOBUYORSELL AS ORDER_SIDE, LTRIM( GOATOSTOCKCO
DE, '0' ) AS STOCK_CD, GOATOORDERQTY AS ORDER_QTY, GOATOORDERTYPE AS ORDER_TYPE,
 GOATOINPUTSOURCE AS ORDER_CHANNEL, GOATOINPUTSOURCE AS INPUTSOURCE, GOATOQTY AS
 TRADED_QTY, GOATOUNITPRICE AS TRADED_PRICE, GOATOUNITPRICE AS ACTUAL_TRADED_PRI
CE, GOATOQTY AS TOTAL_TRADED_QTY, GOATOUNSETTLEDAMT AS UNSETTLED_AMT, GOATOALLOR
NONE AS IS_ALL_OR_NONE, GOATOTIMEINFORCE AS TIME_IN_FORCE, GOATOTRADETYPE AS TRA
DE_TYPE, GOATOTRADEAEID AS AE_ID, 'N' AS IS_INDIRECT_TRADE, SYSDATE AS SYN_TIME,
 NULL AS PROCESS_TIME, NULL AS PROCESS_M

-->进一步观察Session的详细情况
-->发现该session的MODULE为DBMS_SCHEDULER，即为一Oracle job，且ACTION与STATE均有描述
-->由此推论，编译包时的Hang住应该是由该job引起的
SQL> SELECT username
  2        ,command
  3        ,status
  4        ,osuser
  5        ,terminal
  6        ,program
  7        ,module
  8        ,action
  9        ,state
 10  FROM   v$session
 11  WHERE  sid = 1086;

USERNAME      COMMAND STATUS   OSUSER     TERMINAL        PROGRAM         MODULE          ACTION               STATE
---------- ---------- -------- ---------- --------------- --------------- --------------- -------------------- ----------
GOEX_ADMIN          3 ACTIVE   oracle     UNKNOWN         oracle@Dev-DB-0 DBMS_SCHEDULER  STP1_PERFORM_SYNC_DA WAITING
                                                          4 (J000)                        TA

-->查看job中定义的情况，该job正好调用了该包
SQL> select job_name,job_type,enabled,state,job_action from dba_scheduler_jobs where job_name like 'STP1%';

JOB_NAME                       JOB_TYPE         ENABL STATE
------------------------------ ---------------- ----- ----------
JOB_ACTION
------------------------------------------------------------------------------------------------------------------
STP1_PERFORM_SYNC_DATA         PLSQL_BLOCK      TRUE  RUNNING
																															 DECLARE
                                                                  err_num NUMBER;
                                                                  err_msg VARCHAR2(32767);

                                                                BEGIN
                                                                  err_num := NULL;
                                                                  err_msg := NULL;

                                                                  BO_SYN_DATA_PKG.perform_sync_data ( err_num, err_msg );
                                                                  COMMIT;
                                                                END;

-->Author: Robinson Cheng
-->Blog  : http://blog.csdn.net/robinson_0612

-->下面是该job运行的详细情况
SQL> SELECT job_name
  2        ,session_id
  3        ,slave_process_id sl_pid
  4        ,elapsed_time
  5        ,slave_os_process_id sl_os_id
  6  FROM   dba_scheduler_running_jobs;

JOB_NAME                       SESSION_ID     SL_PID ELAPSED_TIME                   SL_OS_ID
------------------------------ ---------- ---------- ------------------------------ ------------
STP1_PERFORM_SYNC_DATA               1086         20 +009 00:51:17.79               5840
RUN_CHAIN$MY_CHAIN2                                  +075 19:55:03.52
RUN_CHAIN$MY_CHAIN1                                  +075 19:57:45.91

-->ELAPSED_TIME列， Elapsed time since the Scheduler job was started
-->即该job一直处于运行状态，导致包编译失败

3、解决
-->将job对应的session kill掉
SQL> alter system kill session '1086,59678';
alter system kill session '1086,59678'
*
ERROR at line 1:
ORA-00031: session marked for kill

Elapsed: 00:01:00.03

SQL> SELECT username
  2        ,command
  3        ,status
  4        ,osuser
  5        ,terminal
  6        ,program
  7        ,module
  8        ,action
  9        ,state
 10  FROM   v$session
 11  WHERE  sid = 1086;

USERNAME      COMMAND STATUS   OSUSER     TERMINAL        PROGRAM         MODULE          ACTION               STATE
---------- ---------- -------- ---------- --------------- --------------- --------------- -------------------- ----------
GOEX_ADMIN          3 KILLED   oracle     UNKNOWN         oracle@Dev-DB-0 DBMS_SCHEDULER  STP1_PERFORM_SYNC_DA WAITING
                                                          4 (J000)                        TA

-->再次编译时还是被hang住，应该是session还没有被彻底kill
SQL> alter package bo_syn_data_pkg compile;
alter package bo_syn_data_pkg compile
*
ERROR at line 1:
ORA-01013: user requested cancel of current operation

-->再次kill session
SQL> alter system kill session '1086,59678' immediate;

System altered.

-->此时包编译通过
SQL> alter package bo_syn_data_pkg compile;

Package altered.

Elapsed: 00:00:00.32

SQL> alter package bo_syn_data_pkg compile body;

Package body altered.

Elapsed: 00:00:00.18

4、总结
-->包编译时被hang住，在排除代码自身编写出错的情形下，应考虑是否有对象或依赖对象被其它session所持有
-->其次，包的编译需要将包pin到library cache，会产生library cahce pin等待事件
-->对于引起异常的session将其kill之后再编译



编译失效对象。

请对比源10g库和目标11g库，确保无新增失效对象。

如果有新增的失效对象，请使用plsql developer客户端工具编译，找出对象失效的原因并解决。
"	"sqlplus '/as sysdba'
SQL> @ /rdbms/admin/utlrp.sql
SQL> @ /rdbms/admin/utlrp.sql
SQL> select owner ,object_name, status from dba_objects where status = 'INVALID';
@ /rdbms/admin/catdwgrd.sql

SQL>  alter database open;
 alter database open
*
ERROR at line 1:
ORA-38760: This database instance failed to turn on flashback database


SQL> select name from v$restore_point;

NAME
--------------------------------------------------------------------------------
DRBK

SQL>  drop restore point DRBK;

Restore point dropped.

SQL> alter database flashback off;

Database altered.

SQL>  alter database open;

Database altered.

SQL> !


ORA-01591: lock held by in-doubt distributed transaction
本站文章除注明转载外，均为本站原创： 转载自love wife & love life —Roger 提供oracle技术支持服务

本文链接地址: ORA-01591: lock held by in-doubt distributed transaction

昨天某客户遇到一个问题是关于两阶段分布式事务的，大概是内容是
一个定时job执行失败，然后报如下错误：
Sun Oct  9 02:38:12 2011
Errors in file /ora/app/admin/oraapp/bdump/oraapp1_j000_643178.trc:
ORA-12012: error on auto execute of job 84
ORA-01591: lock held by in-doubt distributed transaction 19.3.5343485
ORA-06512: at "SODB_ADMIN.PKG_SODB_MAINTAIN", line 1064
ORA-06512: at line 1
Sun Oct  9 02:59:45 2011
Thread 1 advanced to log sequence 63561
这里我们首先需要关注是 ORA-01591 错误，
Error:  ORA 1591
Text:   lock held by in-doubt distributed transaction <num >
-------------------------------------------------------------------------------
Cause:  An attempt was made to access a resource locked by a dead two-phase
        commit transaction that is in prepared state.
Action: Match the transaction number in the message with the GLOBAL_TRAN_ID
        column of the DBA_2PC_PENDING table to determine the database link and
        the state of the transaction.
        Attempt to repair network connections to the coordinator and commit
        point, if necessary.
        If timely repair is not possible, contact the database administrator
        at the commit point, if known, to resolve the pending transaction.
如上是mos关于该错误的一个描述，当然，引起该错误的原因可能有很多很多。
关于分布式事务，其实可以这样理解，就是一个完整的事务，其中包含的多个操作分布在
两个以上的数据库中，只有这些操作都全部完成了，该事务才算完成，不然该事务都将失败。

换句话说，如果该事务失败了，其中涉及到操作表A，那么当其他session访问到表A时将出现
ORA-01591错误。

至于具体说为什么分布式事务会失败，那么就要具体分析了，可能是程序本身的问题或者网络
问题等等。

我们回到我客户的问题上来，既然是分布事务，那么我们就查询dba_2pc_pending视图：
查询结果如下；
LOCAL_TRAN_ID          STATE            FAIL_TIME    OS_USER    DB_USER
---------------------- ---------------- ------------ ---------- ----------
56.29.120915           prepared         09-SEP-11    t3smisbw
19.3.5343485           prepared         01-OCT-11    t3smisbw
12.15.3794557          prepared         03-OCT-11    t3smisbw
从上可以看到，目前该库有3个失败的分布事务，其中 19.3.5343485 是我们需要处理的。

关于字段LOCAL_TRAN_ID的解释，大家可以去查看dba_2pc_pending的说明，这里只简单的
描述一下；

LOCAL_TRAN_ID 格式为：xidusn + xidslot + xidsqn

下面继续查询当前系统回滚段中是否还有如上几个失败的分布式事务信息：
SQL> SELECT KTUXEUSN,
  2         KTUXESLT,
  3         KTUXESQN, /* Transaction ID */
  4         KTUXESTA STATUS,
  5         KTUXECFL Flags
  6  FROM x$ktuxe
  7  WHERE ktuxesta != 'INACTIVE'
  8  AND ktuxeusn IN(56,19,12) ORDER BY 1;

KTUXEUSN   KTUXESLT   KTUXESQN   STATUS           FLAGS
---------- ---------- ---------- ---------------- ------------------------
 12         15        3794557    PREPARED         SCO|COL|REV|EXTDTX
 19          3        5343485    PREPARED         SCO|COL|REV|DEAD|EXTDTX
 56         29         120915    PREPARED         SCO|COL|REV|EXTDTX
我们可以发现，仍然存在，这处理就简单了，处理之前我还需要说明一下的是：

根据分布事务的状态（state）不同，我们需要采取不同的方法进行处理，稍后进行一个
简单的总结，这里我继续描述如何处理该问题。

通过如下两个小步骤进行处理：

rollback force '19.3.5343485';
execute dbms_transaction.purge_lost_db_entry('19.3.5343485');

然后再次执行该job，正常。

当然这仅仅是一个处理的办法，我们最终的目的是想知道为什么该分布事务会执行失败呢？

先来查询该job的基本信息：
SQL> SELECT job,SCHEMA_USER,LAST_DATE,NEXT_DATE,BROKEN,FAILURES,INSTANCE
  2  FROM dba_jobs;

JOB SCHEMA_USER  LAST_DATE    NEXT_DATE    B   FAILURES   INSTANCE
--- ------------ ------------ ------------ - ---------- ----------
 ............
 83 SODB_ADMIN   10-OCT-11    11-OCT-11    N          0          0
 84 SODB_ADMIN   07-OCT-11    11-OCT-11    N         12          0
 85 SODB_ADMIN   10-OCT-11    11-OCT-11    N          0          0
 ............

13 ROWS selected.

JOB SCHEMA_USER LAST_DATE NEXT_DATE  B FAILURES INTERVAL                                    INSTANCE
--- ----------- --------- ---------- - -------- ------------------------------------------- --------
..........
 84 SODB_ADMIN  07-OCT-11 11-OCT-11  N       12 trunc(sysdate)+1+2/24+25/24/60                     0
 85 SODB_ADMIN  10-OCT-11 11-OCT-11  N        0 trunc(sysdate)+1+2/24+50/24/60                     0
..........

13 ROWS selected.
该job (job number为84) 已经执行失败12次了，INTERVAL是该job的执行间隔。对于dba_jobs中的 FAILURES字段，
该字段最大值为16，每次执行失败后该值递增，但是一旦执行成功后将被清0.

从报错信息来看，该job执行失败问题出在PKG_SODB_MAINTAIN的1064行，通过dbms_metadata获取定义后，发现
如下信息：

该过程执行到如下步骤时失败：
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
 PROCEDURE refine_msg (p_date IN DATE)
IS
   v_id   NUMBER;
BEGIN
   proc_expired_msg_log (p_date - pkg_sodb.get_expired_msg_days);
   proc_expired_msg_tbm (p_date - pkg_sodb.get_expired_tbm_days);
EXCEPTION
   WHEN OTHERS
   THEN
      ROLLBACK;
      pkg_sodb.add_event_log ('SODB',
                              'PKG_SODB_MAINTAIN',
                              'Refine_Msg',
                              'DB_ERROR',
                              3,
                              SYSDATE,
                              'êy Y a2ù×÷òì3￡',
                              NULL,
                              v_id
                             );
      COMMIT;
      RAISE;
END refine_msg;
其中: Proc_Expired_Msg_Log 和 Proc_Expired_Msg_Tbm 为存储过程；
      Get_Expired_Msg_Days 和 Get_Expired_Tbm_Days 为过程PKG_SODB中的2个函数；

这样来看似乎问题就出在这里，我怀疑可能是业务逻辑什么的可能有问题，比如
该 Proc_Expired_Msg_Log(p_date - PKG_SODB.Get_Expired_Msg_Days) 有可能计算出来
是负数吗？或者说执行到该步时，后面的rolllback操作时，其他前面的事务是否还存在关联？

不是开发出身，分析起来有些麻烦，主要是这几个包里面包含了太多的存储过程和函数，
看起来就头晕，最好建议客户找开发商看看这几个包。

补充：关于分布式事务处理的简单总结
++++++ 常规处理步骤 ++++++

1. Identify the id OF the TRANSACTION:

COLUMN global_tran_id format a25
COLUMN DATABASE format a22
COLUMN global_name format a22
SELECT * FROM global_name;
SELECT LOCAL_TRAN_ID, GLOBAL_TRAN_ID,to_char(FAIL_TIME,'dd-mon-yyyy HH24:MI:SS'),STATE, MIXED FROM DBA_2PC_PENDING;
SELECT LOCAL_TRAN_ID, IN_OUT,INTERFACE, DATABASE FROM DBA_2PC_NEIGHBORS;

2. Purge the TRANSACTION:

EXECUTE DBMS_TRANSACTION.PURGE_LOST_DB_ENTRY('<transaction_id>');
COMMIT;

3. Confirm that the TRANSACTION has been purged:

SELECT LOCAL_TRAN_ID, GLOBAL_TRAN_ID,to_char(FAIL_TIME,'dd-mon-yyyy HH24:MI:SS'),STATE, MIXED FROM DBA_2PC_PENDING;
SELECT LOCAL_TRAN_ID, IN_OUT,INTERFACE, DATABASE FROM DBA_2PC_NEIGHBORS;

其中有如下五种state：

 collecting
   -- execute DBMS_TRANSACTION.PURGE_LOST_DB_ENTRY('1.10.255'）；
 prepared
   -- rollback force tran_id/commit force tran_id;
   EXECUTE DBMS_TRANSACTION.PURGE_LOST_DB_ENTRY('1.10.255');
 committed
   -- execute DBMS_TRANSACTION.PURGE_LOST_DB_ENTRY('1.10.255');
 forced commit
   -- execute DBMS_TRANSACTION.PURGE_LOST_DB_ENTRY('1.10.255');
 forced ROLLBACK
   -- execute DBMS_TRANSACTION.PURGE_LOST_DB_ENTRY('1.10.255');


++++++ 如果遇到ORA-30019错误，可以采取如下方式：++++++

ALTER SESSION SET "_smu_debug_mode" = 4;
EXECUTE DBMS_TRANSACTION.PURGE_LOST_DB_ENTRY('1.10.255');

====== 情况1 在dba_2pc_pending表中还有事务记录，但是实际已经不存在该事务了

SELECT LOCAL_TRAN_ID,
       GLOBAL_TRAN_ID,
       to_char(FAIL_TIME, 'dd-mon-yyyy HH24:MI:SS'),
       STATE,
       MIXED
FROM DBA_2PC_PENDING;

LOCAL_TRAN_ID         1.92.66874             prepared

1 为回滚段号

SELECT KTUXEUSN,
       KTUXESLT,
       KTUXESQN, /* Transaction ID */
       KTUXESTA STATUS,
       KTUXECFL Flags
FROM x$ktuxe
WHERE ktuxesta != 'INACTIVE'
AND ktuxeusn = 1

返回为0

如果当状态为prepared，且事务表中也不存在相关信息，那么我们只能手工进行清理：

++++++ 使用如下方式进行手工处理：++++++

SET TRANSACTION USE ROLLBACK segment SYSTEM;
DELETE FROM sys.pending_trans$ WHERE local_tran_id = '1.92.66874';
DELETE FROM sys.pending_sessions$ WHERE local_tran_id = '1.92.66874';
DELETE FROM sys.pending_sub_sessions$ WHERE local_tran_id = '1.92.66874';
commit;

====== 情况2  在dba_2pc_pending表中无法查到分布式事务信息，但是实际上却是存在该分布式事务的

SELECT LOCAL_TRAN_ID,
       GLOBAL_TRAN_ID,
       to_char(FAIL_TIME, 'dd-mon-yyyy HH24:MI:SS'),
       STATE,
       MIXED
FROM DBA_2PC_PENDING;

查询无记录

SELECT local_tran_id, state
FROM dba_2pc_pending
WHERE local_tran_id = ' 1.92.66874 ';  -- 为空

SELECT KTUXEUSN,
       KTUXESLT,
       KTUXESQN, /* Transaction ID */
       KTUXESTA STATUS,
       KTUXECFL Flags
FROM x$ktuxe
WHERE ktuxesta != 'INACTIVE'
AND ktuxeusn = 1;

查询有记录

====== 此种情况下，我们无法手工进行ROLLBACK或commit ======

++++++ 我们用如下的方式手工清理：++++++

ALTER system disable distributed recovery ;

INSERT INTO pending_trans $
 (LOCAL_TRAN_ID,
 GLOBAL_TRAN_FMT,
 GLOBAL_ORACLE_ID,
 STATE,
 STATUS,
 SESSION_VECTOR,
 RECO_VECTOR,
 TYPE #,
 FAIL_TIME,
 RECO_TIME)
VALUES
 (' 1.92.66874 ',
 306206,
 ' XXXXXXX.12345.1.2.3 ',
 ' prepared ',
 ' P ',
 hextoraw(' 00000001 '),
 hextoraw(' 00000000 '),
 0,
 sysdate,
 sysdate);

INSERT INTO pending_sessions $
VALUES
 (' 1.92.66874 ',
 1,
 hextoraw(' 05004F003A1500000104 '),
 ' C ',
 0,
 30258592,
 '',
 146);

commit ;

commit   force ' 1.92.66874 ' ;

++++++ 此时如果commit force还是出现报错，需要继续执行：++++++

1. DELETE FROM pending_trans $ WHERE local_tran_id = '1.92.66874' ;
2. DELETE FROM pending_sessions $ WHERE local_tran_id = '1.92.66874' ;
3. commit ;
4. ALTER system enable distributed recovery ;
5. ALTER SESSION SET " _smu_debug_mode " = 4 ;
6. EXEC dbms_transaction.purge_lost_db_entry ( '1.92.66874' )

====== 另外我们还可以通过如下SQL来捕获到导致分布式事务失败的SQL：======

++++++ 获取local_tran_id ++++++

SELECT a.sql_text, s.osuser, s.username
FROM v$transaction t, v$session s, v$sqlarea a
WHERE s.taddr = t.addr
AND a.address = s.prev_sql_addr
AND t.xidusn = 1
AND t.xidslot = 25
AND t.xidsqn = 589367;

如果 v$session 和 v$sqlarea 已经无法查到，那么我们还可以关联一些 dba_hist_* 试图进行查询。



1. [代码]查看用户权限     跳至 [1] [2] [全屏预览]
view sourceprint 
1 show grants for 你的用户;

2 show grants for root@'localhost';
3 show grants for webgametest@10.3.18.158;

4 show create database dbname;  这个可以看到创建数据库时用到的一些参数。

5 show create table tickets;    可以看到创建表时用到的一些参数
2. [代码][SQL]代码     跳至 [1] [2] [全屏预览]
view sourceprint 
001 GRANT USAGE ON *.* TO 'discuz'@'localhost' IDENTIFIED BY PASSWORD '*C242DDD213BE9C6F8DA28D49245BF69FC79A86EB';

002 GRANT ALL PRIVILEGES ON `discuz`.* TO 'discuz'@'localhost';

003

004 我先按我的理解解释一下上面两句的意思

005 建立一个只可以在本地登陆的 不能操作的用用户名 discuz 密码为 ***** 已经加密了的

006 然后第二句的意思是 ，给这个discuz用户操作discuz数据库的所有权限

007

008 使用GRANT

009

010 GRANT命令用来建立新用户，指定用户口令并增加用户权限。其格式如下：

011

012 mysql> GRANT <privileges> ON <what>

013 -> TO <user> [IDENTIFIED BY "<password>"]

014 -> [WITH GRANT OPTION];

015

016

017 　　正如你看到的，在这个命令中有许多待填的内容。让我们逐一地对它们进行介绍，并最终给出一些例子以让你对它们的协同工作有一个了解。

018

019 　　<privileges>是一个用逗号分隔的你想要赋予的权限的列表。你可以指定的权限可以分为三种类型：

020

021 　　数据库/数据表/数据列权限： Alter: 修改已存在的数据表(例如增加/删除列)和索引。

022 Create: 建立新的数据库或数据表。

023 Delete: 删除表的记录。

024 Drop: 删除数据表或数据库。

025 INDEX: 建立或删除索引。

026 Insert: 增加表的记录。

027 Select: 显示/搜索表的记录。

028 Update: 修改表中已存在的记录。

029

030 　　全局管理权限：

031

032 file: 在MySQL服务器上读写文件。

033 PROCESS: 显示或杀死属于其它用户的服务线程。

034 RELOAD: 重载访问控制表，刷新日志等。

035 SHUTDOWN: 关闭MySQL服务。

036

037 　　特别的权限：

038

039 ALL: 允许做任何事(和root一样)。

040 USAGE: 只允许登录--其它什么也不允许做。

041

042

043 　　这些权限所涉及到的MySQL的特征，其中的一些我们至今还没看到，而其中的绝大部分是你所熟悉的。

044

045 <what> 定义了这些权限所作用的区域。*.*意味着权限对所有数据库和数据表有效。dbName.*意味着对名为dbName的数据库中的所有数据表有效。 dbName.tblName意味着仅对名为dbName中的名为tblName的数据表有效。你甚至还可以通过在赋予的权限后面使用圆括号中的数据列的列表以指定权限仅对这些列有效(在后面我们将看到这样的例子)。

046

047 　　<user>指定可以应用这些权限的用户。在MySQL中，一个用户通过它登录的用户名和用户使用的计算机的主机名/IP地址来指定。这两个值都可以使用%通配符(例如kevin@%将允许使用用户名kevin从任何机器上登录以享有你指定的权限)。

048

049 　　<password>指定了用户连接MySQL服务所用的口令。它被用方括号括起，说明IDENTIFIED BY "<password>"在GRANT命令中是可选项。这里指定的口令会取代用户原来的密码。如果没有为一个新用户指定口令，当他进行连接时就不需要口令。

050

051 这个命令中可选的WITH GRANT OPTION部分指定了用户可以使用GRANT/REVOKE命令将他拥有的权限赋予其他用户。请小心使用这项功能--虽然这个问题可能不是那么明显！例如，两个都拥有这个功能的用户可能会相互共享他们的权限，这也许不是你当初想看到的。

052

053 　　让我们来看两个例子。建立一个名为dbmanager的用户，他可以使用口令managedb从server.host.net连接 MySQL，并仅仅可以访问名为db的数据库的全部内容(并可以将此权限赋予其他用户)，这可以使用下面的GRANT命令：

054

055 mysql> GRANT ALL ON db.*

056 -> TO dbmanager@server.host.net

057 -> IDENTIFIED BY "managedb"

058 -> WITH GRANT OPTION;

059

060

061 现在改变这个用户的口令为funkychicken，命令格式如下：

062 　　 mysql> GRANT USAGE ON *.*

063 　　 -> TO dbmanager@server.host.net

064 　　 -> IDENTIFIED BY "funkychicken";

065

066 请注意我们没有赋予任何另外的权限(the USAGE权限只能允许用户登录)，但是用户已经存在的权限不会被改变。

067

068 　　现在让我们建立一个新的名为jessica的用户，他可以从host.net域的任意机器连接到MySQL。他可以更新数据库中用户的姓名和 email地址，但是不需要查阅其它数据库的信息。也就是说他对db数据库具有只读的权限(例如，Select)，但是他可以对Users表的name列和email列执行Update操作。命令如下：

069

070 mysql> GRANT Select ON db.*

071 -> TO jessica@%.host.net

072 -> IDENTIFIED BY "jessrules";

073 mysql> GRANT Update (name,email) ON db.Users

074 -> TO jessica@%.host.net;

075

076

077 　　请注意在第一个命令中我们在指定Jessica可以用来连接的主机名时使用了%(通配符)符号。此外，我们也没有给他向其他用户传递他的权限的能力，因为我们在命令的最后没有带上WITH GRANT OPTION。第二个命令示范了如何通过在赋予的权限后面的圆括号中用逗号分隔的列的列表对特定的数据列赋予权限。

078

079 -----------------------------------------------------

080

081 mysql> grant select,insert,update,delete on 111.* to hongdadbuser@"%" identified by "111";

082

083

084

085

086 测试环境：WIN32 mysql5.0.45

087

088

089 首先要声明一下：一般情况下，修改MySQL密码，授权，是需要有mysql里的root权限的。

090

091 注：本操作是在WIN命令提示符下，phpMyAdmin同样适用。

092     用户：phplamp  用户数据库：phplampDB

093

094 1.新建用户。

095

096 //登录MYSQL

097 @>mysql -u root -p

098 @>密码

099 //创建用户

100 mysql> insert into mysql.user(Host,User,Password) values("localhost","phplamp",password("1234"));

101 //刷新系统权限表

102 mysql>flush privileges;

103 这样就创建了一个名为：phplamp  密码为：1234  的用户。

104

105 然后登录一下。

106

107 mysql>exit;

108 @>mysql -u phplamp -p

109 @>输入密码

110 mysql>登录成功

111

112 2.为用户授权。

113

114 //登录MYSQL（有ROOT权限）。我里我以ROOT身份登录.

115 @>mysql -u root -p

116 @>密码

117 //首先为用户创建一个数据库(phplampDB)

118 mysql>create database phplampDB;

119 //授权phplamp用户拥有phplamp数据库的所有权限。

120 >grant all privileges on phplampDB.* to phplamp@localhost identified by '1234';

121 //刷新系统权限表

122 mysql>flush privileges;

123 mysql>其它操作

124

125 /*

126 如果想指定部分权限给一用户，可以这样来写:

127 mysql>grant select,update on phplampDB.* to phplamp@localhost identified by '1234';

128 //刷新系统权限表。

129 mysql>flush privileges;

130 */

131

132 3.删除用户。

133 @>mysql -u root -p

134 @>密码

135 mysql>DELETE FROM user WHERE User="phplamp" and Host="localhost";

136 mysql>flush privileges;

137 //删除用户的数据库

138 mysql>drop database phplampDB;

139

140 4.修改指定用户密码。

141 @>mysql -u root -p

142 @>密码

143 mysql>update mysql.user set password=password('新密码') where User="phplamp" and Host="localhost";

144 mysql>flush privileges;

145

146 -------------------------------------------------

147

148 mysql> grant all privileges on webgame_test.* to webgametest@10.3.18.158 identified by 'gametestdb';

149 Query OK, 0 rows affected (0.01 sec)

150

151 mysql> flush privileges;

152 Query OK, 0 rows affected (0.01 sec)

153

154 mysql> exit;

155

156 show grants for webgametest@10.3.18.158;




本文实例，运行于 MySQL 5.0 及以上版本。

MySQL 赋予用户权限命令的简单格式可概括为：

grant 权限 on 数据库对象 to 用户






一、grant 普通数据用户，查询、插入、更新、删除 数据库中所有表数据的权利。

grant select on testdb.* to common_user@'%'
grant insert on testdb.* to common_user@'%'
grant update on testdb.* to common_user@'%'
grant delete on testdb.* to common_user@'%'
或者，用一条 MySQL 命令来替代：

grant select, insert, update, delete on testdb.* to common_user@'%'






二、grant 数据库开发人员，创建表、索引、视图、存储过程、函数。。。等权限。

grant 创建、修改、删除 MySQL 数据表结构权限。

grant create on testdb.* to developer@'192.168.0.%';
grant alter  on testdb.* to developer@'192.168.0.%';
grant drop   on testdb.* to developer@'192.168.0.%';


grant 操作 MySQL 外键权限。

grant references on testdb.* to developer@'192.168.0.%';


grant 操作 MySQL 临时表权限。

grant create temporary tables on testdb.* to developer@'192.168.0.%';


grant 操作 MySQL 索引权限。

grant index on testdb.* to developer@'192.168.0.%';


grant 操作 MySQL 视图、查看视图源代码 权限。

grant create view on testdb.* to developer@'192.168.0.%';
grant show   view on testdb.* to developer@'192.168.0.%';


grant 操作 MySQL 存储过程、函数 权限。

grant create routine on testdb.* to developer@'192.168.0.%'; -- now, can show procedure status
grant alter  routine on testdb.* to developer@'192.168.0.%'; -- now, you can drop a procedure
grant execute        on testdb.* to developer@'192.168.0.%';






三、grant 普通 DBA 管理某个 MySQL 数据库的权限。

grant all privileges on testdb to dba@'localhost'
其中，关键字 “privileges” 可以省略。






四、grant 高级 DBA 管理 MySQL 中所有数据库的权限。

grant all on *.* to dba@'localhost'






五、MySQL grant 权限，分别可以作用在多个层次上。

1. grant 作用在整个 MySQL 服务器上：

grant select on *.* to dba@localhost; -- dba 可以查询 MySQL 中所有数据库中的表。
grant all    on *.* to dba@localhost; -- dba 可以管理 MySQL 中的所有数据库


2. grant 作用在单个数据库上：

grant select on testdb.* to dba@localhost; -- dba 可以查询 testdb 中的表。


3. grant 作用在单个数据表上：

grant select, insert, update, delete on testdb.orders to dba@localhost;


这里在给一个用户授权多张表时，可以多次执行以上语句。例如：

grant select(user_id,username) on smp.users to mo_user@'%' identified by '123345';
grant select on smp.mo_sms to mo_user@'%' identified by '123345';

4. grant 作用在表中的列上：

grant select(id, se, rank) on testdb.apache_log to dba@localhost;


5. grant 作用在存储过程、函数上：

grant execute on procedure testdb.pr_add to 'dba'@'localhost'
grant execute on function testdb.fn_add to 'dba'@'localhost'






六、查看 MySQL 用户权限

查看当前用户（自己）权限：

show grants;


查看其他 MySQL 用户权限：

show grants for dba@localhost;






七、撤销已经赋予给 MySQL 用户权限的权限。

revoke 跟 grant 的语法差不多，只需要把关键字 “to” 换成 “from” 即可：

grant  all on *.* to   dba@localhost;
revoke all on *.* from dba@localhost;






八、MySQL grant、revoke 用户权限注意事项

1. grant, revoke 用户权限后，该用户只有重新连接 MySQL 数据库，权限才能生效。

2. 如果想让授权的用户，也可以将这些权限 grant 给其他用户，需要选项 “grant option“

grant select on testdb.* to dba@localhost with grant option;
这个特性一般用不到。实际中，数据库权限最好由 DBA 来统一管理。







*************************************************************************************************



遇到 SELECT command denied to user '用户名'@'主机名' for table '表名' 这种错误，解决方法是需要把吧后面的表名授权，即是要你授权核心数据库也要。

我遇到的是SELECT command denied to user 'my'@'%' for table 'proc'，是调用存储过程的时候出现，原以为只要把指定的数据库授权就行了，什么存储过程、函数等都不用再管了，谁知道也要把数据库mysql的proc表授权



*************************************************************************************************

参考：http://zhidao.baidu.com/question/19633785.html



mysql授权表共有5个表：user、db、host、tables_priv和columns_priv。

授权表的内容有如下用途：
user表
user表列出可以连接服务器的用户及其口令，并且它指定他们有哪种全局（超级用户）权限。在user表启用的任何权限均是全局权限，并适用于所有数据库。例如，如果你启用了DELETE权限，在这里列出的用户可以从任何表中删除记录，所以在你这样做之前要认真考虑。

db表
db表列出数据库，而用户有权限访问它们。在这里指定的权限适用于一个数据库中的所有表。

host表
host表与db表结合使用在一个较好层次上控制特定主机对数据库的访问权限，这可能比单独使用db好些。这个表不受GRANT和REVOKE语句的影响，所以，你可能发觉你根本不是用它。

tables_priv表
tables_priv表指定表级权限，在这里指定的一个权限适用于一个表的所有列。

columns_priv表
columns_priv表指定列级权限。这里指定的权限适用于一个表的特定列。






一．权限表

mysql数据库中的3个权限表：user 、db、 host

权限表的存取过程是：

1)先从user表中的host、 user、 password这3个字段中判断连接的IP、用户名、密码是否存在表中，存在则通过身份验证；

2)通过权限验证，进行权限分配时，按照useràdbàtables_privàcolumns_priv的顺序进行分配。即先检查全局权限表user，如果user中对应的权限为Y，则此用户对所有数据库的权限都为Y，将不再检查db, tables_priv,columns_priv；如果为N，则到db表中检查此用户对应的具体数据库，并得到db中为Y的权限；如果db中为N，则检查tables_priv中此数据库对应的具体表，取得表中的权限Y，以此类推。

二．MySQL各种权限（共27个）

（以下操作都是以root身份登陆进行grant授权，以p1@localhost身份登陆执行各种命令。）

1. usage

连接（登陆）权限，建立一个用户，就会自动授予其usage权限（默认授予）。

mysql> grant usage on *.* to ‘p1′@’localhost’ identified by ‘123′;

该权限只能用于数据库登陆，不能执行任何操作；且usage权限不能被回收，也即REVOKE用户并不能删除用户。

2. select

必须有select的权限，才可以使用select table

mysql> grant select on pyt.* to ‘p1′@’localhost’;

mysql> select * from shop;

3. create

必须有create的权限，才可以使用create table

mysql> grant create on pyt.* to ‘p1′@’localhost’;

4. create routine

必须具有create routine的权限，才可以使用{create |alter|drop} {procedure|function}

mysql> grant create routine on pyt.* to ‘p1′@’localhost’;

当授予create routine时，自动授予EXECUTE, ALTER ROUTINE权限给它的创建者：

mysql> show grants for ‘p1′@’localhost’;

+—————————————————————————+

Grants for p1@localhost

+————————————————————————–+

| GRANT USAGE ON *.* TO ‘p1′@’localhost’ IDENTIFIED BY PASSWORD ‘*23AE809DDACAF96AF0FD78ED04B6A265E05AA257′ |

| GRANT SELECT, CREATE, CREATE ROUTINE ON `pyt`.* TO ‘p1′@’localhost’|

| GRANT EXECUTE, ALTER ROUTINE ON PROCEDURE `pyt`.`pro_shop1` TO ‘p1′@’localhost’ |

+————————————————————————————-+

5. create temporary tables(注意这里是tables，不是table)

必须有create temporary tables的权限，才可以使用create temporary tables.

mysql> grant create temporary tables on pyt.* to ‘p1′@’localhost’;

[mysql@mydev ~]$ mysql -h localhost -u p1 -p pyt

mysql> create temporary table tt1(id int);

6. create view

必须有create view的权限，才可以使用create view

mysql> grant create view on pyt.* to ‘p1′@’localhost’;

mysql> create view v_shop as select price from shop;

7. create user

要使用CREATE USER，必须拥有mysql数据库的全局CREATE USER权限，或拥有INSERT权限。

mysql> grant create user on *.* to ‘p1′@’localhost’;

或：mysql> grant insert on *.* to p1@localhost;

8. insert

必须有insert的权限，才可以使用insert into ….. values….

9. alter

必须有alter的权限，才可以使用alter table

alter table shop modify dealer char(15);

10. alter routine

必须具有alter routine的权限，才可以使用{alter |drop} {procedure|function}

mysql>grant alter routine on pyt.* to ‘p1′@’ localhost ‘;

mysql> drop procedure pro_shop;

Query OK, 0 rows affected (0.00 sec)

mysql> revoke alter routine on pyt.* from ‘p1′@’localhost’;

[mysql@mydev ~]$ mysql -h localhost -u p1 -p pyt

mysql> drop procedure pro_shop;

ERROR 1370 (42000): alter routine command denied to user ‘p1′@’localhost’ for routine ‘pyt.pro_shop’

11. update

必须有update的权限，才可以使用update table

mysql> update shop set price=3.5 where article=0001 and dealer=’A';

12. delete

必须有delete的权限，才可以使用delete from ….where….(删除表中的记录)

13. drop

必须有drop的权限，才可以使用drop database db_name; drop table tab_name;

drop view vi_name; drop index in_name;

14. show database

通过show database只能看到你拥有的某些权限的数据库，除非你拥有全局SHOW DATABASES权限。

对于p1@localhost用户来说，没有对mysql数据库的权限，所以以此身份登陆查询时，无法看到mysql数据库：

mysql> show databases;

+——————–+

| Database |

+——————–+

| information_schema|

| pyt |

| test |

+——————–+

15. show view

必须拥有show view权限，才能执行show create view。

mysql> grant show view on pyt.* to p1@localhost;

mysql> show create view v_shop;

16. index

必须拥有index权限，才能执行[create |drop] index

mysql> grant index on pyt.* to p1@localhost;

mysql> create index ix_shop on shop(article);

mysql> drop index ix_shop on shop;

17. excute

执行存在的Functions,Procedures

mysql> call pro_shop1(0001,@a)；

+———+

| article |

+———+

| 0001 |

| 0001 |

+———+

mysql> select @a;

+——+

| @a |

+——+

| 2 |

+——+

18. lock tables

必须拥有lock tables权限，才可以使用lock tables

mysql> grant lock tables on pyt.* to p1@localhost;

mysql> lock tables a1 read;

mysql> unlock tables;

19. references

有了REFERENCES权限，用户就可以将其它表的一个字段作为某一个表的外键约束。

20. reload

必须拥有reload权限，才可以执行flush [tables | logs | privileges]

mysql> grant reload on pyt.* to p1@localhost;

ERROR 1221 (HY000): Incorrect usage of DB GRANT and GLOBAL PRIVILEGES

mysql> grant reload on *.* to ‘p1′@’localhost’;

Query OK, 0 rows affected (0.00 sec)

mysql> flush tables;

21. replication client

拥有此权限可以查询master server、slave server状态。

mysql> show master status;

ERROR 1227 (42000): Access denied; you need the SUPER,REPLICATION CLIENT privilege for this operation

mysql> grant Replication client on *.* to p1@localhost;

或：mysql> grant super on *.* to p1@localhost;

mysql> show master status;

+——————+———-+————–+——————+

| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |

+——————+———-+————–+——————+

| mysql-bin.000006 | 2111 | | |

+——————+———-+————–+——————+

mysql> show slave status;

22. replication slave

拥有此权限可以查看从服务器，从主服务器读取二进制日志。

mysql> show slave hosts;

ERROR 1227 (42000): Access denied; you need the REPLICATION SLAVE privilege for this operation

mysql> show binlog events;

ERROR 1227 (42000): Access denied; you need the REPLICATION SLAVE privilege for this operation

mysql> grant replication slave on *.* to p1@localhost;

mysql> show slave hosts;

Empty set (0.00 sec)

mysql>show binlog events;

+—————+——-+—————-+———–+————-+————–+

| Log_name | Pos | Event_type | Server_id| End_log_pos|Info | +—————+——-+————–+———–+————-+—————+

| mysql-bin.000005 | 4 | Format_desc | 1 | 98 | Server ver: 5.0.77-log, Binlog ver: 4 | |mysql-bin.000005|98|Query|1|197|use `mysql`; create table a1(i int)engine=myisam|

……………………………………

23. Shutdown

关闭MySQL：

[mysql@mydev ~]$ mysqladmin shutdown

重新连接：

[mysql@mydev ~]$ mysql

ERROR 2002 (HY000): Can’t connect to local MySQL server through socket ‘/tmp/mysql.sock’ (2)

[mysql@mydev ~]$ cd /u01/mysql/bin

[mysql@mydev bin]$ ./mysqld_safe &

[mysql@mydev bin]$ mysql

24. grant option

拥有grant option，就可以将自己拥有的权限授予其他用户（仅限于自己已经拥有的权限）

mysql> grant Grant option on pyt.* to p1@localhost;

mysql> grant select on pyt.* to p2@localhost;

25. file

拥有file权限才可以执行 select ..into outfile和load data infile…操作，但是不要把file, process, super权限授予管理员以外的账号，这样存在严重的安全隐患。

mysql> grant file on *.* to p1@localhost;

mysql> load data infile ‘/home/mysql/pet.txt’ into table pet;

26. super

这个权限允许用户终止任何查询；修改全局变量的SET语句；使用CHANGE MASTER，PURGE MASTER LOGS。

mysql> grant super on *.* to p1@localhost;

mysql> purge master logs before ‘mysql-bin.000006′;

27. process

通过这个权限，用户可以执行SHOW PROCESSLIST和KILL命令。默认情况下，每个用户都可以执行SHOW PROCESSLIST命令，但是只能查询本用户的进程。

mysql> show processlist;

+—-+——+———–+——+———+——+——-+——————+

| Id | User | Host | db | Command | Time | State | Info |

+—-+——+———–+——+———+——+——-+——————+

| 12 | p1 | localhost | pyt | Query | 0 | NULL | show processlist |

+—-+——+———–+——+———+——+——-+——————+

另外，

管理权限（如 super， process， file等）不能够指定某个数据库，on后面必须跟*.*

mysql> grant super on pyt.* to p1@localhost;

ERROR 1221 (HY000): Incorrect usage of DB GRANT and GLOBAL PRIVILEGES

mysql> grant super on *.* to p1@localhost;

Query OK, 0 rows affected (0.01 sec)




SHOW CHARACTER SET

显示所有可用的字符集

SHOW CHARACTER SET;
SHOW CHARACTER SET LIKE 'latin%';


SHOW COLLATION

输出包括所有可用的字符集

SHOW COLLATION;
SHOW COLLATION LIKE 'latin1%';


SHOW COLUMNS

显示在一个给定表中的各列的信息,对于视图，本语句也起作用。

SHOW COLUMNS FROM mydb.mytable;
SHOW COLUMNS FROM mytable FROM mydb;


SHOW CREATE DATABASE

显示用于创建给定数据库CREATE DATABASE语句。也可以使用SHOW CREATE SCHEMA。

SHOW CREATE DATABASE test;
SHOW CREATE DATABASE test\G;


SHOW CREATE TABLE

SHOW CREATE TABLE java;
SHOW CREATE TABLE java\G;


SHOW DATABASES

SHOW DATABASES可以在MySQL服务器主机上列举数据库。您也可以使用mysqlshow命令得到此清单。您只能看到您拥有某些权限的数据库，除非您拥有全局SHOW DATABASES权限。

SHOW DATABASES;


SHOW ENGINE

SHOW ENGINE显示存储引擎的日志或状态信息。目前支持以下语句：

SHOW ENGINE BDB LOGS;
SHOW ENGINE INNODB STATUS;


SHOW ENGINES

SHOW ENGINES显示存储引擎的状态信息。对于检查一个存储引擎是否被支持，或者对于查看默认引擎是什么，本语句十分有用。

SHOW ENGINES;
SHOW ENGINES\G;


SHOW ERRORS

该语句只显示错误，不同时显示错误、警告和注意。

SHOW COUNT(*) ERRORS;
SHOW ERRORS;


SHOW GRANTS

SHOW GRANTS;
SHOW GRANTS FOR user;
SHOW GRANTS FOR CURRENT_USER;
SHOW GRANTS FOR CURRENT_USER();


SHOW INDEX

SHOW INDEX会返回表索引信息。

SHOW INDEX FROM mydb.mytable;
SHOW INDEX FROM mytable FROM mydb;


SHOW INNODB STATUS

这是SHOW ENGINE INNODB STATUS的同义词，但不赞成使用。



SHOW LOGS

这是SHOW ENGINE BDB LOGS的同义词，但是不赞成使用。



SHOW OPEN TABLES

列举在表缓存中当前被打开的非TEMPORARY表。

SHOW OPEN TABLES;


SHOW PRIVILEGES

显示MySQL服务器支持的系统权限清单。确切的输出根据您的服务器的版本而定

SHOW PRIVILEGES;


SHOW PROCESSLIST

显示哪些线程正在运行。您也可以使用mysqladmin processlist语句得到此信息。如果您有SUPER权限，您可以看到所有线程。否则，您只能看到您自己的线程


SHOW STATUS

提供服务器状态信息。此信息也可以使用mysqladmin extended-status命令获得。

SHOW STATUS;


SHOW TABLE STATUS

SHOW TABLE STATUS的性质与SHOW TABLE类似，不过，可以提供每个表的大量信息。您也可以使用mysqlshow --status db_name命令得到此清单。

本语句也显示视图信息。

SHOW TABLE STATUS;
SHOW TABLE STATUS FROM test;


SHOW TABLES

SHOW TABLES列举了给定数据库中的非TEMPORARY表。您也可以使用mysqlshow db_name命令得到此清单。

SHOW TABLES;


SHOW TRIGGERS

SHOW TRIGGERS列出了目前被MySQL服务器定义的触发程序。

SHOW TRIGGERS;


SHOW VARIABLES

SHOW VARIABLES;
SHOW GLOBAL VARIABLES;
SHOW SESSION VARIABLES;
SHOW VARIABLES LIKE 'have%';


SHOW WARNINGS

显示由上一个生成消息的语句导致的错误、警告和注意消息。如果上一个使用表的语句未生成消息，则什么也不显示。SHOW ERRORS是其相关语句，只显示错误。

SHOW COUNT(*) WARNINGS;
SHOW WARNINGS;

 ORA-15081 解决方法 2012-08-16 15:52:17
分类： Linux
解决方法：
1. oracle用户要属于asmdba组，不然无法发现磁盘组
2. $ORACLE_HOME/bin/oracle 文件的所有者和权限不对
执行：
$GRID_HOME/bin/setasmgidwrap O=$ORACLE_HOME/bin/oracle  （注意要先把库down下来）


正确的oracle 文件权限为示例如下：
[oracle@vm05 bin]$ ls -l oracle
-rwsr-s--x 1 oracle asmadmin 210824714 Aug 15 16:09 oracle


如果没有使用dbca创建过数据库，此文件的属主一般是oracle:oinstall，必须使用setasmgidwrap命令改为oracle:asmadmin，否则oracle将没有访问ASM磁盘组的权限。

root@solora11gsty # ls -ltr /app/oracle/product/11.2.0/dbhome_1/bin/oracle
-rwsr-s--x   1 oracle   oinstall 256511080 Oct 30 16:33 /app/oracle/product/11.2.0/dbhome_1/bin/oracle
root@solora11gsty # su - grid
Oracle Corporation      SunOS 5.10      Generic Patch   January 2005
grid@solora11gsty:~ $> $ORACLE_HOME/bin/setasmgidwrap o=/app/oracle/product/11.2.0/dbhome_1/bin/oracle
grid@solora11gsty:~ $> exit
logout
root@solora11gsty # ls -ltr /app/oracle/product/11.2.0/dbhome_1/bin/oracle
-r-sr-s--x   1 oracle   asmadmin 256511080 Oct 30 16:33 /app/oracle/product/11.2.0/dbhome_1/bin/oracle


在进行RMAN DUPLICATE操作之前，我们还要修改oracle二进制命令的权限。参考下面一段：
During 11.2 Gird Infrastructure installation, it prompts to select ASM admin group and ASM dba group. Assume asmadmin is used for ASM admin group and asmdba is used for ASM dba group.

Only users that are members of the asmadmin group have direct access to ASM disks and maintenance. For other database users (software owners or dba group users), the access is gained via the oracle executable ($ORACLE_HOME/bin/oracle). It should have a setgid bit with group set to "asmadmin".

The 11.2 "oracle" binary is changed automatically via setasmgidwrap when the instance is started by the CRS daemon (e.g. srvctl start database/instance). But for earlier release, the "oracle" binary group and ownership need to be set manually.

On Standby Node1 with gird user:
[grid@standby1 ~]$ ls $ORACLE_HOME/bin/oracle
-rwsr-s–x 1 oracle oinstall 232399431 Sep  2 22:28 /u01/app/oracle/product/11.2.0/dbhome_1/bin/oracle

[grid@standby1 ~]$ setasmgidwrap o=/paic/stg/oracle/11g/app/oracle/product/11.2.0.3.5/bin/oracle

[grid@standby1 ~]$ ls /u01/app/oracle/product/11.2.0/dbhome_1/bin/oracle
-rwsr-s–x 1 oracle asmadmin 232399431 Sep  2 22:28 /u01/app/oracle/product/11.2.0/dbhome_1/bin/oracle


如果不做上面的操作，在进行下面DUPLICATE复制操作时候会报ASMLib驱动错误：
Errors in file /u01/app/oracle/diag/rdbms/standby/standby1/trace/standby1_rbal_13010.trc:
ORA-15183: ASMLIB initialization error [driver/agent not installed]
WARNING: FAILED to load library: /opt/oracle/extapi/64/asm/orcl/1/libasm.so
Errors in file /u01/app/oracle/diag/rdbms/standby/standby1/trace/standby1_rbal_13010.trc:
ORA-15183: ASMLIB initialization error [driver/agent not installed]
Mon Sep 03 09:30:10 2012
SUCCESS: diskgroup SDATA was mounted
Errors in file /u01/app/oracle/diag/rdbms/standby/standby1/trace/standby1_ora_13390.trc  (incident=305):
ORA-00600: internal error code, arguments: [kfioTranslateIO03], [], [], [], [], [], [], [], [], [], [], []
Incident details in: /u01/app/oracle/diag/rdbms/standby/standby1/incident/incdir_305/standby1_ora_13390_i305.trc


alter database mount standby database ;

要找出套接字文件的地点，应：
shell> netstat -ln | grep mysql

执行mysql_install_db脚本。运行并重启服务器后，执行该命令来测试初始权限：
shell> mysql -u root test

在新的安装以后，你应该连接服务器并且设置你的用户及其访问许可：
·                shell> mysql -u root mysql


如果你作为root试试连接并且得到这个错误，这意味着，你没有行在user表中的User列值为'root'并且mysqld不能为你的客户端解析主机名：
Access denied for user ''@'unknown' to database mysql
在这种情况下，你必须用--skip-grant-tables选项重启服务器并且编辑“/etc/hosts”或“\windows\hosts”文件为你的主机增加行。


你可以通过使用--no-defaults选项调用客户端程序来禁用选项文件。例如：
shell> mysqladmin --no-defaults -u root version

如果你使用SET PASSWORD、INSERT或UPDATE更改密码，你必须使用  PASSWORD()函数加密密码。如果你不使用PASSWORD()函数，密码不工作。例如，下面的语句设置密码，但没能加密，因此用户后面不能连接：
·                mysql> SET PASSWORD FOR 'abe'@'host_name' = 'eagle';相反，应这样设置密码：
mysql> SET PASSWORD FOR 'abe'@'host_name' = PASSWORD('eagle');



在上面输出信息中我们可以看到datafile 12 not processed because file is read-only一句，这是因为在还原的控制文件内12号数据文件被描述为只读文件，因此在recover database的时候被忽略。但在应用重做日志的时候，发现LTB表空间更改为读写状态的记录，因此也需要进行恢复，但此时为时已晚，因此最后报错。那这时候到什么阶段了？控制文件和数据字典上对12号数据文件的描述已改变，也就是已将其认为是读写状态了。

解决方法是，再重复一下recover database过程

RMAN> run{
2> restore controlfile from '/u01/recovery/MAA/backupset/2012_12_24/o1_mf_ncsnf_TAG20121224T041651_8fgsq3cv_.bkp';
3> mount database;
4> restore datafile 12 force;
5> recover database;
6> recover database;
7> alter database open resetlogs;
8> }

CLOSE #[CURSOR]:c=%u e=%u dep=%d type=%u tim=%u   ==》一个游标关闭的例子

 CLOSE   游标关闭

type    关闭游标的操作类型

■0    该游标从未被缓存且执行次数小于3次，也叫hard close
■1      该游标从未被缓存但执行次数至少3次，若在session cached cursor中有free slot 则将该游标放入session cached cursor
■2     该游标从未被缓存但执行次数至少3次，该游标置入session cached cursor的条件是讲老的缓存age out掉
■3      该游标已经在缓存里，则还会去


STAT #[CURSOR] id=N cnt=0 [pid=0 pos=0 obj=0 op='SORT AGGREGATE ']


■STAT   相关行反应解释执行计划的统计信息
■[CURSOR]     游标号
■id    执行计划的行数 从1开始
■cnt    该数据源的行数
■pid    该数据源的 父ID
■pos    在执行计划中的位置
■obj     对应数据源的  object id
■op=    数据源的访问操作，例如 FULL SCAN
11g 以上还提供如下信息：


STAT #2 id=1 cnt=26 pid=0 pos=1 obj=0 op=’HASH GROUP BY (cr=1143 pr=1139 pw=0 time=61372 us)’
STAT #2 id=2 cnt=77276 pid=1 pos=1 obj=96551 op=’TABLE ACCESS FULL FULLSCAN (cr=1143 pr=1139 pw=0 time=927821 us)’


■CR 代表一致性读的数量
■PR  代表物理读的数量
■pw  代表物理写的数量
■time   单位为microsecond，本步骤的耗时
■cost    本操作的优化器成本
■size    评估的数据源大小，单位为字节
■card       评估的优化器基数Cardinality.

 XCTEND rlbk=0, rd_only=1

■ XCTEND  一个事务结束的标志
■rlbk           如果是1代表 有回滚操作， 如果是0 代表不会滚 即 commit提交了
■rd_only     如果是1代表 事务只读 ， 如果是0 说明数据改变发生过


绑定变量

BINDS #20:
kkscoacd
Bind#0
oacdty=96 mxl=2000(150) mxlc=00 mal=00 scl=00 pre=00
oacflg=03 fl2=1000000 frm=01 csi=873 siz=2000 off=0
kxsbbbfp=7f9ccfec6420 bln=2000 avl=50 flg=05
value=”MACLEAN

■BINDS #20:  说明 绑定变量 是针对 20号游标的
■kkscoacd  是绑定变量相关的描述符
■Bind#0   说明是第0个变量
■oacdty      data type   96 是 ANSI fixed char
■oacflg      代表绑定选项的特殊标志位
■size           为该内存chunk分配的内存大小
■mxl       绑定变量的最大长度
■pre      precision
■scl      Scale
■kxsbbbfp         buffer point
■bln               bind buffer length
■avl     实际的值的长度
■flg          代表绑定状态
■value=”MACLEAN    实际的绑定值

如果看到 “bind 6: (No oacdef for this bind)”类似的信息则说明在trace时 还没有定义绑定数据。 这可能是在trace时游标还没绑定变量。


WAIT #20: nam=’db file scattered read’ ela= 42 file#=1 block#=80386 blocks=7 obj#=96551 tim=1344883874069383


■WAIT #20 等待 20号游标的相关等待事件
■Nam      等待针对的事件名字，它的P1、P2、P3可以参考视图V$EVENT_NAME，也可以从V$SESSION、ASH中观察到等待事件
■ela           本操作的耗时，单位为microsecond
■p1,p2,p3       针对该事件的三个描述参数，见V$EVENT_NAME

在上例中针对 db file scattered read ， P1为文件号， P2为 起始块号， p3为 读的块数，  即db file scattered read 是从 1号文件的第80386 个块开始一次读取了7个块。

注意在10046中 出现的WAIT 行信息 都是 已经结束的等待事件， 而当前等待则不会在trace中出现，直到这个当前等待结束。 你可以通过systemstate dump/errorstack等trace来获得当前等待信息。



gather dongkuifeng
我收集运行时的统计信息:
SELECT /*+ gather_plan_statistics DKF*/max(P.PAGEVIEW)
  FROM PRODUCT P, CATALOGRELATEPRODUCT CATAP
WHERE CATAP.CATALOGID = 291
   AND P.ID = CATAP.PRODUCTID
   AND PUBLISHSTATUS = 3;

实际的运行这个SQL语句,gather_plan_statistics是收集运行时的统计信息的提示,DKF 就是一个普通的注释,是为了唯一的标识这个游标的.

 SELECT SQL_ID,CHILD_NUMBER,sql_text
 FROM V$SQL
 WHERE SQL_TEXT LIKE '%DKUI%'
 AND SQL_TEXT NOT LIKE '%V$SQL%';

SQL_ID        CHILD_NUMBER
------------- ------------
79gcyuucwuzwg            0

查找刚才的游标.
SET PAGESIZE 200;
SET LINESIZE 200;
COL PLAN_TABLE_OUTPUT FOR A195;
SELECT *
FROM TABLE(DBMS_XPLAN.DISPLAY_CURSOR('1zzu06r0xwj01',0,'ALL IOSTATS LAST'));

这里显示:这个语句总的逻辑IO是:17210(buffers 是实际的逻辑IO数量,这里是累计值,包括子操作的值)
starts 是对应的动作执行的次数
E-ROWS 是优化器估算这一步返回的数据行数
A-Rows  是这一步实际返回的数据行数

明显INDEX RANGE SCAN| INDEX2_CATALOGRELATEPRODUCT   这一步估算返回50行.但实际返回了8567行
因为估算返回50行,所以估算INDEX RANGE SCAN| INDEX2_PRODUCT 这一步会执行50次,但实际它执行了8567次.
显然估算与实际执行上存在着巨大的差异.

那优化器估算INDEX RANGE SCAN| INDEX2_CATALOGRELATEPRODUCT 这一步返回8567行的话,执行计划会是什么呢 实际的执行效果会怎样呢 
使用cardinality(t n) 提示不就可以了吗 !


但,事实上你要做的是查找一下优化器为什么估算返回的行数,估算错了呢 
SQL> select a.num_distinct,a.num_buckets,a.num_nulls,a.histogram,b.num_rows,round(b.num_rows/a.num_distinct) rows_per_key
  2  from user_tab_columns a,user_tables b where a.table_name='CATALOGRELATEPRODUCT' and a.column_name='CATALOGID' and b.table_name='CATALOGRELATEPRODUCT';

NUM_DISTINCT NUM_BUCKETS  NUM_NULLS HISTOGRAM         NUM_ROWS ROWS_PER_KEY
------------ ----------- ---------- --------------- ---------- ------------
       17943           1          0 NONE                904362           50
明显,这个列上并没有收集柱状图统计信息.所以对于min~max内的任意给定值,它估算的返回行数都是:num_rows/num_distinct =50
对于CATAP.CATALOGID = 291,估算确实不够准确.但问题在于两点:
1.应用程序中是使用绑定变量的.
2.对于典型输入值来说,确实返回不了几行数据(nl的执行计划确实是好的,不收集柱状图统计信息时,确实走NL了).291其实并不是一个典型输入值(对于这个非典型输入值来说,hash join确实是一个好的执行计划,而nl不是).所以如果收集了柱状图统计信息的话,每次硬分析的时候,都会peeking,这带有很大的随机性,如果peeking的刚好是291这个非典型输入值,采用hash join的话,对于一般的输入值来说,性能上其实是不好的.所以,其实就不应该收集柱状图统计信息:这样虽然对于极少数的输入值来说,执行计划并不好,但对于绝大多数的输入值来说,执行计划是很好的.对于极少数的非典型输入值来说,如果使用字面值的话,你可以使用use_hash之类的提示来纠正它的执行计划.


Script:常用SQL语句优化脚本
2011/01/06 by Maclean Liu 3条评论


select /*+ dynamic_sampling(b 10) dynamic_sampling_est_cdn(b) gather_plan_statistics*/ count(*) from tvb b;
SELECT * FROM TABLE(dbms_xplan.display_cursor(NULL,NULL,'ALLSTATS LAST'));

注意dynamic sampling used for this statement (level=2) 显示的level 2不是真的！ level 10在这里真的是LEVEL 10!

EXPLAIN PLAN SET STATEMENT_ID = 'abc' FOR
select count(*) from tvb ;

SELECT * FROM TABLE(dbms_xplan.display('PLAN_TABLE','abc','ALL'));

set linesize 200 pagesize 1400;

select /* FINDSQLID */ SQL_ID,SQL_FULLTEXT from V$SQL  where SQL_TEXT LIKE '%&SQLTEXT%'  and SQL_FULLTEXT NOT LIKE '%FINDSQLID%'
union all
select SQL_ID,SQL_TEXT FROM DBA_HIST_SQLTEXT where SQL_TEXT LIKE '%&SQLTEXT%'
and SQL_TEXT NOT LIKE '%FINDSQLID%';

alter session set events '10046 trace name context forever,level 12';
alter session set events '10053 trace name context forever,level 1';

alter session set tracefile_identifier='10046';
alter session set timed_statistics = true;
alter session set statistics_level=all;
alter session set max_dump_file_size = unlimited;
alter session set events '10046 trace name context forever,level 12';
-- Execute the queries or operations to be traced here --

1.- Please provide AWR and ADDM report from each instance for interval of 30 minutes when the problem is present.
2.- Upload OS log file /var/log/messages
3.- Please upload background process trace files for each instance. LMD, LMS, LMON, DBWR, LGWR, diag, pmon, smon, etc.

有问题请去http://t.askmaclean.com/forum-4-1.html提问， 会在一定时间内反馈给你
提问请写明 数据库版本、OS版本、问题类型
如果是性能问题请给出 AWR、ASH、ADDM及10046 TRACE
如果是ORA-600/7445错误请给出ALERT.LOG及其TRACE
如果是RAC CLUTERWARE问题请给出CRSD.LOG和CSSD.LOG

SELECT x.ksppinm NAME, y.ksppstvl VALUE, x.ksppdesc describ
FROM SYS.x$ksppi x, SYS.x$ksppcv y
WHERE x.inst_id = USERENV ('Instance')
AND y.inst_id = USERENV ('Instance')
AND x.indx = y.indx
AND x.ksppinm like '%disable%';

select dbms_rowid.rowid_block_number(rowid),dbms_rowid.rowid_relative_fno(rowid) from test;

select spid,pid from v$process where addr = ( select paddr from v$session where sid=(select distinct sid from v$mystat));

select name,value from v$system_parameter where ISDEFAULT!='TRUE'  order by 1;

set linesize 200 pagesize 1400
@ /rdbms/admin/utllockt

==========================================================================================>
ERROR:
  ORA-600 [kzdlk_zt2 err] [a]


Details
SUGGESTIONS:

  This error indicates that the wrong syntax has been used to (originally) create a
  database link being referenced by the current SQL statement.

  Database links are created using the following documented syntax:

      CREATE DATABASE LINK <dblink>
      CONNECT TO <user> IDENTIFIED BY <password>
      USING '<connect_string>';

  The error suggests that when the database link was created, the <password> was
  established using the syntax  IDENTIFIED BY VALUES as compared to the
  document syntax of IDENTIFIED BY

  Use of IDENTIFIED BY VALUES is reserved for internal Oracle use only.

  While earlier Oracle releases allowed the use of IDENTIFIED BY VALUES, this
  is not documented as being valid syntax.

  From Oracle release 10gR2, database links must be created using the documented syntax.

  Solution: Recreate the database link using valid syntax.

  If the Known Issues section below does not help in terms of identifying
  a solution, please submit the trace files and alert.log to Oracle
  Support Services for further analysis.

  Known Issues:



执行计划历史

Want to Know if Execution Plan Changed Recently 

set lines 150 pages 150
col BEGIN_INTERVAL_TIME for a23
col PLAN_HASH_VALUE for 9999999999
col date_time for a30
col snap_id heading 'SnapId'
col executions_delta heading "No. of exec"
col sql_profile heading "SQL|Profile" for a7
col date_time heading 'Date time'

col avg_lio heading 'LIO/exec' for 99999999999.99
col avg_cputime heading 'CPUTIM/exec' for 9999999.99
col avg_etime heading 'ETIME/exec' for 9999999.99
col avg_pio heading 'PIO/exec' for 9999999.99
col avg_row heading 'ROWs/exec' for 9999999.99
SELECT distinct
s.snap_id ,
PLAN_HASH_VALUE,
to_char(s.BEGIN_INTERVAL_TIME,'mm/dd/yy_hh24mi')|| to_char(s.END_INTERVAL_TIME,'_hh24mi') Date_Time,
SQL.executions_delta,
SQL.buffer_gets_delta/decode(nvl(SQL.executions_delta,0),0,1,SQL.executions_delta) avg_lio,
--SQL.ccwait_delta,
(SQL.cpu_time_delta/1000000)/decode(nvl(SQL.executions_delta,0),0,1,SQL.executions_delta) avg_cputime ,
(SQL.elapsed_time_delta/1000000)/decode(nvl(SQL.executions_delta,0),0,1,SQL.executions_delta) avg_etime,
SQL.DISK_READS_DELTA/decode(nvl(SQL.executions_delta,0),0,1,SQL.executions_delta) avg_pio,
SQL.rows_processed_total/decode(nvl(SQL.executions_delta,0),0,1,SQL.executions_delta) avg_row
--,SQL.sql_profile
FROM
dba_hist_sqlstat SQL,
dba_hist_snapshot s
WHERE
SQL.instance_number =(select instance_number from v$instance)
and SQL.dbid =(select dbid from v$database)
and s.snap_id = SQL.snap_id
AND sql_id in
('&SQLID') order by s.snap_id
/

xp_awr.sql

select plan_table_output from table (dbms_xplan.display_awr('&sql_id',null,null,
'ADVANCED +PEEKED_BINDS'));

SELECT to_char(TIME,'hh24:mi') , S.*
  FROM (SELECT NVL(WAIT_CLASS, 'CPU') ACTIVITY,
               TRUNC(SAMPLE_TIME, 'MI') TIME
          FROM GV$ACTIVE_SESSION_HISTORY) V   PIVOT(COUNT(*)  FOR ACTIVITY IN ('CPU' AS "CPU", 'Concurrency' AS "Concurrency", 'System I/O' AS "System I/O", 'User I/O' AS "User I/O", 'Administrative' AS "Administrative", 'Configuration' AS "Configuration", 'Application' AS "Application", 'Network' AS "Network", 'Commit' AS "Commit", 'Scheduler' AS "Scheduler", 'Cluster' AS "Cluster", 'Queueing' AS "Queueing", 'Other' AS "Other"))
 S
 WHERE TIME > SYSDATE - INTERVAL '500' MINUTE
 ORDER BY TIME

   SELECT *
    FROM (SELECT '1.v$sql'||'实例号:'||GV$SQL.inst_id source,
                 SQL_ID,
                 plan_hash_value,
                 TO_CHAR (FIRST_LOAD_TIME) begin_time,
                 '在cursor cache中' end_time,
                 executions "No. of exec",
                 (buffer_gets / executions) "LIO/exec",
                 (cpu_time / executions / 1000000) "CPUTIM/exec",
                 (elapsed_time / executions / 1000000) "ETIME/exec",
                 (disk_reads / executions) "PIO/exec",
                 (ROWS_PROCESSED / executions) "ROWs/exec"
            FROM Gv$SQL
           WHERE sql_id = '&A'
          UNION ALL
          SELECT '2.sqltuning set' source,
                 sql_id,
                 plan_hash_value,
                 'JUST SQLSET NO DATE' begin_time,
                 'JUST SQLSET NO DATE' end_time,
                 EXECUTIONS "No. of exec",
                 (buffer_gets / executions) "LIO/exec",
                 (cpu_time / executions / 1000000) "CPUTIM/exec",
                 (elapsed_time / executions / 1000000) "ETIME/exec",
                 (disk_reads / executions) "PIO/exec",
                 (ROWS_PROCESSED / executions) "ROWs/exec"
            FROM dba_sqlset_statements
           WHERE SQL_ID = '&A'
          UNION ALL
          SELECT '3.dba_advisor_sqlstats' source,
                 sql_id,
                 plan_hash_value,
                 'JUST SQLSET NO DATE' begin_time,
                 'JUST SQLSET NO DATE' end_time,
                 EXECUTIONS "No. of exec",
                 (buffer_gets / executions) "LIO/exec",
                 (cpu_time / executions / 1000000) "CPUTIM/exec",
                 (elapsed_time / executions / 1000000) "ETIME/exec",
                 (disk_reads / executions) "PIO/exec",
                 (ROWS_PROCESSED / executions) "ROWs/exec"
            FROM dba_sqlset_statements
           WHERE SQL_ID = '&A'
          UNION ALL
          SELECT DISTINCT
                 '4.dba_hist_sqlstat' || '实例号:' || SQL.INSTANCE_NUMBER
                    source,
                 sql_id,
                 PLAN_HASH_VALUE,
                 TO_CHAR (s.BEGIN_INTERVAL_TIME ,'YYYY-MM-DD hh24:mi:ss') begin_time,
                 TO_CHAR (s.END_INTERVAL_TIME,'YYYY-MM-DD hh24:mi:ss') end_time,
                 SQL.executions_delta,
                 SQL.buffer_gets_delta
                 / DECODE (NVL (SQL.executions_delta, 0),
                           0, 1,
                           SQL.executions_delta)
                    "LIO/exec",
                 (SQL.cpu_time_delta / 1000000)
                 / DECODE (NVL (SQL.executions_delta, 0),
                           0, 1,
                           SQL.executions_delta)
                    "CPUTIM/exec",
                 (SQL.elapsed_time_delta / 1000000)
                 / DECODE (NVL (SQL.executions_delta, 0),
                           0, 1,
                           SQL.executions_delta)
                    "ETIME/exec",
                 SQL.DISK_READS_DELTA
                 / DECODE (NVL (SQL.executions_delta, 0),
                           0, 1,
                           SQL.executions_delta)
                    "PIO/exec",
                 SQL.ROWS_PROCESSED_DELTA
                 / DECODE (NVL (SQL.executions_delta, 0),
                           0, 1,
                           SQL.executions_delta)
                    "ROWs/exec"
            FROM dba_hist_sqlstat SQL, dba_hist_snapshot s
           WHERE     SQL.INSTANCE_NUMBER = s.INSTANCE_NUMBER
                 AND SQL.dbid = (SELECT dbid FROM v$database)
                 AND s.snap_id = SQL.snap_id
                 AND sql_id IN ('&A'))
ORDER BY source, begin_time DESC;


prompt 15 Most expensive SQL in the cursor cache


SELECT *
  FROM (SELECT SQL_ID,
               ELAPSED_TIME / 1000000 AS ELAPSED,
               SQL_TEXT
          FROM V$SQLSTATS
         ORDER BY ELAPSED_TIME DESC)
 WHERE ROWNUM <= 15;

prompt 15 Most expensive SQL in the workload repository


select * from (
select stat.sql_id as sql_id, sum(elapsed_time_delta) / 1000000 as elapsed,
(select to_char(substr(st.sql_text,1,55))
from dba_hist_sqltext st
where st.dbid = stat.dbid and st.sql_id = stat.sql_id) as sql_text_fragment
from dba_hist_sqlstat stat, dba_hist_sqltext text
where stat.sql_id = text.sql_id and
stat.dbid = text.dbid
group by stat.dbid, stat.sql_id
order by elapsed desc
) where ROWNUM <= 15;



或
110818  7:20:33 [ERROR] Error message file '/usr/share/mysql/english/errmsg.sys' had only 480 error messages,
but it should contain at least 481 error messages.
Check that the above file is the right version for this program!
110818  7:20:33 [ERROR] Aborting

解决办法： 下载对应的mysql版本文件，在 share/english 压缩文件中，找到errmsg.err文件，解压后件对应的 errmsg.sys放到 /usr/share/mysql/english目录下；

执行mysql_install_db成功后，使用
mysqld_safe --user=root& 启动mysql服务，
再使用mysql -uroot -p 语句连接到mysql
出现如下错误：
[root@domain ~]# mysql -uroot -p
mysql: relocation error: mysql: symbol strmov, version libmysqlclient_16 not defined in file libmysqlclient.so.16 with link time reference

是在安装mysql时，mysql的有些lib没有安装，安装对应的libs如下：

应用举例

导出
导出全库备份到本地的目录
mysqldump -u$USER -p$PASSWD -h127.0.0.1 -P3306 --routines --default-character-set=utf8 --lock-all-tables --add-drop-database -A > db.all.sql

导出指定库到本地的目录(例如mysql库)
mysqldump -u$USER -p$PASSWD -h127.0.0.1 -P3306 --routines --default-character-set=utf8 --databases mysql > db.sql

导出某个库的表到本地的目录(例如mysql库的user表)
mysqldump -u$USER -p$PASSWD -h127.0.0.1 -P3306 --routines --default-character-set=utf8 --tables mysql user> db.table.sql

导出指定库的表(仅数据)到本地的目录(例如mysql库的user表,带过滤条件)
mysqldump -u$USER -p$PASSWD -h127.0.0.1 -P3306 --routines --default-character-set=utf8 --no-create-db --no-create-info --tables mysql user --where="host='localhost'"> db.table.sql

导出某个库的所有表结构
mysqldump -u$USER -p$PASSWD -h127.0.0.1 -P3306 --routines --default-character-set=utf8 --no-data --databases mysql > db.nodata.sql

导出某个查询sql的数据为txt格式文件到本地的目录(各数据值之间用"制表符"分隔)
例如sql为'select user,host,password from mysql.user;'
mysql -u$USER -p$PASSWD -h127.0.0.1 -P3306 --default-character-set=utf8 --skip-column-names -B -e 'select user,host,password from mysql.user;' > mysql_user.txt

导出某个查询sql的数据为txt格式文件到MySQL服务器.
登录MySQL,将默认的制表符换成逗号.(适应csv格式文件).
指定的路径,mysql要有写的权限.最好用tmp目录,文件用完之后,再删除!
SELECT user,host,password FROM mysql.user INTO OUTFILE '/tmp/mysql_user.csv' FIELDS TERMINATED BY ',';
导入
恢复全库数据到MySQL,因为包含mysql库的权限表,导入完成需要执行FLUSH PRIVILEGES;命令
第一种方法:
mysql -u$USER -p$PASSWD -h127.0.0.1 -P3306 --default-character-set=utf8 < db.all.sql

第二种方法:
登录MySQL,执行source命令,后面的文件名要用绝对路径.
......
mysql> source /tmp/db.all.sql;
恢复某个库的数据(mysql库的user表)
第一种方法:
mysql -u$USER -p$PASSWD -h127.0.0.1 -P3306 --default-character-set=utf8 mysql < db.table.sql

第二种方法:
登录MySQL,执行source命令,后面的文件名要用绝对路径.
mysql -u$USER -p$PASSWD -h127.0.0.1 -P3306 --default-character-set=utf8
......
mysql> use mysql;
mysql> source /tmp/db.table.sql;
恢复MySQL服务器上面的txt格式文件(需要FILE权限,各数据值之间用"制表符"分隔)
mysql -u$USER -p$PASSWD -h127.0.0.1 -P3306 --default-character-set=utf8
......
mysql> use mysql;
mysql> LOAD DATA INFILE '/tmp/mysql_user.txt' INTO TABLE user ;
恢复MySQL服务器上面的csv格式文件(需要FILE权限,各数据值之间用"逗号"分隔)
mysql -u$USER -p$PASSWD -h127.0.0.1 -P3306 --default-character-set=utf8
......
mysql> use mysql;
mysql> LOAD DATA INFILE '/tmp/mysql_user.csv' INTO TABLE user FIELDS TERMINATED BY ',';
恢复本地的txt或csv文件到MySQL
mysql -u$USER -p$PASSWD -h127.0.0.1 -P3306 --default-character-set=utf8
......
mysql> use mysql;
# txt
mysql> LOAD DATA LOCAL INFILE '/tmp/mysql_user.csv' INTO TABLE user;
# csv
mysql> LOAD DATA LOCAL INFILE '/tmp/mysql_user.csv' INTO TABLE user FIELDS TERMINATED BY ',';
注意事项

关于MySQL连接
-u$USER 用户名
-p$PASSWD 密码
-h127.0.0.1 如果连接远程服务器,请用对应的主机名或者IP地址替换
-P3306 端口
--default-character-set=utf8 指定字符集
关于mysql参数
--skip-column-names 不显示数据列的名字
-B 以批处理的方式运行mysql程序.查询结果将显示为制表符间隔格式.
-e 执行命令后,退出
关于mysqldump参数
-A 全库备份
--routines 备份存储过程和函数
--default-character-set=utf8 设置字符集
--lock-all-tables 全局一致性锁
--add-drop-database 在每次执行建表语句之前,先执行DROP TABLE IF EXIST语句
--no-create-db 不输出CREATE DATABASE语句
--no-create-info 不输出CREATE TABLE语句
--databases 将后面的参数都解析为库名
--tables 第一个参数为库名 后续为表名
关于LOAD DATA语法
如果LOAD DATA语句不带LOCAL关键字,就在MySQL的服务器上直接读取文件,且要具有FILE权限.
如果带LOCAL关键字,就在客户端本地读取数据文件,通过网络传到MySQL.
LOAD DATA语句,同样被记录到binlog,不过是内部的机制.



使用mysqldump -uroot -p'123' --all-database >all.sql 导出所有数据库，在使用
mysql -uroot -p'123'
mysql>show variables like 'max_allowed_packet';
mysql> show variables like 'net_buffer_length';
记录下参数，在导出的时候使用
mysqldump -uroot -p'123' --all-database --max_allowed_packet=1047552 --net_buffer_length=16384 >all.sql
然后再倒入即可。


mysqldump 客户端是由 Igor Romanenko 编写的数据库备份程序。可以用它将整个或部分数据库导出备份或直接导出到另外一个数据库中（不一定非得是 MySQL 数据库）。一般来说，生成的转储文件会包含创建表或插入数据的 SQL ，或者两者兼有。另外， mysqldump 还可以生成 CSV 文件，带分隔符的文本文件或者 XML 。
注： mysqldump 是一个备份程序，并不用作恢复。

（如果你所创建的表都是 MyISAM 类型，推荐使用 mysqlhotcopy 进行备份和恢复，速度会比 mysqldump 更快。）

使用 mysqldump 一般归为三种形式：

Shell代码  收藏代码
shell> mysqldump [ options ] db_name [ tbl_name ... ]
shell> mysqldump [ options ] --database db_name ...
shell> mysqldump [ options ] -all-databases

如果 db_name 后未接表名，或使用 --databases 或 --all-database 选项， 整个库会被转储（ mysqldump 默认不会转储 INFORMATION_SCHEMA ）。

options 都是可选参数，有很多，一般使用默认值即可。其中有两项： --user 和 --password 用来指定连接数据库的用户名和密码。一般用法如下：

Shell代码  收藏代码
shell> mysqldump --user=user_name --password[=password] db_name > backup-file.sql

user_name 和 password 替换成具体的用户名和密码。注意，密码可不在命令行中提供，稍后 MySQL 会提示输入密码。所以也可写成这样：

Shell代码  收藏代码
shell> mysqldump --user=user_name --password db_name > backup-file.sql
也可以将 --user 和 --password 替换成 -u 和 -p，用法如下：

Shell代码  收藏代码
shell> mysqldump -u<user_name> -p[<password>] db_name > backup-file.sql
同样，将 <user_name> 和 <password> 用真实值替换。


在做数据库恢复时，使用 mysql 命令，用法如下：

Shell代码  收藏代码
shell> mysql -u<user_name> -p db_name < backup-file.sql
注意：此处使用的是 mysql 而不是 mysqldump，因为 mysqldump 是用来做导出的。

在导入时，有可能会出现如下错误：

Command prompt代码  收藏代码
ERROR 2006 (HY000) at line <line_num> : MySQL server has gone away
这是因为在导入数据时，往往会把一张表的数据写成一个很大的 insert 语句，导致此 insert 语句超过了缓冲区的大小。一般有两个办法来解决这个问题：（1）把一个大的 SQL 语句拆成几个小的， 网上有这样的工具，如 SplitInsert；（2）加大缓冲区的容量，进入 MySQL 的安装目录，打开 my.ini ，增加或修改以下配置项：

Configuration代码  收藏代码
max_allowed_packet=20M
值的大小取决于数据的多少，修改后需要重启数据库。


小技巧：

生成 backup-file.sql 后可手动在文件的最前处加入：

Shell代码  收藏代码
SET AUTOCOMMIT=0;
SET FOREIGH_KEY_CHECKS=0;
在文件的最后位置加入：

SET FOREIGN_KEY_CHECKS=1;
COMMIT;
SET AUTOCOMMIT=1;
这样在执行导入时速度会快非常多。

如果在 linux 上可以更加简便：

Shell代码  收藏代码
shell> echo 'SET AUTOCOMMIT=0;
SET FOREIGN_KEY_CHECKS=0;
' > pre.sql

shell> echo 'SET FOREIGN_KEY_CHECKS=1;
COMMIT;
SET AUTOCOMMIT=1;
' > post.sql

shell> cat pre.sql backup-file.sql post.sql | mysql --user=user_name --password db_name



Bug #69677 5.6 mysql_install_db on ubuntu 12.04 [ERROR] Can't read from messagefile '/usr
Submitted: 5 Jul 2013 11:07 Modified: 18 Mar 16:44
Reporter: Arnaud Adant  Email Updates:
Status: Closed  Impact on me:  None
Category: Server: Docs Severity: S3 (Non-critical)
Version: 5.6.10 OS: Linux (ubuntu 12.04)
Assigned to: Paul Dubois  Target Version:
Tags: mysql_install_db, ubuntu

ViewAdd CommentFilesDeveloperEdit SubmissionView Progress LogContributions

[5 Jul 2013 11:07] Arnaud Adant
Description:
On Ubuntu 12.04 with LAMP modules installed, the standard command for installing a database, mysql_install_db fails with this message :

./scripts/mysql_install_db --basedir=/home/aadant/mysql-5.6.10-linux-x86_65 --datadir=/home/aadant/data

Installing MySQL system tables...2013-06-20 11:39:41 0 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit_defaults_for_timestamp server option (see documentation for more details).
2013-07-05 11:39:41 22620 [ERROR] Can't read from messagefile '/usr/share/mysql/english/errmsg.sys'

How to repeat:
1. install Ubuntu 12.04 with the LAMP option

2. run mysql_install_db according to the manual with basedir and datadir options.

Suggested fix:
This is not a bug, most likely a documentation feature request.

The problem comes from the fact that the LAMP option installs mysql 5.5.29 with
a configuration file in /etc/mysql/my.cnf

This configuration file contains this line :

lc-messages-dir = /usr/share/mysql

So mysqld reads this standard configuration file and can not read the 5.5 message file in 5.6, leading to this error.

Solutions :

1. pass your configuration file to mysql_install_db

./scripts/mysql_install_db --defaults-file=my.cnf

2. use --no-defaults, not to read other configuration files

./scripts/mysql_install_db --no-defaults --basedir=/home/aadant/mysql-5.6.10-linux-x86_65 --datadir=/home/aadant/data

The manual could document those options.[18 Mar 16:44] Paul Dubois
Thank you for your bug report. This issue has been addressed in the documentation. The updated documentation will appear on our website shortly.

"The manual could document those options."

That's now been done.



Oracle高水位线(HWM)及性能优化[转]

http://blog.csdn.net/wanglinchuan/archive/2008/11/21/3344552.aspx
(资料来自互联网，由本人整理发布。出处列在最后参考资料中)

说到HWM,我们首先要简要的谈谈ORACLE的逻辑存储管理.我们知道,ORACLE在逻辑存储上分4个粒度:表空间,段,区和块.


(1)块:是粒度最小的存储单位,现在标准的块大小是8K,ORACLE每一次I/O操作也是按块来操作的,也就是说当ORACLE从数据文件读数据时,是读取多少个块,而不是多少行.


(2)区:由一系列相邻的块而组成,这也是ORACLE空间分配的基本单位,举个例子来说,当我们创建一个表PM_USER时,首先ORACLE会分配一区的空间给这个表,随着不断的INSERT数据到PM_USER,原来的这个区容不下插入的数据时,ORACLE是以区为单位进行扩展的,也就是说再分配多少个区给PM_USER,而不是多少个块.


(3)段:是由一系列的区所组成,一般来说,当创建一个对象时(表,索引),就会分配一个段给这个对象.所以从某种意义上来说,段就是某种特定的数据.如CREATE TABLE PM_USER,这个段就是数据段,而CREATE INDEX ON PM_USER(NAME),ORACLE同样会分配一个段给这个索引,但这是一个索引段了.查询段的信息可以通过数据字典: SELECT * FROM USER_SEGMENTS来获得,


(4)表空间:包含段,区及块.表空间的数据物理上储存在其所在的数据文件中.一个数据库至少要有一个表空间.

OK,我们现在回到HWM上来,那么,什么是高水位标记呢 这就跟ORACLE的段空间管理相关了.


(一)ORACLE用HWM来界定一个段中使用的块和未使用的块.

举个例子来说,当我们创建一个表:PT_SCHE_DETAIL时,ORACLE就会为这个对象分配一个段.在这个段中,即使我们未插入任何记录,也至少有一个区被分配,第一个区的第一个块就称为段头(SEGMENT HEADE),段头中就储存了一些信息,基中HWM的信息就存储在此.此时,因为第一个区的第一块用于存储段头的一些信息,虽然没有存储任何实际的记录,但也算是被使用,此时HWM是位于第2个块.当我们不断插入数据到PM_USER后,第1个块已经放不下后面新插入的数据,此时,ORACLE将高水位之上的块用于存储新增数据,同时,HWM本身也向上移.也就是说,当我们不断插入数据时,HWM会往不断上移,这样,在HWM之下的,就表示使用过的块,HWM之上的就表示已分配但从未使用过的块.


(二)HWM在插入数据时,当现有空间不足而进行空间的扩展时会向上移,但删除数据时不会往下移.


这就好比是水库的水位,当涨水时,水位往上移,当水退出后,最高水位的痕迹还是清淅可见.
考虑让我们看一个段，如一张表，其中填满了块，如图 1 所示。在正常操作过程中，删除了一些行，如图 2 所示。现有就有了许多浪费的空间：(I) 在表的上一个末端和现有的块之间，以及 (II) 在块内部，其中还有一些没有删除的行。


图1：分配给该表的块。用灰色正方形表示行


ORACLE 不会释放空间以供其他对象使用，有一条简单的理由：由于空间是为新插入的行保留的，并且要适应现有行的增长。被占用的最高空间称为最高使用标记 (HWM)，如图 2 所示。


图2：行后面的块已经删除了；HWM 仍保持不变

(三)HWM的信息存储在段头当中.

HWM本身的信息是储存在段头.在段空间是手工管理方式时,ORACLE是通过FREELIST(一个单向链表)来管理段内的空间分配.在段空间是自动管理方式时(ASSM),ORACLE是通过BITMAP来管理段内的空间分配.


(四)ORACLE的全表扫描是读取高水位标记(HWM)以下的所有块.


所以问题就产生了.当用户发出一个全表扫描时，ORACLE 始终必须从段一直扫描到 HWM，即使它什么也没有发现。该任务延长了全表扫描的时间。


(五)当用直接路径插入行时 — 例如，通过直接加载插入（用 APPEND 提示插入）或通过 SQL*LOADER 直接路径 — 数据块直接置于 HWM 之上。它下面的空间就浪费掉了。


我们来分析这两个问题,后者只是带来空间的浪费,但前者不仅是空间的浪费,而且会带来严重的性能问题.我们来看看下面的例子:

(A)我们先来搭建测试的环境,第一步先创建一个段空间为手工管理的表空间:


CREATE TABLESPACE "RAINNY"
LOGGING
DATAFILE 'D:ORACLE_HOMEORADATARAINNYRAINNY.ORA' SIZE 5M
AUTOEXTEND
ON NEXT 10M MAXSIZE UNLIMITED EXTENT MANAGEMENT LOCAL
SEGMENT SPACE MANAGEMENT MANUAL;

(B)创建一个表,注意,此表的第二个字段我故意设成是CHAR(100),以让此表在插入1千万条记录后,空间有足够大:

CREATE TABLE TEST_TAB(C1 NUMBER(10),C2 CHAR(100)) TABLESPACE RAINNY;

插入记录

DECLARE
    I NUMBER(10);
BEGIN
    FOR I IN 1..10000000 LOOP
        INSERT INTO TEST_TAB VALUES(I,'TESTSTRING');
    END LOOP;
    COMMIT;
END;
/

(C)我们来查询一下,看在插入一千万条记录后所访问的块数和查询所用时间:

SQL> SET TIMING ON
SQL> SET AUTOTRACE TRACEONLY
SQL> SELECT COUNT(*) FROM TEST_TAB;

ELAPSED: 00:01:03.05

EXECUTION PLAN
------------------------------------------------------------
0 SELECT STATEMENT OPTIMIZER=CHOOSE (COST=15056 CARD=1)
1 0 SORT (AGGREGATE)
2 1 TABLE ACCESS (FULL) OF 'TEST_TAB' (COST=15056 CARD=10000
000)

STATISTICS
----------------------------------------------------------
0      RECURSIVE CALLS
0      DB BLOCK GETS
156310 CONSISTENT GETS
154239 PHYSICAL READS
0      REDO SIZE
379    BYTES SENT VIA SQL*NET TO CLIENT
503    BYTES RECEIVED VIA SQL*NET FROM CLIENT
2      SQL*NET ROUNDTRIPS TO/FROM CLIENT
0      SORTS (MEMORY)
0      SORTS (DISK)
1      ROWS PROCESSED

我们来看上面的执行计划,这句SQL总供耗时是:1分3秒.访问方式是采用全表扫描方式(FTS),逻辑读了156310个BLOCK,物理读了154239个BLOCK.
我们来分析一下这个表:


BEGIN
DBMS_STATS.GATHER_TABLE_STATS(OWNNAME=> 'TEST',
TABNAME=> 'TEST_TAB',
PARTNAME=> NULL);END;
/

发现这个表目前使用的BLOCK有: 156532,未使用的BLOCK(EMPTY_BLOCKS)为:0,总行数为(NUM_ROWS):1000 0000


(D)接下来我们把此表的记录用DELETE方式删掉,然后再来看看SELECT COUNT(*) FROM TEST_TAB所花的时间:



Connected.
SQL> exec dbms_stats.unlock_table_stats('TMRLIFEDATA', 'NTL_TASK_CUSTOMER_FREEINS');
BEGIN dbms_stats.unlock_table_stats('TMRLIFEDATA', 'NTL_TASK_CUSTOMER_FREEINS'); END;

*
ERROR at line 1:
ORA-20000: TABLE "TMRLIFEDATA"."NTL_TASK_CUSTOMER_FREEINS" does not exist or
insufficient privileges
ORA-06512: at "SYS.DBMS_STATS", line 18075
ORA-06512: at "SYS.DBMS_STATS", line 18097
ORA-06512: at "SYS.DBMS_STATS", line 18218
ORA-06512: at line 1


SQL> conn /as sysdba
Connected.
SQL> grant  ANALYZE ANY    to  deployop;
SQL> grant  ANALYZE ANY DICTIONARY   to  deployop;





DELETE FROM TEST_TAB;
COMMIT;

SQL> SELECT COUNT(*) FROM TEST_TAB;


ELAPSED: 00:01:04.03


EXECUTION PLAN
----------------------------------------------------------
0 SELECT STATEMENT OPTIMIZER=CHOOSE (COST=15056 CARD=1)
1 0 SORT (AGGREGATE)
2 1 TABLE ACCESS (FULL) OF 'TEST_TAB' (COST=15056 CARD=1)

STATISTICS
----------------------------------------------------------
0      RECURSIVE CALLS
0      DB BLOCK GETS
156310 CONSISTENT GETS
155565 PHYSICAL READS
0      REDO SIZE
378    BYTES SENT VIA SQL*NET TO CLIENT
503    BYTES RECEIVED VIA SQL*NET FROM CLIENT
2      SQL*NET ROUNDTRIPS TO/FROM CLIENT
0      SORTS (MEMORY)
0      SORTS (DISK)
1      ROWS PROCESSED

大家来看,在DELETE表后,此时表中已没有一条记录,为什么SELECT COUNT(*) FROM TEST_TAB花的时间为1分4秒, 反而比有记录稍微长点,这是为什么呢 而且大家看,其逻辑读了156310个 BLOCK,跟之前有一千万行记录时差不多,ORACLE怎么会这么笨啊 

我们在DELETE表后再次分析表,看看有什么变化:
这时, TEST_TAB表目前使用的BLOCK是: 156532,未使用的BLOCK(EMPTY_BLOCKS)为:0,总行数为(NUM_ROWS)已变成:0

为什么表目前使的BLOCK数还是156532呢 

问题的根源就在于ORACLE的HWM.也就是说,在新增记录时,HWM会慢慢往上移,但是在删除记录后,HWM却不会往下移,也就是说,DELETE一千万条记录后,此表的HWM根本没移动,还在原来的那个位置,所以,HWM以下的块数同样也是一样的.ORACLE的全表扫描是读取ORACLE高水位标记下的所有BLOCK,也就是说,不管HWM下的BLOCK现在实际有没有存放数据,ORACLE都会一一读取,这样,大家可想而知,在我们DELETE表后,ORACLE读了大量的空块,耗去了大量的时间.


我们再来看DELETE表后段空间实际使用的状况:

SQL> EXEC SHOW_SPACE('TEST_TAB','TEST');

TOTAL BLOCKS............................164352 --总共164352块
TOTAL BYTES.............................1346371584
UNUSED BLOCKS...........................7168 --有7168块没有用过,也就是在HWM上面的块数
UNUSED BYTES............................58720256
LAST USED EXT FILEID....................9
LAST USED EXT BLOCKID...................158856-- BLOCK ID 是针对数据文件来编号的，表示最后使用的一个EXTENT的第一个BLOCK的编号
LAST USED BLOCK.........................1024 --在最后使用的一个EXTENT 中一共用了1024块


PL/SQL PROCEDURE SUCCESSFULLY COMPLETED


总共用了164352块，除了一个SEGMENT HEADER,实际总共用了164351个块，有7168块从来没有使用过。LAST USED BLOCK表示在最后一个使用的EXTENT 中使用的BLOCK, 结合　LAST USED EXT BLOCK ID可以计算　HWM 位置 :

LAST USED EXT BLOCK ID + LAST USED BLOCK -1 = HWM 所在的数据文件的BLOCK编号

代入得出: 158856+1024-1=159879,这个就是HWM所有的BLOCK编号

HWM所在的块:TOTAL BLOCKS- UNUSED BLOCKS=164352-7168=157184,也就是说,HWM在第157184个块,其BLOCKID是159879


(E)结下来,我们再做几个试验:


第一步:执行ALTER TABLE TEST_TAB DEALLOCATE UNUSED;

我们看看段空间的使用状况:


SQL> EXEC SHOW_SPACE('TEST_TAB','TEST');

TOTAL BLOCKS............................157184
TOTAL BYTES.............................1287651328
UNUSED BLOCKS...........................0
UNUSED BYTES............................0
LAST USED EXT FILEID....................9
LAST USED EXT BLOCKID...................158856
LAST USED BLOCK.........................1024

此时我们再代入上面的公式,算出HWM的位置: 157184-0=157184 HWM所在的BLOCK ID是158856+1024-1=159879,跟刚刚的没有变化,也就是说执行ALTER TABLE TEST_TAB DEALLOCATE UNUSED后,段的高水位标记的位置没有改变,但是大家看看UNUSED BLOCKS变为0了,总的块数减少到157184,这证明,DEALLOCATE UNUSED为释放HWM上面的未使用空间,但是并不会释放HWM下面的自由空间,也不会移动HWM的位置.


第二步:我们再来看看执行ALTER TABLE TEST_TAB MOVE后段空间的使用状况:


SQL> EXEC SHOW_SPACE('TEST_TAB','TEST');

TOTAL BLOCKS............................8
TOTAL BYTES.............................65536
UNUSED BLOCKS...........................5
UNUSED BYTES............................40960
LAST USED EXT FILEID....................9
LAST USED EXT BLOCKID...................2632
LAST USED BLOCK.........................3

此时,总共用到的块数已变为8, 我们再代入上面的公式,算出HWM的位置: 8-5=3 HWM所在的BLOCK ID是2632+3-1=2634,

OK,我们发现,此时HWM的位置已经发生变化,现在HWM的位置是在第3个BLOCK,其BLOCK ID是2634,所有数据文件的ID是9(这个没有发生变化,数据文件还是原来的那个数据文件,只是释放了原来的自由空间),最后使用的块数也变为3,也就是说已经使用了3块,HWM就是在最后一个使用的块上,即第3个块上.大家可能会觉得奇怪,为什么释放空间后,未使用的块还有5个啊 也就是说HWM之上还是有5个已分配但从未使用的块.答案就跟HWM移动的规律有关.当我们在插入数据时,ORACLE首先在HWM之下的块当中定位自由空间(通过自由列表FREELIST),如果FREELIST当中没有自由块了,ORACLE就开始往上扩展,而HWM也跟着往上移,每5块移动一次.我们来看ORACLE的说明:


The high water mark is:
-Recorded in the segment header block
-Set to the beginning of the segment on the creation
-Incremented in five-block increments as rows are inserted
-Reset by the truncate command
-Never reset by the delete command
-Space above the high-water-mark can be reclaimed at the table level by using the following command:
ALTER TABLE DEALLOCATE UNUSED…


我们再来看看:SELECT COUNT(*) FROM TEST_TAB所花的时间:


SQL> SELECT COUNT(*) FROM TEST_TAB;


ELAPSED: 00:00:00.00

EXECUTION PLAN
----------------------------------------------------------
0 SELECT STATEMENT OPTIMIZER=CHOOSE
1 0 SORT (AGGREGATE)
2 1 TABLE ACCESS (FULL) OF 'TEST_TAB'

STATISTICS
----------------------------------------------------------
0     RECURSIVE CALLS
0     DB BLOCK GETS
3     CONSISTENT GETS
0     PHYSICAL READS
0     REDO SIZE
378   BYTES SENT VIA SQL*NET TO CLIENT
503   BYTES RECEIVED VIA SQL*NET FROM CLIENT
2     SQL*NET ROUNDTRIPS TO/FROM CLIENT
0     SORTS (MEMORY)
0     SORTS (DISK)
1     ROWS PROCESSED


很快,不到1秒.

我们最后再来对表作一次分析, 此时这个表目前使用的BLOCK为: 0,未使用的BLOCK(EMPTY_BLOCKS)为:0,总行数为(NUM_ROWS):0
从中我们也可以发现,分析表和SHOW_SPACE显示的数据有点不一致.那么哪个是准的呢 其实这两个都是准的,只不过计算的方法有点不同.事实上,当你创建了一个对象如表以后,不管你有没有插入数据,它都会占用一些块,ORACLE也会给它分配必要的空间.同样,用ALTER TABLE MOVE释放自由空间后,还是保留了一些空间给这个表.
最后,我们再来执行TRUNCATE命令,截断这个表,看看段空间的使用状况:


TRUNCATE TABLE TEST_TAB;


SQL> EXEC SHOW_SPACE('TEST_TAB','TEST');


TOTAL BLOCKS............................8
TOTAL BYTES.............................65536
UNUSED BLOCKS...........................5
UNUSED BYTES............................40960
LAST USED EXT FILEID....................9
LAST USED EXT BLOCKID...................2632
LAST USED BLOCK.........................3


PL/SQL PROCEDURE SUCCESSFULLY COMPLETED


SQL>


我们发现TRUNCATE后和MOVE没有什么变化.


为了,最终验证一下我上面的观点,我再DROP一下表,然后新建这个表,看看这时在没有插入任何数据之前,是否ORACLE确实有给这个对象分配必要的空间:


DROP TABLE TEST_TAB;


CREATE TABLE TEST_TAB(C1 NUMBER(10),C2 CHAR(100)) TABLESPACE RAINNY;


SQL> EXEC SHOW_SPACE('TEST_TAB','TEST');

TOTAL BLOCKS............................8
TOTAL BYTES.............................65536
UNUSED BLOCKS...........................5
UNUSED BYTES............................40960
LAST USED EXT FILEID....................9
LAST USED EXT BLOCKID...................2112
LAST USED BLOCK.........................3

大家看,即使我没有插入任何一行记录,ORACLE还是给它分配了8个块.当然这个跟建表语句的INITIAL 参数及MINEXTENTS参数有关:请看TEST_TAB的存储参数:


S TORAGE
(
INITIAL 64K
MINEXTENTS 1
MAXEXTENTS UNLIMITED
);


也就是说,在这个对象创建以后,ORACLE至少给它分配一个区,初始大小是64K,一个标准块的大小是8K,刚好是8个BLOCK.



总结:


在9I中:


(1)如果MINEXTENT 可以使ALTER TABLE TABLENAME DEALLOCATE UNUSED将HWM以上所有没使用的空间释放
(2)如果MINEXTENT >HWM 则释放MINEXTENTS 以上的空间。如果要释放HWM以上的空间则使用KEEP 0。
ALTER TABLE TABLESNAME DEALLOCATE UNUSED KEEP 0;
(3) TRUNCATE TABLE DROP STORAGE(缺省值)命令可以将MINEXTENT 之上的空间完全释放(交还给操作系统),并且重置HWM。
(4)如果仅是要移动HWM,而不想让表长时间锁住,可以用TRUNCATE TABLE REUSE STORAGE,仅将HWM重置。
(5)ALTER TABLE MOVE会将HWM移动,但在MOVE时需要双倍的表空间,而且如果表上有索引的话,需要重构索引
(6)DELETE表不会重置HWM,也不会释放自由的空间(也就是说DELETE空出来的空间只能给对象本身将来的INSERT/UPDATE使用,不能给其它的对象使用)


在ORACLE 10G:


可以使用ALTER TABLE TEST_TAB SHRINK SPACE命令来联机移动HWM,
如果要同时压缩表的索引,可以发布:ALTER TABLE TEST_TAB SHRINK SPACE CASCADE
注意:在使用此命令时需要先使行可迁移row movement(具体见例子)。
         与使用ALTER TABLE MOVE 不同的是执行此命令后并不需要重构索引。



Oracle 官方说明


Shrinking Database Segments Online
You use online segment shrink to reclaim fragmented free space below the high water mark in an Oracle Database segment. The benefits of segment shrink are these:
    * Compaction of data leads to better cache utilization, which in turn leads to better online transaction processing (OLTP) performance.
    * The compacted data requires fewer blocks to be scanned in full table scans, which in turns leads to better decision support system (DSS) performance.
Segment shrink is an online, in-place operation. DML operations and queries can be issued during the data movement phase of segment shrink. Concurrent DML operation are blocked for a short time at the end of the shrink operation, when the space is deallocated. Indexes are maintained during the shrink operation and remain usable after the operation is complete. Segment shrink does not require extra disk space to be allocated.
Segment shrink reclaims unused space both above and below the high water mark. In contrast, space deallocation reclaims unused space only above the high water mark. In shrink operations, by default, the database compacts the segment, adjusts the high water mark, and releases the reclaimed space.
Segment shrink requires that rows be moved to new locations. Therefore, you must first enable row movement in the object you want to shrink and disable any rowid-based triggers defined on the object.
Shrink operations can be performed only on segments in locally managed tablespaces with automatic segment space management (ASSM). Within an ASSM tablespace, all segment types are eligible for online segment shrink except these:
    * IOT mapping tables
    * Tables with rowid based materialized views
    * Tables with function-based indexes


操作的过程：


SQL> create table demo as select * from dba_source;

Table created.
Elapsed: 00:00:05.83


SQL> select count(*) from demo;


  COUNT(*)
----------
    210992
Elapsed: 00:00:01.06


SQL> insert into demo select * from demo;
210992 rows created.
Elapsed: 00:00:59.83


SQL> commit;
Commit complete.


//得到一个40万条记录的表，下面来查看这个表空间分布情况。


SQL> exec show_space('demo','auto');


PL/SQL procedure successfully completed.
Elapsed: 00:00:00.07


SQL> set serveroutput on


SQL>  exec show_space('demo','auto');


Total Blocks............................9216
Total Bytes.............................75497472
Unused Blocks...........................768
Unused Bytes............................6291456
Last Used Ext FileId....................4
Last Used Ext BlockId...................8328
Last Used Block.........................256


一共有9216个数据块，HWM在9216-768=8448这个块.
也可以通过查看extents得到HWM=8*16+128*63+256=8192+256=8448


PL/SQL procedure successfully completed.
Elapsed: 00:00:00.01


SQL> delete from demo where rownum<220000;


219999 rows deleted.
Elapsed: 00:00:40.99


SQL> commit;


Commit complete.
Elapsed: 00:00:00.01


SQL>  exec show_space('demo','auto');


Total Blocks............................9216
Total Bytes.............................75497472
Unused Blocks...........................768
Unused Bytes............................6291456
Last Used Ext FileId....................4
Last Used Ext BlockId...................8328
Last Used Block.........................256


PL/SQL procedure successfully completed.


//删除操作后表的HWM没有变化，还是在第8448块这个位置。
Elapsed: 00:00:00.00


SQL> alter table demo shrink space;
alter table demo shrink space
*
ERROR at line 1:
ORA-10636: ROW MOVEMENT is not enabled

//先要enable row movement才能shrink
Elapsed: 00:00:00.09


SQL> alter table demo enable row movement;


Table altered.
Elapsed: 00:00:00.10


SQL>  alter table demo shrink space;


Table altered.
Elapsed: 00:01:35.51


SQL>  exec show_space('demo','auto');


Total Blocks............................3656
Total Bytes.............................29949952
Unused Blocks...........................0
Unused Bytes............................0
Last Used Ext FileId....................4
Last Used Ext BlockId...................3720
Last Used Block.........................72


PL/SQL procedure successfully completed.
Elapsed: 00:00:00.02

//可以看到HWM降到了3656这个块上面!




 SHOW_SPACE是TOM写的一个小工具，SHOW_SPACE实际上就是一个存储过程，这个存储过程可以用来分析空间按使用情况，十分的方便。以下为SHOW_SPACE的脚本：

create or replace procedure show_space
( p_segname in varchar2,
  p_owner   in varchar2 default user,
  p_type    in varchar2 default 'TABLE',
  p_partition in varchar2 default NULL )
as
    l_total_blocks              number;
    l_total_bytes               number;
    l_unused_blocks             number;
    l_unused_bytes              number;
    l_LastUsedExtFileId         number;
    l_LastUsedExtBlockId        number;
    l_last_used_block           number;
    procedure p( p_label in varchar2, p_num in number )
    is
    begin
        dbms_output.put_line( rpad(p_label,40,'.') || p_num );
    end;
begin
    dbms_space.unused_space
    ( segment_owner     => p_owner,
      segment_name      => p_segname,
      segment_type      => p_type,
      partition_name    => p_partition,
      total_blocks      => l_total_blocks,
      total_bytes       => l_total_bytes,
      unused_blocks     => l_unused_blocks,
      unused_bytes      => l_unused_bytes,
      last_used_extent_file_id => l_LastUsedExtFileId,
      last_used_extent_block_id => l_LastUsedExtBlockId,
      last_used_block => l_last_used_block );
    p( 'Total Blocks', l_total_blocks );
    p( 'Total Bytes', l_total_bytes );
    p( 'Unused Blocks', l_unused_blocks );
    p( 'Unused Bytes', l_unused_bytes );
    p( 'Last Used Ext FileId', l_LastUsedExtFileId );
    p( 'Last Used Ext BlockId', l_LastUsedExtBlockId );
    p( 'Last Used Block', l_last_used_block );
end;

      此工具的使用方法为：

SQL> create table t as select * from all_users;

表已创建。

SQL> set serveroutput on;
SQL> exec show_space('T');
Total Blocks............................8
Total Bytes.............................65536
Unused Blocks...........................6
Unused Bytes............................49152
Last Used Ext FileId....................1
Last Used Ext BlockId...................60745
Last Used Block.........................2

PL/SQL 过程已成功完成。

      不过此版本只适合表空间为非ASSM的时候，当表空间为ASSM时不能用，因为DBMS_SPACE.FREE_BLOCKS不允许在ASSM上操作。要想在ASSM表空间的时候也能使用则可以使用以下版本：

create or replace procedure show_space
( p_segname_1 in varchar2,
p_space in varchar2 default 'MANUAL',
p_type_1 in varchar2 default 'TABLE' ,
p_analyzed in varchar2 default 'N',
p_owner_1 in varchar2 default user)
as
p_segname varchar2(100);
p_type varchar2(10);
p_owner varchar2(30);
l_unformatted_blocks number;
l_unformatted_bytes number;
l_fs1_blocks number;
l_fs1_bytes number;
l_fs2_blocks number;
l_fs2_bytes number;
l_fs3_blocks number;
l_fs3_bytes number;
l_fs4_blocks number;
l_fs4_bytes number;
l_full_blocks number;
l_full_bytes number;
l_free_blks number;
l_total_blocks number;
l_total_bytes number;
l_unused_blocks number;
l_unused_bytes number;
l_LastUsedExtFileId number;
l_LastUsedExtBlockId number;
l_LAST_USED_BLOCK number;
procedure p( p_label in varchar2, p_num in number )
is
begin
dbms_output.put_line( rpad(p_label,40,'.') ||
p_num );
end;
begin
p_segname := upper(p_segname_1);
p_owner := upper(p_owner_1);
p_type := p_type_1;
if (p_type_1 = 'i' or p_type_1 = 'I') then
p_type := 'INDEX';
end if;
if (p_type_1 = 't' or p_type_1 = 'T') then
p_type := 'TABLE';
end if;
if (p_type_1 = 'c' or p_type_1 = 'C') then
p_type := 'CLUSTER';
end if;
dbms_space.unused_space
( segment_owner => p_owner,
segment_name => p_segname,
segment_type => p_type,
total_blocks => l_total_blocks,
total_bytes => l_total_bytes,
unused_blocks => l_unused_blocks,
unused_bytes => l_unused_bytes,
LAST_USED_EXTENT_FILE_ID => l_LastUsedExtFileId,
LAST_USED_EXTENT_BLOCK_ID => l_LastUsedExtBlockId,
LAST_USED_BLOCK => l_LAST_USED_BLOCK );
if p_space = 'MANUAL' or (p_space <> 'auto' and p_space <> 'AUTO') then
dbms_space.free_blocks
( segment_owner => p_owner,
segment_name => p_segname,
segment_type => p_type,
freelist_group_id => 0,
free_blks => l_free_blks );
p( 'Free Blocks', l_free_blks );
end if;
p( 'Total Blocks', l_total_blocks );
p( 'Total Bytes', l_total_bytes );
p( 'Unused Blocks', l_unused_blocks );
p( 'Unused Bytes', l_unused_bytes );
p( 'Last Used Ext FileId', l_LastUsedExtFileId );
p( 'Last Used Ext BlockId', l_LastUsedExtBlockId );
p( 'Last Used Block', l_LAST_USED_BLOCK );
/*IF the segment is analyzed */
if p_analyzed = 'Y' then
dbms_space.space_usage(segment_owner => p_owner ,
segment_name => p_segname ,
segment_type => p_type ,
unformatted_blocks => l_unformatted_blocks ,
unformatted_bytes => l_unformatted_bytes,
fs1_blocks => l_fs1_blocks,
fs1_bytes => l_fs1_bytes ,
fs2_blocks => l_fs2_blocks,
fs2_bytes => l_fs2_bytes,
fs3_blocks => l_fs3_blocks ,
fs3_bytes => l_fs3_bytes,
fs4_blocks => l_fs4_blocks,
fs4_bytes => l_fs4_bytes,
full_blocks => l_full_blocks,
full_bytes => l_full_bytes);
dbms_output.put_line(rpad(' ',50,'*'));
dbms_output.put_line('The segment is analyzed');
p( '0% -- 25% free space blocks', l_fs1_blocks);
p( '0% -- 25% free space bytes', l_fs1_bytes);
p( '25% -- 50% free space blocks', l_fs2_blocks);
p( '25% -- 50% free space bytes', l_fs2_bytes);
p( '50% -- 75% free space blocks', l_fs3_blocks);
p( '50% -- 75% free space bytes', l_fs3_bytes);
p( '75% -- 100% free space blocks', l_fs4_blocks);
p( '75% -- 100% free space bytes', l_fs4_bytes);
p( 'Unused Blocks', l_unformatted_blocks );
p( 'Unused Bytes', l_unformatted_bytes );
p( 'Total Blocks', l_full_blocks);
p( 'Total bytes', l_full_bytes);
end if;
end;

      以下是此版本的SHOW_SPACE的使用方法简介：

ASSM 类型的表
SQL> exec show_space('t','auto');
Total Blocks............................512
Total Bytes.............................4194304
Unused Blocks...........................78
Unused Bytes............................638976
Last Used Ext FileId....................9
Last Used Ext BlockId...................25608
Last Used Block.........................50
PL/SQL procedure successfully completed.
ASSM 类型的索引
SQL> exec show_space('t_index','auto','i');
Total Blocks............................80
Total Bytes.............................655360
Unused Blocks...........................5
Unused Bytes............................40960
Last Used Ext FileId....................9
Last Used Ext BlockId...................25312
Last Used Block.........................3
PL/SQL procedure successfully completed.
对analyze 过的segment 可以这样
SQL> exec show_space('t','auto','T','Y');
Total Blocks............................512
Total Bytes.............................4194304
Unused Blocks...........................78
Unused Bytes............................638976
Last Used Ext FileId....................9
Last Used Ext BlockId...................25608
Last Used Block.........................50
*************************************************
The segment is analyzed
0% -- 25% free space blocks.............0
0% -- 25% free space bytes..............0
25% -- 50% free space blocks............0
25% -- 50% free space bytes.............0
50% -- 75% free space blocks............0
50% -- 75% free space bytes.............0
75% -- 100% free space blocks...........0
75% -- 100% free space bytes............0
Unused Blocks...........................0
Unused Bytes............................0
Total Blocks............................418
Total bytes.............................3424256
PL/SQL procedure successfully completed.



Show_space 过程源码


1.1 源码
Tom 大师的show_space过程，经pub某位同学完善之后，脚本如下：



CREATE OR REPLACE PROCEDURE show_space (

   p_segname_1     IN VARCHAR2,

   p_type_1        IN VARCHAR2 DEFAULT 'TABLE',

p_space         IN VARCHAR2 DEFAULT 'MANUAL',

   p_analyzed      IN VARCHAR2 DEFAULT  'N',

p_partition_1   IN VARCHAR2 DEFAULT  NULL,

   p_owner_1       IN VARCHAR2 DEFAULT USER)

   AUTHID CURRENT_USER

AS

   p_segname              VARCHAR2 (100);

   p_type                 VARCHAR2 (30);

   p_owner                VARCHAR2 (30);

   p_partition            VARCHAR2 (50);



   l_unformatted_blocks   NUMBER;

   l_unformatted_bytes    NUMBER;

   l_fs1_blocks           NUMBER;

   l_fs1_bytes            NUMBER;

   l_fs2_blocks           NUMBER;

   l_fs2_bytes            NUMBER;

   l_fs3_blocks           NUMBER;

   l_fs3_bytes            NUMBER;

   l_fs4_blocks           NUMBER;

   l_fs4_bytes            NUMBER;

   l_full_blocks          NUMBER;

   l_full_bytes           NUMBER;



   l_free_blks            NUMBER;

   l_total_blocks         NUMBER;

   l_total_bytes          NUMBER;

   l_unused_blocks        NUMBER;

   l_unused_bytes         NUMBER;

   l_LastUsedExtFileId    NUMBER;

   l_LastUsedExtBlockId   NUMBER;

   l_LAST_USED_BLOCK      NUMBER;



   PROCEDURE p (p_label IN VARCHAR2,p_num IN NUMBER)

   IS

   BEGIN

      DBMS_OUTPUT.put_line (RPAD(p_label, 40, '.') || p_num);

   END;

BEGIN

   p_segname := UPPER (p_segname_1);

   p_owner := UPPER (p_owner_1);

   p_type := p_type_1;

   p_partition := UPPER(p_partition_1);



   IF (p_type_1 = 'i' OR p_type_1 ='I')

   THEN

      p_type := 'INDEX';

   END IF;



   IF (p_type_1 = 't' OR p_type_1 ='T')

   THEN

      p_type := 'TABLE';

   END IF;



   IF (p_type_1 = 'tp' OR p_type_1 ='TP')

   THEN

      p_type := 'TABLE PARTITION';

   END IF;



   IF (p_type_1 = 'ip' OR p_type_1 = 'IP')

   THEN

      p_type := 'INDEX PARTITION';

   END IF;



   IF (p_type_1 = 'c' OR p_type_1 ='C')

   THEN

      p_type := 'CLUSTER';

   END IF;



   DBMS_SPACE.UNUSED_SPACE (

      segment_owner               => p_owner,

      segment_name                => p_segname,

      segment_type                => p_type,

      partition_name              => p_partition,

      total_blocks                => l_total_blocks,

      total_bytes                 => l_total_bytes,

      unused_blocks               => l_unused_blocks,

      unused_bytes                => l_unused_bytes,

      LAST_USED_EXTENT_FILE_ID    => l_LastUsedExtFileId,

      LAST_USED_EXTENT_BLOCK_ID   => l_LastUsedExtBlockId,

      LAST_USED_BLOCK             => l_LAST_USED_BLOCK);



   IF p_space = 'MANUAL' OR (p_space<> 'auto' AND p_space <> 'AUTO')

   THEN

      DBMS_SPACE.FREE_BLOCKS (segment_owner       => p_owner,

                             segment_name        =>p_segname,

                              segment_type        => p_type,

                             partition_name      =>p_partition,

                             freelist_group_id   => 0,

                             free_blks           =>l_free_blks);



      p ('Free Blocks', l_free_blks);

   END IF;



   p ('Total Blocks',l_total_blocks);

   p ('Total Bytes', l_total_bytes);

   p ('Unused Blocks',l_unused_blocks);

   p ('Unused Bytes',l_unused_bytes);

   p ('Last Used Ext FileId',l_LastUsedExtFileId);

   p ('Last Used Ext BlockId', l_LastUsedExtBlockId);

   p ('Last Used Block',l_LAST_USED_BLOCK);



   /*IF the segment is analyzed */

   IF p_analyzed = 'Y'

   THEN

      DBMS_SPACE.SPACE_USAGE(segment_owner        => p_owner,

                             segment_name         => p_segname,

                             segment_type         => p_type,

                             partition_name       =>p_partition,

                              unformatted_blocks   => l_unformatted_blocks,

                             unformatted_bytes    =>l_unformatted_bytes,

                             fs1_blocks           =>l_fs1_blocks,

                             fs1_bytes            =>l_fs1_bytes,

                             fs2_blocks           =>l_fs2_blocks,

                              fs2_bytes            => l_fs2_bytes,

                             fs3_blocks           =>l_fs3_blocks,

                             fs3_bytes            =>l_fs3_bytes,

                             fs4_blocks           =>l_fs4_blocks,

                              fs4_bytes            => l_fs4_bytes,

                             full_blocks          =>l_full_blocks,

                             full_bytes           =>l_full_bytes);

      DBMS_OUTPUT.put_line (RPAD ('', 50, '*'));

      DBMS_OUTPUT.put_line ('Thesegment is analyzed');

      p ('0% -- 25% free spaceblocks', l_fs1_blocks);

      p ('0% -- 25% free spacebytes', l_fs1_bytes);

      p ('25% -- 50% free spaceblocks', l_fs2_blocks);

      p ('25% -- 50% free spacebytes', l_fs2_bytes);

      p ('50% -- 75% free spaceblocks', l_fs3_blocks);

      p ('50% -- 75% free spacebytes', l_fs3_bytes);

      p ('75% -- 100% free spaceblocks', l_fs4_blocks);

      p ('75% -- 100% free spacebytes', l_fs4_bytes);

      p ('Unused Blocks', l_unformatted_blocks);

      p ('Unused Bytes',l_unformatted_bytes);

      p ('Total Blocks',l_full_blocks);

      p ('Total bytes',l_full_bytes);

   END IF;

END;



1.2 使用示例


1.2.1 MSSM 管理表空间下示例


SQL> create tablespace mssm

 2  datafile'/u01/app/oracle/oradata/dave/mssm01.dbf'

 3  size 100m

 4  extent management local

 5  segment space managementmanual;



Tablespace created.



SQL> create table t_mssm tablespace mssmas select * from dba_objects;

Table created.



SQL> create index idx_mssm ont_mssm(object_id) tablespace mssm;

Index created.



SQL> set serveroutputon

SQL> execshow_space('T_MSSM','T','MANUAL');

FreeBlocks.............................0   --由DBMS_SPACE.FREE_BLOCKS输出

TotalBlocks............................1152  --以下由DBMS_SPACE.UNUSED_SPACE输出

TotalBytes.............................9437184

Unused Blocks...........................81

UnusedBytes............................663552

Last Used Ext FileId....................6

Last Used ExtBlockId...................1152

Last Used Block.........................47



PL/SQL procedure successfully completed.



SQL> execshow_space('IDX_MSSM','I','MANUAL');

Free Blocks.............................0

Total Blocks............................256

TotalBytes.............................2097152

Unused Blocks...........................87

UnusedBytes............................712704

Last Used Ext FileId....................6

Last Used Ext BlockId...................1408

Last Used Block.........................41



PL/SQL procedure successfully completed.



SQL> execshow_space('T_MSSM','T');

Free Blocks.............................0

TotalBlocks............................1152

TotalBytes.............................9437184

Unused Blocks...........................81

UnusedBytes............................663552

Last Used Ext FileId....................6

Last Used ExtBlockId...................1152

Last Used Block.........................47



PL/SQL procedure successfully completed.







1.2.2 ASSM  管理表空间下示例


SQL> create tablespace assm

 2  datafile'/u01/app/oracle/oradata/dave/assm01.dbf'

 3  size 100m

 4  extent management local

 5  segment space managementauto;



Tablespace created.



SQL> create table t_assm tablespace assmas select * from dba_objects;



Table created.



SQL> create index idx_assm ont_assm(object_id) tablespace assm;



Index created.



SQL> execshow_space('T_ASSM','AUTO','T');

TotalBlocks............................1152

Total Bytes.............................9437184

Unused Blocks...........................54

UnusedBytes............................442368

Last Used Ext FileId....................7

Last Used ExtBlockId...................1152

Last Used Block.........................74



PL/SQL procedure successfully completed.



SQL> exec show_space('IDX_ASSM','AUTO','I');

Total Blocks............................256

TotalBytes.............................2097152

Unused Blocks...........................76

UnusedBytes............................622592

Last Used Ext FileId....................7

Last Used ExtBlockId...................1408

Last Used Block.........................52



PL/SQL procedure successfully completed.



注意：脚本里并显示我们DBMS_SPACE.SPACE_USAGE的内容。因为我们之前有一个判断。



SQL> execshow_space('T_ASSM','AUTO','T',NULL,'Y');

TotalBlocks............................1152

TotalBytes.............................9437184

UnusedBlocks...........................54

Unused Bytes............................442368

Last Used ExtFileId....................7

Last Used ExtBlockId...................1152

Last UsedBlock.........................74

*************************************************

The segment is analyzed

0% -- 25% free space blocks.............0

0% -- 25% free spacebytes..............0

25% -- 50% free spaceblocks............0

25% -- 50% free spacebytes.............0

50% -- 75% free spaceblocks............0

50% -- 75% free spacebytes.............0

75% -- 100% free space blocks...........0

75% -- 100% free spacebytes............0

UnusedBlocks...........................0

UnusedBytes............................0

TotalBlocks............................1072

Totalbytes.............................8781824



PL/SQL procedure successfullycompleted.



--删除部分数据后，在测试：

SQL> delete fromt_assm where rownum<100;



99 rows deleted.



SQL> commit;



Commit complete.



SQL> execshow_space('T_ASSM','T','AUTO','Y',NULL);

TotalBlocks............................1152

TotalBytes.............................9437184

Unused Blocks...........................54

UnusedBytes............................442368

Last Used Ext FileId....................7

Last Used ExtBlockId...................1152

Last Used Block.........................74

*************************************************

The segment is analyzed

0% -- 25% free space blocks.............0

0% -- 25% free space bytes..............0

25% -- 50% free space blocks............0

25% -- 50% free space bytes.............0

50% -- 75% free space blocks............0

50% -- 75% free space bytes.............0

75% -- 100% free space blocks...........1

75% -- 100% free spacebytes............8192

Unused Blocks...........................0

Unused Bytes............................0

TotalBlocks............................1071

Total bytes.............................8773632



PL/SQL procedure successfully completed.



--对表t_assm 收集统计信息：

SQL> execdbms_stats.gather_table_stats(ownname =>'&owner',tabname=>'&tablename',estimate_percent => &est_per ,method_opt =>'forall columns size 1',degree=>&degree,cascade => true);

Enter value for owner: sys

Enter value for tablename: t_assm

Enter value for est_per: 10

Enter value for degree: 8



PL/SQL procedure successfully completed.



SQL> exec show_space('T_ASSM','AUTO','T',NULL,'Y');

TotalBlocks............................1152

TotalBytes.............................9437184

Unused Blocks...........................54

UnusedBytes............................442368

Last Used Ext FileId....................7

Last Used ExtBlockId...................1152

Last Used Block.........................74

*************************************************

The segment is analyzed

0% -- 25% free space blocks.............0

0% -- 25% free space bytes..............0

25% -- 50% free space blocks............0

25% -- 50% free space bytes.............0

50% -- 75% free space blocks............0

50% -- 75% free space bytes.............0

75% -- 100% free space blocks...........1

75% -- 100% free spacebytes............8192

Unused Blocks...........................0

Unused Bytes............................0

TotalBlocks............................1071

Total bytes.............................8773632



PL/SQL procedure successfully completed.

--两次收集信息一致。





再次使用analyze 分析：



SQL> delete from t_assm;



75155 rows deleted.



SQL> commit;



Commit complete.



SQL> execshow_space('T_ASSM','T','AUTO','Y',NULL);

Total Blocks............................1152

TotalBytes.............................9437184

Unused Blocks...........................54

UnusedBytes............................442368

Last Used Ext FileId....................7

Last Used ExtBlockId...................1152

Last Used Block.........................74

*************************************************

The segment is analyzed

0% -- 25% free space blocks.............0

0% -- 25% free space bytes..............0

25% -- 50% free space blocks............0

25% -- 50% free space bytes.............0

50% -- 75% free space blocks............0

50% -- 75% free space bytes.............0

75% -- 100% free spaceblocks...........1072

75% -- 100% free spacebytes............8781824

Unused Blocks...........................0

Unused Bytes............................0

Total Blocks............................0

Total bytes.............................0



PL/SQL procedure successfully completed.



SQL> analyzetable t_assm compute statistics;



Table analyzed.



SQL> exec show_space('T_ASSM','T','AUTO','Y',NULL);

TotalBlocks............................1152

TotalBytes.............................9437184

Unused Blocks...........................54

UnusedBytes............................442368

Last Used Ext FileId....................7

Last Used ExtBlockId...................1152

Last Used Block.........................74

*************************************************

The segment is analyzed

0% -- 25% free space blocks.............0

0% -- 25% free space bytes..............0

25% -- 50% free space blocks............0

25% -- 50% free space bytes.............0

50% -- 75% free space blocks............0

50% -- 75% free space bytes.............0

75% -- 100% free spaceblocks...........1072

75% -- 100% free spacebytes............8781824

Unused Blocks...........................0

Unused Bytes............................0

Total Blocks............................0

Total bytes.............................0



PL/SQL procedure successfully completed.



我这里测试，两者值相同，但实际上，Analyze 会收集如下信息：EMPTY_BLOCKS,AVG_SPACE,CHAIN_CNT，而gather_table_stats则不会收集。





--测试分区表,查看某个分区的信息：

SQL> create table pt_assm

 2  (

 3  object_id number,

 4  created date

 5  )  tablespace assm

 6  partition by hash(object_id)

 7  (

 8  partition part_01,

 9  partition part_02,

 10 partition part_03

 11  );

Table created.



SQL> insert into pt_assm select object_id,createdfrom dba_objects;

75259 rows created.



SQL> commit;

Commit complete.



SQL> Create index idx_pt_assm onpt_assm(object_id) tablespace assm local;

Index created.



SQL> execshow_space('PT_ASSM','TP','AUTO','Y','PART_01');

TotalBlocks............................1024

TotalBytes.............................8388608

Unused Blocks...........................896

UnusedBytes............................7340032

Last Used Ext FileId....................7

Last Used Ext BlockId...................1536

Last Used Block.........................128

*************************************************

The segment is analyzed

0% -- 25% free space blocks.............0

0% -- 25% free space bytes..............0

25% -- 50% free space blocks............0

25% -- 50% free space bytes.............0

50% -- 75% free space blocks............1

50% -- 75% free spacebytes.............8192

75% -- 100% free space blocks...........15

75% -- 100% free spacebytes............122880

Unused Blocks...........................48

UnusedBytes............................393216

Total Blocks............................46

Totalbytes.............................376832



PL/SQL procedure successfully completed.





SQL> execshow_space('IDX_PT_ASSM','IP','AUTO','Y','PART_01');

Total Blocks............................48

TotalBytes.............................393216

Unused Blocks...........................0

Unused Bytes............................0

Last Used Ext FileId....................7

Last Used ExtBlockId...................4648

Last Used Block.........................8

*************************************************

The segment is analyzed

0% -- 25% free space blocks.............0

0% -- 25% free space bytes..............0

25% -- 50% free space blocks............1

25% -- 50% free spacebytes.............8192

50% -- 75% free space blocks............0

50% -- 75% free space bytes.............0

75% -- 100% free space blocks...........0

75% -- 100% free space bytes............0

Unused Blocks...........................0

Unused Bytes............................0

Total Blocks............................42

Totalbytes.............................344064



PL/SQL procedure successfully completed.







二． 相关知识点说明


2.1 表空间管理模式说明
    在看show_space过程里函数之前，需要先了解Oracle 表空间的管理模式。



    LogicalSpace Management分：Locally  managed tablespaces (default) 和 Dictionary-managed tablespaces。 其中Locallymanaged tablespaces 又分ASSM和MSSM。



自动段空间管理（ASSM），在ASSM中链接列表freelist(MSSM)被位图所取代，它是一个二进制的数组，能够迅速有效地管理存储扩展和剩余区块（free block），因此能够改善分段存储本质，ASSM表空间上创建的段还有另外一个称呼叫Bitmap Managed Segments（BMB 段）。



从使用区段空间管理自动参数创建tablespace开始：

create tablespace DAVE

datafile '/u01/data/dave01.dbf '

size 5m

EXTENT MANAGEMENT LOCAL -- Turn on LMT

SEGMENT SPACE MANAGEMENT AUTO -- Turn on ASSM;



    一旦你定义好了tablespace，那么表和索引就能够使用各种方法很容易地被移动到新的tablespace里，带有ASSM的本地管理tablespace会略掉任何为PCTUSED、NEXT和FREELISTS所指定的值。



    当表格或者索引被分配到这个tablespace以后，用于独立对象的PCTUSED的值会被忽略，而Oracle9i会使用位图数组来自动地管理tablespace里表和索引的freelist。



    对于在LMT的tablespace内部创建的表格和索引而言，这个NEXT扩展子句是过时的，因为由本地管理的tablespace会管理它们。但是，INITIAL参数仍然是需要的，因为Oracle不可能提前知道初始表格加载的大小。对于ASSM而言，INITIAL最小的值是三个块。



新的管理机制(ASSM)用位图来跟踪或管理每个分配到对象的块，每个块有多少剩余空间根据位图的状态来确定，如>75%,50%-75%,25%-50%和<25%，也就是说位图其实采用了四个状态位来代替以前的pctused，什么时候该利用该数据块则由设定的pctfree来确定。



    使用ASSM的一个巨大优势是，位图free list(MSSM)肯定能够减轻缓冲区忙等待（buffer busy wait）的负担，这个问题在Oracle9i以前的版本里曾是一个严重的问题。





关于Oracle 表空间的更多说明，参考：

Oracle 自动段空间管理(ASSM:auto segment space management)

http://blog.csdn.net/tianlesoftware/article/details/4958989





几个过程都是出自DBMS_SPACE包，Oracle 11gR2 官方文档中的说明，参考如下链接：

http://docs.oracle.com/cd/E11882_01/appdev.112/e25788/d_space.htm







2.2 DBMS_SPACE.UNUSED_SPACE 过程
Returns information about unused space in anobject (table, index, or cluster)



语法：

DBMS_SPACE.UNUSED_SPACE (

   segment_owner              IN  VARCHAR2,

  segment_name               IN  VARCHAR2,

  segment_type               IN  VARCHAR2,

  total_blocks               OUTNUMBER,

  total_bytes                OUTNUMBER,

  unused_blocks              OUTNUMBER,

  unused_bytes               OUTNUMBER,

  last_used_extent_file_id   OUTNUMBER,

  last_used_extent_block_id  OUTNUMBER,

  last_used_block            OUTNUMBER,

  partition_name             IN  VARCHAR2 DEFAULT NULL);



参数说明：

Parameter
 Description

segment_owner
 Schema name of the segment to be analyzed

segment_name
 Segment name of the segment to be analyzed

segment_type
 Type of the segment to be analyzed (TABLE, INDEX, or CLUSTER):

TABLE

TABLE PARTITION

TABLE SUBPARTITION

INDEX

INDEX PARTITION

INDEX SUBPARTITION

CLUSTER

LOB

LOB PARTITION

LOB SUBPARTITION

total_blocks
 Returns total number of blocks in the segment

total_bytes
 Returns total number of blocks in the segment, in bytes

unused_blocks
 Returns number of blocks which are not used

unused_bytes
 Returns, in bytes, number of blocks which are not used

last_used_extent_file_id
 Returns the file ID of the last extent which contains data

last_used_extent_block_id
 Returns the starting block ID of the last extent which contains data

last_used_block
 Returns the last block within this extent which contains data

partition_name
 Partition name of the segment to be analyzed.

This is only used for partitioned tables; the name of subpartition should be used when partitioning is compose.








2.3. DBMS_SPACE.FREE_BLOCKS 过程（只用MSSM）
This procedure returns information  about free blocks in an object (table, index,or cluster).  该过程只适用非ASSM 管理的对象（MSSM）。



用法：

DBMS_SPACE.FREE_BLOCKS (

  segment_owner     IN  VARCHAR2,

  segment_name      IN  VARCHAR2,

  segment_type      IN  VARCHAR2,

  freelist_group_id IN  NUMBER,

  free_blks         OUT NUMBER,

  scan_limit        IN  NUMBER DEFAULT NULL,

  partition_name    IN  VARCHAR2 DEFAULT NULL);



参数说明：

Parameter
 Description

segment_owner
 Schema name of the segment to be analyzed

segment_name
 Segment name of the segment to be analyzed

segment_type
 Type of the segment to be analyzed (TABLE, INDEX, or CLUSTER):

TABLE

TABLE PARTITION

TABLE SUBPARTITION

INDEX

INDEX PARTITION

INDEX SUBPARTITION

CLUSTER

LOB

LOB PARTITION

LOB SUBPARTITION

freelist_group_id
 Freelist group (instance) whose free list size is to be computed

free_blks
 Returns count of free blocks for the specified group

scan_limit
 Maximum number of free list blocks to read (optional).

Use a scan limit of X you are interested only in the question, "Do I have X blocks on the free list "

partition_name
 Partition name of the segment to be analyzed.

This is only used for partitioned tables. The name of subpartition should be used when partitioning is composite.








2.4. DBMS_SPACE.SPACE_USAGE过程（只用ASSM）


The first form of the procedure shows the space usage of datablocks under the segment High Water Mark. You cancalculate usagefor LOBs, LOB PARTITIONSand LOB SUBPARTITIONS. This procedure can only be used on tablespaces that arecreated with auto segment space management（该过程返回ASSM 管理的对象的free blocks信息（ASSM））. The bitmap blocks, segment header,and extent map blocks are not accounted for by this procedure. Notethat this overload cannot be used on SECUREFILE LOBs.



The second formof the procedure returns information about SECUREFILE LOB spaceusage. It will return the amount of space in blocks being used by all the SECUREFILE LOBsin the LOB segment. The procedure displays the space actively used bythe LOB column, freed space that has retention expired, and freed space thathas retention unexpired. Note that this overload can be used onlyon SECUREFILE LOBs.



语法：

DBMS_SPACE.SPACE_USAGE(

  segment_owner           IN  VARCHAR2,

  segment_name            IN  VARCHAR2,

  segment_type            IN  VARCHAR2,

  unformatted_blocks      OUTNUMBER,

  unformatted_bytes       OUTNUMBER,

  fs1_blocks              OUTNUMBER,

  fs1_bytes               OUTNUMBER,

  fs2_blocks              OUTNUMBER,

  fs2_bytes               OUTNUMBER,

  fs3_blocks              OUTNUMBER,

  fs3_bytes               OUTNUMBER,

  fs4_blocks              OUTNUMBER,

  fs4_bytes               OUTNUMBER,

  full_blocks             OUTNUMBER,

  full_bytes              OUTNUMBER,

  partition_name          IN  VARCHAR2 DEFAULT NULL);



或者：

DBMS_SPACE.SPACE_USAGE(

  segment_owner           IN    VARCHAR2,

  segment_name            IN    VARCHAR2,

  segment_type            IN    VARCHAR2,

  segment_size_blocks     OUT   NUMBER,

  segment_size_bytes      OUT   NUMBER,

  used_blocks             OUT  NUMBER,

  used_bytes              OUT   NUMBER,

  expired_blocks          OUT   NUMBER,

  expired_bytes           OUT   NUMBER,

  unexpired_blocks        OUT   NUMBER,

  unexpired_bytes         OUT   NUMBER,

  partition_name          IN    VARCHAR2 DEFAULT NULL);



参数说明：

Parameter
 Description

segment_owner
 Schema name of the segment to be analyzed

segment_name
 Name of the segment to be analyzed

partition_name
 Partition name of the segment to be analyzed

segment_type
 Type of the segment to be analyzed (TABLE, INDEX, or CLUSTER):

TABLE

TABLE PARTITION

TABLE SUBPARTITION

INDEX

INDEX PARTITION

INDEX SUBPARTITION

CLUSTER

LOB

LOB PARTITION

LOB SUBPARTITION

unformatted_blocks
 Total number of blocks unformatted

unformatted bytes
 Total number of bytes unformatted

fs1_blocks
 Number of blocks having at least 0 to 25% free space

fs1_bytes
 Number of bytes having at least 0 to 25% free space

fs2_blocks
 Number of blocks having at least 25 to 50% free space

fs2_bytes
 Number of bytes having at least 25 to 50% free space

fs3_blocks
 Number of blocks having at least 50 to 75% free space

fs3_bytes
 Number of bytes having at least 50 to 75% free space

fs4_blocks
 Number of blocks having at least 75 to 100% free space

fs4_bytes
 Number of bytes having at least 75 to 100% free space

ful1_blocks
 Total number of blocks full in the segment

full_bytes
 Total number of bytes full in the segment

segment_size_blocks
 Number of blocks allocated to the segment

segment_size_bytes
 Number of bytes allocated to the segment

used_blocks
 Number blocks allocated to the LOB that contains active data

used_bytes
 Number bytes allocated to the LOB that contains active data

expired_blocks
 Number of expired blocks used by the LOB to keep version data

expired_bytes
 Number of expired bytes used by the LOB to keep version data

unexpired_blocks
 Number of unexpired blocks used by the LOB to keep version data

unexpired_bytes
 Number of unexpired bytes used by the LOB to keep version data

partition_name
 Name of the partition (NULL if not a partition)








2.5 ANALYZED 分析
在DBMS_SPACE.SPACE_USAGE收集信息之前，做了一个ANALYZED的判断，因为Analyze 会收集以下信息，而gather_table_stats 则不会收集：

EMPTY_BLOCKS,AVG_SPACE,CHAIN_CNT


1.-- -----------------------------------------------------------------------------------

2.

3.-- Author : Tom Kyte

4.

5.-- Description : Displays free and unused space for the specified object.

6.

7.-- Call Syntax : EXEC Show_Space('Tablename');

8.

9.-- Requirements : SET SERVEROUTPUT ON

10.

11.-- Last Modified: June 22, 2010

12.

13.-- This enhance version has all the fixes for ASSM, LMT, partitions etc (Oracle version 10gr2 +)

14.

15.-- -----------------------------------------------------------------------------------

16.

17.set define off

18.

19.create or replace procedure show_space

20.

21.( p_segname in varchar2,

22.

23. p_owner in varchar2 default user,

24.

25. p_type in varchar2 default 'TABLE',

26.

27. p_partition in varchar2 default NULL )

28.

29.-- this procedure uses authid current user so it can query DBA_*

30.

31.-- views using privileges from a ROLE and so it can be installed

32.

33.-- once per database, instead of once per user that wanted to use it

34.

35.authid current_user

36.

37.as

38.

39.    l_free_blks number;

40.

41.    l_total_blocks number;

42.

43.    l_total_bytes number;

44.

45.    l_unused_blocks number;

46.

47.    l_unused_bytes number;

48.

49.    l_LastUsedExtFileId number;

50.

51.    l_LastUsedExtBlockId number;

52.

53.    l_LAST_USED_BLOCK number;

54.

55.    l_segment_space_mgmt varchar2(255);

56.

57.    l_unformatted_blocks number;

58.

59.    l_unformatted_bytes number;

60.

61.    l_fs1_blocks number; l_fs1_bytes number;

62.

63.    l_fs2_blocks number; l_fs2_bytes number;

64.

65.    l_fs3_blocks number; l_fs3_bytes number;

66.

67.    l_fs4_blocks number; l_fs4_bytes number;

68.

69.    l_full_blocks number; l_full_bytes number;

70.

71.    -- inline procedure to print out numbers nicely formatted

72.

73.    -- with a simple label

74.

75.    procedure p( p_label in varchar2, p_num in number )

76.

77.    is

78.

79.    begin

80.

81.       dbms_output.put_line( rpad(p_label,40,'.') ||

82.

83.                             to_char(p_num,'999,999,999,999') );

84.

85.    end;

86.

87.begin

88.

89.  -- this query is executed dynamically in order to allow this procedure

90.

91.  -- to be created by a user who has access to DBA_SEGMENTS/TABLESPACES

92.

93.  -- via a role as is customary.

94.

95.  -- NOTE: at runtime, the invoker MUST have access to these two

96.

97.  -- views!

98.

99.  -- this query determines if the object is a ASSM object or not

100.

101.  begin

102.

103.     execute immediate

104.

105.         'select ts.segment_space_management

106.

107.            from dba_segments seg, dba_tablespaces ts

108.

109.           where seg.segment_name = :p_segname

110.

111.             and (:p_partition is null or

112.

113.                 seg.partition_name = :p_partition)

114.

115.             and seg.owner = :p_owner

116.

117.             and seg.segment_type = :p_type

118.

119.             and seg.tablespace_name = ts.tablespace_name'

120.

121.            into l_segment_space_mgmt

122.

123.           using p_segname, p_partition, p_partition, p_owner, p_type;

124.

125.  exception

126.

127.      when too_many_rows then

128.

129.         dbms_output.put_line

130.

131.         ( 'This must be a partitioned table, use p_partition => ');

132.

133.         return;

134.

135.  end;

136.

137.  -- if the object is in an ASSM tablespace, we must use this API

138.

139.  -- call to get space information, else we use the FREE_BLOCKS

140.

141.  -- API for the user managed segments

142.

143.  if l_segment_space_mgmt = 'AUTO'

144.

145.  then

146.

147.    dbms_space.space_usage

148.

149.    ( p_owner, p_segname, p_type, l_unformatted_blocks,

150.

151.      l_unformatted_bytes, l_fs1_blocks, l_fs1_bytes,

152.

153.      l_fs2_blocks, l_fs2_bytes, l_fs3_blocks, l_fs3_bytes,

154.

155.      l_fs4_blocks, l_fs4_bytes, l_full_blocks, l_full_bytes, p_partition);

156.

157.    p( 'Unformatted Blocks ', l_unformatted_blocks );

158.

159.    p( 'FS1 Blocks (0-25) ', l_fs1_blocks );

160.

161.    p( 'FS2 Blocks (25-50) ', l_fs2_blocks );

162.

163.    p( 'FS3 Blocks (50-75) ', l_fs3_blocks );

164.

165.    p( 'FS4 Blocks (75-100)', l_fs4_blocks );

166.

167.    p( 'Full Blocks ', l_full_blocks );

168.

169. else

170.

171.    dbms_space.free_blocks(

172.

173.      segment_owner => p_owner,

174.

175.      segment_name => p_segname,

176.

177.      segment_type => p_type,

178.

179.      freelist_group_id => 0,

180.

181.      free_blks => l_free_blks);

182.

183.    p( 'Free Blocks', l_free_blks );

184.

185. end if;

186.

187. -- and then the unused space API call to get the rest of the

188.

189. -- information

190.

191. dbms_space.unused_space

192.

193. ( segment_owner => p_owner,

194.

195.    segment_name => p_segname,

196.

197.    segment_type => p_type,

198.

199.    partition_name => p_partition,

200.

201.    total_blocks => l_total_blocks,

202.

203.    total_bytes => l_total_bytes,

204.

205.    unused_blocks => l_unused_blocks,

206.

207.    unused_bytes => l_unused_bytes,

208.

209.    LAST_USED_EXTENT_FILE_ID => l_LastUsedExtFileId,

210.

211.    LAST_USED_EXTENT_BLOCK_ID => l_LastUsedExtBlockId,

212.

213.    LAST_USED_BLOCK => l_LAST_USED_BLOCK );

214.

215.    p( 'Total Blocks', l_total_blocks );

216.

217.    p( 'Total Bytes', l_total_bytes );

218.

219.    p( 'Total MBytes', trunc(l_total_bytes/1024/1024) );

220.

221.    p( 'Unused Blocks', l_unused_blocks );

222.

223.    p( 'Unused Bytes', l_unused_bytes );

224.

225.    p( 'Last Used Ext FileId', l_LastUsedExtFileId );

226.

227.    p( 'Last Used Ext BlockId', l_LastUsedExtBlockId );

228.

229.    p( 'Last Used Block', l_LAST_USED_BLOCK );

230.

231.end;

232.

233./

234.

235.set define on


            When the table is in the same schema.
S             SET SERVEROUTPUT ON

   exec show_space ('EMP99')



             Example: When the table is in the different schema.
             SET SERVEROUTPUT ON

exec show_space ('EMP33' , 'MOID');







F5 v11 tmsh常用命令操作手册
分类： 暂无分类 阅读量：42 状态：已审核
词条版本[1]  附件[0] 引用情况
V11 TMSH命令行操作手册#
查看当前系统配置：#
# show running-config
# show running-config /net interface
# show running-config /ltm pool
保存base内容：#
#save /sys base-configload base内容：#
#load /sys base-config保存系统配置：#
#save /sys configload系统配置：#
#load /sys config查看网络配置信息：#
#list /net vlan
#list /net interface
#list /net arp
#list /net route
#list /net self
#list /net self-allow
#list /net trunk
查看POOL配置信息：#
# list /ltm pool
# list /ltm pool [http-pool]
查看vs配置信息：#
# list /ltm virtual
# list /ltm virtual-address
查看/sys配置信息：#
# list /sys db
# list /sys httpd allow
# list /sys management-ip（查看设备管理口地址）
# list /sys management-route（查看设备管理口路由）
# list /sys ntp（查看ntp配置信息）
# list /sys provision（查看设备模块激活状态）
# list /sys service（查看服务开启状态）
# list /sys snmp（查看snmp配置信息）
# list /sys syslog（查看syslog配置信息）
show /net命令：
# show /cli history（查看命令行历史记录）
# show /net arp（查看arp映射信息）
# show /net interface（查看各个接口统计流量信息）
# show /net route（查看路由表）
# show /net vlan（查看各个vlan流量统计信息）
# show /net vlan-group
# show /net trunk（查看trunk流量统计信息）
show /sys命令：
# show /sys config-sync（查看系统配置同步状态信息）
# show /sys connection
# show /sys console（查看系统串口调试速率）
# show /sys cpu
# show /sys hardware（查看系统硬件信息）
# show /sys host-info
# show /sys raid（查看硬盘raid状态）
# show /sys performance system（查看系统总体性能）
# show /sys software（查看系统总体软件信息）
# show /sys ip-address（查看系统ip地址，包括所有的vs、pool地址信息）
# show /sys ip-address all-properties（查看系统地址信息，包括地址属性）
# show /sys license（查看系统license摘要信息）
# show /sys license detail
# show /sys log ltm（查看系统log信息）
# show /sys mac-address（查看系统中所有的mac地址信息）
# show /sys mcp-state（查看mcp运行状态）
# show /sys memory（查看系统内存统计信息）
# show /sys ucs（查看保存的ucs文件名称）
# show /sys version（查看系统软件版本信息）
帮助命令的使用：#
# help /net
# help /net vlan
快捷键的使用：#
Ctrl   C（放弃当前正在输入的命令）
Ctrl   A（将光标移到最开始）
Ctrl   E（将光标移到最后）
Ctrl   G（清除正在输入的命令行字符串）
Ctrl   L（清除所有屏幕显示）
Ctrl   N（显示下一个输入的命令）
Ctrl   P（显示上一次输入的命令）
在tmsh模式下使用相关的测试命令：#
# run util ping 1.1.1.1（执行ping操作）
# run util tcpdump（执行tcpdump抓包分析）
# run util tracepath 1.1.1.1（执行tracepath操作）
# run util traceroute 1.1.1.1（执行traceroute操作）
创建和删除pool：#
# create /ltm pool [abc]
# delete /ltm pool [abc]
修改irules内容：#
# edit /ltm rule [replace-302]
安装操作系统和hotfix补丁：#
#install sys software image BIGIP-10.0.0.5376.0.iso volume HD1.2
#install hotfix Hotfix-BIGIP-9.6.1-824.0-HF3.im volume HD1.1
重置pool、vs的统计信息：#
# reset-stats /ltm pool
# reset-stats /ltm pool [http-pool]
# reset-stats /ltm virtual
# reset-stats /ltm virtual [vs-test-80]
启动、停止、重启系统中某个服务：#
# start /sys service [snmpd]
# stop /sys service [snmpd]
# restart /sys service [snmpd]
建立、删除partition分区：#
# create /auth partition [aa]
# delete /auth partition [aa]
查看radius服务器配置：#
# list /auth radius-server
定义和删除别名：#
# create /cli alias [xx] command ["save /sys config"]
# delete /cli alias [xx]
创建pool并添加pool-member：#
# create /ltm pool [abc] members add { 9.9.9.9:http 7.7.7.7:http } 对创建的pool增加健康检查方式：#
# modify /ltm pool [abc] monitor http
# modify /ltm pool [abc] monitor http and https
# modify /ltm pool [abc] monitor none
创建vs，使用源地址会话保持，并指定缺省的pool#
# create /ltm virtual abcd { destination 6.6.6.6:http persist replace-all-with { source_addr }  pool abc }
配置radius服务器：#
# create /auth radius-server [xx] secret [cisco] server 5.5.5.5创建自定义的monitor:#
# create /ltm monitor gateway-icmp [xx] defaults-from gateway_icmp开启、关闭网络接口：#
# modify /net interface [1.1] enabled
# modify /net interface [1.1] disabled查看stp信息：#
# sh running-config /net stp创建vlan：#
# create /net vlan [xx] interfaces add { 1.1 }
Search 帮助#
root@test(Active)(/Common)(tmos)# help search automap
apm policy agent route-domain-selection
ltm snat
ltm virtual
sys application template
root@test(Active)(/Common)(tmos)#


Instance的enable/disable状态监控脚本是
      在10.11.77.41上的/wls/apache/appsystems/agentconsole/script/cron/monitorInstanceIfDisable.pl
      它每10分钟执行一次，异常日志在/wls/apache/appsystems/agentconsole/log/cron/monitorInstanceIfDisable/cron.`date +\%Y\%m\%d`.log

其监控的ip范围在脚本中最后一行中定义，例如：
      $monitor->monitorInstanceIfDisable('cmdline', {filter => '^10\.( :12|33)\.( :6[4,5,6,7]|8[0,1,2,3,8,9]|9[0,1,6,7,8,9])\.'});

如果遇到了新增监控网段时，只修改脚本中标红的正则表达式部分即可，修改用wls81用户进行
修改时要慎重，嘿嘿

现说明一下此正则的意思
^10\.( :12|33)\.( :6[4,5,6,7]|8[0,1,2,3,8,9]|9[0,1,6,7,8,9])\.
它表示ip需要满足一下条件才会被监控
第一部分是10
第二部分是12或33
第三部分是64、65、66、67或80、81、82、83、88、89或90、91、96、97、98、99
第四部分随意

如果修改时没把握可以找我^_^




Drop user 触发 ORA-00600 5463 和ORA-00600 ktecgeb-1错


一、作者


黄陈旭(Williams.huang @oracle.com)


二、更新时间


首次发布时间：2012年05月12日 星期六


历次修订时间：2012年05月14日 星期一


2012年05月21日 星期一


三、问题影响范围


（1）产品（数据库、Golden Gate、Quest 等）版本


 Oracle  9I以上


 （2）OS平台和版本


 不限。


四、问题现象


Drop user username cascade的时候，报ORA-00600 5463和ORA-00600 ktecgeb-1错误，接着instance crash


五、原因分析


原因是由于删除用户会先把用户下面的对象全部删除，Smon要清理临时对象的时候，需要去查找表空间的bitmap index,但是由于这个bitmap index损坏，导致了Smon无法清查临时对象，Smon重试了100次之后，实例被终止。处理思路如下：


1、设置event 10061阻止Smon对临时对象进行清理


2、查出所有需要清查的对象


3、使用dbms_space_admin.segment_corrupt将对象设置为corrupt


4、使用dbms_space_admin.segment_drop_corrupt将对象清除


5、使用dbms_space_admin.tablespace_rebuild_bitmaps重建表空间的bitmap index


6、重启数据库，将event 10061去掉


7、使用dbms_space_admin.tablespace_verify检查表空间是否正常


六、解决方法


由于用户下面的对象有28325个，其中有某些对象有问题，当drop user遇到这些对象的时候，语句将会失败，按照上面提供的思路，具体的操作步骤如下：


1、重启数据库，设置event = '10061 trace name context forever, level 10'


2、执行drop user username cascade操作，中间会中断多次，由于设置了event 10061，数据库crash，只要重新执行drop user操作就行，直到用户删除。


3、检查有问题的对象：


select owner,segment_name, segment_type ,tablespace_name


from dba_segments


where segment_type=’TEMPORARY’;


4、将对象标识为corrupt


如：exec dbms_space_admin.segment_corrupt('TABLESPACE_NAME',5,237068) ;


5、将对象删除


如：exec dbms_space_admin.segment_drop_corrupt(‘ TABLESPACE_NAME ‘,49,1183372) ;


6、重建表空间的bitmap index


exec dbms_space_admin.tablespace_rebuild_bitmaps('TABLESPACE_NAME');


7、重启数据库，将event 10061去除


8、较验表空间是否正常


exec dbms_space_admin.tablespace_verify ('TABLESPACE_NAME');


七、参考文档


ORA-600 [5463] While SMON is Doing Temporary Segment Drop ID 422039.1


八、关键字


ora-00600 5463


ora-00600  ktecgeb-1


Drop user


如何查询一个表空间上有哪些对象？

select * from dba_segments a where a.tablespace_name='XXX'

迁移索引到另一个表空间；
alter index GBSMAN.IDX_QDSI_POL_RE_CODE_ID rebuild online tablespace  HSCQDDATA;

迁移表到另一个表空间。
alter table test move tablespace example;  --把表从user空间转移到example空间上


su: warning: cannot change directory to /paic/mysql: Permission denied
su: /bin/bash: Permission denied带来的疑惑
通过star命令，看到了问题根本，
[root@localhost ~]#stat /
输出如下：因为你ls是看不到的。
File: “/”
Size: 1024            Blocks: 2          IO Block: 1024   目录
Device: 803h/2051d      Inode: 2           Links: 22
Access: (0666/drw-rw-rw-) Uid: (    0/    root)   Gid: (    0/    root)
Access: 2007-12-01 22:28:48.000000000 +0800
Modify: 2007-12-01 22:28:34.000000000 +0800
Change: 2007-12-01 23:17:35.000000000 +0800

问题出来了，这里的权限是错误的，X权限的丢失造成的。

[root@localhost ~]#chmod 755 /


修改后,问题消失。

产生上述问题的方法：
第一种，chmod 666 /，可以导致。

或者，
第二种，chmod 700 /lib/ld-xxxx.so，也可以导致su失败。






安全快速修改Mysql数据库名的5种方法

作者： 字体：[增加 减小] 类型：转载
mysql中如何重命名数据库？这篇文章主要介绍了安全快速修改Mysql数据库名的5种方法,需要的朋友可以参考下



1. RENAME DATABASE db_name TO new_db_name

这个。。这个语法在mysql 5.1.7中被添加进来，到了5.1.23又去掉了。
据说有可能丢失数据。还是不要用的好。
详见： http://dev.mysql.com/doc/refman/5.1/en/rename-database.html
2.如果所有表都是MyISAM类型的话，可以改文件夹的名字
关闭mysqld
把data目录中的db_name目录重命名为new_db_name
开启mysqld
3.重命名所有的表
复制代码 代码如下:
CREATE DATABASE new_db_name;
RENAME TABLE db_name.table1 TO new_db_name.table1,
db_name.table2 TO new_db_name.table2;
DROP DATABASE db_name;
4. mysqldump导出数据再导入
复制代码 代码如下:
mysqldump -uxxxx -pxxxx -h xxxx db_name > db_name_dump.SQL
mysql -uxxxx -pxxxx -h xxxx -e “CREATE DATABASE new_db_name”
mysql -uxxxx -pxxxx -h xxxx new_db_name < db_name_dump.SQL
mysql -uxxxx -pxxxx -h xxxx -e “DROP DATABASE db_name”
5.使用shell脚本重命名所有的表

复制代码 代码如下:
#!/bin/bash
mysqlconn=”mysql -u xxxx -pxxxx -S /var/lib/mysql/mysql.sock -h localhost”
olddb=”db_name”
newdb=”new_db_name”
#$mysqlconn -e “CREATE DATABASE $newdb”
params=$($mysqlconn -N -e “SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES WHERE table_schema='$olddb'”)
for name in $params; do
$mysqlconn -e “RENAME TABLE $olddb.$name to $newdb.$name”;
done;
#$mysqlconn -e “DROP DATABASE $olddb”
就是方法3的优化版。

小编注：以上这些操作都是危险的，所以请在执行操作前，备份你的数据库！



infobright：
mysqldump导出mysql schema
infobright：
mysqldump -uroot -p'123456' dopool_serv_logs --lock-tables=false -E -R -q -d > /tmp/merge_dopool_serv_logs.sql
因为infobright不支持lock table命令，所以--lock-tables=false
mysqldump -uroot -p'123456' dopool_serv_logs --opt  -E -R -q -d > /tmp/merge_dopool_serv_logs.sql

-E 导出events
-R 导出存储过程和自定义函数
-q --quick 直接写文件，不会缓冲
-d --no-data 不导出数据
#Mysql


很简单的方法：在my.cnf中添加
[mysql]
default-character-set=utf8

我在网上查到的是在/etc/my.cnf中加入
sql_mode=''
character-set-server=utf8
collation-server=utf8_general_ci
init_connect="SET NAMES 'utf8'"

我用了一下，没起作用！！！

目前每次查询。sql前必须加一个set names utf8;


正解~ 在 [client] 段 加default-character-set=utf8 也ok



修改mysql默认字符集的方法
2010-10-09 11:12 佚名 互联网 字号：T | T
一键收藏，随时查看，分享好友！
mysql默认字符集的修改方法未必人人都会，下文就介绍了两个最常见的修改mysql默认字符集的方法，供您参考学习。
AD：WOT2014：用户标签系统与用户数据化运营培训专场
mysql默认字符集能否进行修改呢？答案是肯定的，下面就将教您两种修改mysql默认字符集的方法，希望对您学习mysql默认字符集方面能有所启迪。

(1) 最简单的修改方法，就是修改mysql的my.ini文件中的字符集键值，

如 default-character-set = utf8
character_set_server = utf8

修改完后，重启mysql的服务，service mysql restart

使用 mysql> SHOW VARIABLES LIKE 'character%';查看，发现数据库编码均已改成utf8

+--------------------------+---------------------------------+
| Variable_name | Value |
+--------------------------+---------------------------------+
| character_set_client | utf8 |
| character_set_connection | utf8 |
| character_set_database | utf8 |
| character_set_filesystem | binary |
| character_set_results | utf8 |
| character_set_server | utf8 |
| character_set_system | utf8 |
| character_sets_dir | D:"mysql-5.0.37"share"charsets" |
+--------------------------+---------------------------------+
(2) 还有一种修改mysql默认字符集的方法，就是使用mysql的命令

mysql> SET character_set_client = utf8 ;
mysql> SET character_set_connection = utf8 ;
mysql> SET character_set_database = utf8 ;
mysql> SET character_set_results = utf8 ;
mysql> SET character_set_server = utf8 ;

mysql> SET collation_connection = utf8 ;
mysql> SET collation_database = utf8 ;
mysql> SET collation_server = utf8 ;
一般就算设置了表的mysql默认字符集为utf8并且通过UTF-8编码发送查询，你会发现存入数据库的仍然是乱码。问题就出在这个connection连接层上。解决方法是在发送查询前执行一下下面这句：

SET NAMES 'utf8';
它相当于下面的三句指令：

SET character_set_client = utf8;
SET character_set_results = utf8;
SET character_set_connection = utf8;






























Last login: Fri Jul  4 10:22:58 2014 from 10.11.108.41
If you are not authorized to access this private computer system, disconnect now. All activities on this system will be monitored and recorded without prior notification or permission.
[root@DEV-L002102 ~]#
[root@DEV-L002102 ~]#
[root@DEV-L002102 ~]#
[root@DEV-L002102 ~]#
[root@DEV-L002102 ~]#
[root@DEV-L002102 ~]#
[root@DEV-L002102 ~]#
[root@DEV-L002102 ~]#  fdisk -l

Disk /dev/sda: 21.5 GB, 21474836480 bytes
255 heads, 63 sectors/track, 2610 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x0009bb7d

   Device Boot      Start         End      Blocks   Id  System
/dev/sda1   *           1          26      204800   83  Linux
Partition 1 does not end on cylinder boundary.
/dev/sda2              26        2611    20765696   8e  Linux LVM

Disk /dev/vda: 408.0 GB, 408021893120 bytes
16 heads, 63 sectors/track, 790593 cylinders
Units = cylinders of 1008 * 512 = 516096 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x00000000


Disk /dev/mapper/Volgroup00-LV_root: 17.0 GB, 16965959680 bytes
255 heads, 63 sectors/track, 2062 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x00000000


Disk /dev/mapper/Volgroup00-LV_swap: 4294 MB, 4294967296 bytes
255 heads, 63 sectors/track, 522 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x00000000

[root@DEV-L002102 ~]# fdisk /dev/vda
Device contains neither a valid DOS partition table, nor Sun, SGI or OSF disklabel
Building a new DOS disklabel with disk identifier 0x3d301e49.
Changes will remain in memory only, until you decide to write them.
After that, of course, the previous content won't be recoverable.

Warning: invalid flag 0x0000 of partition table 4 will be corrected by w(rite)

WARNING: DOS-compatible mode is deprecated. It's strongly recommended to
         switch off the mode (command 'c') and change display units to
         sectors (command 'u').

Command (m for help): m
Command action
   a   toggle a bootable flag
   b   edit bsd disklabel
   c   toggle the dos compatibility flag
   d   delete a partition
   l   list known partition types
   m   print this menu
   n   add a new partition
   o   create a new empty DOS partition table
   p   print the partition table
   q   quit without saving changes
   s   create a new empty Sun disklabel
   t   change a partition's system id
   u   change display/entry units
   v   verify the partition table
   w   write table to disk and exit
   x   extra functionality (experts only)

Command (m for help): n
Command action
   e   extended
   p   primary partition (1-4)
p
Partition number (1-4): 1
First cylinder (1-790593, default 1):
Using default value 1
Last cylinder, +cylinders or +size{K,M,G} (1-790593, default 790593):
Using default value 790593

Command (m for help): p

Disk /dev/vda: 408.0 GB, 408021893120 bytes
16 heads, 63 sectors/track, 790593 cylinders
Units = cylinders of 1008 * 512 = 516096 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x3d301e49

   Device Boot      Start         End      Blocks   Id  System
/dev/vda1               1      790593   398458840+  83  Linux

Command (m for help): m
Command action
   a   toggle a bootable flag
   b   edit bsd disklabel
   c   toggle the dos compatibility flag
   d   delete a partition
   l   list known partition types
   m   print this menu
   n   add a new partition
   o   create a new empty DOS partition table
   p   print the partition table
   q   quit without saving changes
   s   create a new empty Sun disklabel
   t   change a partition's system id
   u   change display/entry units
   v   verify the partition table
   w   write table to disk and exit
   x   extra functionality (experts only)

Command (m for help): t
Selected partition 1
Hex code (type L to list codes): L

 0  Empty           24  NEC DOS         81  Minix / old Lin bf  Solaris
 1  FAT12           39  Plan 9          82  Linux swap / So c1  DRDOS/sec (FAT-
 2  XENIX root      3c  PartitionMagic  83  Linux           c4  DRDOS/sec (FAT-
 3  XENIX usr       40  Venix 80286     84  OS/2 hidden C:  c6  DRDOS/sec (FAT-
 4  FAT16 <32M      41  PPC PReP Boot   85  Linux extended  c7  Syrinx
 5  Extended        42  SFS             86  NTFS volume set da  Non-FS data
 6  FAT16           4d  QNX4.x          87  NTFS volume set db  CP/M / CTOS / .
 7  HPFS/NTFS       4e  QNX4.x 2nd part 88  Linux plaintext de  Dell Utility
 8  AIX             4f  QNX4.x 3rd part 8e  Linux LVM       df  BootIt
 9  AIX bootable    50  OnTrack DM      93  Amoeba          e1  DOS access
 a  OS/2 Boot Manag 51  OnTrack DM6 Aux 94  Amoeba BBT      e3  DOS R/O
 b  W95 FAT32       52  CP/M            9f  BSD/OS          e4  SpeedStor
 c  W95 FAT32 (LBA) 53  OnTrack DM6 Aux a0  IBM Thinkpad hi eb  BeOS fs
 e  W95 FAT16 (LBA) 54  OnTrackDM6      a5  FreeBSD         ee  GPT
 f  W95 Ext'd (LBA) 55  EZ-Drive        a6  OpenBSD         ef  EFI (FAT-12/16/
10  OPUS            56  Golden Bow      a7  NeXTSTEP        f0  Linux/PA-RISC b
11  Hidden FAT12    5c  Priam Edisk     a8  Darwin UFS      f1  SpeedStor
12  Compaq diagnost 61  SpeedStor       a9  NetBSD          f4  SpeedStor
14  Hidden FAT16 <3 63  GNU HURD or Sys ab  Darwin boot     f2  DOS secondary
16  Hidden FAT16    64  Novell Netware  af  HFS / HFS+      fb  VMware VMFS
17  Hidden HPFS/NTF 65  Novell Netware  b7  BSDI fs         fc  VMware VMKCORE
18  AST SmartSleep  70  DiskSecure Mult b8  BSDI swap       fd  Linux raid auto
1b  Hidden W95 FAT3 75  PC/IX           bb  Boot Wizard hid fe  LANstep
1c  Hidden W95 FAT3 80  Old Minix       be  Solaris boot    ff  BBT
1e  Hidden W95 FAT1
Hex code (type L to list codes): 8e
Changed system type of partition 1 to 8e (Linux LVM)

Command (m for help): m
Command action
   a   toggle a bootable flag
   b   edit bsd disklabel
   c   toggle the dos compatibility flag
   d   delete a partition
   l   list known partition types
   m   print this menu
   n   add a new partition
   o   create a new empty DOS partition table
   p   print the partition table
   q   quit without saving changes
   s   create a new empty Sun disklabel
   t   change a partition's system id
   u   change display/entry units
   v   verify the partition table
   w   write table to disk and exit
   x   extra functionality (experts only)

Command (m for help): p

Disk /dev/vda: 408.0 GB, 408021893120 bytes
16 heads, 63 sectors/track, 790593 cylinders
Units = cylinders of 1008 * 512 = 516096 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x3d301e49

   Device Boot      Start         End      Blocks   Id  System
/dev/vda1               1      790593   398458840+  8e  Linux LVM

Command (m for help): m
Command action
   a   toggle a bootable flag
   b   edit bsd disklabel
   c   toggle the dos compatibility flag
   d   delete a partition
   l   list known partition types
   m   print this menu
   n   add a new partition
   o   create a new empty DOS partition table
   p   print the partition table
   q   quit without saving changes
   s   create a new empty Sun disklabel
   t   change a partition's system id
   u   change display/entry units
   v   verify the partition table
   w   write table to disk and exit
   x   extra functionality (experts only)

Command (m for help): w
The partition table has been altered!

Calling ioctl() to re-read partition table.
Syncing disks.
[root@DEV-L002102 ~]#
[root@DEV-L002102 ~]#
[root@DEV-L002102 ~]#
[root@DEV-L002102 ~]#
[root@DEV-L002102 ~]#
[root@DEV-L002102 ~]# fdisk -l

Disk /dev/sda: 21.5 GB, 21474836480 bytes
255 heads, 63 sectors/track, 2610 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x0009bb7d

   Device Boot      Start         End      Blocks   Id  System
/dev/sda1   *           1          26      204800   83  Linux
Partition 1 does not end on cylinder boundary.
/dev/sda2              26        2611    20765696   8e  Linux LVM

Disk /dev/vda: 408.0 GB, 408021893120 bytes
16 heads, 63 sectors/track, 790593 cylinders
Units = cylinders of 1008 * 512 = 516096 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x3d301e49

   Device Boot      Start         End      Blocks   Id  System
/dev/vda1               1      790593   398458840+  8e  Linux LVM

Disk /dev/mapper/Volgroup00-LV_root: 17.0 GB, 16965959680 bytes
255 heads, 63 sectors/track, 2062 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x00000000


Disk /dev/mapper/Volgroup00-LV_swap: 4294 MB, 4294967296 bytes
255 heads, 63 sectors/track, 522 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x00000000

[root@DEV-L002102 ~]# pvcreate /dev/vda1
  Physical volume "/dev/vda1" successfully created
[root@DEV-L002102 ~]# pvs
  PV         VG         Fmt  Attr PSize   PFree
  /dev/sda2  Volgroup00 lvm2 a--   19.80g      0
  /dev/vda1             lvm2 a--  380.00g 380.00g
[root@DEV-L002102 ~]# vgs
  VG         #PV #LV #SN Attr   VSize  VFree
  Volgroup00   1   2   0 wz--n- 19.80g    0
[root@DEV-L002102 ~]# vgcreate VGapp_d1aims /dev/vda1
  Volume group "VGapp_d1aims" successfully created
[root@DEV-L002102 ~]# vgs
  VG           #PV #LV #SN Attr   VSize   VFree
  VGapp_d1aims   1   0   0 wz--n- 380.00g 380.00g
  Volgroup00     1   2   0 wz--n-  19.80g      0
[root@DEV-L002102 ~]# lvcreate -L 50g -n LV_d1aims_rdbms  VGapp_d1aims
  Logical volume "LV_d1aims_rdbms" created
[root@DEV-L002102 ~]# lvs
  LV              VG           Attr      LSize  Pool Origin Data%  Move Log Cpy%Sync Convert
  LV_d1aims_rdbms VGapp_d1aims -wi-a---- 50.00g
  LV_root         Volgroup00   -wi-ao--- 15.80g
  LV_swap         Volgroup00   -wi-ao---  4.00g
[root@DEV-L002102 ~]# vgs
  VG           #PV #LV #SN Attr   VSize   VFree
  VGapp_d1aims   1   1   0 wz--n- 380.00g 330.00g
  Volgroup00     1   2   0 wz--n-  19.80g      0
[root@DEV-L002102 ~]# lvcreate -L 5g -n LV_d1aims_app  VGapp_d1aims
  Logical volume "LV_d1aims_app" created
[root@DEV-L002102 ~]# lvcreate -L 50g -n LV_d1aims_log  VGapp_d1aims
  Logical volume "LV_d1aims_log" created
[root@DEV-L002102 ~]# vgs
  VG           #PV #LV #SN Attr   VSize   VFree
  VGapp_d1aims   1   3   0 wz--n- 380.00g 275.00g
  Volgroup00     1   2   0 wz--n-  19.80g      0
[root@DEV-L002102 ~]# lvs
  LV              VG           Attr      LSize  Pool Origin Data%  Move Log Cpy%Sync Convert
  LV_d1aims_app   VGapp_d1aims -wi-a----  5.00g
  LV_d1aims_log   VGapp_d1aims -wi-a---- 50.00g
  LV_d1aims_rdbms VGapp_d1aims -wi-a---- 50.00g
  LV_root         Volgroup00   -wi-ao--- 15.80g
  LV_swap         Volgroup00   -wi-ao---  4.00g
[root@DEV-L002102 ~]# lvcreate -L 200g -n LV_d1aims_data01  VGapp_d1aims
  Logical volume "LV_d1aims_data01" created
[root@DEV-L002102 ~]#
[root@DEV-L002102 ~]#
[root@DEV-L002102 ~]#
[root@DEV-L002102 ~]#
[root@DEV-L002102 ~]# lvs
  LV               VG           Attr      LSize   Pool Origin Data%  Move Log Cpy%Sync Convert
  LV_d1aims_app    VGapp_d1aims -wi-a----   5.00g
  LV_d1aims_data01 VGapp_d1aims -wi-a---- 200.00g
  LV_d1aims_log    VGapp_d1aims -wi-a----  50.00g
  LV_d1aims_rdbms  VGapp_d1aims -wi-a----  50.00g
  LV_root          Volgroup00   -wi-ao---  15.80g
  LV_swap          Volgroup00   -wi-ao---   4.00g
[root@DEV-L002102 ~]# mount -v
/dev/mapper/Volgroup00-LV_root on / type ext4 (rw)
proc on /proc type proc (rw)
sysfs on /sys type sysfs (rw)
devpts on /dev/pts type devpts (rw,gid=5,mode=620)
tmpfs on /dev/shm type tmpfs (rw)
/dev/sda1 on /boot type ext4 (rw)
none on /proc/sys/fs/binfmt_misc type binfmt_misc (rw)
[root@DEV-L002102 ~]# mk
mkdict            mkfontdir         mkfs.ext4         mklost+found      mksock
mkdir             mkfontscale       mkfs.ext4dev      mkmanifest        mkstore
mkdosfs           mkfs              mkfs.msdos        mknod             mkstore.ouibak
mkdumprd          mkfs.cramfs       mkfs.vfat         mkpatch           mkswap
mke2fs            mkfs.ext2         mkhomedir_helper  mkpatchO          mktemp
mkfifo            mkfs.ext3         mkinitrd          mkrfc2734         mkxauth
[root@DEV-L002102 ~]# mkfs -t ext4 ^C
[root@DEV-L002102 ~]# cd /dev/VGapp_d1aims
[root@DEV-L002102 VGapp_d1aims]# ls
LV_d1aims_app  LV_d1aims_data01  LV_d1aims_log  LV_d1aims_rdbms
[root@DEV-L002102 VGapp_d1aims]# pwd
/dev/VGapp_d1aims
[root@DEV-L002102 VGapp_d1aims]# mkfs
mkfs          mkfs.ext2     mkfs.ext4     mkfs.msdos
mkfs.cramfs   mkfs.ext3     mkfs.ext4dev  mkfs.vfat
[root@DEV-L002102 VGapp_d1aims]# mkfs
mkfs          mkfs.ext2     mkfs.ext4     mkfs.msdos
mkfs.cramfs   mkfs.ext3     mkfs.ext4dev  mkfs.vfat
[root@DEV-L002102 VGapp_d1aims]# mkfs
mkfs          mkfs.ext2     mkfs.ext4     mkfs.msdos
mkfs.cramfs   mkfs.ext3     mkfs.ext4dev  mkfs.vfat
[root@DEV-L002102 VGapp_d1aims]# mkfs
mkfs          mkfs.ext2     mkfs.ext4     mkfs.msdos
mkfs.cramfs   mkfs.ext3     mkfs.ext4dev  mkfs.vfat
[root@DEV-L002102 VGapp_d1aims]# mkfs -t ext4 /dev/VGapp_d1aims/LV_d1aims_app
mke2fs 1.41.12 (17-May-2010)
Filesystem label=
OS type: Linux
Block size=4096 (log=2)
Fragment size=4096 (log=2)
Stride=0 blocks, Stripe width=0 blocks
327680 inodes, 1310720 blocks
65536 blocks (5.00%) reserved for the super user
First data block=0
Maximum filesystem blocks=1342177280
40 block groups
32768 blocks per group, 32768 fragments per group
8192 inodes per group
Superblock backups stored on blocks:
        32768, 98304, 163840, 229376, 294912, 819200, 884736

Writing inode tables: done
Creating journal (32768 blocks): done
Writing superblocks and filesystem accounting information: done

This filesystem will be automatically checked every 33 mounts or
180 days, whichever comes first.  Use tune2fs -c or -i to override.
[root@DEV-L002102 VGapp_d1aims]# mkfs -t ext4 /dev/VGapp_d1aims/LV_d1aims_rdbms
mke2fs 1.41.12 (17-May-2010)
Filesystem label=
OS type: Linux
Block size=4096 (log=2)
Fragment size=4096 (log=2)
Stride=0 blocks, Stripe width=0 blocks
3276800 inodes, 13107200 blocks
655360 blocks (5.00%) reserved for the super user
First data block=0
Maximum filesystem blocks=4294967296
400 block groups
32768 blocks per group, 32768 fragments per group
8192 inodes per group
Superblock backups stored on blocks:
        32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208,
        4096000, 7962624, 11239424

Writing inode tables: done
Creating journal (32768 blocks): done
Writing superblocks and filesystem accounting information: done

This filesystem will be automatically checked every 29 mounts or
180 days, whichever comes first.  Use tune2fs -c or -i to override.
[root@DEV-L002102 VGapp_d1aims]# mkfs -t ext4 /dev/VGapp_d1aims/LV_d1aims_data01
mke2fs 1.41.12 (17-May-2010)
Filesystem label=
OS type: Linux
Block size=4096 (log=2)
Fragment size=4096 (log=2)
Stride=0 blocks, Stripe width=0 blocks
13107200 inodes, 52428800 blocks
2621440 blocks (5.00%) reserved for the super user
First data block=0
Maximum filesystem blocks=4294967296
1600 block groups
32768 blocks per group, 32768 fragments per group
8192 inodes per group
Superblock backups stored on blocks:
        32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208,
        4096000, 7962624, 11239424, 20480000, 23887872

Writing inode tables: done
Creating journal (32768 blocks): done
Writing superblocks and filesystem accounting information: done

This filesystem will be automatically checked every 31 mounts or
180 days, whichever comes first.  Use tune2fs -c or -i to override.
[root@DEV-L002102 VGapp_d1aims]# mkfs -t ext4 /dev/VGapp_d1aims/LV_d1aims_log
mke2fs 1.41.12 (17-May-2010)
Filesystem label=
OS type: Linux
Block size=4096 (log=2)
Fragment size=4096 (log=2)
Stride=0 blocks, Stripe width=0 blocks
3276800 inodes, 13107200 blocks
655360 blocks (5.00%) reserved for the super user
First data block=0
Maximum filesystem blocks=4294967296
400 block groups
32768 blocks per group, 32768 fragments per group
8192 inodes per group
Superblock backups stored on blocks:
        32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208,
        4096000, 7962624, 11239424

Writing inode tables: done
Creating journal (32768 blocks): done
Writing superblocks and filesystem accounting information: done

This filesystem will be automatically checked every 32 mounts or
180 days, whichever comes first.  Use tune2fs -c or -i to override.
[root@DEV-L002102 VGapp_d1aims]#
[root@DEV-L002102 VGapp_d1aims]#
[root@DEV-L002102 VGapp_d1aims]#
[root@DEV-L002102 VGapp_d1aims]#
[root@DEV-L002102 VGapp_d1aims]#
[root@DEV-L002102 VGapp_d1aims]# umask 0022
[root@DEV-L002102 VGapp_d1aims]# mkdir -p /paic/d1aims/rdbms
[root@DEV-L002102 VGapp_d1aims]# mkdir -p /paic/d1aims/data01
[root@DEV-L002102 VGapp_d1aims]# mkdir -p /paic/d1aims/log
[root@DEV-L002102 VGapp_d1aims]# mkdir -p /paic/app/d1aims
[root@DEV-L002102 VGapp_d1aims]#
[root@DEV-L002102 VGapp_d1aims]# chmod 755 /paic/d1aims/rdbms
[root@DEV-L002102 VGapp_d1aims]# chmod 755 /paic/d1aims/data01
[root@DEV-L002102 VGapp_d1aims]# chmod 755 /paic/d1aims/log
[root@DEV-L002102 VGapp_d1aims]# chmod 755 /paic/app/d1aims
[root@DEV-L002102 VGapp_d1aims]#
[root@DEV-L002102 VGapp_d1aims]#
[root@DEV-L002102 VGapp_d1aims]#
[root@DEV-L002102 VGapp_d1aims]# ls
LV_d1aims_app  LV_d1aims_data01  LV_d1aims_log  LV_d1aims_rdbms
[root@DEV-L002102 VGapp_d1aims]# pwd
/dev/VGapp_d1aims
[root@DEV-L002102 VGapp_d1aims]# cd /etc/
[root@DEV-L002102 etc]# vi fstab


#
# /etc/fstab
# Created by anaconda on Wed Nov  6 01:35:51 2013
#
# Accessible filesystems, by reference, are maintained under '/dev/disk'
# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info
#
/dev/mapper/Volgroup00-LV_root /                       ext4    defaults        1 1
UUID=336e9ba5-c3b5-4f8c-909c-bd600e6407c9 /boot                   ext4    defaults        1 2
/dev/VGapp_d1aims/LV_d1aims_app /paic/app/d1aims    ext4    defaults        1 2
/dev/VGapp_d1aims/LV_d1aims_rdbms /paic/d1aims/rdbms    ext4    defaults        1 2
/dev/VGapp_d1aims/LV_d1aims_log /paic/d1aims/log    ext4    defaults        1 2
/dev/VGapp_d1aims/LV_d1aims_data01 /paic/d1aims/data01    ext4    defaults        1 2
/dev/mapper/Volgroup00-LV_swap swap                    swap    defaults        0 0
tmpfs                   /dev/shm                tmpfs   defaults        0 0
devpts                  /dev/pts                devpts  gid=5,mode=620  0 0
sysfs                   /sys                    sysfs   defaults        0 0
proc                    /proc                   proc    defaults        0 0
~
~
~
~
~
~
~
~
~
~
~
~
~
~
~
~
~
~
~
"fstab" 19L, 1113C written
[root@DEV-L002102 etc]# mount -a
[root@DEV-L002102 etc]# df -h
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/Volgroup00-LV_root
                       16G   11G  4.2G  72% /
tmpfs                 7.8G     0  7.8G   0% /dev/shm
/dev/sda1             194M   32M  152M  18% /boot
/dev/mapper/VGapp_d1aims-LV_d1aims_app
                      5.0G  138M  4.6G   3% /paic/app/d1aims
/dev/mapper/VGapp_d1aims-LV_d1aims_rdbms
                       50G  180M   47G   1% /paic/d1aims/rdbms
/dev/mapper/VGapp_d1aims-LV_d1aims_log
                       50G  180M   47G   1% /paic/d1aims/log
/dev/mapper/VGapp_d1aims-LV_d1aims_data01
                      197G  188M  187G   1% /paic/d1aims/data01
[root@DEV-L002102 etc]#



















我以前测试做的笔记，希望对lz有用：
1. 主备数据库的切换：

  主库查询
  select switchover_status from v$database ;

  = to_standby 可以切换
  = session active

2.将主数据库转换为备库。
  alter database commit to switchover to physical standby ;

  当= session active 时：

  alter database commit to switchover to physical standby with session shutdown ;

3.关闭主库，以备库启动：
  shutdown immediate ;
  startup mount ;

4. 在备库上查询：
  select switchover_status from v$database ;
  = to_primary  可以切换为主库。
  = not allowed 表示不能切换。
  = session shutdown

5. 将备库转换为主库:

  alter database commit to switchover to primary ;

  当= session active 时：

  alter database commit to switchover to primary  with session shutdown ;

6.关闭备库，以主库启动：
  shutdown immediate ;
  startup mount ;



通过故障切换实现角色转换：

1。查询获得没有完成的日志：
select * from v$archive_gap

2。在备用数据库上对归档日志注册：

alter datasbe register physical logfile 'foo.arc';

3. 在备用数据库上通过带finish 关键字的管理恢复命令来执行恢复：
如果有备用重做日子，并且处于激活状态：
alter database recover managed standby database finish ;
如果没有备用重做日子，或者没有处于激活状态：
alter database recover managed standby database finish skip standby logfile  ;

4. 切换备用数据库为主数据库
alter database commit to switchover to primary ;




CREATE OR REPLACE TRIGGER DBMGR.TRG_RESTICT_EXP_TOADEXP
   AFTER LOGON
   ON toadexp.SCHEMA
DECLARE
   v_systime   VARCHAR2 (30);
   n_hour      NUMBER (2);
   v_count     VARCHAR2 (50);
BEGIN
   SELECT TO_CHAR (SYSDATE, 'YYYY-MM-DD HH24:MI') INTO v_systime FROM DUAL;

   SELECT COUNT (*)
     INTO v_count
     FROM v$session
    WHERE username = 'TOADEXP' AND program LIKE 'exp%';

   n_hour := TO_NUMBER (SUBSTR (v_systime, 12, 2));

   IF (n_hour >= 8 AND n_hour <= 20 AND v_count > 0)
   THEN
      RAISE_APPLICATION_ERROR (-20001, '8点-21点不允许做导出!');
   END IF;
END;


CREATE OR REPLACE TRIGGER DBMGR.TR_DDL_RESTRICTION_GACREPT
   BEFORE CREATE OR ALTER OR DROP
   ON GACREPT.SCHEMA
DECLARE
   v_day    VARCHAR2 (3);                                       ---Day of week
   v_time   VARCHAR2 (4);                                              ---time
BEGIN
   SELECT TO_CHAR (SYSDATE, 'd') INTO v_day FROM DUAL;

   SELECT TO_CHAR (SYSDATE, 'hh24mi') INTO v_time FROM DUAL;

   --not Saturday and not Sunday
   IF UPPER (TRIM (v_day)) <> '7' AND UPPER (TRIM (v_day)) <> '1'
   THEN
      IF '0800' <= v_time AND v_time <= '1800'
      THEN
         IF    DICTIONARY_OBJ_TYPE = 'TABLE'
            OR DICTIONARY_OBJ_TYPE = 'VIEW'
            OR DICTIONARY_OBJ_TYPE = 'INDEX'
            OR DICTIONARY_OBJ_TYPE = 'SYNONYM'
            OR DICTIONARY_OBJ_TYPE = 'FUNCTION'
            OR DICTIONARY_OBJ_TYPE = 'PROCEDURE'
            OR DICTIONARY_OBJ_TYPE = 'PACKAGE'
            OR DICTIONARY_OBJ_TYPE = 'PACKAGE BODY'
            OR DICTIONARY_OBJ_TYPE = 'OBJECT PRIVILEGE'
         THEN
            raise_application_error (
               -20908,
                  DICTIONARY_OBJ_TYPE
               || ':Can not do DDL operation in LBS production database now!');
         END IF;
      END IF;
   END IF;
END;




oracle队列
概念：
高级队列（Advanced Queue，简称AQ）:
高级队列是oracle的一种高级应用,它主要是表和触发器之间的组合而成的一种应用。其主要作用是在各应用系统中进行消息传递。
目的：
利用高级队列来实现消息在两个不同数据库之间的异步传输，满足业务系统的改造需求。
基本环境：
DB1：Oracle 10g Version 10.2.0.4.0
DB2：Oracle 10g Version 10.2.0.4.0
基本组成：
发送方（DB1）：
Queue type：决定发送消息的类型
Queue table：消息发送的载体
Queue：队列
Subscriber：订购者，同一个队列可以有n个订购者
Propagation：传播进程
接收方（DB2）：
Queue type：决定接收消息的类型
Queue table：消息接收的载体
Queue：队列
发送方（DB1）代码：
1.创建aq用户并赋权
--sys用户操作，其他操作为aq用户
create user aq identified by aq;
grant connect,resource,aq_administrator_role,unlimited tablespace to aq;
grant create database link to aq;
grant execute on dbms_aq to aq;
grant execute on dbms_aqadm to aq;

begin
dbms_aqadm.grant_system_privilege('ENQUEUE_ANY', 'aq', FALSE);
dbms_aqadm.grant_system_privilege('DEQUEUE_ANY', 'aq', FALSE);
end;
/

begin
dbms_aqadm.revoke_system_privilege('ENQUEUE_ANY', 'aq');
dbms_aqadm.revoke_system_privilege('DEQUEUE_ANY', 'aq');
end;
/

2.创建db link
create database link db2.LK connect to AQ using db2;
确认dblink有效。
3.创建type
CREATE type aq.Message_typ as object (
subject      VARCHAR2(30),
text         VARCHAR2(80));
可根据自己的需求决定具体字段。
4.创建queue
DECLARE
   subscriber sys.aq$_agent;
BEGIN
   --根据type创建queue table
   DBMS_AQADM.CREATE_QUEUE_TABLE(queue_table         => 'aq.que_shenshou_tab',
                                 multiple_consumers => TRUE,
                                 queue_payload_type => 'aq.Message_typ');
   --根据queue table创建queue
   DBMS_AQADM.CREATE_QUEUE(queue_name   => 'aq.que_shenshou',
                           queue_table => 'aq.que_shenshou_tab');
   --开始这个queue
   DBMS_AQADM.START_QUEUE(queue_name => 'aq.que_shenshou');
   --添加一个subscriber
   --这里可以添加n个subscriber，每个subscriber相当于一个独立的通道
   --这里shenshou1为consumer name，接收端要根据这个名字来决定出队
   --aq.que_shenshou@db2.Lk为接收端（db2）上的queue名和dblink的组合
   subscriber := sys.aq$_agent('shenshou1', 'aq.que_shenshou@db2.lk', NULL);
   DBMS_AQADM.ADD_SUBSCRIBER(queue_name => 'que_shenshou',
                             subscriber => subscriber);
   --创建propagation
   DBMS_AQADM.SCHEDULE_PROPAGATION(queue_name   => 'que_shenshou',
                                   destination => 'db2.lk');
END;
至此，发送端队列创建完毕。
可通过以下视图查看：
select * from user_queue_tables;
select * from user_queues;
select * from user_queue_subscribers;
select * from user_queue_schedules;



http://tahiti.oracle.com/pls/db92/homepage
9i refrence  doc

10g refrence  doc
http://www.oracle.com/pls/db102/homepage

11g refrence  doc
http://docs.oracle.com/cd/E11882_01/index.htm





MySQL表锁情况

mysql> show global status like 'table_locks%';
+-----------------------+-----------+
| Variable_name | Value |
+-----------------------+-----------+
| Table_locks_immediate | 490206328 |
| Table_locks_waited | 2084912 |
+-----------------------+-----------+
Table_locks_immediate表示立即释放MySQL表锁数，Table_locks_waited表示需要等待的MySQL表锁数，如果Table_locks_immediate / Table_locks_waited > 5000，最好采用InnoDB引擎，因为InnoDB是行锁而MyISAM是MySQL表锁，对于高并发写入的应用InnoDB效果会好些。示例中的服务器Table_locks_immediate / Table_locks_waited = 235，MyISAM就足够了。

在MySQL数据库中，我们需要根据数据库的状态调整一些系统参数，下面为您介绍的是MySQL表锁情况和文件打开数的调整方法，供您参考。

文件打开数(open_files)

mysql> show global status like 'open_files';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| Open_files | 1410 |
+---------------+-------+
mysql> show variables like 'open_files_limit';
+------------------+-------+
| Variable_name | Value |
+------------------+-------+
| open_files_limit | 4590 |
+------------------+-------+
比较合适的设置：Open_files / open_files_limit * 100%


[padep@cnsz081003 trustdw]$ dscp padba@g3ah1020:/paic/xt/trustdw/data/oradata/trustdw/* padba@z4ah8020:/paic/xt/t0tdw/data/oradata/t0tdw >data.out 2>&1 &
[1] 26051
[padep@cnsz081003 trustdw]$ dscp padba@g3ah1020:/paic/xt/trustdw/data1/oradata/trustdw/* padba@z4ah8020:/paic/xt/t0tdw/data1/oradata/t0tdw >data1.out 2>&1 &
[2] 29306
[padep@cnsz081003 trustdw]$ ls -l
total 12
-rw-r--r-- 1 padep usr03 1679 Jul 16 17:02 data1.out
-rw-r--r-- 1 padep usr03 6160 Jul 16 17:02 data.out



Step 4 : (作者 ZHANGJIE982 variationId:2909393)
特殊操作:mongodb脚本移交
mongo js脚本执行方法：
执行命令
./mongo ip:port/admin -u admin –p **** /path/to/script/SR_181060_01_ucms_chanxian_wangcong189.js
注:
ip:请用mongodb的ip代替
port:请用mongodb的port代替
****:请用mongodb的password代替

然后确认脚本执行结果输出，及返回是否SUCCESS



[padba@cnsh040434 ~]$ 2012GtMa
[padba@cnsh040434 ~]$ mima  password
[padba@cnsh040434 ~]$





 RAC环境单实例启动数据库收到ORA-29702报错 2013-04-02 16:36:03
分类： Linux

         在RAC环境中，如果你在没有启动节点的集群服务的情况下单实例启动数据库，将收到类似如下的报错：
[oracle@rhel1 u01]$ sql

SQL*Plus: Release 10.2.0.5.0 - Production on Tue Apr 2 15:00:27 2013

Copyright (c) 1982, 2010, Oracle.  All Rights Reserved.

Connected to an idle instance.

SQL> startup nomount
ORA-29702: error occurred in Cluster Group Service operation

        数据库实例无法启动，要求先启动CGS服务，原因可以大概从下面这篇METALINK文章中知道：
AIX: ORA-29702 When Creating A Single Instance Database In A Clustered Environment [ID 198901.1]
修改时间:2010-10-19类型:PROBLEM状态:PUBLISHED优先级:2

Problem Description
-------------------

When starting up a single instance on aan AIX clustered environment, the
following error is reported:

Error:	ORA-29702
Text:	error occurred in Cluster Group Service operation
---------------------------------------------------------------------------
Cause:	An unexpected error occurred while performing a CGS operation.
Action:	Verify that the LMON process is still active. Also, check the Oracle
	LMON trace files for errors.


Solution Description
--------------------

1) reinstall Oracle software by de-selecting Oracle Parallel Server option.
2) deinstall Oracle Parallel Server option and relink oracle kernel.

   It is possible to do it manually by entering the following commands:

   cd ORACLE_HOME/rdbms/lib
   make -f ins_rdbms.mk no_parropt or make -f ins_rdbms.mk ops_off
   make -f ins_rdbms.mk install


Explanation
-----------

High Availability Group Services (HAGS) is not configured .
When creating a single instance database in a clustered environment, if you
have a cluster software installed, then OUI detects it and installs Oracle
Parallel Server option by default.


Additional Search Words
-----------------------

ORA-29702, startup, start up, create

        从上面的文章，大概知道是由于Oracle Database软件中的Oracle Parallel Server option引起的问题，解决办法是执行相关命令卸载Oracle Parallel Server Option，然后重新编译Oracle内核。
        这里用一个简单的办法，在RAC的节点上新安装一个单机版的Oracle Database软件，用它来单实例启动数据库，下面是例子：
[root@rhel1 bin]# su - oracle
[oracle@rhel1 ~]$ echo $ORACLE_HOME
/u01/app/oracle/db_2
        这是新安装的单机版Oracle软件HOME。
[oracle@rhel1 ~]$ sql

SQL*Plus: Release 10.2.0.5.0 - Production on Tue Apr 2 15:39:37 2013

Copyright (c) 1982, 2010, Oracle.  All Rights Reserved.

Connected to an idle instance.

SQL> startup nomount
ORACLE instance started.

Total System Global Area  432013312 bytes
Fixed Size                  2096824 bytes
Variable Size             125829448 bytes
Database Buffers          297795584 bytes
Redo Buffers                6291456 bytes
        启动实例前，先去掉和RAC相关的参数设置。

SQL> show parameter control

NAME                                 TYPE
------------------------------------ ----------------------
VALUE
------------------------------
control_file_record_keep_time        integer
7
control_files                        string
/u01/ractest/control01.ctl, /u
01/ractest/control02.ctl, /u01
/ractest/control03.ctl
SQL> alter database mount;

Database altered.
        注意对数据文件和在线Redo文件位置的调整。

SQL> alter database open;

Database altered.
        数据库正常启动。

        从这个例子可以猜想，如果将参数文件、控制文件、日志文件和数据文件拷贝到其他单机版数据库环境中也能正常的启动。








测试库stginvdw2中dml_trans_invest分区表降低高水位
该表中2014年的分区存在高水位问题，影响测试性能。
请帮忙把2014分区先备份，然后truncate该分区，然后恢复该分区。
stginvdw2= (description =(address = (protocol = tcp)(host = 10.31.10.93 )(port = 1542))(connect_data=(sid = stginvdw2)))

select * from dba_tables where table_name ='DML_TRANS_INVEST';

select dbms_metadata.get_ddl('TABLE','DML_TRANS_INVEST','INVDWCDATA') FROM DUAL;

select count(1) from INVDWCDATA.DML_TRANS_INVEST partition(PT_DML_TRANSACTION_DATE_2014)

PT_DML_TRANSACTION_DATE_2014


 alter table INVDWCDATA.DML_TRANS_INVEST truncate partition PT_DML_TRANSACTION_DATE_2014;

 PT_DML_TRANSACTION_DATE_2014


 select * from  DML_TRANS_INVEST as select * from INVDWCDATA.DML_TRANS_INVEST

 insert into INVDWCDATA.DML_TRANS_INVEST select * from DML_TRANS_INVEST
 where TRANSACTION_DATE <TO_DATE(' 2015-01-01 00:00:00', 'SYYYY-MM-DD HH24:MI:SS' ) and
 TRANSACTION_DATE >TO_DATE(' 2014-01-01 00:00:00', 'SYYYY-MM-DD HH24:MI:SS')

 select * from dba_indexes where table_name ='DML_TRANS_INVEST';
 alter index  INVDWCDATA.PK_DML_TRANS_INVEST rebuild online;

  select * from dba_part_indexes where table_name ='DML_TRANS_INVEST';

 select  count(1)  from DML_TRANS_INVEST
 where TRANSACTION_DATE <TO_DATE(' 2015-01-01 00:00:00', 'SYYYY-MM-DD HH24:MI:SS' ) and
 TRANSACTION_DATE >TO_DATE(' 2014-01-01 00:00:00', 'SYYYY-MM-DD HH24:MI:SS')

 PARTITION "PT_DML_TRANSACTION_DATE_2014"  VALUES LESS THAN (TO_DATE(' 2015-01-01 00:00:00', 'SYYYY-MM-DD HH24:MI:SS', 'NLS_CALENDAR=GREGORIAN'))
PCTFREE 10 PCTUSED 40 INITRANS 1 MAXTRANS 255




create database error：

SQL>   2    3    4    5    6    7    8    9   10   11   12   13   14   15   16   17   18  CREATE DATABASE d1lucs0
*
ERROR at line 1:
ORA-30014: operation only supported in Automatic Undo Management mode






昨天我从9i R2里导出了几张表，然后导入到11g R2中，在导入成功后我要收集下这些表的信息，结果发现好几张表都没法收集，用DBMS_STATS包显示ORA-20005：object statistics are locked (stattype = ALL)，用Analyze命令显示ORA-38029： 对象统计信息已锁定。

解决办法很明确，就是解锁。
可以从两个层面去处理：
A、解锁Schema
DBMS_STATS.UNLOCK_schema_STATS(user);

B、解锁单个对象
1)先查出被锁定的表select table_name from user_tab_statistics where stattype_locked is not null;
然后再解锁对象
exec dbms_stats.unlock_table_stats(user,'表名');
2)也可直接生成sql脚本
select 'exec dbms_stats.unlock_table_stats('''||user||''','''||table_name||''');' from user_tab_statistics where stattype_locked is not null;
这里不在生成的sql中用动态的user是为了让执行者明确知道到底是解锁哪个schema下的表，防止误操作。


不过，你要特别注意，Oracle为什么会要锁定住统计信息？
一般而言，这是为了稳定执行计划，因为在Oracle 10g以上，Oracle默认会自动收集统计信息，要想锁住统计信息，请使用LOCK_SCHEMA_STATS、LOCK_TABLE_STATS包。


在 Oracle 8i 及以前的版本，可通过对语句执行explain plan后，使用下述查询获得其执行计划：
select /*+ no_merge */
       rpad('| '||substr(lpad(' ',1*(level-1))||operation||
            decode(options, null,'',' '||options), 1, 40), 41, ' ')||'|'||
       lpad(' ',1*(level-1))||object_name   as "Explain plan"
from plan_table
start with id=0
and timestamp = (select max(timestamp) from plan_table
                                 where id=0)
connect by prior id = parent_id
        and prior nvl(statement_id, ' ') = nvl(statement_id, ' ')
        and prior timestamp <= timestamp
order by id, position
/




查看实时执行计划
前提：该语句的执行计划尚在 COL_5d pool 中，即，该语句尚未 age out或是invalidate等。
优点：为该语句的实际执行计划
select '| Operation                         | PHV/Object Name                    |  Rows | Bytes|   Cost |'
as "Optimizer Plan:" from dual
union all
select
    rpad('| '||substr(lpad(' ',1*(depth-1))||operation||
     decode(options, null,'',' '||options), 1, 35), 36, ' ')||'|'||
  rpad(decode(id, 0, '---------------------------------- '
    , substr(decode(substr(object_name, 1, 7), 'SYS_LE_', null, object_name)
       ||' ',1, 35)), 36, ' ')||'|'||
   lpad(decode(cardinality,null,'  ',
      decode(sign(cardinality-1000), -1, cardinality||' ',
      decode(sign(cardinality-1000000), -1, trunc(cardinality/1000)||'K',
      decode(sign(cardinality-1000000000), -1, trunc(cardinality/1000000)||'M',
      trunc(cardinality/1000000000)||'G')))), 7, ' ') || '|' ||
  lpad(decode(bytes,null,' ',
    decode(sign(bytes-1024), -1, bytes||' ',
    decode(sign(bytes-1048576), -1, trunc(bytes/1024)||'K',
       decode(sign(bytes-1073741824), -1, trunc(bytes/1048576)||'M',
         trunc(bytes/1073741824)||'G')))), 6, ' ') || '|' ||
    lpad(decode(cost,null,' ', decode(sign(cost-10000000), -1, cost||' ',
                decode(sign(cost-1000000000), -1, trunc(cost/1000000)||'M',
                       trunc(cost/1000000000)||'G'))), 8, ' ') || '|' as "Explain plan"
from v$sql_plan sp
where sp.hash_value=&sql_hash_value


set verify off
accept username char prompt 'username:'
accept passwd prompt 'new password of this user: ' hide
alter user &username identified by &passwd;


select 'exec prc_kill_session('''||username||''','''||sid||''','''||serial#||''');' from v$session where sql_id=’4u4czz8wcq8cj’;


显示explain plan 后存于plan_table 中的信息，与9i第二种方法相似
SET LINESIZE 130
SET PAGESIZE 0
SELECT * FROM table(DBMS_XPLAN.DISPLAY);
2.14.3.2显示当前内存中的执行计划的信息 ，与9i第一种方法相似
SELECT * FROM table(DBMS_XPLAN.DISPLAY_CURSOR(('sql_id',child_number));
其中 sql_id 与child_number 可从 v$sql 中查出。
2.14.3.3显示awr 中存放的历史的执行计划
SELECT * FROM table(DBMS_XPLAN.DISPLAY_AWR('sql_id'));
其中 sql_id可从 v$sql 中查出。
其会显示该 sql_id 的所有执行计划。
也可通过：
SELECT * FROM table(DBMS_XPLAN.DISPLAY_AWR('sql_id'，’plan_hash_value’));
来从 awr 历史记录中查看某一执行计划的具体内容。
Plan_hash_value 可从 v$sql 中获得。



-----------EPCISUDWR.CAIU_FACT_POLICY_BY_MONTH-----------
BEGIN
DBMS_STATS.GATHER_TABLE_STATS(OWNNAME => 'EPCISUDWR',
TABNAME => 'CAIU_FACT_POLICY_BY_MONTH',
ESTIMATE_PERCENT => 5,
METHOD_OPT => 'FOR ALL COLUMNS SIZE 1',
DEGREE => 6,
GRANULARITY => 'ALL',
CASCADE => TRUE,
NO_INVALIDATE => FALSE);
END;
/

DECLARE
V_COUNT NUMBER;
BEGIN
Select Num_Rows
 Into  v_Count
 From Dba_Tables
Where Owner = 'EPCISUDWR'
 And Table_Name = 'CAIU_FACT_POLICY_BY_MONTH';
 If v_Count = 0 Then
Dbms_Stats.Delete_Table_Stats(Ownname         => 'EPCISUDWR',
Tabname         => 'CAIU_FACT_POLICY_BY_MONTH',
Cascade_Columns => True,
Cascade_Indexes => True);
End If;
End;
/

DECLARE
V_COUNT NUMBER;
begin
 for i in(select * from dba_tab_partitions
         where table_owner='EPCISUDWR'
         and Table_Name='CAIU_FACT_POLICY_BY_MONTH') loop
Select  Num_Rows
 Into  v_Count
 From dba_tab_partitions
 Where table_owner ='EPCISUDWR'
 And Table_Name = 'CAIU_FACT_POLICY_BY_MONTH'
 And partition_name=i.partition_name;
 if v_Count = 0 Then
 Dbms_Stats.Delete_Table_Stats(Ownname=>'EPCISUDWR',
Tabname=> 'CAIU_FACT_POLICY_BY_MONTH' ,
Partname => i.partition_name,
Cascade_Columns => True,
Cascade_Indexes => True,
Cascade_Parts   => True);
End If;
 end loop ;
 end;
/




查看alert 日志

上周去巡检.结果一个用户问我如何使用sql语句来查看alert日志中的内容. 当时想着用存储过程来做.回来后想了想,用external测试一下看看:
SQL> !pwd
/u01/app/oracle/admin/ORALINUX/bdump
create directory BDUMP as '/u01/app/oracle/admin/ORALINUX/bdump';

SQL> !ls
ALERT_LOG_3220.bad alert_ORALINUX.log oralinux_lgwr_3202.trc oralinux_lgwr_7056.trc
ALERT_LOG_3220.log oralinux_lgwr_3123.trc oralinux_lgwr_6993.trc oralinux_pmon_7048.trc
create table alert_log ( text varchar2(80) )
organization external (
type oracle_loader
default directory BDUMP
access parameters (
records delimited by newline
)
location('alert_ORALINUX.log')
)
reject limit 1000;
SQL> select * from alert_log where text like '%ORA-%';
TEXT
--------------------------------------------------------------------------------
ORA-1109 signalled during: ALTER DATABASE CLOSE NORMAL...
ORA-00313: open failed for members of log group 1 of thread 1
ORA-00312: online log 1 thread 1: '/u02/oradata/ORALINUX/redo01.log'
ORA-27037: unable to obtain file status
ORA-00313: open failed for members of log group 2 of thread 1
ORA-00312: online log 2 thread 1: '/u02/oradata/ORALINUX/redo02.log'
ORA-27037: unable to obtain file status
ORA-00313: open failed for members of log group 3 of thread 1
ORA-00312: online log 3 thread 1: '/u02/oradata/ORALINUX/redo03.log'
ORA-27037: unable to obtain file status



Script:利用外部表实现SQL查询Oracle告警日志Alert.log
2011/11/10 BY MACLEAN LIU 6条评论
有同学问是否可以用SQL语句直接查询告警日志的内容，即创建一张包含Alert.log内容的表或视图。 实际上之前已经有人这样做了(http://t.cn/SwGvq9)，只需要运行一个存储过程即可达到目的， 这里我对原有的语句做了一些改良， 直接执行PL/SQL块即可无需创建存储过程了，而且现在支持RAC了。

--drop table alert_log_view;
--drop directory bdump;

declare
  path_bdump varchar2(4000);
  name_alert varchar2(4000);
  ins_name   varchar2(200);
begin

  select value
    into path_bdump
    from sys.v_$parameter
   where name = 'background_dump_dest';
  select 'alert_' || value || '.log'
    into name_alert
    from sys.v_$parameter
   where name = 'instance_name';

  select value
    into ins_name
    from sys.v_$parameter
   where name = 'instance_number';

  if ins_name = '0' then
    ins_name := '';
  end if;

  execute immediate 'create or replace directory bdump'||ins_name||' as ''' || path_bdump || '''';
  execute immediate 'create table ALERT_LOG_VIEW' || ins_name ||
                    '  (MSG_line varchar2(4000)   ) ' ||
                    ' organization external ' || ' (type oracle_loader ' ||
                    ' default directory bdump' || ins_name ||
                    ' access parameters ( ' ||
                    ' records delimited by newline ' || ' nobadfile ' ||
                    ' nologfile ' || ' nodiscardfile ' || ' skip 0 ' ||
                    ' READSIZE 10485760 ' || ' FIELDS LDRTRIM ' ||
                    ' REJECT ROWS WITH ALL NULL FIELDS ' ||
                    ' (MSG_LINE (1:1000) CHAR(1000)) ' || ' ) ' ||
                    ' location (''' || name_alert || ''') )' ||
                    ' reject limit unlimited ' ||
                    ' noparallel nomonitoring ';

end;
/

执行以上PL/SQL代码，会创建名为bdump$SID的目录 和ALERT_LOG_VIEW$SID的外部表(如RAC中的1号实例PROD1，则为ALERT_LOG_VIEW1,单实例single instance则为 ALERT_LOG_VIEW)， 需要时直接查询ALERT_LOG_VIEW即可，譬如要从告警信息中找出最近三天ORA-错误的记录:

col lineno noprint
col ora_error noprint
col msg_line format a132
set pages 0 lines 300 trimspool on trim on
alter session set nls_date_language = 'american';
alter session set nls_date_format='dd/mm/yyyy hh24:mi:ss';
alter session set sql_trace=false;
break on thedate
prompt
prompt ERROR IN ALERT LOG FILE - LAST 3 DAYS
prompt =====================================
select "LINENO", "THEDATE", "ORA_ERROR", "MSG_LINE"
  from (select *
          from (select lineno,
                       msg_line,
                       thedate,
                       max(case
                             when (ora_error like 'ORA-%' or
                                  ora_error like 'PLS-%') then
                              rtrim(substr(ora_error, 1, instr(ora_error, ' ') - 1),
                                    ':')
                             else
                              null
                           end) over(partition by thedate) ora_error
                  from (select lineno,
                               msg_line,
                               max(thedate) over(order by lineno) thedate,
                               lead(msg_line) over(order by lineno) ora_error
                          from (select rownum lineno,
                                       substr(msg_line, 1, 132) msg_line,
                                       case
                                         when msg_line like
                                              '___ ___ __ __:__:__ ____' then
                                          to_date(msg_line,
                                                  'Dy Mon DD hh24:mi:ss yyyy')
                                         else
                                          null
                                       end thedate
                                  from ALERT_LOG_VIEW))))
 where ora_error is not null
   and thedate >= (trunc(sysdate) - 3)
 order by thedate

示例输出

10/11/2011 03:15:49 Thu Nov 10 03:15:49 2011
                    Errors in file /s01/orabase/diag/rdbms/vprod/VPROD1/trace/VPROD1_ora_5547.trc  (incident=11105):
                    ORA-00700: soft internal error, arguments: [kgerev1], [600], [600], [700], [], [], [], [], [], [], [], []
                    Incident details in: /s01/orabase/diag/rdbms/vprod/VPROD1/incident/incdir_11105/VPROD1_ora_5547_i11105.trc
                    Errors in file /s01/orabase/diag/rdbms/vprod/VPROD1/trace/VPROD1_ora_5547.trc  (incident=11106):
                    ORA-00600: internal error code, arguments: [], [], [], [], [], [], [], [], [], [], [], []
                    Incident details in: /s01/orabase/diag/rdbms/vprod/VPROD1/incident/incdir_11106/VPROD1_ora_5547_i11106.trc
10/11/2011 03:15:52 Thu Nov 10 03:15:52 2011
                    Dumping diagnostic data in directory=[cdmp_20111110031552], requested by (instance=1, osid=5547), summary=[incident=11105].


以下脚本用于生成创建表的DDL语句,需要用到DBMS_METADATA.GET_DDL：
-- How to use ddl.sql
-- Run ddl.sql on the sql*plus.
-- Login the sql*plus with apps user or dba user
-- Start ddl.sql, which will ask you table_name and table_owner that you're looking for.
-- It will generate tablename_ddl.txt

set long 1000000
SET PAGESIZE 3000
set lines 200
SET HEADING OFF
SET VERIFY OFF
SET FEEDBACK OFF
set echo on
set timing off
set wrap On

ACCEPT TABLE_NAME CHAR PROMPT 'Enter Table Name : '
ACCEPT TABLE_OWNER CHAR PROMPT 'Enter Table Owner : '

select DBMS_METADATA.GET_DDL('TABLE',OBJECT_NAME,OWNER)
FROM Dba_objects
where owner = UPPER('&TABLE_OWNER') and object_name = UPPER('&TABLE_NAME')
and object_type = 'TABLE'
union all
select dbms_metadata.GET_DEPENDENT_DDL ('COMMENT', TABLE_NAME, OWNER )
FROM (select table_name,owner
from Dba_col_comments
where owner = UPPER('&TABLE_OWNER')
and table_name = UPPER('&TABLE_NAME')
and comments is not null
union
select table_name,owner
from sys.Dba_TAB_comments
where owner = UPPER('&TABLE_OWNER')
and table_name = UPPER('&TABLE_NAME')
and comments is not null)
union all
select DBMS_METADATA.GET_DEPENDENT_DDL('INDEX',TABLE_NAME, TABLE_OWNER)
FROM (select table_name,table_owner
FROM Dba_indexes
where table_owner = UPPER('&TABLE_OWNER')
and table_name = UPPER('&TABLE_NAME')
and index_name not in (select constraint_name
from sys.Dba_constraints
where table_name = table_name
and constraint_type = 'P' )
and rownum = 1)
union all
select dbms_metadata.GET_DDL ('TRIGGER', trigger_name ,owner )
from Dba_triggers
where table_owner = UPPER('&TABLE_OWNER')
and table_name = UPPER('&TABLE_NAME')
.
SET CONCAT +
spool &TABLE_NAME+_ddl.txt
/
spool off

Sample output:
SQL> @ddl
SQL> set timing off
SQL> set wrap On
SQL>
SQL> ACCEPT TABLE_NAME CHAR PROMPT 'Enter Table Name : '
Enter Table Name : TAB$
SQL> ACCEPT TABLE_OWNER CHAR PROMPT 'Enter Table Owner : '
Enter Table Owner : SYS
SQL>
SQL> select DBMS_METADATA.GET_DDL('TABLE',OBJECT_NAME,OWNER)
  2  FROM Dba_objects
  3  where owner = UPPER('&TABLE_OWNER') and object_name = UPPER('&TABLE_NAME')
  4  and object_type = 'TABLE'
  5  union all
  6  select dbms_metadata.GET_DEPENDENT_DDL ('COMMENT', TABLE_NAME, OWNER )
  7  FROM (select table_name,owner
  8  from Dba_col_comments
  9  where owner = UPPER('&TABLE_OWNER')
 10  and table_name = UPPER('&TABLE_NAME')
 11  and comments is not null
 12  union
 13  select table_name,owner
 14  from sys.Dba_TAB_comments
 15  where owner = UPPER('&TABLE_OWNER')
 16  and table_name = UPPER('&TABLE_NAME')
 17  and comments is not null)
 18  union all
 19  select DBMS_METADATA.GET_DEPENDENT_DDL('INDEX',TABLE_NAME, TABLE_OWNER)
 20  FROM (select table_name,table_owner
 21  FROM Dba_indexes
 22  where table_owner = UPPER('&TABLE_OWNER')
 23  and table_name = UPPER('&TABLE_NAME')
 24  and index_name not in (select constraint_name
 25  from sys.Dba_constraints
 26  where table_name = table_name
 27  and constraint_type = 'P' )
 28  and rownum = 1)
 29  union all
 30  select dbms_metadata.GET_DDL ('TRIGGER', trigger_name ,owner )
 31  from Dba_triggers
 32  where table_owner = UPPER('&TABLE_OWNER')
 33  and table_name = UPPER('&TABLE_NAME')
 34  .
SQL> SET CONCAT +
SQL> spool &TABLE_NAME+_ddl.txt
SP2-0332: Cannot create spool file.
SQL> /


  CREATE TABLE "SYS"."TAB$"
   (    "OBJ#" NUMBER NOT NULL ENABLE,
        "DATAOBJ#" NUMBER,
        "TS#" NUMBER NOT NULL ENABLE,
        "FILE#" NUMBER NOT NULL ENABLE,
        "BLOCK#" NUMBER NOT NULL ENABLE,
        "BOBJ#" NUMBER,
        "TAB#" NUMBER,
        "COLS" NUMBER NOT NULL ENABLE,
        "CLUCOLS" NUMBER,
        "PCTFREE$" NUMBER NOT NULL ENABLE,
        "PCTUSED$" NUMBER NOT NULL ENABLE,
        "INITRANS" NUMBER NOT NULL ENABLE,
        "MAXTRANS" NUMBER NOT NULL ENABLE,
        "FLAGS" NUMBER NOT NULL ENABLE,
        "AUDIT$" VARCHAR2(38) NOT NULL ENABLE,
        "ROWCNT" NUMBER,
        "BLKCNT" NUMBER,
        "EMPCNT" NUMBER,
        "AVGSPC" NUMBER,
        "CHNCNT" NUMBER,
        "AVGRLN" NUMBER,
        "AVGSPC_FLB" NUMBER,
        "FLBCNT" NUMBER,
        "ANALYZETIME" DATE,
        "SAMPLESIZE" NUMBER,
        "DEGREE" NUMBER,
        "INSTANCES" NUMBER,
        "INTCOLS" NUMBER NOT NULL ENABLE,
        "KERNELCOLS" NUMBER NOT NULL ENABLE,
        "PROPERTY" NUMBER NOT NULL ENABLE,
        "TRIGFLAG" NUMBER,
        "SPARE1" NUMBER,
        "SPARE2" NUMBER,
        "SPARE3" NUMBER,
        "SPARE4" VARCHAR2(1000),
        "SPARE5" VARCHAR2(1000),
        "SPARE6" DATE
   ) CLUSTER "SYS"."C_OBJ#" ("OBJ#")



  CREATE INDEX "SYS"."I_TAB1" ON "SYS"."TAB$" ("BOBJ#")
  PCTFREE 10 INITRANS 2 MAXTRANS 255 COMPUTE STATISTICS
  STORAGE(INITIAL 65536 NEXT 1048576 MINEXTENTS 1 MAXEXTENTS 2147483645
  PCTINCREASE 0 FREELISTS 1 FREELIST GROUPS 1 BUFFER_POOL DEFAULT)
  TABLESPACE "SYSTEM"



以下脚本可以用于列出相关模式或表上的Constraints约束:
---<tfsscons.sql begin>------------------------------------------------------
SET ECHO off
REM NAME: tfsscons.sql
REM USAGE:"@path/tfsscons"
REM --------------------------------------------------------------------------
REM REQUIREMENTS:
REM SELECT permissions on dba_constraints, dba_cons_columns and
REM    dba_ind_columns.
REM --------------------------------------------------------------------------

SET ARRAYSIZE 1
SET FEEDBACK off
SET SERVEROUT on
SET PAGESIZE 66
SET NEWPAGE 6
SET LINESIZE 75
SET PAUSE off
SET VERIFY off
ACCEPT puser PROMPT 'Enter the schema name: '
ACCEPT pexcp PROMPT 'Enter the EXCEPTIONS table name for schema &puser: '
PROMPT 'NOTE: This will take some time, please wait...'

SPOOL schema_cons_&puser
DECLARE
    CURSOR cons_cur (v_userid VARCHAR2) IS
      SELECT * FROM dba_constraints
      WHERE owner = v_userid
        AND constraint_type in ('P','U','C','R')
      ORDER BY constraint_type;
    CURSOR col_cur (con_name VARCHAR2, con_owner VARCHAR2) IS
      SELECT * FROM dba_cons_columns
      WHERE owner = con_owner
        AND constraint_name = con_name
      ORDER BY position;
    CURSOR indx_cur (con_name VARCHAR2, ind_own VARCHAR2) IS
      SELECT a.*
      FROM dba_indexes a, dba_ind_columns b, dba_cons_columns c
      WHERE c.constraint_name = con_name
        AND a.owner = ind_own
        AND b.index_owner = ind_own
        AND c.owner = b.index_owner
        AND c.position = 1
        AND c.table_name = b.table_name
        AND c.column_name = b.column_name
        AND b.index_name = a.index_name;
    col_str VARCHAR2(200);
    v_user      VARCHAR2(30) := UPPER('&puser');
    v_output    VARCHAR2(480);    -- max of 16 cols at 30 chars each
    v_excp      NUMBER(1) := 0;
    v_excptab   VARCHAR2(60) := NULL;
    v_delrule   VARCHAR2(4);
    v_status    VARCHAR2(4);
    srch_cond   VARCHAR2(1000);
    v_errcode   NUMBER := 0;
    v_errmsg    varchar2(50) := ' ';
BEGIN
  DBMS_OUTPUT.ENABLE(1000000);         -- Prevents buffer exceeded error
  BEGIN
    v_excptab := UPPER('&pexcp');
    IF v_excptab IS NOT NULL THEN
      SELECT 1
        INTO v_excp
      FROM dba_objects
      WHERE owner = UPPER('&puser')
        AND   object_name = UPPER('&pexcp');
      v_excptab := 'EXCEPTIONS INTO '||LOWER('&pexcp');
    END IF;
    EXCEPTION
    WHEN NO_DATA_FOUND THEN
    DBMS_OUTPUT.PUT_LINE('Exceptions table does not exist in the schema: ');
    RAISE NO_DATA_FOUND;
    GOTO err;
  END;
  FOR c1 IN cons_cur(v_user) LOOP
    begin
      srch_cond := substr(c1.search_condition,1,length(c1.search_condition));
      -- Dont remove table constraint NOT NULL
      IF (instr(srch_cond,'NOT NULL') < 1) or
        (instr(srch_cond,'NOT NULL') IS NULL) THEN
        BEGIN
          DBMS_OUTPUT.PUT_LINE('ALTER TABLE '||C1.OWNER||'.'||C1.TABLE_NAME);
          DBMS_OUTPUT.PUT_LINE('  ADD (CONSTRAINT '||C1.CONSTRAINT_NAME);

          IF c1.constraint_type = 'P' THEN v_output := '    PRIMARY KEY (';
          ELSIF c1.constraint_type = 'R' THEN v_output := '    FOREIGN KEY (';
          ELSIF c1.constraint_type = 'U' THEN v_output := '    UNIQUE (';
          ELSIF c1.constraint_type = 'C' THEN
            v_output := '    CHECK ('||c1.search_condition||') '||v_excptab;
          END IF;

          FOR c2 IN col_cur(c1.constraint_name, c1.owner) LOOP
            IF c2.position = 1 THEN
              v_output := v_output||c2.column_name;
            ELSIF c2.position > 1 THEN
              v_output := v_output||', '||c2.column_name;
            END IF;
          END LOOP;
          v_output := v_output||')';
          DBMS_OUTPUT.PUT_LINE(v_output);
          IF c1.constraint_type = 'R' THEN
            v_output := NULL;
            FOR c3 IN col_cur(c1.r_constraint_name, c1.r_owner) LOOP
              IF c3.position = 1 THEN
                v_output := '    REFERENCES '||c3.owner||'.'||c3.table_name||'(';
                v_output := v_output||c3.column_name;
              ELSIF c3.position > 1 THEN
                v_output := v_output||', '||c3.column_name;
              END IF;
            END LOOP;
            v_output := v_output||')';
            DBMS_OUTPUT.PUT_LINE(v_output);
            v_delrule := substr(c1.delete_rule,1,2);
            IF v_delrule IS NULL THEN v_output := v_excptab ||  ' )';
            ELSIF v_delrule = 'NO' THEN v_output :=  v_excptab || ' )';
            ELSIF v_delrule = 'CA' THEN v_output := ' ON DELETE CASCADE '||v_excptab || ')';
            END IF;
            DBMS_OUTPUT.PUT_LINE(v_output);
          END IF;

          FOR c4 IN indx_cur(c1.constraint_name, c1.owner) LOOP
            IF c1.constraint_type in ('P','U') THEN
              DBMS_OUTPUT.PUT_LINE(' USING INDEX ');
              DBMS_OUTPUT.PUT_LINE('   pctfree       '||c4.pct_free);
              DBMS_OUTPUT.PUT_LINE('   initrans      '||c4.ini_trans);
              DBMS_OUTPUT.PUT_LINE('   maxtrans      '||c4.max_trans);
              DBMS_OUTPUT.PUT_LINE('   tablespace    '||c4.tablespace_name);
              DBMS_OUTPUT.PUT_LINE(' Storage (');
              DBMS_OUTPUT.PUT_LINE('   initial        '||c4.initial_extent);
              DBMS_OUTPUT.PUT_LINE('   next           '||c4.next_extent);
              DBMS_OUTPUT.PUT_LINE('   minextents'||c4.min_extents);
              DBMS_OUTPUT.PUT_LINE('   maxextents     '||c4.max_extents);
              DBMS_OUTPUT.PUT_LINE('   pctincrease    '||c4.pct_increase||') '|| v_excptab ||')');
            END IF;
          END LOOP;

          v_output := NULL;
          v_status := substr(c1.status,1,1);
          IF v_status = 'E' THEN
            v_output := ' REM This constraint '||c1.constraint_name||' was ENABLED';
          ELSIF v_status = 'D' THEN
            v_output :=' REM This constraint '||c1.constraint_name ||' was DISABLED';
          END IF;
          DBMS_OUTPUT.PUT_LINE('/ ');
          DBMS_OUTPUT.PUT_LINE(v_output);
          DBMS_OUTPUT.PUT_LINE('-------------------------------------------- ');
          DBMS_OUTPUT.PUT_LINE('  ');
        END;
      END IF;
    EXCEPTION
    WHEN no_data_found THEN
      DBMS_OUTPUT.PUT_LINE('No Data Found');
    WHEN others THEN
      v_errcode := sqlcode;
      v_errmsg := SUBSTR(sqlerrm, 1, 50);
      DBMS_OUTPUT.PUT_LINE('ERROR: '||v_errcode||': ' || v_errmsg);
      DBMS_OUTPUT.PUT_LINE(c1.constraint_name||' '||c1.constraint_type);
      DBMS_OUTPUT.PUT_LINE(c1.search_condition);
    END;
  END LOOP;
  <<err>>
  NULL;
END;
/
SPOOL off
SET PAGESIZE 14
SET FEEDBACK on
SET NEWPAGE 0
SET ARRAYSIZE 20
SET SERVEROUT off
SET LINESIZE 79
SET VERIFY on
---<tfsscons.sql end>------------------------------------------------------

---<tfstcons.sql begin>------------------------------------------------------
SET ECHO off
REM NAME: tfstcons.sql
REM USAGE:"@path/tfstcons"
REM --------------------------------------------------------------------------
REM REQUIREMENTS:
REM    SELECT permissions on dba_constraints, dba_cons_columns and
REM    dba_ind_columns.
REM --------------------------------------------------------------------------

SET ARRAYSIZE 1
SET SERVEROUT on
SET PAGESIZE 66
SET NEWPAGE 6
SET LINESIZE 75
SET PAUSE off
SET VERIFY off
SET FEEDBACK off
ACCEPT puser PROMPT 'Enter the schema name: '
ACCEPT ptab  PROMPT 'Enter the table name: '
ACCEPT pexcp PROMPT 'Enter the EXCEPTIONS table name for schema &puser: '
PROMPT 'NOTE: This will take some time, please be patient...'

SPOOL tab_cons_&ptab
DECLARE
    CURSOR cons_cur (v_userid VARCHAR2, v_tabname VARCHAR2) IS
      SELECT * FROM sys.dba_constraints
      WHERE owner = v_userid
        AND constraint_type in ('P','U','C','R')
        AND table_name = v_tabname
      ORDER BY constraint_type;
    CURSOR col_cur (con_name VARCHAR2, con_owner VARCHAR2) IS
      SELECT * FROM sys.dba_cons_columns
      WHERE owner = con_owner
        AND constraint_name = con_name
      ORDER BY position;
    CURSOR indx_cur (con_name VARCHAR2, ind_own VARCHAR2) IS
      SELECT a.*
      FROM sys.dba_indexes a, sys.dba_ind_columns b, sys.dba_cons_columns c
      WHERE c.constraint_name = con_name
        AND a.owner = ind_own
        AND b.index_owner = ind_own
        AND c.owner = b.index_owner
        AND c.position = 1
        AND c.table_name = b.table_name
        AND c.column_name = b.column_name
        AND b.index_name = a.index_name;
    col_str     VARCHAR2(200);
    v_user      VARCHAR2(30) := UPPER('&puser');
    v_tabname   VARCHAR2(30) := UPPER('&ptab');
    v_output    VARCHAR2(480);    -- max of 16 cols at 30 chars each
    v_dummy     NUMBER := 0;
    v_delrule   VARCHAR2(4);
    v_status    VARCHAR2(4);
    v_excp      NUMBER(1) := 0;
    v_excptab   VARCHAR2(60) := NULL;
    srch_cond   VARCHAR2(1000);
BEGIN
  DBMS_OUTPUT.ENABLE(1000000);         -- Prevents buffer exceeded error

  SELECT 1                             -- Check to see if the table exists
  INTO v_dummy
  FROM dba_tables
  WHERE table_name = v_tabname
  AND   owner = v_user;
  BEGIN
    v_excptab := UPPER('&pexcp');
    IF v_excptab IS NOT NULL THEN
      SELECT 1
        INTO v_excp
      FROM sys.dba_objects
      WHERE owner = UPPER('&puser')
        AND   object_name = UPPER('&pexcp');
      v_excptab := 'EXCEPTIONS INTO '||LOWER('&pexcp');
    END IF;
  EXCEPTION
    WHEN NO_DATA_FOUND THEN
    DBMS_OUTPUT.PUT_LINE('Exceptions table does not exist in your schema: ');
    RAISE NO_DATA_FOUND;
    GOTO err;
  END;
  FOR c1 IN cons_cur(v_user, v_tabname) LOOP
    begin
      srch_cond := substr(c1.search_condition,1,length(c1.search_condition));
      -- Dont remove table constraint NOT NULL
      IF (instr(srch_cond,'NOT NULL') < 1) or
        (instr(srch_cond,'NOT NULL') IS NULL) THEN
        BEGIN
          DBMS_OUTPUT.PUT_LINE('ALTER TABLE '||C1.OWNER||'.'||C1.TABLE_NAME);
          DBMS_OUTPUT.PUT_LINE('  ADD (CONSTRAINT '||C1.CONSTRAINT_NAME);

          IF c1.constraint_type = 'P' THEN v_output := '    PRIMARY KEY (';
          ELSIF c1.constraint_type = 'R' THEN v_output := '    FOREIGN KEY (';
          ELSIF c1.constraint_type = 'U' THEN v_output := ' UNIQUE (';
          ELSIF c1.constraint_type = 'C' THEN
            v_output := '    CHECK ('||c1.search_condition||') '||v_excptab;
          END IF;

          FOR c2 IN col_cur(c1.constraint_name, c1.owner) LOOP
            IF c2.position = 1 THEN
              v_output := v_output||c2.column_name;
            ELSIF c2.position > 1 THEN
              v_output := v_output||', '||c2.column_name;
            END IF;
          END LOOP;
          v_output := v_output ||')';
          DBMS_OUTPUT.PUT_LINE(v_output);
          IF c1.constraint_type = 'R' THEN
            v_output := NULL;
            FOR c3 IN col_cur(c1.r_constraint_name, c1.r_owner) LOOP
              IF c3.position = 1 THEN
                v_output := '    REFERENCES '||c3.owner||'.'||c3.table_name||'(';
                v_output := v_output||c3.column_name;
              ELSIF c3.position > 1 THEN
                v_output := v_output||', '||c3.column_name;
              END IF;
            END LOOP;
            v_output := v_output||') ';
            DBMS_OUTPUT.PUT_LINE(v_output);
            v_delrule := substr(c1.delete_rule,1,2);
            IF v_delrule IS NULL THEN v_output :=  v_excptab ||' )';
            ELSIF v_delrule = 'NO' THEN v_output := v_excptab || ' )';
            ELSIF v_delrule = 'CA' THEN v_output := ' ON DELETE CASCADE '||v_excptab || ')';
            END IF;
            DBMS_OUTPUT.PUT_LINE(v_output);
          END IF;

          FOR c4 IN indx_cur(c1.constraint_name, c1.owner) LOOP
            IF c1.constraint_type in ('P','U') THEN
              DBMS_OUTPUT.PUT_LINE(' USING INDEX ');
              DBMS_OUTPUT.PUT_LINE('   pctfree  '||c4.pct_free);
              DBMS_OUTPUT.PUT_LINE('   initrans      '||c4.ini_trans);
              DBMS_OUTPUT.PUT_LINE('   maxtrans      '||c4.max_trans);
              DBMS_OUTPUT.PUT_LINE('   tablespace    '||c4.tablespace_name);
              DBMS_OUTPUT.PUT_LINE(' Storage (');
              DBMS_OUTPUT.PUT_LINE('   initial        '||c4.initial_extent);
              DBMS_OUTPUT.PUT_LINE('   next           '||c4.next_extent);
              DBMS_OUTPUT.PUT_LINE(' minextents     '||c4.min_extents);
              DBMS_OUTPUT.PUT_LINE('   maxextents     '||c4.max_extents);
              DBMS_OUTPUT.PUT_LINE('   pctincrease    '||c4.pct_increase||') '|| v_excptab ||')');
            END IF;
          END LOOP;

          v_output := NULL;
          v_status := substr(c1.status,1,1);
          IF v_status = 'E' THEN
            v_output := ' REM This constraint '||c1.constraint_name||' was ENABLED';
          ELSIF v_status = 'D' THEN
            v_output :=' REM This constraint '||c1.constraint_name ||' was DISABLED';
          END IF;
          DBMS_OUTPUT.PUT_LINE('/ ');
          DBMS_OUTPUT.PUT_LINE(v_output);
          DBMS_OUTPUT.PUT_LINE('-------------------------------------------- ');
          DBMS_OUTPUT.PUT_LINE(' ');
        END;
      END IF;
    EXCEPTION
      WHEN no_data_found THEN
        DBMS_OUTPUT.PUT_LINE('No Data Found');
      WHEN others THEN
        DBMS_OUTPUT.PUT_LINE('Other: '||substr(sqlerrm,1,60));
        DBMS_OUTPUT.PUT_LINE(c1.constraint_name||' '||c1.constraint_type);
        DBMS_OUTPUT.PUT_LINE(c1.search_condition);
    END;
  END LOOP;
  <<err>>
  NULL;
EXCEPTION
WHEN no_data_found THEN
DBMS_OUTPUT.PUT_LINE('This table: '||v_tabname||', Does not exist or has no constraints!');
END;
/
SPOOL off
SET PAGESIZE 14
SET FEEDBACK on
SET NEWPAGE 0
SET ARRAYSIZE 20
SET SERVEROUT off
SET LINESIZE 79
SET VERIFY on
---<tfstcons.sql end>------------------------------------------------------


该脚本用于列出在子表上没有对应索引的外键，没有索引可能引发额外的表锁:
"You should almost always index foreign keys.
The only exception is when the matching unique or primary key is never updated or deleted."

When a foreign key is unindexed, DML on the parent primary key results in a share row exclusive table lock
(or share-subexclusive table lock, SSX) on the child table, preventing DML from other transactions
against the child table. If the DML affects several rows in the parent table, the lock on the child table
is obtained and released immediately for each row in turn. Despite the speed of the lock-release process,
this can cause significant amounts of contention on the child table during periods of
heavy update/delete activity on the parent table.

When a foreign key is indexed, DML on the parent primary key results in a row share table lock
(or subshare table lock, SS) on the child table. This type of lock prevents other transactions
from issuing whole table locks on the child table, but does not block DML on either the parent or
the child table. Only the rows relating to the parent primary key are locked in the child table.
Script:
REM  List foreign keys with no matching index on child table - causes locks

set linesize 150;

col owner for a20;
col COLUMN_NAME for a20;

SELECT c.owner,
         c.constraint_name,
         c.table_name,
         cc.column_name,
         c.status
    FROM dba_constraints c, dba_cons_columns cc
   WHERE c.constraint_type = 'R'
         AND c.owner NOT IN
                ('SYS',
                 'SYSTEM',
                 'SYSMAN',
                 'EXFSYS',
                 'WMSYS',
                 'OLAPSYS',
                 'OUTLN',
                 'DBSNMP',
                 'ORDSYS',
                 'ORDPLUGINS',
                 'MDSYS',
                 'CTXSYS',
                 'AURORA$ORB$UNAUTHENTICATED',
                 'XDB',
                 'FLOWS_030000',
                 'FLOWS_FILES')
         AND c.owner = cc.owner
         AND c.constraint_name = cc.constraint_name
         AND NOT EXISTS
                    (SELECT 'x'
                       FROM dba_ind_columns ic
                      WHERE     cc.owner = ic.table_owner
                            AND cc.table_name = ic.table_name
                            AND cc.column_name = ic.column_name
                            AND cc.position = ic.column_position
                            AND NOT EXISTS
                                       (SELECT owner, index_name
                                          FROM dba_indexes i
                                         WHERE     i.table_owner = c.owner
                                               AND i.index_Name = ic.index_name
                                               AND i.owner = ic.index_owner
                                               AND (i.status = 'UNUSABLE'
                                                    OR i.partitioned = 'YES'
                                                       AND EXISTS
                                                              (SELECT 'x'
                                                                 FROM dba_ind_partitions ip
                                                                WHERE status =
                                                                         'UNUSABLE'
                                                                      AND ip.
                                                                           index_owner =
                                                                             i.
                                                                              owner
                                                                      AND ip.
                                                                           index_Name =
                                                                             i.
                                                                              index_name
                                                               UNION ALL
                                                               SELECT 'x'
                                                                 FROM dba_ind_subpartitions isp
                                                                WHERE status =
                                                                         'UNUSABLE'
                                                                      AND isp.
                                                                           index_owner =
                                                                             i.
                                                                              owner
                                                                      AND isp.
                                                                           index_Name =
                                                                             i.
                                                                              index_name))))
ORDER BY 1, 2
/





his script is intended to provide a user friendly output to diagnose the status of the database either before (or) after upgrade. The script will create a file called db_upg_diag__.log.
-- - - - - - - - - - - - - - Script begins here - - - - - - - - - - - - - -

col TODAY    NEW_VALUE    _DATE
col VERSION NEW_VALUE _VERSION
set termout off
select to_char(SYSDATE,'fmMonth DD, YYYY') TODAY from DUAL;
select version from v$instance;
set termout on
set echo off
set feedback off
set head off
set verify off
Prompt
PROMPT Enter location for Spooled output:
Prompt
DEFINE log_path = &1
column timecol new_value timestamp
column spool_extension new_value suffix
SELECT to_char(sysdate,'dd-Mon-yyyy_hhmi') timecol,'.log' spool_extension FROM
sys.dual;
column output new_value dbname
SELECT value || '_' output FROM v$parameter WHERE name = 'db_name';
spool &log_path/db_upg_diag_&&dbname&&timestamp&&suffix
set linesize 150
set pages 100
set trim on
set trims on
col Compatible for a35
col comp_id for a12
col comp_name for a40
col org_version for a11
col prv_version for a11
col owner for a12
col object_name for a40
col object_type for a40
col Wordsize for a25
col Metadata for a8
col 'Initial DB Creation Info' for a35
col 'Total Invalid JAVA objects' for a45
col 'Role' for a30
col 'User Existence' for a27
col "JAVAVM TESTING" for a15
Prompt
Prompt
set feedback off head off
select LPAD('*** Start of LogFile ***',50) from dual;
select LPAD('Oracle Database Upgrade Diagnostic Utility',44)||
 LPAD(TO_CHAR(SYSDATE, 'MM-DD-YYYY HH24:MI:SS'),26) from dual;
Prompt
Prompt ===============
Prompt Database Uptime
Prompt ===============
SELECT to_char(startup_time, 'HH24:MI DD-MON-YY') "Startup Time"
FROM v$instance;
Prompt
Prompt =================
Prompt Database Wordsize
Prompt =================
SELECT distinct('This is a ' || (length(addr)*4) || '-bit database') "WordSize"
FROM v$process;
Prompt
Prompt ================
Prompt Software Version
Prompt ================
SELECT * FROM v$version;
Prompt
Prompt =============
Prompt Compatibility
Prompt =============
SELECT 'Compatibility is set as '||value Compatible
FROM v$parameter WHERE name ='compatible';
Prompt
Prompt ================
Prompt Component Status
Prompt ================
Prompt
SET SERVEROUTPUT ON;
DECLARE

ORG_VERSION varchar2(12);
PRV_VERSION varchar2(12);
P_VERSION VARCHAR2(10);

BEGIN

SELECT version INTO p_version
FROM registry$ WHERE cid='CATPROC' ;

IF SUBSTR(p_version,1,5) = '9.2.0' THEN

DBMS_OUTPUT.PUT_LINE(RPAD('Comp ID', 8) ||RPAD('Component',35)||
 RPAD('Status',10) ||RPAD('Version', 15));

DBMS_OUTPUT.PUT_LINE(RPAD(' ',8,'-') ||RPAD(' ',35,'-')||
 RPAD(' ',10,'-') ||RPAD(' ',15,'-'));

FOR x in (SELECT SUBSTR(dr.comp_id,1,8) comp_id,
 SUBSTR(dr.comp_name,1,35) comp_name,
 dr.status Status,SUBSTR(dr.version,1,15) version
 FROM dba_registry dr,registry$ r
 WHERE dr.comp_id=r.cid and dr.comp_name=r.cname
 ORDER BY 1)

LOOP

DBMS_OUTPUT.PUT_LINE(RPAD(SUBSTR(x.comp_id,1,8),8) ||
 RPAD(SUBSTR(x.comp_name,1,35),35)||
 RPAD(x.status,10) || RPAD(x.version, 15));
END LOOP;

ELSIF SUBSTR(p_version,1,5) != '9.2.0' THEN

DBMS_OUTPUT.PUT_LINE(RPAD('Comp ID', 8) ||RPAD('Component',35)||
 RPAD('Status',10) ||RPAD('Version', 15)||
 RPAD('Org_Version',15)||RPAD('Prv_Version',15));

DBMS_OUTPUT.PUT_LINE(RPAD(' ',8,'-') ||RPAD(' ',35,'-')||
 RPAD(' ',10,'-')||RPAD(' ',15,'-')||RPAD(' ',15,'-')||
 RPAD(' ',15,'-'));

FOR y in (SELECT SUBSTR(dr.comp_id,1,8) comp_id,
 SUBSTR(dr.comp_name,1,35) comp_name, dr.status Status,
 SUBSTR(dr.version,1,11) version,org_version,prv_version
 FROM dba_registry dr,registry$ r
 WHERE dr.comp_id=r.cid and dr.comp_name=r.cname
 ORDER BY 1)

LOOP

DBMS_OUTPUT.PUT_LINE(RPAD(substr(y.comp_id,1,8), 8) ||
 RPAD(substr(y.comp_name,1,35),35)||RPAD(y.status,10) ||
 RPAD(y.version, 15)||RPAD(y.org_version,15)||RPAD(y.prv_version,15));

END LOOP;

END IF;
END;
/
SET SERVEROUTPUT OFF
Prompt
Prompt
Prompt ======================================================
Prompt List of Invalid Database Objects Owned by SYS / SYSTEM
Prompt ======================================================
Prompt
set head on
SELECT case count(object_name)
WHEN 0 THEN 'There are no Invalid Objects'
ELSE 'There are '||count(object_name)||' Invalid objects'
END "Number of Invalid Objects"
FROM dba_objects
WHERE status='INVALID'
AND owner in ('SYS','SYSTEM');
Prompt
DOC
################################################################

 If there are no Invalid objects below will result in zero rows.

################################################################
#
Prompt
set feedback on
SELECT owner,object_name,object_type
FROM dba_objects
WHERE status='INVALID'
AND owner in ('SYS','SYSTEM')
ORDER BY owner,object_type;
set feedback off
Prompt
Prompt ================================
Prompt List of Invalid Database Objects
Prompt ================================
Prompt
set head on
SELECT case count(object_name)
WHEN 0 THEN 'There are no Invalid Objects'
ELSE 'There are '||count(object_name)||' Invalid objects'
END "Number of Invalid Objects"
FROM dba_objects
WHERE status='INVALID'
AND owner not in ('SYS','SYSTEM');
Prompt
DOC
################################################################

 If there are no Invalid objects below will result in zero rows.

################################################################
#
Prompt
set feedback on
SELECT owner,object_name,object_type
FROM dba_objects
WHERE status='INVALID'
AND owner not in ('SYS','SYSTEM')
ORDER BY owner,object_type;
set feedback off
Prompt
Prompt ==============================================================
Prompt Identifying whether a database was created as 32-bit or 64-bit
Prompt ==============================================================
Prompt
DOC
###########################################################################

 Result referencing the string 'B023' ==> Database was created as 32-bit
 Result referencing the string 'B047' ==> Database was created as 64-bit
 When String results in 'B023' and when upgrading database to 10.2.0.3.0
 (64-bit) , For known issue refer below articles

 Note 412271.1 ORA-600 [22635] and ORA-600 [KOKEIIX1] Reported While
 Upgrading Or Patching Databases To 10.2.0.3
 Note 579523.1 ORA-600 [22635], ORA-600 [KOKEIIX1], ORA-7445 [KOPESIZ] and
 OCI-21500 [KOXSIHREAD1] Reported While Upgrading To 11.1.0.6

###########################################################################
#
Prompt
SELECT SUBSTR(metadata,109,4) "Metadata",
CASE SUBSTR(metadata,109,4)
WHEN 'B023' THEN 'Database was created as 32-bit'
WHEN 'B047' THEN 'Database was created as 64-bit'
ELSE 'Metadata not Matching'
END "Initial DB Creation Info"
FROM sys.kopm$;
Prompt
Prompt ===================================================
Prompt Number of Duplicate Objects Owned by SYS and SYSTEM
Prompt ===================================================
Prompt
Prompt Counting duplicate objects ....
Prompt
SELECT count(1)
FROM dba_objects
WHERE object_name||object_type in
 (SELECT object_name||object_type
 from dba_objects
 where owner = 'SYS')
and owner = 'SYSTEM';
Prompt
Prompt =========================================
Prompt Duplicate Objects Owned by SYS and SYSTEM
Prompt =========================================
Prompt
Prompt Querying duplicate objects ....
Prompt
SELECT object_name, object_type
FROM dba_objects
WHERE object_name||object_type in
 (SELECT object_name||object_type
 FROM dba_objects
 WHERE owner = 'SYS')
AND owner = 'SYSTEM';
Prompt
DOC

################################################################################

 If any objects found please follow below article.
 Note 1030426.6 How to Clean Up Duplicate Objects Owned by SYS and SYSTEM schema
 Read the Exceptions carefully before taking actions.

################################################################################
#
Prompt
Prompt ================
Prompt JVM Verification
Prompt ================
Prompt
SET SERVEROUTPUT ON
DECLARE

V_CT NUMBER;
P_VERSION VARCHAR2(10);

BEGIN

-- If so, get the version of the JAVAM component
EXECUTE IMMEDIATE 'SELECT version FROM registry$ WHERE cid=''JAVAVM''
 AND status <> 99' INTO p_version;

SELECT count(*) INTO v_ct FROM dba_objects
WHERE object_type LIKE '%JAVA%' AND owner='SYS';

IF SUBSTR(p_version,1,5) = '8.1.7' THEN
 IF v_ct>=6787 THEN
 DBMS_OUTPUT.PUT_LINE('JAVAVM - Installed properly');
 ELSE
 DBMS_OUTPUT.PUT_LINE('JAVAVM - Not Installed properly');
 END IF;
ELSIF SUBSTR(p_version,1,5) = '9.0.1' THEN
 IF v_ct>=8585 THEN
 DBMS_OUTPUT.PUT_LINE('JAVAVM - Installed properly');
 ELSE
 DBMS_OUTPUT.PUT_LINE('JAVAVM - Not Installed properly');
 END IF;
ELSIF SUBSTR(p_version,1,5) = '9.2.0' THEN
 IF v_ct>=8585 THEN
 DBMS_OUTPUT.PUT_LINE('JAVAVM - Installed properly');
 ELSE
 DBMS_OUTPUT.PUT_LINE('JAVAVM - Not Installed properly');
 END IF;
ELSIF SUBSTR(p_version,1,6) = '10.1.0' THEN
 IF v_ct>=13866 THEN
 DBMS_OUTPUT.PUT_LINE('JAVAVM - Installed properly');
 ELSE
 DBMS_OUTPUT.PUT_LINE('JAVAVM - Not Installed properly');
 END IF;
ELSIF SUBSTR(p_version,1,6) = '10.2.0' THEN
 IF v_ct>=14113 THEN
 DBMS_OUTPUT.PUT_LINE('JAVAVM - Installed properly');
 ELSE
 DBMS_OUTPUT.PUT_LINE('JAVAVM - Not Installed properly');
 END IF;
END IF;

EXCEPTION WHEN NO_DATA_FOUND THEN
 DBMS_OUTPUT.PUT_LINE('JAVAVM - NOT Installed. Below results can be ignored');

END;
/
SET SERVEROUTPUT OFF
Prompt
Prompt ================================================
Prompt Checking Existence of Java-Based Users and Roles
Prompt ================================================
Prompt
DOC

################################################################################

 There should not be any Java Based users for database version 9.0.1 and above.
 If any users found, it is faulty JVM.

################################################################################
#

Prompt
SELECT CASE count(username)
WHEN 0 THEN 'No Java Based Users'
ELSE 'There are '||count(*)||' JAVA based users'
END "User Existence"
FROM dba_users WHERE username LIKE '%AURORA%' AND username LIKE '%OSE%';
Prompt
DOC

###############################################################

 Healthy JVM Should contain Six Roles.
 If there are more or less than six role, JVM is inconsistent.

###############################################################
#

Prompt
SELECT CASE count(role)
WHEN 0 THEN 'No JAVA related Roles'
ELSE 'There are '||count(role)||' JAVA related roles'
END "Role"
FROM dba_roles
WHERE role LIKE '%JAVA%';
Prompt
Prompt Roles
Prompt
SELECT role FROM dba_roles WHERE role LIKE '%JAVA%';
set head off
Prompt
Prompt =========================================
Prompt List of Invalid Java Objects owned by SYS
Prompt =========================================
SELECT CASE count(*)
 WHEN 0 THEN 'There are no SYS owned invalid JAVA objects'
 ELSE 'There are '||count(*)||' SYS owned invalid JAVA objects'
 END "Total Invalid JAVA objects"
FROM dba_objects
WHERE object_type LIKE '%JAVA%'
AND status='INVALID'
AND owner='SYS';
Prompt
DOC

#################################################################

 Check the status of the main JVM interface packages DBMS_JAVA
 and INITJVMAUX and make sure it is VALID.
 If there are no Invalid objects below will result in zero rows.

#################################################################
#
Prompt
set feedback on
SELECT owner,object_name,object_type
FROM dba_objects
WHERE object_type LIKE '%JAVA%'
AND status='INVALID'
AND owner='SYS';
set feedback off
Prompt
Prompt INFO: Below query should succeed with 'foo' as result.
set heading on
select dbms_java.longname('foo') "JAVAVM TESTING" from dual;
set heading off
Prompt

set feedback off head off
select LPAD('*** End of LogFile ***',50) from dual;
set feedback on head on
Prompt
spool off
Prompt
set heading off
set heading off
set feedback off
select 'Upload db_upg_diag_&&dbname&&timestamp&&suffix from "&log_path" directory'
from dual;
set heading on
set feedback on
Prompt
-- - - - - - - - - - - - - - - - Script ends here - - - - - - - - - - - - - -


如何找出Oracle中需要或值得重建的索引
2009/09/10 BY MACLEAN LIU 4条评论
This script determines whether an index is a good candidate for a rebuild or for
a bitmap index.  All indexes for a given schema or for a subset of schema’s are
analyzed (except indexes under SYS and SYSTEM)
Instructions
Execution Environment:
<SQL, SQL*Plus, iSQL*Plus>
Access Privileges:
Requires DBA privileges in order to be executed.
Usage:
sqlplus <user>/<pw> @rebuild.index.sql
Instructions:
Copy the script into the file ind_an.sql. Execute the script from SQL*Plus connected
with a user with DBA privileges.  The script requires to parameters:
1. Name of the output file where the report while be generated
2. Name of the SCHEMA to be analyzed.
PROOFREAD THIS SCRIPT BEFORE USING IT! Due to differences in the way text
editors, e-mail packages, and operating systems handle text formatting (spaces,
tabs, and carriage returns), this script may not be in an executable state
when you first receive it. Check over the script to ensure that errors of
this type are corrected.
Description
This script determines whether an index is a good candidate for a rebuild or for
a bitmap index.  All indexes for a given schema or for a subset of schema’s are
analyzed (except indexes under SYS and SYSTEM).
REM =============================================================
REM
REM                         rebuild_indx.sql
REM
REM  Copyright (c) Oracle Software, 1998 - 2000
REM
REM  Author  : Jurgen Schelfhout
REM
REM  The sample program in this article is provided for educational
REM  purposes only and is NOT supported by Oracle Support Services.
REM  It has been tested internally, however, and works as documented.
REM  We do not guarantee that it will work for you, so be sure to test
REM  it in your environment before relying on it.
REM
REM  This script will analyze all the indexes for a given schema
REM  or for a subset of schema's. After this the dynamic view
REM  index_stats is consulted to see if an index is a good
REM  candidate for a rebuild or for a bitmap index.
REM
REM  Database Version : 7.3.X and above.
REM
REM  NOTE:  If running this on 10g, you must exclude the
REM  objects in the Recycle Bin
REM        cursor c_indx is
REM          select owner, table_name, index_name
REM            from dba_indexes
REM           where owner like upper('&schema')
REM             and table_name not like 'BIN$%'
REM             and owner not in ('SYS','SYSTEM');
REM
REM  Additional References for Recycle Bin functionality:
REM  Note.265254.1 Flashback Table feature in Oracle Database 10g
REM  Note.265253.1 10g Recyclebin Features And How To Disable it(_recyclebin)
REM
REM =============================================================

prompt
ACCEPT spoolfile CHAR prompt 'Output-file : ';
ACCEPT schema CHAR prompt 'Schema name (% allowed) : ';
prompt
prompt
prompt Rebuild the index when :
prompt   - deleted entries represent 20% or more of the current entries
prompt   - the index depth is more then 4 levels.
prompt Possible candidate for bitmap index :
prompt   - when distinctiveness is more than 99%
prompt

spool &spoolfile;
set serveroutput on;
set verify off;
set linesize 140;
declare
  c_name        INTEGER;
  ignore        INTEGER;
  height        index_stats.height%TYPE := 0;
  lf_rows       index_stats.lf_rows%TYPE := 0;
  del_lf_rows   index_stats.del_lf_rows%TYPE := 0;
  distinct_keys index_stats.distinct_keys%TYPE := 0;
  cursor c_indx is
    select owner, table_name, index_name
      from dba_indexes
     where owner like upper('&schema')
       and owner not in ('SYS', 'SYSTEM');
begin
  dbms_output.enable(1000000);
  dbms_output.put_line('Owner           Index Name                              % Deleted Entries Blevel Distinctiveness');
  dbms_output.put_line('--------------  ---------------------------------            ------------  -----           -----');

  c_name := DBMS_SQL.OPEN_CURSOR;
  for r_indx in c_indx loop
    DBMS_SQL.PARSE(c_name,
                   'analyze index ' || r_indx.owner || '.' ||
                   r_indx.index_name || ' validate structure',
                   DBMS_SQL.NATIVE);
    ignore := DBMS_SQL.EXECUTE(c_name);

    select HEIGHT,
           decode(LF_ROWS, 0, 1, LF_ROWS),
           DEL_LF_ROWS,
           decode(DISTINCT_KEYS, 0, 1, DISTINCT_KEYS)
      into height, lf_rows, del_lf_rows, distinct_keys
      from index_stats;
    /*
    - Index is considered as candidate for rebuild when :
    -   - when deleted entries represent 20% or more of the current entries
    -   - when the index depth is more then 4 levels.(height starts counting from 1 so > 5)
    - Index is (possible) candidate for a bitmap index when :
    -   - distinctiveness is more than 99%
    */
    if (height > 5) OR ((del_lf_rows / lf_rows) > 0.2) then
      dbms_output.put_line(rpad(r_indx.owner, 16, ' ') ||
                           rpad(r_indx.index_name, 40, ' ') ||
                           lpad(round((del_lf_rows / lf_rows) * 100, 3),
                                17,
                                ' ') || lpad(height - 1, 7, ' ') ||
                           lpad(round((lf_rows - distinct_keys) * 100 /
                                      lf_rows,
                                      3),
                                16,
                                ' '));
    end if;

  end loop;
  DBMS_SQL.CLOSE_CURSOR(c_name);
end;
/
spool off;
set verify on;
Sample Output:
SQL> @rebuild_index

Output-file : index_rebuild
Schema name (% allowed) : maclean

Rebuild the index when :
- deleted entries represent 20% or more of the current entries
- the index depth is more then 4 levels.
Possible candidate for bitmap index :
- when distinctiveness is more than 99%

Owner           Index Name                              % Deleted Entries Blevel Distinctiveness
--------------  ---------------------------------            ------------  -----           -----
MACLEAN         SYS_MTABLE_00000CFD4_IND_2                             25      0              25
MACLEAN         SYS_MTABLE_00000D3F3_IND_2                         33.333      0          33.333
PL/SQL procedure successfully completed.



以下脚本用以列出数据库中对象的依赖性:
REM OBJECT DEPENDENT

select D_OBJ#,
       do.object_name,
       do.object_type dtyp,
       do.status      dsta,
       D_TIMESTAMP,
       ORDER#,
       P_OBJ#,
       po.object_name,
       po.object_type ptyp,
       po.status      psta,
       P_TIMESTAMP
  from dependency$ d, DBA_OBJECTS do, DBA_OBJECTS po
 where D_OBJ# = do.object_ID
   and P_OBJ# = po.object_ID
   and do.object_ID in
       (select object_id from dba_objects where OBJECT_NAME = '&OBJNAME')
/


Select object_id, referenced_object_id, level
 from public_dependency
start with object_id = (Select object_id
from sys.DBA_OBJECTS
WHERE owner        = upper('&owner')
AND   object_name  = upper('&name')
AND   object_type  = upper('&type'))
connect by prior referenced_object_id = object_id
/

Select to_char(object_id) object_id, to_char(referenced_object_id) referenced_object_id, to_char(level) "LEVEL"
 from public_dependency
connect by prior object_id = referenced_object_id
start with referenced_object_id = (
   Select object_id from sys.DBA_OBJECTS
WHERE owner        = upper('&owner')
AND   object_name  = upper('&name')
AND   object_type  = upper('&type'))
/

set feedback off
set ver off
set pages 10000
column Owner format "A10"
column Obj#  format "9999999999"
column Object format "A35"
rem
ACCEPT OWN   CHAR PROMPT "Enter OWNER pattern: "
ACCEPT NAM   CHAR PROMPT "Enter OBJECT NAME pattern: "
prompt
prompt Objects matching &&OWN..&&NAM
prompt ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
select o.obj# "Obj#",
       decode(o.linkname, null, u.name||'.'||o.name,
        o.remoteowner||'.'||o.name||'@'||o.linkname) "Object",
       decode(o.type#, 0, 'NEXT OBJECT', 1, 'INDEX', 2, 'TABLE', 3, 'CLUSTER',
                       4, 'VIEW', 5, 'SYNONYM', 6, 'SEQUENCE',
                       7, 'PROCEDURE', 8, 'FUNCTION', 9, 'PACKAGE',
                      10, '*Not Exist*',
                      11, 'PKG BODY', 12, 'TRIGGER',
                      13, 'TYPE', 14, 'TYPE BODY',
                      19, 'TABLE PARTITION', 20, 'INDEX PARTITION', 21, 'LOB',
                      22, 'LIBRARY', 23, 'DIRECTORY', 24, 'QUEUE',
                      28, 'JAVA SOURCE', 29, 'JAVA CLASS', 30, 'JAVA RESOURCE',
                      32, 'INDEXTYPE', 33, 'OPERATOR',
                      34, 'TABLE SUBPARTITION', 35, 'INDEX SUBPARTITION',
                      40, 'LOB PARTITION', 41, 'LOB SUBPARTITION',
                      42, 'MATERIALIZED VIEW',
                      43, 'DIMENSION',
                      44, 'CONTEXT', 46, 'RULE SET', 47, 'RESOURCE PLAN',
                      48, 'CONSUMER GROUP',
                      51, 'SUBSCRIPTION', 52, 'LOCATION',
                      55, 'XML SCHEMA', 56, 'JAVA DATA',
                      57, 'SECURITY PROFILE', 59, 'RULE',
                      62, 'EVALUATION CONTEXT', 66, 'JOB', 67, 'PROGRAM',
                      68, 'JOB CLASS', 69, 'WINDOW', 72, 'WINDOW GROUP',
                      74, 'SCHEDULE', 'UNDEFINED') "Type",
       decode(o.status,0,'N/A',1,'VALID', 'INVALID') "Status"
  from sys.obj$ o, sys.user$ u
 where owner#=user#
   and u.name like upper('&&OWN') and o.name like upper('&&NAM') ;
prompt
ACCEPT OBJID CHAR PROMPT "Enter Object ID required: "
prompt
prompt
prompt Object &&OBJID is:
prompt ~~~~~~~~~~~~~~~~~~~
select o.obj# "Obj#",
       decode(o.linkname, null, u.name||'.'||o.name,
        o.remoteowner||'.'||o.name||'@'||o.linkname) "Object",
       decode(o.type#, 0, 'NEXT OBJECT', 1, 'INDEX', 2, 'TABLE', 3, 'CLUSTER',
                       4, 'VIEW', 5, 'SYNONYM', 6, 'SEQUENCE',
                       7, 'PROCEDURE', 8, 'FUNCTION', 9, 'PACKAGE',
                      10, '*Not Exist*',
                      11, 'PKG BODY', 12, 'TRIGGER',
                      13, 'TYPE', 14, 'TYPE BODY',
                      19, 'TABLE PARTITION', 20, 'INDEX PARTITION', 21, 'LOB',
                      22, 'LIBRARY', 23, 'DIRECTORY', 24, 'QUEUE',
                      28, 'JAVA SOURCE', 29, 'JAVA CLASS', 30, 'JAVA RESOURCE',
                      32, 'INDEXTYPE', 33, 'OPERATOR',
                      34, 'TABLE SUBPARTITION', 35, 'INDEX SUBPARTITION',
                      40, 'LOB PARTITION', 41, 'LOB SUBPARTITION',
                      42, 'MATERIALIZED VIEW',
                      43, 'DIMENSION',
                      44, 'CONTEXT', 46, 'RULE SET', 47, 'RESOURCE PLAN',
                      48, 'CONSUMER GROUP',
                      51, 'SUBSCRIPTION', 52, 'LOCATION',
                      55, 'XML SCHEMA', 56, 'JAVA DATA',
                      57, 'SECURITY PROFILE', 59, 'RULE',
                      62, 'EVALUATION CONTEXT', 66, 'JOB', 67, 'PROGRAM',
                      68, 'JOB CLASS', 69, 'WINDOW', 72, 'WINDOW GROUP',
                      74, 'SCHEDULE', 'UNDEFINED') "Type",
       decode(o.status,0,'N/A',1,'VALID', 'INVALID') "Status",
       substr(to_char(stime,'DD-MON-YYYY HH24:MI:SS'),1,20) "S-Time"
  from sys.obj$ o, sys.user$ u
 where owner#=user# and o.obj#='&&OBJID' ;
prompt
prompt Depends on:
prompt ~~~~~~~~~~~~
select o.obj# "Obj#",
       decode(o.linkname, null,
        nvl(u.name,'Unknown')||'.'||nvl(o.name,'Dropped '),
        o.remoteowner||'.'||nvl(o.name,'Dropped ')||'@'||o.linkname) "Object",
       decode(o.type#, 0, 'NEXT OBJECT', 1, 'INDEX', 2, 'TABLE', 3, 'CLUSTER',
                       4, 'VIEW', 5, 'SYNONYM', 6, 'SEQUENCE',
                       7, 'PROCEDURE', 8, 'FUNCTION', 9, 'PACKAGE',
                      10, '*Not Exist*',
                      11, 'PKG BODY', 12, 'TRIGGER',
                      13, 'TYPE', 14, 'TYPE BODY',
                      19, 'TABLE PARTITION', 20, 'INDEX PARTITION', 21, 'LOB',
                      22, 'LIBRARY', 23, 'DIRECTORY', 24, 'QUEUE',
                      28, 'JAVA SOURCE', 29, 'JAVA CLASS', 30, 'JAVA RESOURCE',
                      32, 'INDEXTYPE', 33, 'OPERATOR',
                      34, 'TABLE SUBPARTITION', 35, 'INDEX SUBPARTITION',
                      40, 'LOB PARTITION', 41, 'LOB SUBPARTITION',
                      42, 'MATERIALIZED VIEW',
                      43, 'DIMENSION',
                      44, 'CONTEXT', 46, 'RULE SET', 47, 'RESOURCE PLAN',
                      48, 'CONSUMER GROUP',
                      51, 'SUBSCRIPTION', 52, 'LOCATION',
                      55, 'XML SCHEMA', 56, 'JAVA DATA',
                      57, 'SECURITY PROFILE', 59, 'RULE',
                      62, 'EVALUATION CONTEXT', 66, 'JOB', 67, 'PROGRAM',
                      68, 'JOB CLASS', 69, 'WINDOW', 72, 'WINDOW GROUP',
                      74, 'SCHEDULE', 'UNDEFINED') "Type",
        decode(sign(stime-P_TIMESTAMP),
                  1,'*NEWER*',-1,'* OLDER *',null,'-','-SAME-')
"TimeStamp",
decode(o.status,0,'N/A',1,'VALID','INVALID') "Status"
  from sys.dependency$ d,  sys.obj$ o, sys.user$ u
 where P_OBJ#=obj#(+) and o.owner#=u.user#(+) and D_OBJ#='&&OBJID' ;



 以下脚本可以用于收集数据库安全风险评估信息:
REM list database vulnerability assessment info

set escape on;
set linesize 140 ;
spool db_vulnerability_assessment.log

Select role
  from dba_roles r
 where role not in ('CONNECT',
                    'RESOURCE',
                    'DBA',
                    'SELECT_CATALOG_ROLE',
                    'EXECUTE_CATALOG_ROLE',
                    'DELETE_CATALOG_ROLE',
                    'EXP_FULL_DATABASE',
                    'WM_ADMIN_ROLE',
                    'IMP_FULL_DATABASE',
                    'RECOVERY_CATALOG_OWNER',
                    'AQ_ADMINISTRATOR_ROLE',
                    'AQ_USER_ROLE',
                    'GLOBAL_AQ_USER_ROLE',
                    'OEM_MONITOR',
                    'HS_ADMIN_ROLE')
   and not exists
 (Select 1 from dba_role_privs p where p.granted_role = r.role)
/

select tp.grantee, tp.table_name
  from dba_tab_privs tp, dba_users u
 where tp.owner = 'SYS'
   and (tp.table_name like 'V_$%' or tp.table_name like 'G_V$')
   and tp.grantee = u.username
   and u.username not in ('SYS',
                          'SYSTEM',
                          'SYSMAN',
                          'EXFSYS',
                          'WMSYS',
                          'OLAPSYS',
                          'OUTLN',
                          'DBSNMP',
                          'ORDSYS',
                          'ORDPLUGINS',
                          'MDSYS',
                          'DMSYS',
                          'CTXSYS',
                          'AURORA$ORB$UNAUTHENTICATED',
                          'XDB',
                          'FLOWS_030000',
                          'FLOWS_FILES')
 order by 1, 2
/


select *
  from (select 'Hidden User in DBA_USERS' ddview, name
          from sys.user$
         where type# = 1
        minus
        select 'Hidden User in DBA_USERS', username from SYS.dba_users) q1
union all
select *
  from (select 'Hidden User in ALL_USERS', name
          from sys.user$
         where type# = 1
        minus
        select 'Hidden User in ALL_USERS', username from SYS.all_users) q2
/



select grantee, granted_role
  from dba_role_privs
 where grantee in (select role from dba_roles)
 order by grantee, granted_role
/

select grantee, privilege, admin_option
  from dba_sys_privs sp, dba_users u
 where sp.GRANTEE = u.username
   and grantee not in ('SYS', 'SYSTEM')
   and privilege in (select name
                       from sys.system_privilege_map
                      where 0 = 1
                         or name like '%ANY%'
                         or name like '%DATABASE%'
                         or name like '%DIRECTORY%'
                         or name like '%LIBRARY%'
                         or name like '%LINK%'
                         or name like '%PROFILE%'
                         or name like '%RESTRICTED%'
                         or name like 'SYS%'
                         or name like '%SYSTEM%'
                         or name like '%TABLESPACE%'
                         or name like '%USER%')
 order by 1
/

select role,
       (select count(*)
          from dba_role_privs rp
         where rp.granted_role = r.role) GRANT_COUNT
  from dba_roles r
 where r.role in ('DBA', 'CONNECT', 'RESOURCE')
 order by 1
/

select grantee, granted_role, admin_option
  from dba_role_privs rp, dba_users u
 where rp.grantee = u.username
   and grantee not in ('SYS', 'SYSTEM')
   and granted_role in (select role
                          from dba_roles
                         where 0 = 1
                            or role like '%CATALOG%'
                            or role like '%DATABASE%'
                            or role like '%DBA%')
 order by 1
/

select distinct profile, resource_name, actual_limit
from (select P.Profile, p.resource_Name,
             decode(p.limit, 'UNLIMITED', '9999999999999999999',
                   'NULL', null, to_number(p.limit)) limit,
             limit actual_limit
      from ( select profile, resource_name,
                    decode(resource_name,  'IDLE_TIME', decode(limit, 'DEFAULT', 'UNLIMITED', limit),
                                           'FAILED_LOGIN_ATTEMPTS', decode(limit, 'DEFAULT', '10', limit),
                                           'PASSWORD_LIFE_TIME', decode(limit, 'DEFAULT', 'UNLIMITED', limit),
                                           'PASSWORD_REUSE_MAX', decode(limit, 'DEFAULT', 'UNLIMITED', limit),
                                           'PASSWORD_REUSE_TIME', decode(limit, 'DEFAULT', 'UNLIMITED', limit),
                                           'PASSWORD_GRACE_TIME', decode(limit, 'DEFAULT', 'UNLIMITED', limit),
                                'PASSWORD_VERIFY_FUNCTION', decode(limit, 'NULL', '0', null, 0, 'DEFAULT', 0, 1), limit) limit
              from   dba_profiles
              where resource_name in ('IDLE_TIME', 'FAILED_LOGIN_ATTEMPTS',
                                      'PASSWORD_LIFE_TIME', 'PASSWORD_REUSE_MAX',
                                      'PASSWORD_REUSE_TIME','PASSWORD_GRACE_TIME',
                                      'PASSWORD_VERIFY_FUNCTION')) p )
where 1=0
or    (RESOURCE_NAME = 'IDLE_TIME' AND LIMIT > 60)
or    (RESOURCE_NAME = 'FAILED_LOGIN_ATTEMPTS' AND LIMIT > 3)
or    (RESOURCE_NAME = 'PASSWORD_LIFE_TIME' AND LIMIT > 90)
or    (RESOURCE_NAME = 'PASSWORD_REUSE_MAX' AND LIMIT > 20)
or    (RESOURCE_NAME = 'PASSWORD_REUSE_TIME' AND LIMIT > 180)
or    (RESOURCE_NAME = 'PASSWORD_GRACE_TIME' AND LIMIT > 3)
or    (RESOURCE_NAME = 'PASSWORD_VERIFY_FUNCTION' AND LIMIT = 0)
order by 1,2
/

Select s.owner, s.synonym_name, s.table_owner, s.table_name
  from sys.DBA_synonyms s
 where not exists (Select 'x'
          from sys.DBA_objects o
         where o.owner = s.table_owner
           and o.object_name = s.table_name)
   and db_link is null
   and s.owner <> 'PUBLIC'
 order by 1
/

Select distinct profile
  from dba_profiles
minus
Select distinct profile from dba_users
/

select table_name
  from dba_tab_privs
 where owner = 'SYS'
   and grantee = 'PUBLIC'
   and table_name in ('UTL_SMTP',
                      'UTL_TCP',
                      'UTL_HTTP',
                      'UTL_FILE',
                      'DBMS_RANDOM',
                      'DBMS_LOB',
                      'DBMS_SYS_SQL',
                      'DBMS_BACKUP_RESTORE',
                      'EMD_SYSTEM',
                      'DBMS_NAMESPACE',
                      'DBMS_SCHEDULER')
 order by 1
/


select username, password from dba_users order by 1
/


select tp.grantee, tp.table_name, tp.privilege
  from dba_tab_privs tp, dba_users u, dba_tables t
 where tp.owner = 'SYS'
   and tp.grantee = u.username
   and tp.owner = t.owner
   and tp.table_name = t.table_name
   and u.username not in ('SYS',
                          'SYSTEM',
                          'SYSMAN',
                          'EXFSYS',
                          'WMSYS',
                          'OLAPSYS',
                          'OUTLN',
                          'DBSNMP',
                          'ORDSYS',
                          'ORDPLUGINS',
                          'MDSYS',
                          'CTXSYS',
                          'AURORA$ORB$UNAUTHENTICATED',
                          'XDB',
                          'FLOWS_030000',
                          'FLOWS_FILES')
 order by 1, 2, 3
/

 select sp.grantee, sp.privilege
   from dba_sys_privs sp, dba_users u
  where sp.admin_option = 'YES'
    and u.username = sp.grantee
    and u.username not in ('SYS',
                           'SYSTEM',
                           'SYSMAN',
                           'EXFSYS',
                           'WMSYS',
                           'OLAPSYS',
                           'OUTLN',
                           'DBSNMP',
                           'ORDSYS',
                           'ORDPLUGINS',
                           'MDSYS',
                           'CTXSYS',
                           'AURORA$ORB$UNAUTHENTICATED',
                           'XDB',
                           'FLOWS_030000',
                           'FLOWS_FILES')
  order by 1, 2
/

  select p.grantee, p.owner, p.table_name, p.privilege
    from dba_tab_privs p, dba_users u
   where p.grantable = 'YES'
     and u.USERNAME = p.grantee
     and u.username not in ('SYS',
                            'SYSTEM',
                            'SYSMAN',
                            'EXFSYS',
                            'WMSYS',
                            'OLAPSYS',
                            'OUTLN',
                            'DBSNMP',
                            'ORDSYS',
                            'ORDPLUGINS',
                            'MDSYS',
                            'CTXSYS',
                            'AURORA$ORB$UNAUTHENTICATED',
                            'XDB',
                            'FLOWS_030000',
                            'FLOWS_FILES')
   order by 1, 2, 3, 4
/

select username
  from dba_users
 where account_status!='EXPIRED \& LOCKED'
 order by 1
/

Select s.synonym_name, s.table_owner, s.table_name
  from sys.DBA_synonyms s
 where not exists (Select 'x'
          from sys.DBA_objects o
         where o.owner = s.table_owner
           and o.object_name = s.table_name)
   and db_link is null
   and s.owner = 'PUBLIC'
 order by 1
/

select r.grantee, r.granted_role
  from dba_role_privs r, dba_users u
 where r.admin_option = 'YES'
   and u.username = r.grantee
   and u.username not in ('SYS',
                          'SYSTEM',
                          'SYSMAN',
                          'EXFSYS',
                          'WMSYS',
                          'OLAPSYS',
                          'OUTLN',
                          'DBSNMP',
                          'ORDSYS',
                          'ORDPLUGINS',
                          'MDSYS',
                          'CTXSYS',
                          'AURORA$ORB$UNAUTHENTICATED',
                          'XDB',
                          'FLOWS_030000',
                          'FLOWS_FILES')
 order by 1, 2
/


select username
  from dba_users
 where password = 'EXTERNAL'
 order by username
/





 Redo丢失的4种情况及处理方法 2013-06-18 09:21:01
分类： Android平台
一.说明：
1.以下所说的当前日志指日志状态为CURRENT,ACTIVE,非当前日志指日志状态为INACTIVE
2.不用考虑归档和非归档模式，2种模式下的Redo丢失情况一样。

二.丢失Redo的4种情况：
第一种情况：非当前日志，正常关闭。
第二种情况：非当前日志，非正常关闭。
第三种情况：当前日志，正常关闭。
第四种情况：当前日志，非正常关闭。

三.处理方法：
第一、二种情况的处理方法一样，直接把日志文件clear即可。
SQL> alter database clear logfile group 3;
SQL> alter database clear unarchived logfile group 3;//如果INACTIVE状态的在线Redo还未归档，增加关键字unarchived完成clear操作。（ACTIVE,INACTIVE都有可能未完成归档，归档是否完成可以查看v$log.archived字段）。

例子：

SQL> startup mount

ORACLE 例程已经启动。



Total System Global Area  263639040 bytes

Fixed Size                  1384012 bytes

Variable Size             167772596 bytes

Database Buffers           88080384 bytes

Redo Buffers                6402048 bytes

数据库装载完毕。

SQL> select group#,thread#,status,archived from v$log;


    GROUP#    THREAD# STATUS                           ARCHIV

---------- ---------- -------------------------------- ------

         1          1 CURRENT                          NO

         3          1 ACTIVE                           NO

         2          1 INACTIVE                         YES



SQL> alter database clear logfile group 3;

alter database clear logfile group 3

*

第 1 行出现错误:

ORA-01624: 日志 3 是紧急恢复实例 orcl (线程 1) 所必需的

ORA-00312: 联机日志 3 线程 1: 'E:\APP\ORADATA\ORCL\REDO03.LOG'



SQL> alter database clear logfile group 2;



数据库已更改。


第三种情况的处理办法：
SQL>startup mount;
SQL>recover database until cancel;
SQL>alter database open resetlogs;


例子1：

SQL> shutdown immediate
数据库已经关闭。
已经卸载数据库。
ORACLE 例程已经关闭。
SQL> startup mount
ORACLE 例程已经启动。

Total System Global Area  263639040 bytes
Fixed Size                  1384012 bytes
Variable Size             167772596 bytes
Database Buffers           88080384 bytes
Redo Buffers                6402048 bytes
数据库装载完毕。
SQL> alter database open resetlogs;
alter database open resetlogs
*
第 1 行出现错误:
ORA-01139: RESETLOGS 选项仅在不完全数据库恢复后有效


SQL> recover database until cancel;
完成介质恢复。
SQL> alter database open resetlogs;

数据库已更改。

例子2（第三种情况的第二个处理方法）：

SQL> shutdown immediate

数据库已经关闭。

已经卸载数据库。

ORACLE 例程已经关闭。

SQL> startup mount

ORACLE 例程已经启动。



Total System Global Area  263639040 bytes

Fixed Size                  1384012 bytes

Variable Size             167772596 bytes

Database Buffers           88080384 bytes

Redo Buffers                6402048 bytes

数据库装载完毕。

SQL> select group#,thread#,status,archived from v$log;



    GROUP#    THREAD# STATUS                           ARCHIV

---------- ---------- -------------------------------- ------

         1          1 CURRENT                          NO

         3          1 INACTIVE                         YES

         2          1 INACTIVE                         YES



SQL> alter database clear logfile group 2;



数据库已更改。



SQL> alter database clear logfile group 3;



数据库已更改。



SQL> alter database clear unarchived logfile group 3;



数据库已更改。

       这里CURRENT的Redo日志文件组能被clear unarchived。

SQL> alter database open;



数据库已更改。

       如果Redo日志文件丢失，clear操作完成之后将在原有位置创建新的Redo日志文件。


第四种情况的处理方法：
1.通过备份来还原、恢复数据。
2.通过修改参数文件中的参数
_allow_resetlogs_corruption=TRUE
来强制启动数据库。//虽然能够启动数据库到open状态，但是启动后的数据库数据字典、数据有可能导致不一致的情况出现，故需要在open下把整个数据库export，然后删除库，重建，再将export的数据import到新的数据库中。

四.验证数据库是否正常关闭的方法

SQL> select open_mode from v$database;

OPEN_MODE

--------------------

READ WRITE

SQL> select status from v$instance;

STATUS

------------

OPEN

SQL> select file#,checkpoint_change#,fuzzy from v$datafile_header;

    FILE# CHECKPOINT_CHANGE# FUZ

---------- ------------------ ---

         1            1165820 YES

         2            1165820 YES

         3            1165820 YES

         4            1165820 YES

        FUZZY bit in datafile header means that there may have been writes into a datafile after the last checkpoint. E.g. there may be changes written to datafile with higher SCN than checkpoint_change# stored in datafile header (seen from v$datafile_header.checkpoint_change#).
        FUZYY表示模糊性，意思是，该数据文件处于模糊状态，在最近一次CHECKPOINT后，该文件上的数据可能被修改过了，但没来得及更新到该文件上（或者该文件不知道），需要读取日志信息来判断。

SQL> select file#,checkpoint_change#,last_change# from v$datafile;

    FILE# CHECKPOINT_CHANGE# LAST_CHANGE#

---------- ------------------ ------------

         1            1165820

         2            1165820

         3            1165820

         4            1165820

        由于数据库是打开的状态，所以终止SCN是空，SCN的内容可参考文章：http://space.itpub.net/23135684/viewspace-627343

SQL> shutdown immediate

数据库已经关闭。

已经卸载数据库。

ORACLE 例程已经关闭。

SQL> startup mount

ORACLE 例程已经启动。

Total System Global Area  313860096 bytes

Fixed Size                  1384352 bytes

Variable Size             155189344 bytes

Database Buffers          150994944 bytes

Redo Buffers                6291456 bytes

数据库装载完毕。

SQL> select file#,checkpoint_change#,fuzzy from v$datafile_header;

    FILE# CHECKPOINT_CHANGE# FUZ

---------- ------------------ ---

         1            1166324 NO

         2            1166324 NO

         3            1166324 NO

         4            1166324 NO

        在正常管理数据库的情况下，FUZZY字段都应该是NO，表示没有模糊不清的SCN存储在数据文件中。

SQL> select file#,checkpoint_change#,last_change# from v$datafile;

    FILE# CHECKPOINT_CHANGE# LAST_CHANGE#

---------- ------------------ ------------

         1            1166324      1166324

         2            1166324      1166324

         3            1166324      1166324

         4            1166324      1166324

       正常关闭数据库的终止SCN应该和启动SCN相同。FUZZY等于NO，且数据库的终止SCN等于启动SCN等于数据文件SCN，那么可以认为数据库是正常关闭，且在打开数据库之前不需要执行实例恢复或Crash恢复。

SQL> alter database open;

数据库已更改。

SQL> shutdown abort

ORACLE 例程已经关闭。

SQL> startup mount

ORACLE 例程已经启动。

Total System Global Area  313860096 bytes

Fixed Size                  1384352 bytes

Variable Size             155189344 bytes

Database Buffers          150994944 bytes

Redo Buffers                6291456 bytes

数据库装载完毕。

SQL> select file#,checkpoint_change#,fuzzy from v$datafile_header;

    FILE# CHECKPOINT_CHANGE# FUZ

---------- ------------------ ---

         1            1166327 YES

         2            1166327 YES

         3            1166327 YES

         4            1166327 YES

       非正常关闭数据库实例，FUZZY字段的值是YES。

SQL> select file#,checkpoint_change#,last_change# from v$datafile;

    FILE# CHECKPOINT_CHANGE# LAST_CHANGE#

---------- ------------------ ------------

         1            1166327

         2            1166327

         3            1166327

         4            1166327

       非正常关闭数据库实例，终止SCN依然为空。那么，在数据库被打开之前必须使用归档Redo日志完成实例恢复或Crash恢复。

五.结论：
非正常关闭的当前日志丢失，可能导致数据库启动后的混乱，并可能造成少量数据的丢失。其他情况不会导致数据的丢失。


        相关文章：《alter system archive log current / all / switch logfile》：http://space.itpub.net/35489/viewspace-673824





上周在客户一套BRM系统上执行分区交换Exchange Partition操作的时候出现了ORA-14098错误，该错误是由于分区表上的LOCAL分区索引与非分区表上的索引不匹配造成的，我们来看一下这个错误:
[oracle@rh2 ~]$ oerr ora 14098
14098, 00000, "index mismatch for tables in ALTER TABLE EXCHANGE PARTITION"
// *Cause:  The two tables specified in the EXCHANGE have indexes which are
//          not equivalent
// *Action: Ensure that the indexes for the two tables have indexes which
//          follow this rule
//          For every non partitioned index for the non partitioned table,
//          there has to be an identical LOCAL index on the partitioned
//          table and vice versa. By identical, the column position, type
//          and size have to be the same.

SQL> ALTER TABLE sales EXCHANGE PARTITION SALES_Q4_2003 with
table SALES_TMP INCLUDING INDEXES WITH VALIDATION UPDATE GLOBAL INDEXES;

ALTER TABLE sales EXCHANGE PARTITION SALES_Q4_2003 with
table SALES_TMP INCLUDING INDEXES WITH VALIDATION UPDATE GLOBAL INDEXES
                                                              *
ERROR at line 1:
ORA-14098: index mismatch for tables in ALTER TABLE EXCHANGE PARTITION
如果表上有很多的索引，以至于你无法确定到底是哪个索引引发了ORA-14098错误，那么我们可以通过trace的方式来协助定位到具体的索引:
SQL>  select * from v$version;

BANNER
----------------------------------------------------------------
Oracle Database 10g Enterprise Edition Release 10.2.0.4.0 - 64bi
PL/SQL Release 10.2.0.4.0 - Production
CORE    10.2.0.4.0      Production
TNS for Linux: Version 10.2.0.4.0 - Production
NLSRTL Version 10.2.0.4.0 - Production

SQL> select * from global_name;

GLOBAL_NAME
--------------------------------------------------------------------------------
www.oracledatabase12g.com


SQL> alter session set max_dump_file_size = unlimited;
Session altered.

SQL> alter session set events '10046 trace name context forever, level 12';
Session altered.

SQL> alter session set events '14098 trace name errorstack forever, level 4';
Session altered.

##SQL> alter system flush buffer_cache;
System altered.


Rerun Exchange Partition DDL

SQL> ALTER TABLE sales EXCHANGE PARTITION SALES_Q4_2003 with table SALES_TMP
INCLUDING INDEXES WITH VALIDATION UPDATE GLOBAL INDEXES;

ALTER TABLE sales EXCHANGE PARTITION SALES_Q4_2003 with table SALES_TMP
INCLUDING INDEXES WITH VALIDATION UPDATE GLOBAL INDEXES
                                                              *
ERROR at line 1:
ORA-14098: index mismatch for tables in ALTER TABLE EXCHANGE PARTITION

11g中直接查询v$diag_info就可以得到trace的路径，10g执行gettracename.sql

SELECT    d.VALUE
       || '/'
       || LOWER (RTRIM (i.INSTANCE, CHR (0)))
       || '_ora_'
       || p.spid
       || '.trc' trace_file_name
  FROM (SELECT p.spid
          FROM v$mystat m, v$session s, v$process p
         WHERE m.statistic# = 1 AND s.SID = m.SID AND p.addr = s.paddr) p,
       (SELECT t.INSTANCE
          FROM v$thread t, v$parameter v
         WHERE v.NAME = 'thread'
           AND (v.VALUE = 0 OR t.thread# = TO_NUMBER (v.VALUE))) i,
       (SELECT VALUE
          FROM v$parameter
         WHERE NAME = 'user_dump_dest') d;

TRACE_FILE_NAME
--------------------------------------------------------------------------------
/s01/admin/G10R2/udump/g10r2_ora_17749.trc

==========================10046/errorstack trace contents========================
PARSING IN CURSOR #1 len=127 dep=0 uid=64 oct=15 lid=64 tim=1277655207436065 hv=1207961095 ad='9098f018'
ALTER TABLE sales EXCHANGE PARTITION SALES_Q4_2003 with table SALES_TMP
INCLUDING INDEXES WITH VALIDATION UPDATE GLOBAL INDEXES
END OF STMT
PARSE #1:c=0,e=1145,p=0,cr=0,cu=0,mis=1,r=0,dep=0,og=1,tim=1277655207436059
BINDS #1:
STAT #2 id=2 cnt=0 pid=1 pos=1 obj=98001 op='INDEX FULL SCAN SALES_UNID_TMP (cr=1 pr=0 pw=0 time=39 us)'
*** 2011-06-17 21:55:32.417
ksedmp: internal or fatal error
ORA-14098: index mismatch for tables in ALTER TABLE EXCHANGE PARTITION
Current SQL statement for this session:
ALTER TABLE sales EXCHANGE PARTITION SALES_Q4_2003 with table SALES_TMP
INCLUDING INDEXES WITH VALIDATION UPDATE GLOBAL INDEXES

我们可以在trace中看到在出现ORA-14098错误前，正在对索引SALES_UNID_TMP的Fast Full Scan
除了通过10046/errorstack的trace信息诊断外，更多的问题可以直接从DDL语句中发现,在以上示例中非分区表的DDL语句:
-- Create table
create table SALES_TMP
(
  UNI_ID        NUMBER NOT NULL,
  PROD_ID       NUMBER not null,
  CUST_ID       NUMBER not null,
  TIME_ID       DATE not null,
  CHANNEL_ID    NUMBER not null,
  PROMO_ID      NUMBER not null,
  QUANTITY_SOLD NUMBER(10,2) not null,
  AMOUNT_SOLD   NUMBER(10,2) not null
);

create index SALES_CHANNEL_TMP       ON SALES_TMP (CHANNEL_ID) ;
create index SALES_CUST_TMP          ON SALES_TMP (CUST_ID)    ;
create index SALES_UNID_TMP          ON SALES_TMP  (UNI_ID,TIME_ID);  --注意细节该索引是非UNIQUE的
create index SALES_PROD_TMP          ON SALES_TMP (PROD_ID)    ;
create index SALES_PROMO_TMP         ON SALES_TMP (PROMO_ID)   ;
create index SALES_TIME_TMP          ON SALES_TMP (TIME_ID)    ;
下为分区表的DDL语句:
-- Create table
create table SALES
(
  UNI_ID        NUMBER NOT NULL,
  PROD_ID       NUMBER not null,
  CUST_ID       NUMBER not null,
  TIME_ID       DATE not null,
  CHANNEL_ID    NUMBER not null,
  PROMO_ID      NUMBER not null,
  QUANTITY_SOLD NUMBER(10,2) not null,
  AMOUNT_SOLD   NUMBER(10,2) not null
)
partition by range (TIME_ID)
...............

create index SALES_CHANNEL       ON SALES (CHANNEL_ID) LOCAL;
create index SALES_CUST          ON SALES (CUST_ID)    LOCAL;
create UNIQUE index SALES_UNID   ON SALES (UNI_ID,TIME_ID) LOCAL;      -- 对应的索引是UNIQUE的
create index SALES_PROD          ON SALES (PROD_ID)    LOCAL;
create index SALES_PROMO         ON SALES (PROMO_ID)   LOCAL;
create index SALES_TIME          ON SALES (TIME_ID)    LOCAL;
解决ORA-14098错误的要点是要找出引发错误的原因。当我们交换分区的时候，我们要确保所有交换表上的索引和分区表上的本地索引匹配。这意味着如果在分区表上有N个LOCAL INDEXES，那么在交换表上就应当有N个等价的索引。这里的等价要求存在映射关系的2个索引，在列的位置、类型、大小及UNIQUE/NON-UNIQUE都要一致。
可以利用如下SQL语句来找出分区表和交换表上索引的差异:
set linesize 160 pagesize 1400

 col TABLE_NAME for a30
 col INDEX_NAME for a30
 col COLUMN_NAME for a30
 col COLUMN_POSITION for 99
 col COLUMN_LENGTH for 99
 col CHAR_LENGTH for 99
 col DESCEND for a4

Select TABLE_NAME,INDEX_NAME, COLUMN_NAME,COLUMN_POSITION, COLUMN_LENGTH, CHAR_LENGTH, DESCEND
FROM SYS.DBA_IND_COLUMNS DICN
WHERE INDEX_OWNER = '&own'
 and DICN.TABLE_NAME in ('&TABNAME1','&TABNAME2')
ORDER BY  INDEX_NAME, COLUMN_POSITION
/

select TABLE_NAME, INDEX_NAME, INDEX_TYPE, UNIQUENESS, PARTITIONED
  from dba_indexes
 where owner='&OWNER'
   and TABLE_NAME in ('&TABNAME1', '&TABNAME2')
 order by index_name
/
也可以使用Toad的Single Schema Object Compare功能来对比检验索引:
single_object_compare
对于存在主键的分区表，可以在主键上以DISABLE VALIDATE方式创建unique constraint约束，以代替全局的主键索引。若交换表(Exchange Table)上存在主键索引的话，那么建议在交换前暂时将该索引drop掉，待交换完成后再重建。
如果实在无法解决该ORA-14098错误，那么可以尝试使用EXCLUDING INDEXES子句以跳过索引维护，而在交换完成后重建相关失效索引2014/8/16



Script:To Report Information on Indexes
2007/06/30 BY MACLEAN LIU 暂无评论
Reports index fragmentation statistics:
==========
Script #1:
==========

SET ECHO off
REM NAME:   TFSIFRAG.SQL
REM USAGE:"@path/tfsifrag schema_name index_name"
REM ------------------------------------------------------------------------
REM REQUIREMENTS:
REM    SELECT on INDEX_STATS
REM ------------------------------------------------------------------------
REM PURPOSE:
REM    Reports index fragmentation statistics
REM ------------------------------------------------------------------------
REM EXAMPLE:
REM                     Index Fragmentation Statistic
REM
REM    index name        S_EMP_USERID_UK
REM    leaf rows deleted            0
REM    leaf rows in use            25
REM    index badness            0.000
REM
REM ------------------------------------------------------------------------
REM Main text of script follows:
set verify off
def ownr  = &&1
def name  = &&2

ttitle -
  center 'Index Fragmentation Statistic'   skip 2

set heading off

col name                 newline
col lf_blk_rows          newline
col del_lf_rows          newline
col ibadness newline

validate index &ownr..&name;

select
  'index name        '||name,
  'leaf rows deleted '||to_char(del_lf_rows,'999,999,990')  del_lf_rows,
  'leaf rows in use  '||to_char(lf_rows-del_lf_rows,'999,999,990')  lf_blk_rows,
  'index badness     '||to_char(del_lf_rows/(lf_rows+0.00001),'999,990.999') ibadness
from
  index_stats
/

undef ownr
undef name
set verify on


==============
Sample Output:
==============

                         Index Fragmentation Statistic


index name                   S_EMP_USERID_UK
leaf rows deleted            0
leaf rows in use             25
index badness                0.000




==========
Script #2:
==========

SET ECHO off
REM NAME:   TFSISTAT.SQL
REM USAGE:"@path/tfsistat schema_name index_name"
REM ------------------------------------------------------------------------
REM REQUIREMENTS:
REM    SELECT on INDEX_STATS
REM ------------------------------------------------------------------------
REM PURPOSE:
REM    Report index statistics.
REM ------------------------------------------------------------------------
REM EXAMPLE:
REM                                Index Statistics
REM
REM    S_EMP_USERID_UK
REM    ----------------------------------------------------------
REM    height                          1
REM    blocks                          5
REM    del_lf_rows                     0
REM    del_lf_rows_len                 0
REM    distinct_keys                  25
REM    most_repeated_key               1
REM    btree_space                 1,876
REM    used_space                    447
REM    pct_used                       24
REM    rows_per_key                    1
REM    blks_gets_per_access            2
REM    lf_rows                        25            br_rows               0
REM    lf_blks                         1            br_blks               0
REM    lf_rows_len                   447            br_rows_len           0
REM    lf_blk_len                  1,876            br_blk_len            0
REM
REM ------------------------------------------------------------------------
REM Main text of script follows:
set verify off
def ownr        = &&1
def name        = &&2

ttitle -
  center  'Index Statistics'  skip 2

set heading off

col name   newline
col headsep              newline
col height               newline
col blocks               newline
col lf_rows              newline
col lf_blks        	 newline
col lf_rows_len          newline
col lf_blk_len           newline
col br_rows              newline
col br_blks              newline
col br_rows_len          newline
col br_blk_len           newline
col del_lf_rows          newline
col del_lf_rows_len      newline
col distinct_keys        newline
col most_repeated_key    newline
col btree_space          newline
col used_space    	 newline
col pct_used             newline
col rows_per_key         newline
col blks_gets_per_access newline

validate index &ownr..&name;

select
  name,
  '----------------------------------------------------------'    headsep,
  'height               '||to_char(height,     '999,999,990')     height,
  'blocks               '||to_char(blocks,     '999,999,990')     blocks,
  'del_lf_rows          '||to_char(del_lf_rows,'999,999,990')     del_lf_rows,
  'del_lf_rows_len      '||to_char(del_lf_rows_len,'999,999,990') del_lf_rows_len,
  'distinct_keys        '||to_char(distinct_keys,'999,999,990')   distinct_keys,
  'most_repeated_key    '||to_char(most_repeated_key,'999,999,990') most_repeated_key,
  'btree_space          '||to_char(btree_space,'999,999,990')       btree_space,
  'used_space           '||to_char(used_space,'999,999,990')        used_space,
  'pct_used                     '||to_char(pct_used,'990')          pct_used,
  'rows_per_key         '||to_char(rows_per_key,'999,999,990')      rows_per_key,
  'blks_gets_per_access '||to_char(blks_gets_per_access,'999,999,990') blks_gets_per_access,
  'lf_rows      '||to_char(lf_rows,    '999,999,990')||'        '||+
  'br_rows      '||to_char(br_rows,    '999,999,990')                  br_rows,
  'lf_blks      '||to_char(lf_blks,    '999,999,990')||'        '||+
  'br_blks      '||to_char(br_blks,    '999,999,990')                  br_blks,
  'lf_rows_len  '||to_char(lf_rows_len,'999,999,990')||'        '||+
  'br_rows_len  '||to_char(br_rows_len,'999,999,990')                  br_rows_len,
  'lf_blk_len   '||to_char(lf_blk_len, '999,999,990')||'        '||+
  'br_blk_len   '||to_char(br_blk_len, '999,999,990')                br_blk_len
from
  index_stats
/

undef ownr
undef name
set verify on


==============
Sample Output:
==============

                                Index Statistics
S_EMP_USERID_UK
----------------------------------------------------------
height                          1
blocks                          5
del_lf_rows                     0
del_lf_rows_len                 0
distinct_keys                  	25
most_repeated_key               1
btree_space                 	1,876
used_space                    	447
pct_used                       	24
rows_per_key                    1
blks_gets_per_access            2
lf_rows                		25
br_rows                 	0
lf_blks				1
br_blks                 	0
lf_rows_len           		447
br_rows_len            		0
lf_blk_len          		1,876
br_blk_len              	0




==========
Script #3:
==========

SET ECHO off
REM NAME:   TFSIKEYS.SQL
REM USAGE:"@path/tfsikeys idx_owner table_name"
REM ------------------------------------------------------------------------
REM REQUIREMENTS:
REM    SELECT on DBA_IND_COLUMNS and DBA_INDEXES
REM ------------------------------------------------------------------------
REM PURPOSE:
REM Shows the index keys for a particular table.
REM ------------------------------------------------------------------------
REM EXAMPLE:
REM             Index Keys Summary
REM
REM    Uniqueness                Index Name                    Column Name
REM    ---------- ----------------------------------------  ------------------
REM    UNIQUE                    SCOTT.S_EMP_ID_PK               ID
REM
REM    UNIQUE                    SCOTT.S_EMP_USERID_UK           USERID
REM
REM ------------------------------------------------------------------------
REM Main text of script follows:
set verify off
def ixowner	= &&1
def tabname	= &&2

ttitle -
   center  'Index Keys Summary'  skip 2

col uniq    format a10 heading 'Uniqueness'  justify c trunc
col indname format a40 heading 'Index Name'  justify c trunc
col colname format a25 heading 'Column Name' justify c trunc

break -
  on indname skip 1 -
  on uniq

select
  ind.uniqueness                  uniq,
  ind.owner||'.'||col.index_name  indname,
  col.column_name                 colname
from
  dba_ind_columns  col,
  dba_indexes      ind
where
  ind.owner = upper('&ixowner')
    and
  ind.table_name = upper('&tabname')
    and
  col.index_owner = ind.owner
    and
  col.index_name = ind.index_name
order by
  col.index_name,
  col.column_position
/

undef ixowner
undef tabname
set verify on


==============
Sample Output:
==============


         Index Keys Summary


Uniqueness                Index Name                    Column Name
---------- ---------------------------------------- ----------------------
UNIQUE                SCOTT.S_EMP_ID_PK                        ID

UNIQUE                SCOTT.S_EMP_USERID_UK                    USERID




Script:List Schema/Table Constraints
2011/09/07 BY MACLEAN LIU 暂无评论
以下脚本可以用于列出相关模式或表上的Constraints约束:
---<tfsscons.sql begin>------------------------------------------------------
SET ECHO off
REM NAME: tfsscons.sql
REM USAGE:"@path/tfsscons"
REM --------------------------------------------------------------------------
REM REQUIREMENTS:
REM SELECT permissions on dba_constraints, dba_cons_columns and
REM    dba_ind_columns.
REM --------------------------------------------------------------------------

SET ARRAYSIZE 1
SET FEEDBACK off
SET SERVEROUT on
SET PAGESIZE 66
SET NEWPAGE 6
SET LINESIZE 75
SET PAUSE off
SET VERIFY off
ACCEPT puser PROMPT 'Enter the schema name: '
ACCEPT pexcp PROMPT 'Enter the EXCEPTIONS table name for schema &puser: '
PROMPT 'NOTE: This will take some time, please wait...'

SPOOL schema_cons_&puser
DECLARE
    CURSOR cons_cur (v_userid VARCHAR2) IS
      SELECT * FROM dba_constraints
      WHERE owner = v_userid
        AND constraint_type in ('P','U','C','R')
      ORDER BY constraint_type;
    CURSOR col_cur (con_name VARCHAR2, con_owner VARCHAR2) IS
      SELECT * FROM dba_cons_columns
      WHERE owner = con_owner
        AND constraint_name = con_name
      ORDER BY position;
    CURSOR indx_cur (con_name VARCHAR2, ind_own VARCHAR2) IS
      SELECT a.*
      FROM dba_indexes a, dba_ind_columns b, dba_cons_columns c
      WHERE c.constraint_name = con_name
        AND a.owner = ind_own
        AND b.index_owner = ind_own
        AND c.owner = b.index_owner
        AND c.position = 1
        AND c.table_name = b.table_name
        AND c.column_name = b.column_name
        AND b.index_name = a.index_name;
    col_str VARCHAR2(200);
    v_user      VARCHAR2(30) := UPPER('&puser');
    v_output    VARCHAR2(480);    -- max of 16 cols at 30 chars each
    v_excp      NUMBER(1) := 0;
    v_excptab   VARCHAR2(60) := NULL;
    v_delrule   VARCHAR2(4);
    v_status    VARCHAR2(4);
    srch_cond   VARCHAR2(1000);
    v_errcode   NUMBER := 0;
    v_errmsg    varchar2(50) := ' ';
BEGIN
  DBMS_OUTPUT.ENABLE(1000000);         -- Prevents buffer exceeded error
  BEGIN
    v_excptab := UPPER('&pexcp');
    IF v_excptab IS NOT NULL THEN
      SELECT 1
        INTO v_excp
      FROM dba_objects
      WHERE owner = UPPER('&puser')
        AND   object_name = UPPER('&pexcp');
      v_excptab := 'EXCEPTIONS INTO '||LOWER('&pexcp');
    END IF;
    EXCEPTION
    WHEN NO_DATA_FOUND THEN
    DBMS_OUTPUT.PUT_LINE('Exceptions table does not exist in the schema: ');
    RAISE NO_DATA_FOUND;
    GOTO err;
  END;
  FOR c1 IN cons_cur(v_user) LOOP
    begin
      srch_cond := substr(c1.search_condition,1,length(c1.search_condition));
      -- Dont remove table constraint NOT NULL
      IF (instr(srch_cond,'NOT NULL') < 1) or
        (instr(srch_cond,'NOT NULL') IS NULL) THEN
        BEGIN
          DBMS_OUTPUT.PUT_LINE('ALTER TABLE '||C1.OWNER||'.'||C1.TABLE_NAME);
          DBMS_OUTPUT.PUT_LINE('  ADD (CONSTRAINT '||C1.CONSTRAINT_NAME);

          IF c1.constraint_type = 'P' THEN v_output := '    PRIMARY KEY (';
          ELSIF c1.constraint_type = 'R' THEN v_output := '    FOREIGN KEY (';
          ELSIF c1.constraint_type = 'U' THEN v_output := '    UNIQUE (';
          ELSIF c1.constraint_type = 'C' THEN
            v_output := '    CHECK ('||c1.search_condition||') '||v_excptab;
          END IF;

          FOR c2 IN col_cur(c1.constraint_name, c1.owner) LOOP
            IF c2.position = 1 THEN
              v_output := v_output||c2.column_name;
            ELSIF c2.position > 1 THEN
              v_output := v_output||', '||c2.column_name;
            END IF;
          END LOOP;
          v_output := v_output||')';
          DBMS_OUTPUT.PUT_LINE(v_output);
          IF c1.constraint_type = 'R' THEN
            v_output := NULL;
            FOR c3 IN col_cur(c1.r_constraint_name, c1.r_owner) LOOP
              IF c3.position = 1 THEN
                v_output := '    REFERENCES '||c3.owner||'.'||c3.table_name||'(';
                v_output := v_output||c3.column_name;
              ELSIF c3.position > 1 THEN
                v_output := v_output||', '||c3.column_name;
              END IF;
            END LOOP;
            v_output := v_output||')';
            DBMS_OUTPUT.PUT_LINE(v_output);
            v_delrule := substr(c1.delete_rule,1,2);
            IF v_delrule IS NULL THEN v_output := v_excptab ||  ' )';
            ELSIF v_delrule = 'NO' THEN v_output :=  v_excptab || ' )';
            ELSIF v_delrule = 'CA' THEN v_output := ' ON DELETE CASCADE '||v_excptab || ')';
            END IF;
            DBMS_OUTPUT.PUT_LINE(v_output);
          END IF;

          FOR c4 IN indx_cur(c1.constraint_name, c1.owner) LOOP
            IF c1.constraint_type in ('P','U') THEN
              DBMS_OUTPUT.PUT_LINE(' USING INDEX ');
              DBMS_OUTPUT.PUT_LINE('   pctfree       '||c4.pct_free);
              DBMS_OUTPUT.PUT_LINE('   initrans      '||c4.ini_trans);
              DBMS_OUTPUT.PUT_LINE('   maxtrans      '||c4.max_trans);
              DBMS_OUTPUT.PUT_LINE('   tablespace    '||c4.tablespace_name);
              DBMS_OUTPUT.PUT_LINE(' Storage (');
              DBMS_OUTPUT.PUT_LINE('   initial        '||c4.initial_extent);
              DBMS_OUTPUT.PUT_LINE('   next           '||c4.next_extent);
              DBMS_OUTPUT.PUT_LINE('   minextents'||c4.min_extents);
              DBMS_OUTPUT.PUT_LINE('   maxextents     '||c4.max_extents);
              DBMS_OUTPUT.PUT_LINE('   pctincrease    '||c4.pct_increase||') '|| v_excptab ||')');
            END IF;
          END LOOP;

          v_output := NULL;
          v_status := substr(c1.status,1,1);
          IF v_status = 'E' THEN
            v_output := ' REM This constraint '||c1.constraint_name||' was ENABLED';
          ELSIF v_status = 'D' THEN
            v_output :=' REM This constraint '||c1.constraint_name ||' was DISABLED';
          END IF;
          DBMS_OUTPUT.PUT_LINE('/ ');
          DBMS_OUTPUT.PUT_LINE(v_output);
          DBMS_OUTPUT.PUT_LINE('-------------------------------------------- ');
          DBMS_OUTPUT.PUT_LINE('  ');
        END;
      END IF;
    EXCEPTION
    WHEN no_data_found THEN
      DBMS_OUTPUT.PUT_LINE('No Data Found');
    WHEN others THEN
      v_errcode := sqlcode;
      v_errmsg := SUBSTR(sqlerrm, 1, 50);
      DBMS_OUTPUT.PUT_LINE('ERROR: '||v_errcode||': ' || v_errmsg);
      DBMS_OUTPUT.PUT_LINE(c1.constraint_name||' '||c1.constraint_type);
      DBMS_OUTPUT.PUT_LINE(c1.search_condition);
    END;
  END LOOP;
  <<err>>
  NULL;
END;
/
SPOOL off
SET PAGESIZE 14
SET FEEDBACK on
SET NEWPAGE 0
SET ARRAYSIZE 20
SET SERVEROUT off
SET LINESIZE 79
SET VERIFY on
---<tfsscons.sql end>------------------------------------------------------

---<tfstcons.sql begin>------------------------------------------------------
SET ECHO off
REM NAME: tfstcons.sql
REM USAGE:"@path/tfstcons"
REM --------------------------------------------------------------------------
REM REQUIREMENTS:
REM    SELECT permissions on dba_constraints, dba_cons_columns and
REM    dba_ind_columns.
REM --------------------------------------------------------------------------

SET ARRAYSIZE 1
SET SERVEROUT on
SET PAGESIZE 66
SET NEWPAGE 6
SET LINESIZE 75
SET PAUSE off
SET VERIFY off
SET FEEDBACK off
ACCEPT puser PROMPT 'Enter the schema name: '
ACCEPT ptab  PROMPT 'Enter the table name: '
ACCEPT pexcp PROMPT 'Enter the EXCEPTIONS table name for schema &puser: '
PROMPT 'NOTE: This will take some time, please be patient...'

SPOOL tab_cons_&ptab
DECLARE
    CURSOR cons_cur (v_userid VARCHAR2, v_tabname VARCHAR2) IS
      SELECT * FROM sys.dba_constraints
      WHERE owner = v_userid
        AND constraint_type in ('P','U','C','R')
        AND table_name = v_tabname
      ORDER BY constraint_type;
    CURSOR col_cur (con_name VARCHAR2, con_owner VARCHAR2) IS
      SELECT * FROM sys.dba_cons_columns
      WHERE owner = con_owner
        AND constraint_name = con_name
      ORDER BY position;
    CURSOR indx_cur (con_name VARCHAR2, ind_own VARCHAR2) IS
      SELECT a.*
      FROM sys.dba_indexes a, sys.dba_ind_columns b, sys.dba_cons_columns c
      WHERE c.constraint_name = con_name
        AND a.owner = ind_own
        AND b.index_owner = ind_own
        AND c.owner = b.index_owner
        AND c.position = 1
        AND c.table_name = b.table_name
        AND c.column_name = b.column_name
        AND b.index_name = a.index_name;
    col_str     VARCHAR2(200);
    v_user      VARCHAR2(30) := UPPER('&puser');
    v_tabname   VARCHAR2(30) := UPPER('&ptab');
    v_output    VARCHAR2(480);    -- max of 16 cols at 30 chars each
    v_dummy     NUMBER := 0;
    v_delrule   VARCHAR2(4);
    v_status    VARCHAR2(4);
    v_excp      NUMBER(1) := 0;
    v_excptab   VARCHAR2(60) := NULL;
    srch_cond   VARCHAR2(1000);
BEGIN
  DBMS_OUTPUT.ENABLE(1000000);         -- Prevents buffer exceeded error

  SELECT 1                             -- Check to see if the table exists
  INTO v_dummy
  FROM dba_tables
  WHERE table_name = v_tabname
  AND   owner = v_user;
  BEGIN
    v_excptab := UPPER('&pexcp');
    IF v_excptab IS NOT NULL THEN
      SELECT 1
        INTO v_excp
      FROM sys.dba_objects
      WHERE owner = UPPER('&puser')
        AND   object_name = UPPER('&pexcp');
      v_excptab := 'EXCEPTIONS INTO '||LOWER('&pexcp');
    END IF;
  EXCEPTION
    WHEN NO_DATA_FOUND THEN
    DBMS_OUTPUT.PUT_LINE('Exceptions table does not exist in your schema: ');
    RAISE NO_DATA_FOUND;
    GOTO err;
  END;
  FOR c1 IN cons_cur(v_user, v_tabname) LOOP
    begin
      srch_cond := substr(c1.search_condition,1,length(c1.search_condition));
      -- Dont remove table constraint NOT NULL
      IF (instr(srch_cond,'NOT NULL') < 1) or
        (instr(srch_cond,'NOT NULL') IS NULL) THEN
        BEGIN
          DBMS_OUTPUT.PUT_LINE('ALTER TABLE '||C1.OWNER||'.'||C1.TABLE_NAME);
          DBMS_OUTPUT.PUT_LINE('  ADD (CONSTRAINT '||C1.CONSTRAINT_NAME);

          IF c1.constraint_type = 'P' THEN v_output := '    PRIMARY KEY (';
          ELSIF c1.constraint_type = 'R' THEN v_output := '    FOREIGN KEY (';
          ELSIF c1.constraint_type = 'U' THEN v_output := ' UNIQUE (';
          ELSIF c1.constraint_type = 'C' THEN
            v_output := '    CHECK ('||c1.search_condition||') '||v_excptab;
          END IF;

          FOR c2 IN col_cur(c1.constraint_name, c1.owner) LOOP
            IF c2.position = 1 THEN
              v_output := v_output||c2.column_name;
            ELSIF c2.position > 1 THEN
              v_output := v_output||', '||c2.column_name;
            END IF;
          END LOOP;
          v_output := v_output ||')';
          DBMS_OUTPUT.PUT_LINE(v_output);
          IF c1.constraint_type = 'R' THEN
            v_output := NULL;
            FOR c3 IN col_cur(c1.r_constraint_name, c1.r_owner) LOOP
              IF c3.position = 1 THEN
                v_output := '    REFERENCES '||c3.owner||'.'||c3.table_name||'(';
                v_output := v_output||c3.column_name;
              ELSIF c3.position > 1 THEN
                v_output := v_output||', '||c3.column_name;
              END IF;
            END LOOP;
            v_output := v_output||') ';
            DBMS_OUTPUT.PUT_LINE(v_output);
            v_delrule := substr(c1.delete_rule,1,2);
            IF v_delrule IS NULL THEN v_output :=  v_excptab ||' )';
            ELSIF v_delrule = 'NO' THEN v_output := v_excptab || ' )';
            ELSIF v_delrule = 'CA' THEN v_output := ' ON DELETE CASCADE '||v_excptab || ')';
            END IF;
            DBMS_OUTPUT.PUT_LINE(v_output);
          END IF;

          FOR c4 IN indx_cur(c1.constraint_name, c1.owner) LOOP
            IF c1.constraint_type in ('P','U') THEN
              DBMS_OUTPUT.PUT_LINE(' USING INDEX ');
              DBMS_OUTPUT.PUT_LINE('   pctfree  '||c4.pct_free);
              DBMS_OUTPUT.PUT_LINE('   initrans      '||c4.ini_trans);
              DBMS_OUTPUT.PUT_LINE('   maxtrans      '||c4.max_trans);
              DBMS_OUTPUT.PUT_LINE('   tablespace    '||c4.tablespace_name);
              DBMS_OUTPUT.PUT_LINE(' Storage (');
              DBMS_OUTPUT.PUT_LINE('   initial        '||c4.initial_extent);
              DBMS_OUTPUT.PUT_LINE('   next           '||c4.next_extent);
              DBMS_OUTPUT.PUT_LINE(' minextents     '||c4.min_extents);
              DBMS_OUTPUT.PUT_LINE('   maxextents     '||c4.max_extents);
              DBMS_OUTPUT.PUT_LINE('   pctincrease    '||c4.pct_increase||') '|| v_excptab ||')');
            END IF;
          END LOOP;

          v_output := NULL;
          v_status := substr(c1.status,1,1);
          IF v_status = 'E' THEN
            v_output := ' REM This constraint '||c1.constraint_name||' was ENABLED';
          ELSIF v_status = 'D' THEN
            v_output :=' REM This constraint '||c1.constraint_name ||' was DISABLED';
          END IF;
          DBMS_OUTPUT.PUT_LINE('/ ');
          DBMS_OUTPUT.PUT_LINE(v_output);
          DBMS_OUTPUT.PUT_LINE('-------------------------------------------- ');
          DBMS_OUTPUT.PUT_LINE(' ');
        END;
      END IF;
    EXCEPTION
      WHEN no_data_found THEN
        DBMS_OUTPUT.PUT_LINE('No Data Found');
      WHEN others THEN
        DBMS_OUTPUT.PUT_LINE('Other: '||substr(sqlerrm,1,60));
        DBMS_OUTPUT.PUT_LINE(c1.constraint_name||' '||c1.constraint_type);
        DBMS_OUTPUT.PUT_LINE(c1.search_condition);
    END;
  END LOOP;
  <<err>>
  NULL;
EXCEPTION
WHEN no_data_found THEN
DBMS_OUTPUT.PUT_LINE('This table: '||v_tabname||', Does not exist or has no constraints!');
END;
/
SPOOL off
SET PAGESIZE 14
SET FEEDBACK on
SET NEWPAGE 0
SET ARRAYSIZE 20
SET SERVEROUT off
SET LINESIZE 79
SET VERIFY on
---<tfstcons.sql end>------------------------------------------------------


以下脚本可以用于Oracle db系统上线前检测单颗CPu运算能力频率：


SET SERVEROUTPUT ON



SET TIMING ON

DECLARE
  n NUMBER := 0;
BEGIN
  FOR f IN 1..10000000
  LOOP
    n := MOD (n,999999) + SQRT (f);
  END LOOP;
  DBMS_OUTPUT.PUT_LINE ('Res = '||TO_CHAR (n,'999999.99'));
END;
/

create table cpu_speed tablespace users pctfree 99 pctused 0 cache as select * from dba_objects where rownum<=30000;





alter session set optimizer_dynamic_sampling=0;

set autotrace on;
set timing on;
select sum(object_id) from cpu_speed;
select sum(object_id) from cpu_speed;


set autotrace off;

set serveroutput on;

alter session set nls_date_format='DD-MM-YY hh24:mi:ss';
exec DBMS_STATS.CREATE_STAT_TABLE ('SYS','sys_stats');



BEGIN
   DBMS_STATS.GATHER_SYSTEM_STATS ('interval',interval => 1, stattab => 'sys_stats', statid => 'OLTP');
END;
/


exec dbms_lock.sleep(60);

DECLARE
  STATUS VARCHAR2(20);
  DSTART DATE;
  DSTOP  DATE;
  PVALUE NUMBER;
  PNAME  VARCHAR2(30);
BEGIN
  PNAME := 'cpuspeed';
  DBMS_STATS.GET_SYSTEM_STATS(status,
                              dstart,
                              dstop,
                              pname,
                              pvalue,
                              stattab => 'sys_stats',
                              statid  => 'OLTP',
                              statown => 'SYS');
  DBMS_OUTPUT.PUT_LINE('status : ' || status);
  DBMS_OUTPUT.PUT_LINE('cpu in mhz : ' || pvalue);
  DBMS_OUTPUT.PUT_LINE('start :' || dstart);
  DBMS_OUTPUT.PUT_LINE('stop :' || dstop);
  PNAME := 'sreadtim';
  DBMS_STATS.GET_SYSTEM_STATS(status,
                              dstart,
                              dstop,
                              pname,
                              pvalue,
                              stattab => 'sys_stats',
                              statid  => 'OLTP',
                              statown => 'SYS');
  DBMS_OUTPUT.PUT_LINE('single block readtime in ms : ' || pvalue);
  PNAME := 'mreadtim';
  DBMS_STATS.GET_SYSTEM_STATS(status,
                              dstart,
                              dstop,
                              pname,
                              pvalue,
                              stattab => 'sys_stats',
                              statid  => 'OLTP',
                              statown => 'SYS');
  DBMS_OUTPUT.PUT_LINE('multiblock readtime in ms : ' || pvalue);
  PNAME := 'mbrc';
  DBMS_STATS.GET_SYSTEM_STATS(status,
                              dstart,
                              dstop,
                              pname,
                              pvalue,
                              stattab => 'sys_stats',
                              statid  => 'OLTP',
                              statown => 'SYS');
  DBMS_OUTPUT.PUT_LINE('average multiblock readcount: ' || pvalue);
END;
/




例：查询执行次数和失效次数：

select sum(pins) pins,  sum(reloads) reloads  from  v$librarycache;

如果 ratio = ( reloads / pins ) * 100 大于 1 或更大。就需要加大共享池的大小。

类似地，数据字典高速缓存取决于数据库访问的用户数、权限、数据表、索引等。数据库系统会重复使用相同的数据库对象。如果程序频繁地访问硬盘，就说明数据字典高速缓存过快失效造成。

例：查询用户可以获得gets(找到对象 )次数和getmisses(高速缓存失效)的次数：

select sum(gets) gets , sum(getmisses) getmisses
from  v$rowcache;

如果 ratio = ( getmisses / gets ) * 100 大于 10%，就要考虑加大SHARED_POOL_SIZE参数值。



SQL 性能分析器 SQL Performance Analyzer SPA
Oracle Database 11g 引入了 SQL 性能分析器；使用该工具可以准确地评估更改对组成工作量的 SQL 语句的影响。SQL 性能分析器可帮助预测潜在的更改对 SQL 查询工作量的性能影响。这种功能可向 DBA 提供有关 SQL 语句性能的详细信息，例如，执行前后的统计信息，提高或降低性能的语句。这样一来，您就可以执行诸如以下操作的操作：在测试环境中进行更改，以确定数据库升级是否会改进工作量性能。

11g 的新增功能
目标用户：DBA、QA、应用程序开发人员
帮助预测系统更改对 SQL 工作量响应时间的影响
建立不同版本的 SQL 工作量性能（即 SQL 执行计划和执行统计信息）
以串行方式执行 SQL（不考虑并发性）
分析性能差异
提供对单个 SQL 的细粒度性能分析
与 SQL 优化指导集成在一起以优化回归
SQL 性能分析器：使用情形
SQL 性能分析器可用于预测和防止会影响 SQL 执行计划结构的任何数据库环境更改所带来的潜在性能问题。这些更改可以包括（但不限于）以下任何一种更改：
数据库升级
实施优化建议
更改方案
收集统计信息
更改数据库参数
更改操作系统和硬件

DBA 甚至可以使用 SQL 性能分析器为最复杂的环境预测先期更改导致的 SQL 性能更改。例如，随着应用程序在开发周期中的变化，数据库应用程序开发人员可以测试对方案、数据库对象和重写应用程序的更改，以减轻任何潜在的性能影响。
使用 SQL 性能分析器还可以比较 SQL 性能统计信息。
SQL 性能分析器：概要
1.  收集 SQL：在这个阶段中，将收集用于表示生产系统中的 SQL 工作量的 SQL 语句集。可以使用 SQL 优化集或自动工作量资料档案库 (AWR) 来捕获要传送的信息。因为 AWR 本质上是捕获高负载的 SQL，所以应考虑修改默认的 AWR 快照设置和捕获的顶级 SQL，以确保 AWR 捕获最大数量的 SQL 语句。这可以确保捕获更加完整的 SQL 工作量。
2.  传送：在这个阶段中，应将得到的工作量结果传送到测试系统。从生产系统导出 STS，然后将 STS 导入到测试系统。
3.  计算“之前版本”性能：在进行任何更改之前，执行 SQL 语句，收集评估将来的更改对工作量性能的可能影响所需的基线信息。在此阶段收集的信息给出了系统工作量当前状态的一个快照。性能数据包括：
-执行计划（如由解释计划生成的计划）
-执行统计信息（如由占用时间、缓冲获取次数、磁盘读取次数和已处理的行数组成的信息）
4. 进行更改：获得了之前版本数据后，可以实施计划的更改，然后开始查看对性能的影响。
5.  计算“之后版本”性能：在数据库环境中进行了更改之后才执行此步骤。SQL 工作量的每个语句都在虚拟执行（仅收集统计信息）模式下运行，收集与步骤 3 所捕获的信息相同的信息。
6.  比较和分析 SQL 性能：在获得了两个版本的 SQL 工作量性能数据后，可以通过比较之后版本与之前版本的数据来进行性能分析。比较的根据是执行统计信息，如所用时间、CPU 时间和缓冲区获取次数等。
7.  优化回归的 SQL：在此阶段中，已经准确地确认了哪些 SQL 语句在进行数据库更改时可能导致性能问题。在此阶段中可以使用任何一种数据库工具来优化系统。例如，可以对确认的语句使用 SQL 优化指导或访问指导，然后实施相应的建议。也可以使用在步骤 3 中捕获的计划植入 SQL 计划管理 (SPM) 以确保计划保持不变。在实施了任何优化操作后，应重复该过程来创建新的之后版本，然后分析性能差异以确保新的性能是可接受的。
默认情况下SPA若涉及到DML语句则只有查询部分Query会被执行，但是貌似是从11.2开始可以执行完全的DML了，需要加入参数EXECUTE_FULLDML，但是该参数目前有一些BUG:
Bug 10428438 : WITH EXECUTE_FULLDML ROWS IS ALWAYS SET TO 0 11.2.0.1
Bug 14635522 : SPA SHOULD CAPTURE AND REPLAY TRANSACTIONS 11.2.0.3

By default, only the query portion of DMLs is executed. Using APIs, you can execute the full DML by using the EXECUTE_FULLDML task parameter.EXECUTE_FULLDML when set to TRUE executes DML statement fully, including acquiring row locks and modifying rows; When EXECUTE_FULLDML is set to FALSE (the default value is false) to execute only the query part of the DML without modifying data. When TRUE, SQL Performance Analyzer will issue a rollback following DML execution to prevent persistent changes from being made by the DML. So SPA does not make make any change to the data in the tables.

执行方法如下：

execute DBMS_SQLPA.SET_ANALYSIS_TASK_PARAMETER(task_name   => 'TASK_21137', -
                                               parameter   => 'EXECUTE_FULLDML', -
                                               value       => 'TRUE');




从cursor cache中收集tuning set, 持续12分钟，间隔5秒钟


begin
DBMS_SQLTUNE.CREATE_SQLSET (sqlset_name => 'MAC_SPA');
dbms_sqltune.capture_cursor_cache_sqlset(
sqlset_name => 'MAC_SPA' ,
time_limit => 12*60,
repeat_interval => 5);
end ;
/

basic_filter=> q'# module like 'DWH_TEST%' and sql_text not like '%applicat%' and parsing_schema_name in ('APPS') #'

basic_filter   => 'sql_text LIKE ''%my_objects%'' and parsing_schema_name = ''SPA_TEST_USER''',

==>过滤条件使用

从当前cursor cache中匹配条件 获得SQLset ROW


SELECT sql_id, sql_text
FROM table(DBMS_SQLTUNE.SELECT_CURSOR_CACHE('buffer_gets > 500'))
ORDER BY sql_id;

SELECT *
FROM table(DBMS_SQLTUNE.SELECT_CURSOR_CACHE('sql_id = ''4rm4183czbs7j'''));

 DECLARE
  cur sys_refcursor;
BEGIN
  OPEN cur FOR
    SELECT value(P)
    FROM table(DBMS_SQLTUNE.SELECT_CURSOR_CACHE) P;

  -- Process each statement (or pass cursor to load_sqlset).

  CLOSE cur;
END;
/

 -- create the tuning set
EXEC DBMS_SQLTUNE.CREATE_SQLSET('MAC_SPA');
-- populate the tuning set from the cursor cache
DECLARE
 cur DBMS_SQLTUNE.SQLSET_CURSOR;
BEGIN
 OPEN cur FOR
   SELECT VALUE(P)
     FROM table(
       DBMS_SQLTUNE.SELECT_CURSOR_CACHE(
         'parsing_schema_name <> ''SYS'' AND elapsed_time > 5000000',
          NULL, NULL, NULL, NULL, 1, NULL,
         'ALL')) P;

DBMS_SQLTUNE.LOAD_SQLSET(sqlset_name => 'MAC_SPA',
                        populate_cursor => cur);

END;
/


从AWR快照中加载SQLset ROW到SQL TUNING SET


DECLARE
  cur sys_refcursor;
BEGIN
  OPEN cur FOR
    SELECT VALUE (P)
    FROM table(dbms_sqltune.select_workload_repository(4146,4161)) P;

  -- Process each statement (or pass cursor to load_sqlset)
  DBMS_SQLTUNE.LOAD_SQLSET(sqlset_name => 'MAC_SPA',
                        populate_cursor => cur);
  CLOSE cur;
END;
/



将SQL TUNING SET Pack到表中：


set echo on
select name,statement_count from dba_sqlset;

drop table maclean.pack_sqlset purge;

exec DBMS_SQLTUNE.CREATE_STGTAB_SQLSET('PACK_SQLSET','MACLEAN');

exec DBMS_SQLTUNE.PACK_STGTAB_SQLSET('MAC_SPA','SYS','PACK_SQLSET','MACLEAN');

SQL> desc maclean.pack_sqlset;
 Name                                      Null     Type
 ----------------------------------------- -------- ----------------------------
 NAME                                               VARCHAR2(30)
 OWNER                                              VARCHAR2(30)
 DESCRIPTION                                        VARCHAR2(256)
 SQL_ID                                             VARCHAR2(13)
 FORCE_MATCHING_SIGNATURE                           NUMBER
 SQL_TEXT                                           CLOB
 PARSING_SCHEMA_NAME                                VARCHAR2(30)
 BIND_DATA                                          RAW(2000)
 BIND_LIST                                          SQL_BIND_SET
 MODULE                                             VARCHAR2(48)
 ACTION                                             VARCHAR2(32)
 ELAPSED_TIME                                       NUMBER
 CPU_TIME                                           NUMBER
 BUFFER_GETS                                        NUMBER
 DISK_READS                                         NUMBER
 DIRECT_WRITES                                      NUMBER
 ROWS_PROCESSED                                     NUMBER
 FETCHES                                            NUMBER
 EXECUTIONS                                         NUMBER
 END_OF_FETCH_COUNT                                 NUMBER
 OPTIMIZER_COST                                     NUMBER
 OPTIMIZER_ENV                                      RAW(1000)
 PRIORITY                                           NUMBER
 COMMAND_TYPE                                       NUMBER
 FIRST_LOAD_TIME                                    VARCHAR2(19)
 STAT_PERIOD                                        NUMBER
 ACTIVE_STAT_PERIOD                                 NUMBER
 OTHER                                              CLOB
 PLAN_HASH_VALUE                                    NUMBER
 PLAN                                               SQL_PLAN_TABLE_TYPE
 SPARE1                                             NUMBER
 SPARE2                                             NUMBER
 SPARE3                                             BLOB
 SPARE4                                             CLOB



将测试对应 schema的数据和 上述PACK TABLE 导出导入到 目标测试库中：

set echo on
exec DBMS_SQLTUNE.UNPACK_STGTAB_SQLSET('MAC_SPA','SYS',TRUE,'PACK_SQLSET','MACLEAN');
alter system flush buffer_cache;
alter system flush shared_pool;


创建SPA任务 并运行;


var sts_task varchar2(64);
exec :sts_task:= dbms_sqlpa.create_analysis_task(task_name => '10g_11g_spa',description => 'experiment for 10gR2 to 11gR2 upgrade',sqlset_name=> 'MAC_SPA');

PL/SQL procedure successfully completed.

var exe_task varchar2(64);
exec :exe_task:=dbms_sqlpa.execute_analysis_task(task_name=>'10g_11g_spa',execution_name=>'10g_trail',execution_type=>'CONVERT SQLSET',execution_desc=>'10g sql trail');

var exe_task varchar2(64);
exec :exe_task:=dbms_sqlpa.execute_analysis_task(task_name=>'10g_11g_spa',execution_name=>'11g_trail',execution_type=>'TEST EXECUTE',execution_desc=>'11g sql trail');



执行任务比较



比较CPU_TIME
EXEC dbms_sqlpa.execute_analysis_task( -
  task_name => '10g_11g_spa', -
  execution_name => 'compare_10g_112_cpu', -
  execution_type => 'COMPARE PERFORMANCE', -
  execution_params => dbms_advisor.arglist('COMPARISON_METRIC','CPU_TIME','EXECUTION_NAME1','10g_trail','EXECUTION_NAME2','11g_trail'), -
  execution_desc => 'Compare 10g SQL Trace Performance to 11g Test-Execute for CPU_TIME')
  /

比较BUFFER_GETS
EXEC dbms_sqlpa.execute_analysis_task( -
  task_name => '10g_11g_spa', -
  execution_name => 'compare_10g_112_buffergets', -
  execution_type => 'COMPARE PERFORMANCE', -
  execution_params => dbms_advisor.arglist('COMPARISON_METRIC','BUFFER_GETS','EXECUTION_NAME1','10g_trail','EXECUTION_NAME2','11g_trail'), -
  execution_desc => 'Compare 10g SQL Trace Performance to 11g Test-Execute for BUFFER_GETS')
  /

比较实际执行时长

begin
DBMS_SQLPA.EXECUTE_ANALYSIS_TASK(
task_name => 'SPA_TEST',
execution_type => 'COMPARE PERFORMANCE',
execution_name => 'Compare_elapsed_time',
execution_params => dbms_advisor.arglist('execution_name1', '10g_trail', 'execution_name2', '11g_trail', 'comparison_metric', 'elapsed_time') );
end;
/

比较物理读

begin
DBMS_SQLPA.EXECUTE_ANALYSIS_TASK(
task_name => '10g_11g_spa',
execution_type => 'COMPARE PERFORMANCE',
execution_name => 'Compare_physical_reads0',
execution_params => dbms_advisor.arglist('execution_name1', '10g_trail', 'execution_name2', '11g_trail', 'comparison_metric', 'disk_reads') );
end;
/

Set the comparison_metric parameter to specify an expression of execution
statistics to use in the performance impact analysis. Possible values include
the following metrics or any combination of them: elapsed_time (default),
cpu_time, buffer_gets, disk_reads, direct_writes, and optimizer_cost.



set trimspool on
set trim on
set pages 0
set linesize 1000
set long 20000000000
set longchunksize 10000000000

spool spa_report_elapsed_time.html
SELECT dbms_sqlpa.report_analysis_task('SPA_TEST', 'HTML', 'ALL','ALL', top_sql=>300,execution_name=>'Compare_elapsed_time') FROM dual;
spool off;

ERROR:
ORA-27163: out of memory
ORA-06512: at "SYS.DBMS_SQLTUNE_INTERNAL", line 8211
ORA-06512: at "SYS.DBMS_SQLPA", line 515
ORA-06512: at line 1
出现这种内部的问题，只好抱着在MOS上搜一搜的态度。同时我也开了SR。很快SR就回复了,同时我也搜到了一篇文档叫XML Parser Fails With ORA-27163 (Out Of Memory) (文档 ID 1599434.1)。SR回复的方法和我搜索到的解决办法都是一样的，需要设置event 31156。这个可以直接在session级别进行设置，设置完成之后，再次生成SPA报告没有报错。

ALTER SESSION SET EVENTS '31156 trace name context forever, level 0x400';

获得SPA报告:



set long 100000 longchunksize 100000 linesize 200 head off feedback off echo off
spool spa_report_elapsed_time.html
SELECT dbms_sqlpa.report_analysis_task('SPA_TEST', 'HTML', 'ALL','ALL', execution_name=>'Compare_elapsed_time') FROM dual;
spool off

产生buffergets 比较report

set heading off long 100000000 longchunksize 10000 echo off;
set linesize 1000 trimspool on;
spool buffergets_summary.html
select xmltype(dbms_sqlpa.report_analysis_task('10g_11g_spa',
                                                'html',
                                                'typical',
                                                'all',
                                                null,
                                                100,
                                                'compare_10g_112_buffergets')).getclobval(0,0)
from dual;
spool off

产生errors比较report
spool errors_summary.html
select xmltype(dbms_sqlpa.report_analysis_task('10g_11g_spa',
                                                'html',
                                                'errors',
                                                'summary',
                                                null,
                                                100,
                                                '11g_trail')).getclobval(0,0)
from dual;
spool off

产生unsupport比较report
spool unsuppor_all.html
select xmltype(dbms_sqlpa.report_analysis_task('10g_11g_spa',
                                                'html',
                                                'unsupported',
                                                'all',
                                                null,
                                                100,
                                                '11g_trail')).getclobval(0,0)
from dual;
spool off



The sql tuning set contains a sql statement that is causing issues.





SOLUTION

In 11.2.0.1, Patch 8868231 should  fix most of the problems associated with this error.   This fix is included in 11.2.0.2 onwards.

The error can also be related to a sql statement being captured that is executing an "EXPLAIN PLAN for SQL"

To identify these sql statement within the tuning set run:-




SELECT sql_id, sql_text, sqlset_owner, sqlset_name
FROM    dba_sqlset_statements
WHERE sqlset_name='&TUNING_SET_NAME'
AND       upper(sql_text) like 'EXPLAIN%'



A problem "Explain Plan for" Sql statement can be removed from a sqlset using the following command.




BEGIN
DBMS_SQLTUNE.DELETE_SQLSET( sqlset_name => '&TUNING_SET_NAME', basic_filter => 'sql_id = ''&sql_id''');
E


execution_type
Type of the action to perform by the function. If NULL it will default to the value of the DEFAULT_EXECUTION_TYPE parameter. Possible values are:
[TEST] EXECUTE – test-execute every SQL statement and collect its execution plans and execution statistics. The resulting plans and statistics will be stored in the advisor framework. This is default.
EXPLAIN PLAN – generate explain plan for every statement in the SQL workload. This is similar to the EXPLAIN PLAN command. The resulting plans will be stored in the advisor framework in association with the task.
COMPARE [PERFORMANCE] – analyze and compare two versions of SQL performance data. The performance data is generated by test-executing or generating explain plan of the SQL statements. Use this option when two executions of type EXPLAIN_PLAN or TEST_EXECUTE already exist in the task
CONVERT SQLSET – used to read the statistics captured in a SQL Tuning Set and model them as a task execution. This can be used when you wish to avoid executing the SQL statements because valid data for the experiment already exists in the SQL Tuning Set.


For 9i Upgrade to 10g


exec dbms_stats.gather_system_stats(gathering_mode=>'NOWORKLOAD');

alter system set "_optim_peek_user_binds"=false;           ==> 禁用BIND PEEK特性，该特性在10g中有

exec DBMS_STATS.SET_PARAM( 'method_opt','FOR ALL COLUMNS SIZE 1' );
commit;

9i

 /rdbms/admin/dbmssupp

exec dbms_support.start_trace(binds=>TRUE, waits=> FALSE);

exec dbms_support.stop_trace;

exec dbms_support.start_trace_in_session(sid=>sid,serial=>ser, binds=>TRUE, waits=>FALSE);

select sid,serial# from v$SESSION WHERE ... ;

exec dbms_support.stop_trace_in_session(sid=>SID,serial=>ser);

create table mapping_table tablespace USERS as
select object_id id, owner, substr(object_name, 1, 30) name
  from dba_objects
 where object_type not in ('CONSUMER GROUP',
                           'EVALUATION CONTEXT',
                           'FUNCTION',
                           'INDEXTYPE',
                           'JAVA CLASS',
                           'JAVA DATA',
                           'JAVA RESOURCE',
                           'LIBRARY',
                           'LOB',
                           'OPERATOR',
                           'PACKAGE',
                           'PACKAGE BODY',
                           'PROCEDURE',
                           'QUEUE',
                           'RESOURCE PLAN',
                           'SYNONYM',
                           'TRIGGER',
                           'TYPE',
                           'TYPE BODY')
union all
select user_id id, username owner, null name from dba_users;

declare
  mycur dbms_sqltune.sqlset_cursor;
begin
  dbms_sqltune.create_sqlset('9i_prod_wkld');
    open mycur for
      select value(p)
      from table(dbms_sqltune.select_sql_trace(
                   directory=>'SPADIR',
                   file_name=>'%trc',
                   mapping_table_name => 'MAPPING_TABLE',
                   select_mode => dbms_sqltune.single_execution)) p;
  dbms_sqltune.load_sqlset(
    sqlset_name => '9i_prod_wkld',
    populate_cursor => mycur,
    commit_rows => 1000);

  close mycur;
end;
/

create user spadba identified by oracle;
grant dba to spadba;
grant all on dbms_sqlpa to spadba;

create public database link to10g connect to spadba identified by oracle using 'STRINGS';

var sts_task varchar2(64);
exec :sts_task:= dbms_sqlpa.create_analysis_task(task_name => '9i_11g_spa1',description => 'experiment for 9i to 11gR2 upgrade',sqlset_name=> '9i_prod_wkld');

var exe_task varchar2(64);
exec :exe_task:=dbms_sqlpa.execute_analysis_task(task_name=>'9i_11g_spa1',execution_name=>'9i_trail1',execution_type=>'CONVERT SQLSET',execution_desc=>'9i sql trail generated from sts');

dbms_sqlpa.execute_analysis_task(task_name=>'9i_11g_spa1',execution_name=>'10g_trail1',execution_type=>'TEST EXECUTE',execution_desc=>'10g trail test',-
execution_params=>dbms_advisor.arglist('DATABASE_LINK','DBLINKNAME'));

select sofar,totalwork from V$ADVISOR_PROGRESS where task_id=<TID>;


如何诊断ORA-125XX连接问题
2012/01/25 BY MACLEAN LIU 暂无评论
以下这个Action Script是我收集的在解决ORA-125XX(如ORA-12560)这类网络链接故障时的一些思路，主要包括 现有的网络配置(client & server side)、监听日志、SQLNET Client trace等信息– How to troubleshooting ORA-125** connection issues：

ORA-12560

# CHECK FIREWALL, WINDOWS FIREWALL , ANTI-Virus Software First !
ping hostname
tnsping TNS
trcroute TNS
telnet  <hostname> <port>
tracert hostname
client side
sqlplus scott/tiger@TNS
&
server side
sqlplus scott/tiger@TNS
cat /etc/hosts
cat /etc/resolv.conf
cat /etc/nsswitch.conf
ipconfig -a
ping 127.0.0.1
$ORACLE_HOME/network/admin/sqlnet.ora
$ORACLE_HOME/network/admin/tnsnames.ora
$ORACLE_HOME/network/admin/listener.ora
$ORACLE_HOME/network/admin/endpoints_listener.ora
$ORACLE_HOME/network/log/*
sqlnet.log listener.log
/var/log/messages
/var/adm/messages
errpt -a
ls -ld $ORACLE_HOME
netstat -rn
ps -ef | grep -i tns
lsnrctl status {listener_name}
lsnrvtl services {listener_name}
ulimit -a
1. Complete database alert log.
2. If the database was not restarted from the time of last occurance of the
issue,
select * from v$resource_limit
3. RAM and SWAP configured on the server.
4. ulimit settings for oracle user:
ulimit -aS
ulimit -aH
5. Kernel parameter settings:
/etc/sysctl.conf
dblogin
show parameter cluster_database
show parameter listener
$srvctl config vip -n {nodename}
$lsnrctl status listener
agent.log and the crsd.log ..
crsd agent log and the crsd.log
$crsctl getperm resource ora.LISTENER.lsnr
sql net client trace , Client side tracing is done by adding the following syntax to the client’s sqlnet.ora file:
We will need a timestamped matching set of client/listener sqlnet traces while error is reproduced in order to find the root cause of the issue.
++ Enable client sqlnet tracing.
=======================
To do this add the following to client sqlnet.ora:
TRACE_LEVEL_CLIENT=16
TRACE_UNIQUE_CLIENT=TRUE
TRACE_DIRECTORY_CLIENT=path
TRACE_FILE_CLIENT=client
TRACE_TIMESTAMP_CLIENT=ON
replace path with a local directory for the trace files. (for example c:\temp)
Do a test connection from the problematic client and check if the trace files are created.
Upload the traces containing the error to me on metalink.
++ Enable listener sqlnet tracing.
==========================
To do this edit the listener.ora and add,
TRACE_LEVEL_{listener name}=16
TRACE_TIMESTAMP_{listener name}=TRUE
TRACE_DIRECTORY_{listener name}=/tmp {– this can be any directory other than a top level directory like / or c:\
Replace {listener name} with the name of the listener. For example if your listener was called LISTENER then TRACE_LEVEL_LISTENER=16
You need to restrict the amount of disk space used by the tracing then you must also set,
TRACE_FILELEN_{listener name}=500000 {– size of the files in K
TRACE_FILENO_{listener name}=10 {– number of files
This will limit the traces to 10 files of around 500Mb, so 5000Mb in total. When the 10th file is full it will reuse file number one.
You will need to stop/start the listener for this to take effect.
When the problem reproduces please can you upload the listener trace and the listener log.
Trace_level_client=16
Trace_directory_client={path_to_the_trace_directory} # use the full path to the trace directory
Trace_unique_client=on
Trace_timestamp_client=on
Diag_adr_enabled=off
trace Local listener or SCAN listeners
TRACE_LEVEL_{listener_name}= 16
TRACE_TIMESTAMP_{listener_name}=on
TRACE_DIRECTORY_{listener_name}={path_to_the_trace_directory}
truss -o /tmp/lisener.out -fae lsnrctl start {listener_name}
Some Useful Note:
Note.444705.1 TroubleShooting Guide For ORA-12514 TNS listener could not resolve SERVICE_NAME given in connect descriptor
Note.761740.1 Technicians Unable To Receive Orders While MWM Components Display ODBC Errors And Are Connected
Note.119007.1 ORA-12560: Administering the Listener on UNIX – Troubleshooting
Note 276812.1 TNS-12542 Error When Executing Batch Jobs or in High Transaction Environment
Note.219208.1 Ext/Pub Client Connection via Connect Manager Fails with TNS-12564
Note.393941.1 Ext/Mod ORA-12564 Reported When Using 10g Connection Manager
Note.1116960.1 ORA-609 TNS-12537 and TNS-12547 in 11g Alert.log
Note.550859.1 Abstract TROUBLESHOOTING GUIDE TNS-12518 TNS listener could not hand off client connection.
Note.207303.1 Client / Server / Interoperability Support Between Different Oracle Versions
Note.119706.1 Troubleshooting Guide TNS-12535 or ORA-12535 or ORA-12170 Errors
For database links between different Oracle versions connections must be supported in BOTH directions in the matrix found in Note 207303.1
eg: As 9.2 -} 7.3.4 is not supported then database links between these version
are not supported in either direction.
You are trying to connect two versions (client-server) that are not certified (as confirmed by Note 207303.1) and between which exist many technical incompatibilities.
CLIENT — LISTENER — SERVER RESULT
8 11.1 8 OK
9 11.1 9 OK
10 11.1 10 OK
11 11.1 11 OK
8 11.2 8 FAILS
9 11.2 9 OK
10 11.2 10 OK
11 11.2 11 OK
9 11.1 8 OK
10 11.1 8 OK
11 11.1 8 OK
9 11.2 8 FAILS
10 11.2 8 FAILS
11 11.2 8 FAILS
The relevant relationship that appears to be at issue is LISTENER and DATABASE. Client version is not a factor.
But if the ultimate outcome is that the 11.2 (11gR2) LISTENER is indicated (though I still haven’t seen documentation of this) as not compatible with use on a ORACLE 8i (8.1.7.0) DATABASE, then we’ll capture that here and move on. I would, however, like to see some evidence of this, if it is available. I can find notes in the KB about 10gR2′s listener not supporting 8i database, and I can find notes about 11gR1 having resolved that regression. But I can find nothing regarding listener/database compatibility that mentions 11gR2, that would explain our results.
Clients should be complied with Servers , For Sever 11.2 the only supported clients are 11.2.0 , 11.1.0 , 10.2.0 : 10g end MUST be at 10.2.0.2 (or higher) respectively in order to use PLSQL between those versions. See Note:4511371.8 for more details and finally 10.1.0.5 only with extended support .
On the other Side in order to connect from listener to DB server in a supported way , Listener version should be greater than or equal to the server version .
Note 207303.1 should still be followed.



oracle定义变量（常量）常用：declare、define、variable
1）define、variable用于sqlplus中，在整个sqlplus连接中都生效(until exit,disc是cut down session)，而declare用于pl/sql中。
2）variable（var）和define区别在于，前者用于绑定变量，后者是用于&或&&进行变量替换(使用场合,拿来当输入参数)。

define
SQL> define x='SCOTT'
SQL> define
DEFINE _DATE           = "29-9月 -13" (CHAR)
DEFINE _CONNECT_IDENTIFIER = "myorcl11" (CHAR)
DEFINE _USER           = "SYS" (CHAR)
DEFINE _PRIVILEGE      = "AS SYSDBA" (CHAR)
DEFINE _SQLPLUS_RELEASE = "1102000100" (CHAR)
DEFINE _EDITOR         = "vim" (CHAR)
DEFINE _O_VERSION      = "Oracle Database 11g Enterprise Edition Release 11.2.0.1.0 - Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options" (CHAR)
DEFINE _O_RELEASE      = "1102000100" (CHAR)
DEFINE X               = "SCOTT" (CHAR)
SQL> select distinct owner from dba_segments where wner='&x';
old   1: select distinct owner from dba_segments where wner='&x'
new   1: select distinct owner from dba_segments where wner='SCOTT'

OWNER
------------------------------------------------------------
SCOTT

var
SQL> var y numb
Usage: VAR[IABLE] [ <variable> [ NUMBER | CHAR | CHAR (n [CHAR|BYTE]) |
                    VARCHAR2 (n [CHAR|BYTE]) | NCHAR | NCHAR (n) |
                    NVARCHAR2 (n) | CLOB | NCLOB | BLOB | BFILE
                    REFCURSOR | BINARY_FLOAT | BINARY_DOUBLE ] ]
SQL> var y varchar2(20)
SQL> var
variable   y
datatype   VARCHAR2(20)
SQL> exec :y := 'SCOTT'

PL/SQL procedure successfully completed.

SQL> print :y

Y
-------
SCOTT

SQL> select distinct owner from dba_segments where owner=':y'; --wrong

no rows selected

SQL> select distinct owner from dba_segments where wner=:y;

OWNER
------------------------------------------------------------
SCOTT


SQL> variable dba varchar2(30)
SQL> exec :dba := dbms_utility.make_data_block_address(4, 20);

PL/SQL procedure successfully completed.
SQL> print dba
DBA
--------------------------------
16777236

执行存储过程：(加楼上共4种方法)

法1
BEGIN
    getDeptCount;
END;
法2
EXEC getDeptCount
法3
CALL  getDeptCount();
注意：

定义无参存储过程时，存储过程名后不能加()
在块中或是通过EXEC调用存储过程时可以省略()
通过CALL调用无参存储过程必须加上()

参数只能指定类型,不能指定长度精度范围,可以指定默认值：
varchar2(200)  ,只能用varchar2

    ...PROCEDURE add_deptno(v_deptno IN dept.deptno%TYPE,
                v_dname IN VARCHAR2,
                v_loc IN dept.loc%TYPE DEFAULT 'BEJING')...
给过程传递参数的方法：
    1，位置传递 exec add_dept(50,'SALES','BEIJING')
    2，名称传递 exec add_dept(v_dname=>'SALES',v_deptno=>50,v_loc=>'BEIJING')
    3，组合传递 exec add_dept(50,v_loc=>'BEIJING,v_dname=>'SALES')









以下脚本可以用于找出ASM存储中的Spfile参数文件，因为使用asmcmd去查找很不方便，而spfile丢失又是很头大的事情， 所以有一个脚本代劳可以省不少功夫呢！


--- listspfiles.sql
--- Purpose: Sample script to list spfiles kept in ASM instance
--- Usage: This should be run against an ASM instance,
--- not a database instance.
---
--- cut here --%<----%<----%<----%<----%<----%<--

--list all spfiles

set lines 120
col full_path for a110
SELECT full_path, dir, sys
FROM
(SELECT
CONCAT('+'||gname,SYS_CONNECT_BY_PATH(aname,'/')) full_path,
dir, sys FROM
(SELECT g.name gname,
a.parent_index pindex, a.name aname,
a.reference_index rindex, a.ALIAS_DIRECTORY dir,
a.SYSTEM_CREATED sys
FROM v$asm_alias a, v$asm_diskgroup g
WHERE a.group_number = g.group_number)
START WITH (MOD(pindex, POWER(2, 24))) = 0
CONNECT BY PRIOR rindex = pindex
ORDER BY dir desc, full_path asc)
WHERE UPPER(full_path) LIKE '%SPFILE%'
/

Sample output:

FULL_PATH                                                                                                      D S
-------------------------------------------------------------------------------------------------------------- - -
+DATA/Aspfile.ora                                                                                              N N
+DATA/VPROD/PARAMETERFILE/spfile.273.766620265                                                                 N Y
+DATA/VPROD/PARAMETERFILE/spfile.365.773976489                                                                 N Y
+DATA/VPROD/spfileVPROD.ora                                                                                    N N




[MySQLSlowlog]正确安全清空在线慢查询日志slowlog的流程
2014-02-14     我来说两句    来源：[MySQL Slow log]正确安全清空在线慢查询日志slow log的流程   收藏     我要投稿
1, see the slow log status;
mysql> show variables like '%slow%';
+---------------------+------------------------------------------+
| Variable_name | Value |
+---------------------+------------------------------------------+
| log_slow_queries | ON |
| slow_launch_time | 2 |
| slow_query_log | ON |
| slow_query_log_file | /mysqllog/slow_log/slow_queries_3306.log |
+---------------------+------------------------------------------+
4 rows in set (0.00 sec)

2, stop the slow log server.
mysql> set global slow_query_log=0;
Query OK, 0 rows affected (0.27 sec)

mysql> show variables like '%slow%';
+---------------------+------------------------------------------+
| Variable_name | Value |
+---------------------+------------------------------------------+
| log_slow_queries | OFF |
| slow_launch_time | 2 |
| slow_query_log | OFF |
| slow_query_log_file | /mysqllog/slow_log/slow_queries_3306.log |
+---------------------+------------------------------------------+
4 rows in set (0.00 sec)

mysql>
mysql> show variables like '%slow%'; -- check slow log status
+---------------------+------------------------------------------+
| Variable_name | Value |
+---------------------+------------------------------------------+
| log_slow_queries | OFF |
| slow_launch_time | 2 |
| slow_query_log | OFF |
| slow_query_log_file | /mysqllog/slow_log/slow_queries_3306.log |
+---------------------+------------------------------------------+
4 rows in set (0.00 sec)

3, reset the new path of slow log
mysql> set global slow_query_log_file='/mysqllog/slow_log/slow_queries_3306_new.log';
Query OK, 0 rows affected (0.03 sec)

4, start the slow log server
mysql>
mysql>
mysql> set global slow_query_log=1;
Query OK, 0 rows affected (0.01 sec)

mysql> show variables like '%slow%';
+---------------------+----------------------------------------------+
| Variable_name | Value |
+---------------------+----------------------------------------------+
| log_slow_queries | ON |
| slow_launch_time | 2 |
| slow_query_log | ON |
| slow_query_log_file | /mysqllog/slow_log/slow_queries_3306_new.log |
+---------------------+----------------------------------------------+
4 rows in set (0.00 sec)

5, check the slow sql in the new slow log file.
mysql> select sleep(10) as a, 1 as b;
+---+---+
| a | b |
+---+---+
| 0 | 1 |
+---+---+
1 row in set (10.00 sec)

mysql>
[mysql@xxx-xxx ~]$ more /mysqllog/slow_log/slow_queries_3306_new.log
......
Time Id Command Argument
# Time: 140213 6:44:24
# User@Host: root[root] @ localhost []
# Query_time: 10.000365 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 0
SET timestamp=1392273864;
select sleep(10) as a, 1 as b;

6, backup the old big slow log file to other directory.
mv /mysqllog/slow_log/slow_queries_3306.log /mysqlbackup/slow_log/slow_queries_3306.log.bak.20140213








How to Find which Session is Holding a Particular Library Cache Lock [ID 122793.1]【每日一译】--2012-11-13
2012-11-12 17:22 348人阅读 评论(0) 收藏 举报
目录( )[+]

白话一遍，简单可分两步去查找
1.
select  kgllkses saddr,kgllkhdl handle,kgllkmod mod,kglnaobj object
from x$kgllk lock_a
where kgllkmod > 0
and exists (select 1 from x$kgllk lock_b
where kgllkses in (select saddr from v$session where event= 'library cache lock')
and lock_a.kgllkhdl = lock_b.kgllkhdl
and kgllkreq > 0)
SADDR                                           HANDLE    MOD    OBJECT
0000000084C6B9C0    000000007DCD4AE0    3    PINING
2.
select sid,username,terminal,program,sql_id ,blocking_session from v$session where saddr in ('0000000084C6B9C0')
union all
select sid,username,terminal,program,sql_id ,blocking_session from v$session
where sid in (select blocking_session from v$session where saddr in ('0000000084C6B9C0'))
SID    USERNAME    TERMINAL    PROGRAM                   SQL_ID        BLOCKING_SESSION
194    AIKI    pts/3    sqlplus@kfctest (TNS V1-V3)    axdyhbwz084bp    209
209    AIKI    pts/2    sqlplus@kfctest (TNS V1-V3)    5whptv3nstk28


Applies to:
Oracle Server - Enterprise Edition - Version 9.2.0.1 and later
Oracle Server - Personal Edition - Version 9.2.0.1 and later
Oracle Server - Standard Edition - Version 9.2.0.1 and later
Information in this document applies to any platform.
Purpose
Purpose
In some situations it may happen that your session is hanging and is waiting for a 'Library cache lock'. This document describes how to find the session that  is holdig the lock that you are waiting for.
 在一些环境它将发生你的会话卡在那并且等待一个事件“LIBRARY CACHE LOCK'。这个文档描述了如何找到占用你等待锁的会话。
Scope and Application
Support Analysts and DBAs

Troubleshooting Steps

Common Situations
A DML operation that is hanging because the table which is accessed is currently undergoing changes (ALTER TABLE). This may take quite a long time depending on the size of the table and the type of the modification (e.g. ALTER TABLE x MODIFY (col1 CHAR(200) on a table with thousands of records)
In this case, V$LOCK will show that the session doing the 'ALTER TABLE' with an exclusive DML enqueue lock on the table object (LMODE=6, TYPE=TM where ID1 is the OBJECT_ID of the table). The waiting session however does not show up in V$LOCK yet so in an environment with a lot of concurrent sessions the V$LOCK information will be insufficient to track down the culprit blocking your operation.
The compilation of package will hang on Library Cache Lock and Library Cache Pin if any users are executing a procedure/function defined in the same package

常见情形
#一个DML操作挂起因为当前访问的表在经历修改（ALTER TABLE).这个可能会花费很长的时间，它取决于表的大小和修改的类型（如ALTER TABLE x MODIFY (col1 CHAR(200)在表上有几千行的记录）
在这种情况下，V$LOCK将显示会话正在做”ALTER TABLE“采用独占DML对列锁在表对象上（LMODE=6,TYPE=TM ID1是表的OBJECT_ID字段).等待会话不会显示在
V$LOCK视图，所以在存有许多并发会话的环境里，V$LOCK的信息将不足以跟踪到阻碍你操作的元凶。
#包的编译将因为LIBRARY CACHE LOCK和LIBRARY CACHE PIN事件挂起，如果任何用户执行一个过程/函数在同一个包体中的定义。
Method 1: Systemstate Analysis
Systemstate event will create a tracefile containing detailed information on every Oracle process. This information includes all the resources held & requested by a specific process.
方法1：系统状态分析
While an operation is hanging, open a new session and launch the following statement:
For Oracle 9.2.0.1 or higher:
$sqlplus '/ as sysdba'
oradebug setmypid
oradebug unlimit
oradebug dump systemstate 266

For older versions you can use the following syntax that is also possible in higher versions.The level 266 is not available before 9.2.0.6
对于老版本的DB，你可以使用如下的语法，它也可以用于高版本中。266级别在9.2.0.6之前是不可用的。
alter session set max_dump_file_size=unlimited;
alter session set events 'immediate trace name systemstate level 10'

 Oracle will create a systemstate tracefile in your USER_DUMP_DEST directory.
ORACLE将创建一个系统状态的跟踪文件在你的USER_DUMP_DEST目录里。
Get the PID (ProcessID) of the 'hanging' session:
--获取PID
select pid from v$process where addr=
(select paddr from v$session where sid= <sid_of_hanging_session> );

The systemstate dump contains a separate section with information for each process.
Open the tracefile and do a search for "PROCESS <PID from above>".
In the process section search for the wait event by doing a search on 'waiting for'.
系统状态的DUMP包含一个独立的部份的信息对于每一个进程。
打开跟踪文件并且执行一个关于”PROCESS PID“的搜索 --PID为上面找出的PID
在进程部份信息里查找关于‘WAITING FOR’的等待事件。
PROCESS 20:
----------------------------------------
SO: 0x7d2bd820, type: 2, owner: (nil), flag: INIT/-/-/0x00
(process) Oracle pid=20, calls cur/top: 0x7d3d62d0/0x7d3d85dc, flag: (0) -
int error: 0, call error: 0, sess error: 0, txn error 0
(post info) last post received: 109 0 4
last post received-location: kslpsr
last process to post me: 7d2b8d94 1 6
last post sent: 0 0 24
last post sent-location: ksasnd
last process posted by me: 7d2b8d94 1 6
(latch info) wait_event=0 bits=0
Process Group: DEFAULT, pseudo proc: 0x7d2ed5dc
O/S info: user: oracle, term: pts/7, ospid: 19759
OSD pid info: Unix process pid: 19759, image: goblin.forgotten.realms (TNS V1-V3)

<cut> --片段

(session) sid: 141 trans: (nil), creator: 0x7d2bd820, flag: (41) USR/- BSY/-/-/-/-/-
DID: 0001-0014-00000668, short-term DID: 0000-0000-00000000
txn branch: (nil)
oct: 6, prv: 0, sql: 0x62d01c34, psql: 0x7c20f24c, user: 542/SCOTT
service name: SYS$USERS
O/S info: user: oracle, term: pts/7, ospid: 19758, machine: goblin.forgotten.realms
program: sqlplus@goblin.forgotten.realms (TNS V1-V3)
application name: SQL*Plus, hash value=3669949024
waiting for 'library cache lock' blocking sess=0x(nil) seq=36 wait_time=0 seconds since wait started=11
handle address=62d064dc, lock address=79f88a68, 100*mode+namespace=c9

Use the handle address to find information on the object locked:
 #使用HANDLE ADDRESS去查找被锁对象的信息
SO: 0x79f88a68, type: 53, owner: 0x7d3d62d0, flag: INIT/-/-/0x00
LIBRARY OBJECT LOCK: lock=79f88a68 handle=62d064dc request=S
call pin=(nil) session pin=(nil) hpc=0000 hlc=0000
htl=0x79f88ab4[0x79e71e60,0x79e71e60] htb=0x79e71e60 ssga=0x79e716fc
user=7d3a13b8 session=7d3a13b8 count=0 flags=[0000] savepoint=0xce
LIBRARY OBJECT HANDLE: handle=62d064dc mtx=0x62d06590(0) cdp=0
name=SCOTT.EMPLOYEES

We see the library object lock is being requested in Shared mode (request=S)
Name of the the object is SCOTT.EMPLOYEES
我们看到LIBRARY的对象锁正被要求以共享模式（REQUEST=S)
对象的名称叫做SCOTT.EMPLOYEES
Use the 'handle address' to find the process that is holding the lock on  your resource by doing a search on the address within the same tracefile.
 #使用‘HANDLE ADDRESS'去查找占有资源锁的进程，在同一个跟踪文件里查找地址。
PROCESS 18:
----------------------------------------
SO: 0x7d2bcca8, type: 2, owner: (nil), flag: INIT/-/-/0x00
(process) Oracle pid=18, calls cur/top: 0x79f3ab84/0x7d3d5fc8, flag: (0) -
int error: 0, call error: 0, sess error: 0, txn error 0
(post info) last post received: 109 0 4
last post received-location: kslpsr
last process to post me: 7d2b8d94 1 6
last post sent: 0 0 24
last post sent-location: ksasnd
last process posted by me: 7d2b8d94 1 6

<cut>

SO: 0x75fe8f7c, type: 53, owner: 0x7b751914, flag: INIT/-/-/0x00
LIBRARY OBJECT LOCK: lock=75fe8f7c handle=62d064dc mode=X
call pin=(nil) session pin=(nil) hpc=0000 hlc=0000
htl=0x75fe8fc8[0x79f81790,0x79fc3ef8] htb=0x79f81790 ssga=0x79f8102c
user=7d3988d0 session=7d3988d0 count=1 flags=[0000] savepoint=0x146e
LIBRARY OBJECT HANDLE: handle=62d064dc mtx=0x62d06590(0) cdp=0
name=SCOTT.EMPLOYEES

From the output we can see that the Process 18 (pid)  is holding  an exclusive lock (mode=X) on the object we are trying to access. Using V$PROCESS and V$SESSION we can retrieve the sid, user, terminal, program,... for this process.

The actual statement that was launched by this session is also listed in the tracefile (statements and other library cache objects are preceded by 'name=').
从输出中我们可以看到PROCESS 18(PID)正占有排它锁（MODE=X）在我们试图访问的对象上。使用V$PROCESS和V$SESSION我们可以返回SID,USER,TEMINAL,PROGRAM,...对于这个进程。
 METHOD 2: EXAMINE THE X$KGLLK TABLE
The X$KGLLK table (accessible only as SYS/INTERNAL) contains all the library object locks (both held & requested) for all sessions and is more complete than the V$LOCK view although the column names don't always reveal their meaning.

You can examine the locks requested (and held) by the waiting session by looking up the session address (SADDR) in V$SESSION and doing the following select:
表X$KGLLK表（仅SYS/INTERNAL访问）包含了所有的库对象锁（占有的和要求的）对于所有的会话并且对比于V$LOCK它更全面的，只是列名通常不能显示它的意思。
select sid,saddr from v$session where event= 'library cache lock';

SID SADDR
---------- --------
16 572ed244


select kgllkhdl Handle,kgllkreq Request, kglnaobj Object
from x$kgllk where kgllkses = '572ed244'
and kgllkreq > 0;

HANDLE   REQUEST   OBJECT
-------- ---------- ------------------------------------------------------------
62d064dc          2 EMPLOYEES

This will show you the library cache lock requested by this session (KGLLKREQ > 0) where KGLNAOBJ contains the first 80 characters of the name of the object.The value in KGLLKHDL corresponds with the 'handle address' of the object in Method 1 Systemstate Analysis as shown above.
它显示了库缓存锁要求的锁对于这个用户（KGLLKREQ>0），KGLNAOBJ包含了对象名称的前80个字符。值KGLLKHDL对应于对象的’HANDLE ADDRESS‘ 在上面的系统分析方法1中。
 If we now match the KGLLKHDL with the handles of other sessions in X$KGLLK that should give us the address of the blocking session.The session holding the lock will have KGLLKMOD > 0 as it is holding the lock.
如果我们现在在X$KGLLK中去匹配KGLLKHDL值的其它用户，它将给出阻塞会话的地址。这个会话占有锁将拥有KGLLKMOD》0 当它占有锁时。
select kgllkses saddr,kgllkhdl handle,kgllkmod mod,kglnaobj object
from x$kgllk lock_a
where kgllkmod > 0
and exists (select lock_b.kgllkhdl from x$kgllk lock_b
where kgllkses = '572ed244' /* blocked session */
and lock_a.kgllkhdl = lock_b.kgllkhdl
and kgllkreq > 0);

SADDR     HANDLE   MOD
--------  -------- ----------
OBJECT
------------------------------------------------------------
572eac94  62d064dc          3
EMPLOYEES


If we look a bit further we can then again match KGLLKSES with SADDR in v$session to find further information on the blocking session:
如果我们看了更远一点，我们可以获得匹配KGLLKSES和在V$SESSION中的SADDR的值去发现阻塞会话的进一步信息。

select sid,username,terminal,program from v$session where saddr = '572eac94'

SID        USERNAME                  TERMINAL
---------- ------------------------------ ------------------------------
PROGRAM
------------------------------------------------
12          SCOTT                          pts/20
sqlplus@goblin.forgotten.realms (TNS V1-V3)


In the same way we can also find all the blocked sessions:
用同样的方法我们也可以查询所有被阻塞的会话：
select sid,username,terminal,program from v$session
where saddr in
(select kgllkses from x$kgllk lock_a
 where kgllkreq > 0
 and exists (select lock_b.kgllkhdl from x$kgllk lock_b
             where kgllkses = '572eac94' /* blocking session */
             and lock_a.kgllkhdl = lock_b.kgllkhdl
             and kgllkreq = 0)
);

SID        USERNAME                       TERMINAL
---------- ------------------------------ ------------------------------
PROGRAM
------------------------------------------------
13         SCOTT                           pts/22
sqlplus@goblin.forgotten.realms (TNS V1-V3)

16         SCOTT                           pts/7
sqlplus@goblin.forgotten.realms (TNS V1-V3)


Related Documents

Note:1020008.6 SCRIPT FULLY DECODED LOCKING SCRIPT
Note:1054939.6 COMPILATION OF PACKAGE IS HANGING ON LIBRARY CACHE LOCK



 Oracle Library Cache Lock 解决思路
分类： Oracle Troubleshooting 2012-09-07 23:26 10860人阅读 评论(3) 收藏 举报
librarycacheoraclesessionobjectnull

一.  Library Cache Lock



Library cacheHandle 里保存了lock 和 pin 的信息。而且在Library cache handle 和child cursor 上都有lock 和pin。它们称为library cache lock和library cache pin。

Library cachelock/pin是用来控制对librarycache object的并发访问的。Lock管理并发，pin管理一致性，lock是针对于librarycache handle, 而pin是针对于heap。
       当我们想要访问某个library cache object，我们首先要获得这个指向这个object的handle的lock，获得这个lock之后我们就需要pin住指向这个object的heap。

       当我们对包，存储过程，函数，视图进行编译的时候，Oracle就会在这些对象的handle上面首先获得一个library cache lock，然后再在这些对象的heap上获得pin，这样就能保证在编译的时候其它进程不会来更改这些对象的定义，或者将对象删除。

       当一个session对SQL语句进行硬解析的时候，这个session就必须获得librarycache lock，这样其他session就不能够访问或者更改这个SQL所引用的对象。如果这个等待事件花了很长时间，通常表明共享池太小(由于共享池太小，需要搜索free的chunk，或者将某些可以被移出的object page out，这样要花很长时间)，当然了，也有可能另外的session正在对object进行修改(比如split 分区),而当前session需要引用那个table，那么这种情况下我们必须等另外的session进行完毕。

Library Cache lock有3中模式：
       （1）Share(S):      当读取一个library cache object的时候获得
       （2）Exclusive(X):  当创建/修改一个library cache object的时候获得
       （3）Null(N)：     用来确保对象依赖性

       比如一个进程想要编译某个视图，那么就会获得一个共享锁，如果我们要create/drop/alter某个对象，那么就会获得exclusive lock。Null锁非常特殊，我们在任何可以执行的对象(cursor，function)上面都拥有NULL锁，我们可以随时打破这个NULL锁，当这个NULL锁被打破了,就表示这个对象被更改了，需要从新编译。
       NULL锁主要的目的就是标记某个对象是否有效。比如一个SQL语句在解析的时候获得了NULL 锁，如果这个SQL的对象一直在共享池中，那么这个NULL锁就会一直存在下去，当这个SQL语句所引用的表被修改之后，这个NULL锁就被打破了，因为修改这个SQL语句的时候会获得Exclusive 锁，由于NULL锁被打破了，下次执行这个SQL的时候就需要从新编译。

Library Cache pin有2种模式：
       （1）Share(S):      读取object heap
       （2）Exclusive(X)： 修改object heap

       当某个session想要读取object heap，就需要获得一个共享模式的pin，当某个session想要修改object heap，就需要获得排他的pin。当然了在获得pin之前必须获得lock。

       在Oracle10gR2中，library cache pin被library cache mutex 所取代。

Library cache latch用来控制对library cache object的并发访问。前面已经提到，我们要访问library cacheobject之前必须获得librarycache lock， lock不是一个原子操作(原子操作就是在操作程中不会被打破的操作，很明显这里的lock可以被打破), Oracle为了保护这个lock，引入了library cache latch机制，也就是说在获得library cachelock之前，需要先获得library cache latch，当获得library cache lock之后就释放librarycache latch。

       如果某个librarycache object没有在内存中，那么这个lock就不能被获取，这个时候需要获得一个library cache load lock latch，然后再获取一个librarycache load lock,当load lock获得之后就释放library cache load lock latch。

       librarycache latch受隐含参数_KGL_LATCH_COUNT的控制，默认值为大于等于系统中CPU个数的最小素数，但是Oracle对其有一个硬性限制，该参数不能大于67。
       注意：我们去查询_kgl_latch_count有时候显示为0,这是一个bug。

Oracle利用下面算法来确定library cache object handle是由哪个子latch来保护的：
       latch#= mod(bucket#, #latches)

       也就是说用哪个子latch去保护某个handle是根据那个handle所在的bucket号，以及总共有多少个子latch来进行hash运算得到的。


MOS 的文档【122793.1】里说导致librarycache lock通常有2种原因：

（1）A DML operation that is hangingbecause the table which is accessed is currently undergoing changes (ALTERTABLE). This may take quite a long time depending on the size of the table andthe type of the modification (e.g. ALTER TABLE x MODIFY (col1 CHAR(200) on atable with thousands of records)
In this case,V$LOCK will show that the session doing the 'ALTER TABLE' with an exclusive DMLenqueue lock on the table object (LMODE=6, TYPE=TM where ID1 is the OBJECT_IDof the table). The waiting session however does not show up in V$LOCK yet so inan environment with a lot of concurrent sessions the V$LOCK information will beinsufficient to track down the culprit blocking your operation.

（2）The compilation of package willhang on Library Cache Lock and Library Cache Pin if any users are executing aprocedure/function defined in the same package.


更多内容参考：
OracleLibrary cache 内部机制 说明
http://blog.csdn.net/tianlesoftware/article/details/6629869

OracleLibrary Cache 的lock 与 pin 说明
http://blog.csdn.net/tianlesoftware/article/details/6641440

OracleNamespace 说明
http://blog.csdn.net/tianlesoftware/article/details/6624122

一次librarycache pin故障的解决过程
http://blog.csdn.net/tianlesoftware/article/details/6638899


二.  处理Library cache lock

2.1 使用hanganalyze  + systemstat 分析

Systemstat 事件包含每个oracle 进程的详细信息。当操作hang住时，可以新开一个窗口，使用该事件，捕获相关信息。

Systemdump 级别说明：

LEVEL参数：
10   Dump all processes (IGN state)
5    Level 4 + Dump all processes involved in wait chains (NLEAF state)
4 Level 3 + Dump leaf nodes (blockers) in wait chains(LEAF,LEAF_NW,IGN_DMP state)
3    Level 2 + Dump only processes thought to be in a hang (IN_HANG state)
1-2  Only HANGANALYZE output, no process dump at all

level 266= SYSTEM STATE (level=10, withshort stacks) =  level 10 + short stacks
level 266 在level 10的基础上包含了进程的short stacks信息


Oracle 9.2.0.1 之后，执行如下脚本：
$sqlplus '/ as sysdba'
oradebugs etmypid
oradebug unlimit
oradebug dump systemstate 266
oradebug tracefile_name

systemstat 226级别在9.2.0.6 之前不可用，所以在之前的版本可以使用如下命令：
alter session set max_dump_file_size=unlimited;
alter session set events 'immediate trace name systemstate level 10'


先执行hanganalyze，如下：
SQL> oradebug setmypid
SQL>oradebug unlimit
SQL> oradebug setinst all
SQL> oradebug -g def hanganalyze 3;
SQL>oradebug tracefile_name

如下文件里其他session都被1169的阻塞：
State of ALL nodes
([nodenum]/cnode/sid/sess_srno/session/ospid/state/[adjlist]):
[1001]/1/1002/9/c00000063d7aff78/9720/NLEAF/[1169]
[1159]/1/1160/51635/c00000063d8dfc68/19539/NLEAF/[1169]
[1160]/1/1161/15627/c000000631959658/8818/NLEAF/[1169]
[1162]/1/1163/27931/c0000006398d7810/20170/NLEAF/[1169]
[1165]/1/1166/4003/c0000006358f4d58/22069/NLEAF/[1169]
[1166]/1/1167/45511/c0000006398d4868/15674/NLEAF/[1169]
[1167]/1/1168/46253/c00000063d8d9d18/29492/NLEAF/[1169]
[1169]/1/1170/9233/c0000006358f1db0/9434/LEAF_NW/
[1170]/1/1171/43901/c0000006398d18c0/13246/NLEAF/[1169]
[1171]/1/1172/53701/c00000063d8d6d70/13794/NLEAF/[1169]
[1172]/1/1173/23737/c000000631950760/25188/NLEAF/[1169]
[1173]/1/1174/28801/c0000006358eee08/24770/NLEAF/[1169]
[1175]/1/1176/25017/c00000063d8d3dc8/18795/NLEAF/[1169]
[1177]/1/1178/3/c0000006358ebe60/10170/NLEAF/[1169]

这里sess_srno 是v$session 中的serial#.
Ospid 是系统进程号。

找到了sid和serial# 就可以查看对应session 的信息，是什么操作。 如果session 没有sql_id, 那么可以进一步使用oradebug systemdump 对应的进程。 来查看信息。

SYS@dave2(db2)> oradebug setospid 9434
Oracle pid: 18, Unix processpid: 27028, image: oracledave2@db2
SYS@dave2(db2)> oradebug unlimit
Statement processed.
SYS@dave2(db2)> oradebug dump systemstate 10
Statement processed.
SYS@dave2(db2)> oradebug TRACEFILE_NAME
/u01/app/oracle/admin/dave2/udump/dave2_ora_27028.trc

SYS@dave2(db2)> oradebug close_trace
Statement processed.

然后使用awk来分析systemdump 的trace：
Oracle 使用ass.awk 工具查看system state dump 说明
http://blog.csdn.net/tianlesoftware/article/details/7237729

这里也可以直接用systemdump 查看所有的进程信息。


2.2 查看X$KGLLK表
The X$KGLLK table (accessibleonly as SYS/INTERNAL) contains all the library object locks (both held &requested) for all sessions and is more complete than the V$LOCK view althoughthe column names don't always reveal their meaning.
--X$KGLLK 表只能被SYS/INTERNAL用户访问，其包含所有library object locks的信息（held和requested）。


--查看等待事件为librarycache lock的session 的session address (SADDR):

SQL>select sid,saddr from v$session where event='library cache lock';
SID SADDR
---------- --------
16 572ed244

--从x$kgllk查看具体的锁信息：
select kgllkhdl Handle, kgllkreq Request,kglnaobj Object
  from x$kgllk
 where kgllkses = '572ed244'
   and kgllkreq > 0;


HANDLE      REQUEST   OBJECT
-------- ---------- -------------------
62d064dc          2EMPLOYEES


KGLLKREQ: This will show you the library cache lock requested by this session(KGLLKREQ > 0)
KGLNAOBJ:contains the first 80 characters of the name of the object.
KGLLKHDL:corresponds with the 'handle address' of the object


--然后根据KGLLKHDL从X$KGLLK查看KGLLKMOD > 0的session，其正在持有该锁：

select kgllkses saddr, kgllkhdl handle,kgllkmod mod, kglnaobj object
  from x$kgllk lock_a
 where kgllkmod > 0
   andexists (select lock_b.kgllkhdl
          from x$kgllk lock_b
         where kgllkses = '572ed244'/* blocked session*/
           and lock_a.kgllkhdl =lock_b.kgllkhdl
           and kgllkreq > 0);


SADDR    HANDLE         MOD    OBJECT
-------- ----------- ------- --------
572eac94  62d064dc      3      EMPLOYEES



--查看所有blocked的session：
selectsid, username,terminal, program
  from v$session
 where saddr in
       (select kgllkses
          from x$kgllk lock_a
         where kgllkreq > 0
           andexists (select lock_b.kgllkhdl
                  from x$kgllk lock_b
                 where kgllkses = '572eac94'/* blocking session*/
                   and lock_a.kgllkhdl =lock_b.kgllkhdl
                   and kgllkreq = 0));


--查看所有持有librarycache pin 或者lock的session 在做什么：

SELECT s.sid, kglpnmod"Mode",kglpnreq "Req", SPID "OS Process"
  FROM v$session_wait w,x$kglpn p, v$session s, v$process o
 WHERE p.kglpnuse =s.saddr
   AND kglpnhdl = w.p1raw
   and w.event like'%library cache %'
   and s.paddr = o.addr


2.3 处理问题
一般来说，使用2.1 或者2.2 的方法都可以找到library cache lock的根源，确定是哪个session 导致的，如我们上面的hanganalyze中，是1169的session。 我们只需要kill 掉这个session，其他的问题就会自动解决了。

先在DB级别kill session，如果kill 不了，在os 级别kill。

alter systemkill session '1170,9233';

注意在os 级别kill 之前，先用ps 命令查看一下该进程，如果是DB 进程，不可随意kill，否则会导致系统crash。

ps �0�2–ef|grep 9434
kill -9 9434


参考：
How to Find which Session is Holding a ParticularLibrary Cache Lock [ID 122793.1]








    在11gR1和11gR2的数据库使用RMAN执行duplicate ... from active database操作时遇到类似如下的错误：
Starting backup at 2013-01-22 20:19:41
using channel ORA_DISK_1
channel ORA_DISK_1: starting datafile copy
input datafile file number=00001 name=+DATA1/ractest/datafile/system.256.769378761
RMAN-03009: failure of backup command on ORA_DISK_1 channel at 01/22/2013 20:19:58
ORA-17628: Oracle error 19505 returned by remote Oracle server
continuing other job steps, job failed will not be re-run
channel ORA_DISK_1: starting datafile copy
input datafile file number=00002 name=+DATA1/ractest/datafile/sysaux.257.769378769
RMAN-03009: failure of backup command on ORA_DISK_1 channel at 01/22/2013 20:20:00
ORA-17628: Oracle error 19505 returned by remote Oracle server
continuing other job steps, job failed will not be re-run
channel ORA_DISK_1: starting datafile copy
input datafile file number=00003 name=+DATA1/ractest/datafile/undotbs1.258.769378771
RMAN-03009: failure of backup command on ORA_DISK_1 channel at 01/22/2013 20:20:02
ORA-17628: Oracle error 19505 returned by remote Oracle server
continuing other job steps, job failed will not be re-run
channel ORA_DISK_1: starting datafile copy
input datafile file number=00005 name=+DATA1/ractest/datafile/undotbs2.264.769379825
RMAN-03009: failure of backup command on ORA_DISK_1 channel at 01/22/2013 20:20:10
ORA-17628: Oracle error 19505 returned by remote Oracle server
continuing other job steps, job failed will not be re-run
channel ORA_DISK_1: starting datafile copy
input datafile file number=00004 name=+DATA1/ractest/datafile/users.259.769378773

请参考以下两篇METALINK文章：

ORA-17628, ORA-19505 during RMAN DUPLICATE FROM ACTIVE [ID 1331986.1]
修改时间:2012-6-1类型:PROBLEM状态:PUBLISHED优先级:3

In this Document
Symptoms
Changes
Cause
Solution
References
Applies to:
Oracle Server - Enterprise Edition - Version 11.1.0.7 and later
Information in this document applies to any platform.
Symptoms

The following error is reported trying to create a Physical Standby database   using "duplicate from active database" :
RMAN-00571: ===========================================================
RMAN-00569: =============== ERROR MESSAGE STACK FOLLOWS ===============
RMAN-00571: ===========================================================
RMAN-03002: failure of Duplicate Db command at 05/16/2011 09:54:23
RMAN-03015: error occurred in stored script. Memory Script
RMAN-03009: failure of backup command on disk2 channel at 05/16/2011 09:54:23
ORA-17628: Oracle error 19505 returned by remote Oracle server
Changes
One datafile  is not using OMF name while the rest of the datafiles are using OMF name.
Cause

This behaviour was analyzed in Bug 12609412:  ORA-17628 ORA-19505 DURING DUPLICATE FROM ACTIVE

Development confirmed that this behaviour is not a Bug and this is expected behavior.

The reason the duplicate of the database is failing is because there is no db_file_name_convert and the datafile that has an alias is not using an OMF name, so a new OMF name is not created for it and the filename is unchanged.

The parameter "parameter_value_convert"  changes the string  from 'xxx' to 'yyy' in other  initialization parameters, but not in the datafile names.  If the names of the datafiles are desired to be changed,  then  db_file_name_convert should be used
Solution

1. Use the parameter DB_FILE_NAME_CONVERT and specify the complete location of the datafile using alias :


RMAN> .....
       SET DB_FILE_NAME_CONVERT='+DATA/xxx/datafile','+DATA/yyy/datafile/'
      .....

or

2. Create the directory "xxx" in the diskgroup where the image copy is being created by the auxiliary database.

References
BUG:12609412 - ORA-17628 ORA-19505 DURING DUPLICATE FROM ACTIVE


另一篇文章是：

Duplicate from Active Database Failing with: RMAN-03009, ORA-17628, and ORA-19505 [ID 1439632.1]
修改时间:2012-3-23类型:PROBLEM状态:MODERATED优先级:3

In this Document
  Symptoms
  Cause
  Solution
This document is being delivered to you via Oracle Support's Rapid Visibility (RaV) process and therefore has not been subject to an independent technical review.
Applies to:
Oracle Server - Enterprise Edition - Version: 11.1.0.7 and later   [Release: 11.1 and later ]
Information in this document applies to any platform.
Symptoms
Recreating the standby database.

RMAN duplicate from active database failing with errors when the files already exist on disk under the same path and file name where the restore is being run.

The following errors reported:

RMAN-03009: failure of backup command on ORA_DISK_1 channel at 03/22/2012 09:44:43
ORA-17628: Oracle error 19505 returned by remote Oracle server

-From the RMAN Log:


RMAN>
Starting Duplicate Db at 22-MAR-12
using target database control file instead of recovery catalog
allocated channel: ORA_AUX_SBT_TAPE_1
channel ORA_AUX_SBT_TAPE_1: SID=262 device type=SBT_TAPE
channel ORA_AUX_SBT_TAPE_1: Data Protection for Oracle: version 5.4.1.0
allocated channel: ORA_AUX_DISK_1
channel ORA_AUX_DISK_1: SID=261 device type=DISK

contents of Memory Script.:
{
backup as copy reuse
file '/db_scb/oracle/product/11.1.0/db_1/dbs/orapwautobk' auxiliary format
'/db_scp/oracle/product/11.1.0/db_1/dbs/orapwautopr' ;
}
executing Memory Script

Starting backup at 22-MAR-12
allocated channel: ORA_DISK_1
channel ORA_DISK_1: SID=174 device type=DISK
Finished backup at 22-MAR-12

contents of Memory Script.:
{
backup as copy current controlfile for standby auxiliary format '/ora1_scp/oradata/autopr/control01.ctl';
restore clone controlfile to '/ora1_scp/oradata/autopr/control02.ctl' from
'/ora1_scp/oradata/autopr/control01.ctl';
restore clone controlfile to '/ora1_scp/oradata/autopr/control03.ctl' from
'/ora1_scp/oradata/autopr/control01.ctl';
sql clone 'alter database mount standby database';
}
executing Memory Script

Starting backup at 22-MAR-12
using channel ORA_DISK_1
channel ORA_DISK_1: starting datafile copy
copying standby control file
output file name=/db_scb/oracle/product/11.1.0/db_1/dbs/snapcf_autobk.f tag=TAG20120322T094333 RECID=17 STAMP=778585413
channel ORA_DISK_1: datafile copy complete, elapsed time: 00:00:01
Finished backup at 22-MAR-12

Starting restore at 22-MAR-12
using channel ORA_AUX_SBT_TAPE_1
using channel ORA_AUX_DISK_1

channel ORA_AUX_DISK_1: skipped, AUTOBACKUP already found
channel ORA_AUX_SBT_TAPE_1: copied control file copy
Finished restore at 22-MAR-12

Starting restore at 22-MAR-12
using channel ORA_AUX_SBT_TAPE_1
using channel ORA_AUX_DISK_1

channel ORA_AUX_DISK_1: skipped, AUTOBACKUP already found
channel ORA_AUX_SBT_TAPE_1: copied control file copy
Finished restore at 22-MAR-12

sql statement: alter database mount standby database

contents of Memory Script.:
{
set newname for tempfile 1 to
"/ora1_scp/oradata/autopr/temp01.dbf";
switch clone tempfile all;
set newname for datafile 1 to
"/ora1_scp/oradata/autopr/system01.dbf";
set newname for datafile 2 to
"/ora1_scp/oradata/autopr/sysaux01.dbf";
set newname for datafile 3 to
"/ora1_scp/oradata/autopr/undotbs01.dbf";
set newname for datafile 4 to
"/ora1_scp/oradata/autopr/users01.dbf";
set newname for datafile 5 to
"/ora1_scp/oradata/autopr/mdb_DATA.dbf";
set newname for datafile 6 to
"/ora1_scp/oradata/autopr/mdb_INDEX.dbf";
backup as copy reuse
datafile 1 auxiliary format
"/ora1_scp/oradata/autopr/system01.dbf" datafile
2 auxiliary format
"/ora1_scp/oradata/autopr/sysaux01.dbf" datafile
3 auxiliary format
"/ora1_scp/oradata/autopr/undotbs01.dbf" datafile
4 auxiliary format
"/ora1_scp/oradata/autopr/users01.dbf" datafile
5 auxiliary format
"/ora1_scp/oradata/autopr/mdb_DATA.dbf" datafile
6 auxiliary format
"/ora1_scp/oradata/autopr/mdb_INDEX.dbf" ;
sql 'alter system archive log current';
}
executing Memory Script

executing command: SET NEWNAME

renamed tempfile 1 to /ora1_scp/oradata/autopr/temp01.dbf in control file

executing command: SET NEWNAME

executing command: SET NEWNAME

executing command: SET NEWNAME

executing command: SET NEWNAME

executing command: SET NEWNAME

executing command: SET NEWNAME

Starting backup at 22-MAR-12
using channel ORA_DISK_1
channel ORA_DISK_1: starting datafile copy
input datafile file number=00001 name=/ora1_scb/oradata/autobk/system01.dbf
output file name=/ora1_scp/oradata/autopr/system01.dbf tag=TAG20120322T094356 RECID=0 STAMP=0
channel ORA_DISK_1: datafile copy complete, elapsed time: 00:00:45
channel ORA_DISK_1: starting datafile copy
input datafile file number=00002 name=/ora1_scb/oradata/autobk/sysaux01.dbf
RMAN-03009: failure of backup command on ORA_DISK_1 channel at 03/22/2012 09:44:43
ORA-17628: Oracle error 19505 returned by remote Oracle server
continuing other job steps, job failed will not be re-run
channel ORA_DISK_1: starting datafile copy
input datafile file number=00003 name=/ora1_scb/oradata/autobk/undotbs01.dbf
RMAN-03009: failure of backup command on ORA_DISK_1 channel at 03/22/2012 09:44:45
ORA-17628: Oracle error 19505 returned by remote Oracle server
continuing other job steps, job failed will not be re-run
channel ORA_DISK_1: starting datafile copy
input datafile file number=00005 name=/ora1_scb/oradata/autobk/mdb_DATA.dbf
RMAN-03009: failure of backup command on ORA_DISK_1 channel at 03/22/2012 09:44:46
ORA-17628: Oracle error 19505 returned by remote Oracle server
continuing other job steps, job failed will not be re-run
channel ORA_DISK_1: starting datafile copy
input datafile file number=00006 name=/ora1_scb/oradata/autobk/mdb_INDEX.dbf
RMAN-03009: failure of backup command on ORA_DISK_1 channel at 03/22/2012 09:44:47
ORA-17628: Oracle error 19505 returned by remote Oracle server
continuing other job steps, job failed will not be re-run
channel ORA_DISK_1: starting datafile copy
input datafile file number=00004 name=/ora1_scb/oradata/autobk/users01.dbf
RMAN-00571: ===========================================================
RMAN-00569: =============== ERROR MESSAGE STACK FOLLOWS ===============
RMAN-00571: ===========================================================
RMAN-03002: failure of Duplicate Db command at 03/22/2012 09:44:48
RMAN-03015: error occurred in stored script. Memory Script
RMAN-03009: failure of backup command on ORA_DISK_1 channel at 03/22/2012 09:44:48
ORA-17628: Oracle error 19505 returned by remote Oracle server

Cause
There was older copy of the database files under the same location where the duplicate is restoring. Files with the same name as well.

The datafiles under /ora1_scp/oradata/autopr on the standby already exist from previous database in this case.



Solution
Make sure you dont have already existing files with the same name under the same path where you trying to create the new database.

Delete the old datafiles from previous database under the location where you trying to restore the database. In this case under /ora1_scp/oradata/autopr
















sed -n '/CREATE.*/,/;/p'



sed -n '/CREATE CONTROLFILE.*NORESETLOGS/,/;/p' /u01/app/oracle/diag/rdbms/yft/yft/trace/yft_ora_3964.trc
202 CREATE CONTROLFILE REUSE DATABASE "YFT" RESETLOGS   FORCE LOGGING  NOARCHIVELOG
203     MAXLOGFILES 16
204     MAXLOGMEMBERS 3
205     MAXDATAFILES 100
206     MAXINSTANCES 8
207     MAXLOGHISTORY 292
208 LOGFILE
209   GROUP 1 '/u01/app/oracle/oradata/yft/redo01.log'  SIZE 50M BLOCKSIZE 512,
210   GROUP 2 '/u01/app/oracle/oradata/yft/redo02.log'  SIZE 50M BLOCKSIZE 512,
211   GROUP 3 '/u01/app/oracle/oradata/yft/redo03.log'  SIZE 50M BLOCKSIZE 512
212 -- STANDBY LOGFILE
213 DATAFILE
214   '/u01/app/oracle/oradata/yft/system01.dbf',
215   '/u01/app/oracle/oradata/yft/sysaux01.dbf',
216   '/u01/app/oracle/oradata/yft/undotbs01.dbf',
217   '/u01/app/oracle/oradata/yft/users01.dbf',
218   '/u01/app/oracle/oradata/yft/example01.dbf',
219   '/u01/app/oracle/oradata/yft/jack01.dbf'
220 CHARACTER SET AL32UTF8
221 ;


自动刷新网页
set wshshell = wscript.createobject ("wscript.shell")
wshshell.appactivate"henanyidong"
for i=1 to 1
wscript.sleep 10000
wshshell.sendkeys"{F5}"
next



On Error Resume Next
Set objExplorer = CreateObject("InternetExplorer.Application")
objExplorer.Navigate "http://request.paic.com.cn/request/request/requestSearch.screen"
objExplorer.Visible = 1
Wscript.Sleep 5000
Set objDoc = objExplorer.Document
Do While True
Wscript.Sleep 30000
objDoc.Location.Reload(True)
If Err <> 0 Then
Wscript.Quit
End If
Loop



set a =WScript.CreateObject("WScript.Shell") '插件WScript.Sehll象
app=a.Run("iexplore")'打IE浏览器
WScript.Sleep 1000 '停顿1000毫秒即1秒
a.AppActivate app
a.SendKeys "+{TAB}" '移光标浏览器址栏
a.SendKeys "http://request.paic.com.cn/request/request/requestSearch.screen" '输入网页址
a.SendKeys "{ENTER}" '按车键
  Do
    Wscript.Sleep 5000 '10秒刷新 自修改
    a.SendKeys "{F5}" '按F5刷新页面
  Loop
  '直循环、直打任务管理器结束wscript.exe进程 才退



dbms_stats与analyze

2012-06-22 12:56:26|  分类： 默认分类 |举报|字号 订阅
dbms_stats

DBMS_STATS.GATHER_TABLE_STATS的语法如下:
DBMS_STATS.GATHER_TABLE_STATS (ownname VARCHAR2, tabname VARCHAR2, partname VARCHAR2, estimate_percent NUMBER,   block_sample BOOLEAN, method_opt VARCHAR2, degree NUMBER, granularity VARCHAR2, cascade BOOLEAN, stattab VARCHAR2, statid VARCHAR2, statown VARCHAR2,   no_invalidate BOOLEAN, force BOOLEAN);
参数说明:
ownname:要分析表的拥有者
tabname:要分析的表名.
partname:分区的名字,只对分区表或分区索引有用.
estimate_percent:采样行的百分比,取值范围[0.000001,100],null为全部分析,不采样. 常量:DBMS_STATS.AUTO_SAMPLE_SIZE是默认值,由oracle决定最佳取采样值.
block_sapmple:是否用块采样代替行采样.
method_opt:决定histograms信息是怎样被统计的
通过设置 method_opt参数可以智能地生成直方图,具体取值如下:
for all columns:10g默认值(根据版本的不同，默认值也会有所差异)，统计所有列的histograms.
for all indexed columns:统计所有indexed列的histograms.
for all hidden columns:统计你看不到列的histograms
for columns <list> SIZE <N> | REPEAT | AUTO | SKEWONLY:统计指定列的histograms.N的取值范围[1,254];
REPEAT上次统计过的histograms;
AUTO由oracle决定N的大小;
SKEWONLY选项会耗费大量处理时间，因为它要检查每个索引中的每个列的值的分布情况。
假如dbms_stat发现一个索引的各个列分布得不均匀，就会为那个索引创建直方图，帮助基于代价的SQL优化器决定是进行索引访问，还是进行全表扫描访问。
degree:决定并行度.默认值为null.
granularity:设置分区表收集统计信息的粒度，分别有
all：对表达全局，分区，子分区的数据都做分析
auto：Oracle根据分区的类型，自动决定做哪一种粒度的分析
global：只做全局级别的分析
global and partition：只对全局和分区级别做分析，对子分区不做分析，这是和all的一个区别
partition：只做分区级别做分析
subpartition：只做子分区做分析
exec DBMS_STATS.GATHER_TABLE_STATS(NULL,'T3', GRANULARITY => 'SUBPARTITION', CASCADE => TRUE);
exec DBMS_STATS.GATHER_TABLE_STATS(NULL,'T2', GRANULARITY => 'PARTITION', CASCADE => TRUE);
exec DBMS_STATS.GATHER_TABLE_STATS(NULL,'T1', GRANULARITY => 'GLOBAL', CASCADE => TRUE);

其中，T1为全表，T2为分区，T3为子分区
cascace:是收集索引的信息.默认为falase.
stattab指定要存储统计信息的表；statid如果多个表的统计信息存储在同一个stattab中用于进行区分；statown存储统计信息表的拥有者。以上三个参数若不指定,统计信息会直接更新到数据字典.
no_invalidate: Does not invalidate the dependent cursors if set to TRUE. The procedure invalidates the dependent cursors immediately if set to FALSE.
force:即使表锁住了也收集统计信息.

dbms_stats的使用
dbms_stats包除了gather_table_stats过程外还有如下过程
EXPORT_COLUMN_STATS：导出列的分析信息
EXPORT_INDEX_STATS：导出索引分析信息
EXPORT_SYSTEM_STATS：导出系统分析信息
EXPORT_TABLE_STATS：导出表分析信息
EXPORT_SCHEMA_STATS：导出方案分析信息
EXPORT_DATABASE_STATS：导出数据库分析信息
IMPORT_COLUMN_STATS：导入列分析信息
IMPORT_INDEX_STATS：导入索引分析信息
IMPORT_SYSTEM_STATS：导入系统分析信息
IMPORT_TABLE_STATS：导入表分析信息
IMPORT_SCHEMA_STATS：导入方案分析信息
IMPORT_DATABASE_STATS：导入数据库分析信息
GATHER_INDEX_STATS：分析索引信息
GATHER_TABLE_STATS：分析表信息，当cascade为true时，分析表、列（索引）信息
GATHER_SCHEMA_STATS：分析方案信息
GET_COLUMN_STATS：获取字段的统计信息
GET_SYSTEM_STATS：获取系统的统计信息
GET_INDEX_STATS：获取索引的统计信息
GET_TABLE_STATS：获取表的统计信息
SET_COLUMN_STATS：设置字段的统计信息。通常应用在测试环境，也不排除在极端情况下起到奇效。
SET_SYSTEM_STATS：设置系统的统计信息
SET_INDEX_STATS：设置索引的统计信息
SET_TABLE_STATS：设置表的统计信息
DELETE_COLUMN_STATS：删除字段的统计信息
DELETE_SYSTEM_STATS：删除系统的统计信息
DELETE_INDEX_STATS：删除索引的统计信息
DELETE_TABLE_STATS：删除表的统计信息
DELETE_DATABASE_STATS：删除数据库的统计信息
DELETE_DICTIONARY_STATS：删除数据字典的统计信息
DELETE_SCHEMA_STATS：删除用户方案的统计信息
DELETE_FIXED_OBJECTS_STATS：删除固定对象的统计信息
GATHER_SCHEMA_STATS：分析方案信息
GATHER_DATABASE_STATS：分析数据库信息
GATHER_SYSTEM_STATS：分析系统信息
CREATE_STAT_TABLE：建立存放统计信息的表
DROP_STAT_TABLE：删除存放统计信息的表
LOCK_TABLE_STATS：锁定表的统计信息。当觉得当前统计信息非常好，且表数据几乎不变化时，可以考虑锁定统计信息，锁定之后相关的所有数据分析，包括表级，列级，直方图、索引的分析都将被锁定，不允许被更新。
LOCK_SCHEMA_STATS：锁定用户方案的统计信息
UNLOCK_TABLE_STATS：解锁表的统计信息
UNLOCK_SCHEMA_STATS：解锁用户方案的统计信息
RESTORE_SYSTEM_STATS：还原系统的统计信息
RESTORE_INDEX_STATS：还原索引的统计信息
RESTORE_TABLE_STATS：还原表的统计信息
RESTORE_DATABASE_STATS：还原数据库的统计信息
RESTORE_DICTIONARY_STATS：还原数据字典的统计信息
RESTORE_SCHEMA_STATS：还原用户方案的统计信息
RESTORE_FIXED_OBJECTS_STATS：还原固定对象的统计信息
统计信息还原过程如下
通过dbms_stats.get_stats_history_availability查找分析数据恢复到最早时间点，只有在这个时间点之后的分析数据才可以被恢复。
SQL> select dbms_stats.get_stats_history_availability from dual;

GET_STATS_HISTORY_AVAILABILITY
---------------------------------------------------------------------------
12-MAR-12 10.58.17.552941000 AM +08:00
查看最后一次分析表T的时间

SQL> select last_analyzed from user_tables where table_name='T';

LAST_ANALYZED
------------------
12-APR-12
恢复表T的统计信息
SQL>  exec  dbms_stats.rEstore_table_stats('HR','T','11-APR-12 10.58.17.552941000 AM +08:00');

PL/SQL procedure successfully completed.
再次查看最后一次分析表T的时间，恢复成功

SQL> select last_analyzed from user_tables where table_name='T';


LAST_ANALYZED
------------------
11-APR-12





我们在收集统计信息时，有可能由于统计信息收集错误，而额导致性能下降，这时我们就要保存之前收集的统计信息来快速恢复统计信息。下面就通过具体案例来贯穿dbms_stats的使用
1、首先创建一个分析表，该表是用来保存之前的分析值：
SQL> exec dbms_stats.create_stat_table('HR',stattab=>'STAT_TABLE');
PL/SQL procedure successfully completed.
2、收集表的统计信息:
SQL> exec dbms_stats.gather_table_stats(ownname=>'HR',tabname=>'T',ESTIMATE_PERCENT=>dbms_stats.auto_sample_size,METHOD_OPT=>'FOR ALL INDEXED COLUMNS',DEGREE=>4,CASCADE=>TRUE);
PL/SQL procedure successfully completed.
3、导出表分析信息到stat_table中
SQL> select count(*) from stat_table;
  COUNT(*)
----------
         0
SQL> exec dbms_stats.export_table_stats(ownname=>'HR',TABNAME=>'T',STATTAB=>'STAT_TABLE');
PL/SQL procedure successfully completed.
SQL> select count(*) from  stat_table;
  COUNT(*)
----------
         4
4、删除分析信息
SQL> exec dbms_stats.delete_table_stats(ownname=>'HR',TABNAME=>'T');
PL/SQL procedure successfully completed.
SQL> SELECT num_rows,blocks,empty_blocks as empty, avg_space, chain_cnt, avg_row_len FROM dba_tables WHERE owner = 'TEST'
AND table_name = 'T1';
NUM_ROWS     BLOCKS      EMPTY AVG_SPACE CHAIN_CNT AVG_ROW_LEN
---------- ---------- ---------- ---------- ---------- -----------
没有查到分析数据
5、导入统计信息
SQL> exec dbms_stats.import_table_stats(ownNAME=>'HR',TABNAME=>'T',STATTAB=>'STAT_TABLE');
PL/SQL procedure successfully completed.
SQL> select num_rows,blocks,empty_blocks,avg_space,chain_cnt from user_tables where table_name='T';
  NUM_ROWS     BLOCKS EMPTY_BLOCKS  AVG_SPACE  CHAIN_CNT
---------- ---------- ------------ ---------- ----------
     10104         20            0          0          0
可以查到分析数据

ANALYZE
analyze语法如下

ANALYZE
  { TABLE [ schema.]table
      [ PARTITION ( partition ) | SUBPARTITION ( subpartition ) ]
  | INDEX [ schema. ]index
      [ PARTITION ( partition ) | SUBPARTITION ( subpartition ) ]
  | CLUSTER [ schema. ]cluster
  }
  { COMPUTE [ SYSTEM ] STATISTICS [for_clause]
  | ESTIMATE [ SYSTEM ] STATISTICS [for_clause][SAMPLE integer { ROWS | PERCENT }]
  | validation_clauses
  | LIST CHAINED ROWS [ into_clause ]
  | DELETE [ SYSTEM ] STATISTICS
  } ;
PARTITION | SUBPARTITION：对分区表或索引进行分析
CLUSTER cluster:对簇进行分析，分析的结果会放在ALL_CLUSTERS, USER_CLUSTERS and DBA_CLUSTERS.
compute_statistics_clause
语法：COMPUTE [ SYSTEM ] STATISTICS [for_clause]
对分析对像进行精确的统计，然后把信息存储的数据字典中。可以选择对表或对字段进行分析。
computed和estimated这两种方式的统计数据都被优化器用来影响sql的执行计划
如果指定system选项就只统计系统产生的信息
for_clause
FOR TABLE：只统计表
FOR COLUMNS：只统计某个字段
FOR ALL COLUMNS：统计所有字段
FOR ALL INDEXED COLUMNS：统计索引的所有字段，如
analyze table t compute statistics for table for all indexed columns size  25;       #size为直方图的桶数
estimate_statistics_clause
ESTIMATE [ SYSTEM ] STATISTICS [for_clause][SAMPLE integer { ROWS | PERCENT }]
只是对部分行做一个大概的统计。适用于大表
SAMPLE：指定具体统计多少行，如果忽略这个参数的话，oracle会默认为1064行
ROWS causes：行数 Oracle to sample integer rows of the table or cluster or integer entries from the index. The integer must be at least 1.
PERCENT causes：百分数，如
ANALYZE TABLE employees ESTIMATE STATISTICS SAMPLE 100 ROWS;
ANALYZE TABLE employees ESTIMATE STATISTICS SAMPLE 15 PERCENT;
validation_clauses
分析REF(游标,动态关联结果集的临时对象)或是对像的结构，如
ANALYZE TABLE employees VALIDATE STRUCTURE CASCADE;
ANALYZE TABLE customers VALIDATE REF UPDATE;
analyze的限制
不可以分析数据字典表
Oracle 9i中不可以分析外部表，但可以用DBMS_STATS来实现这个目的
不可以分析临时表
不可以计算或估计下列字段类型
REFs, varrays, nested tables, LOBs (LOBs are not analyzed, they are skipped), LONGs, or object types.
统计信息相关的视图
对索引进行分析后，分析的结果默认会放在USER_INDEXES, ALL_INDEXES,或 DBA_INDEXES中
分析的内容：
Depth of the index from its root block to its leaf blocks (BLEVEL)
Number of leaf blocks (LEAF_BLOCKS)
Number of distinct index values (DISTINCT_KEYS)
Average number of leaf blocks for each index value (AVG_LEAF_BLOCKS_PER_KEY)
Average number of data blocks for each index value (for an index on a table) (AVG_DATA_BLOCKS_PER_KEY)
Clustering factor (how well ordered the rows are about the indexed values) (CLUSTERING_FACTOR)
对表进行分析后，分析的结果默认会放在USER_TABLES, ALL_TABLES, and DBA_TABLES表中，在分析表的时候，oracle也会分析基于函数的index所引用的表达式
分析的内容：
Number of rows (NUM_ROWS) *
Number of data blocks below the high water mark (that is, the number of data blocks that have been formatted to
receive data, regardless whether they currently contain data or are empty) (BLOCKS)
* Number of data blocks allocated to the table that have never been used (EMPTY_BLOCKS) Average available free
space in each data block in bytes (AVG_SPACE)
Number of chained rows (CHAIN_COUNT) Average row length, including the row's overhead, in bytes (AVG_ROW_LEN)
USER_TAB_COL_STATISTICS：用于存储与列相关的统计信息。
USER_HISTOGRAMS :用于存储与直方图相关的统计信息。

dbms_stats和analyze的使用场景

自dbms_stats推出后，Oracle就强烈建议在收集CBO统计信息时用dbms_stats替代analyze，原因如下：
1、dbms_stats可以并行分析
2、dbms_stats有自动分析的功能(alter table monitor )
3、analyze 分析分区表时统计信息不准确

关于第3点原因是，dbms_stats会实在的去分析表全局统计信息（当指定参数）；而analyze是将表分区（局部）的statistics 汇总计算成表全局statistics ,可能导致误差。
如果想分析整个用户或数据库，还可以采用工具包，可以并行分析
Dbms_utility(8i以前的工具包)
Dbms_stats(8i以后提供的工具包)，如
dbms_stats.gather_schema_stats(User,estimate_percent=>100,cascade=> TRUE);
dbms_stats.gather_table_stats(User,TableName,degree => 4,cascade => true);
既然dbms_stats相对于analyze有如此之多的优势，是否可以完全废弃analyze命令呢？答案是否定的，现在关于analyze的定位Oracle解释：
Use the ANALYZE statement (rather than DBMS_STATS) for statistics collection not related to the cost-based optimizer,for example:
1、Collect or delete statistics about an index or index partition, table or table partition, index-organized table, cluster, or scalar object attribute.
2、Validate the structure of an index or index partition, table or table partition, index-organized table, cluster, or object reference (REF).
3、Identify migrated and chained rows of a table or cluster.
可以看到analyze已经不是用来收集与CBO相关的统计信息了，而侧重于对象结构的分析。故通常我们会这样使用analyze:
1、通过Validate Structure来分析对象的结构信息
2、通过analyze….list chained rows收集块中行链接的信息。
注：必须先在执行analyze语句所在的schema内执行$ORACLE_HOME/rdbms/admin/utlchain.sql(或utlchn1.sql)脚本建立chained_rows表。在chained_rows建立之后﹐才能收集行链接信息
两个注意点

1、当某个索引处于monitoring usage的时候，如果使用dbms_stats去分析表并且同时分析索引，oracle会调用gather_index_stat来分析索引，需要用到索引名，故会将该索引的v$object_usage.USED设置为TRUE。analyze 虽然分析了索引，但是其实只需要obj#，不会将索引状态设置为USE = TRUE
2、dbms_stats无法分析cluster表，分析cluster表仍然需要analyze












 未启用归档数据库非数据文件(spfile,control,redo,undo,temp)全丢失的恢复方法
分类： ORACLE 2008-05-22 08:35 1682人阅读 评论(3) 收藏 举报
数据库databaseoraclesqlsystemdomain


本文介绍了一个未启用归档数据库的，没有任何备份，所有非数据文件(spfile,control,redo,undo,temp)全丢失的恢复方法。非数据文件包括启动参数文件、重做日志文件、撤消表空间及临时表空间文件。


测试环境：

假设一个数据库包括如下文件:

控制文件：
CONTROL01.CTL
CONTROL02.CTL
CONTROL03.CTL
重做日志文件：
REDO01.LOG
REDO02.LOG
REDO03.LOG
临时文件：
TEMP01.DBF
撤消表空间：
UNDOTBS01.DBF
数据文件：
DRSYS01.DBF
INDX01.DBF
SYSTEM01.DBF
TOOLS01.DBF
USERS01.DBF
XDB01.DBF

现在仅存在数据文件：
DRSYS01.DBF
INDX01.DBF
SYSTEM01.DBF
TOOLS01.DBF
USERS01.DBF
XDB01.DBF

其它文件都没有了，备份也没有，但是数据文件事务是完整的(上次是正常关闭)，且数据库未启用归档。

以下是恢复步骤：


1.创建启动参数文件
c:/mypfile.ora

启动参数可以从alert.log中启动信息中COPY下来，也可以自己手工写一个。
如下所示：
注：
由于撤消表空间文件没有，所以去除撤消段自动管理相关参数(undo_management,undo_retention,undo_tablespace)
control_files指定为你想要创建的新的控制文件

*.compatible='9.2.0.0.0'
*.control_files='H:/oracle/oradata/ydgl/control01.ctl','H:/oracle/oradata/ydgl/control02.ctl','H:/oracle/oradata/ydgl/control03.ctl'
*.db_block_size=8192
*.db_cache_size=25165824
*.db_domain=''
*.db_file_multiblock_read_count=16
*.db_name='ydgl'
*.instance_name='ydgl'
*.pga_aggregate_target=25165824
*.shared_pool_size=50331648
#*.undo_management='AUTO'
#*.undo_retention=10800
#*.undo_tablespace='UNDOTBS1'



2.重启服务(仅windows系统)

以下命令表示只启动ORACLE服务，不启动数据库实例。
oradim -stop -sid ydgl
oradim -startup -sid ydgl -starttype srvc


3.使用创建的pfile启动到未加载模式

startup nomount pfile='c:/mypfile.ora'


e:/>sqlplus

SQL*Plus: Release 9.2.0.1.0 - Production on 星期三 5月 21 21:51:19 2008

Copyright (c) 1982, 2002, Oracle Corporation.  All rights reserved.

请输入用户名:  / as sysdba
已连接到空闲例程。

SQL> startup nomount pfile='c:/mypfile.ora'
ORACLE 例程已经启动。

Total System Global Area  114367248 bytes
Fixed Size                   453392 bytes
Variable Size              88080384 bytes
Database Buffers           25165824 bytes
Redo Buffers                 667648 bytes
SQL>


4.使用resetlogs创建控制文件，创建后的控制文件由mypfile.ora中的*.control_files指定

CREATE CONTROLFILE REUSE DATABASE "YDGL" RESETLOGS  NOARCHIVELOG
    MAXLOGFILES 5
    MAXLOGMEMBERS 3
    MAXDATAFILES 100
    MAXINSTANCES 1
    MAXLOGHISTORY 1
LOGFILE--指定新的重做日志文件的组和位置(不一定要和原来一样)
  GROUP 1 'H:/ORACLE/ORADATA/YDGL/REDO01.LOG'  SIZE 10M,
  GROUP 2 'H:/ORACLE/ORADATA/YDGL/REDO02.LOG'  SIZE 10M,
  GROUP 3 'H:/ORACLE/ORADATA/YDGL/REDO03.LOG'  SIZE 10M
DATAFILE
  'H:/ORACLE/ORADATA/YDGL/SYSTEM01.DBF',
--  'H:/ORACLE/ORADATA/YDGL/UNDOTBS01.DBF',去除撤消表空间（因为文件不存在）
  'H:/ORACLE/ORADATA/YDGL/DRSYS01.DBF',
  'H:/ORACLE/ORADATA/YDGL/INDX01.DBF',
  'H:/ORACLE/ORADATA/YDGL/TOOLS01.DBF',
  'H:/ORACLE/ORADATA/YDGL/USERS01.DBF',
  'H:/ORACLE/ORADATA/YDGL/XDB01.DBF'
CHARACTER SET ZHS16GBK
;


5.使用重建的控制文件恢复数据库

RECOVER DATABASE USING BACKUP CONTROLFILE;

SQL> RECOVER DATABASE USING BACKUP CONTROLFILE;
ORA-00279: 更改 133071 (在 05/18/2008 17:46:33 生成) 对于线程 1 是必需的
ORA-00289: 建议: C:/ORACLE/ORA92/RDBMS/ARC00066.001
ORA-00280: 更改 133071 对于线程 1 是按序列 # 66 进行的


指定日志: {<RET>=suggested | filename | AUTO | CANCEL}
cancel
介质恢复已取消。
SQL>


6.设置_allow_resetlogs_corruption参数，并重启数据库到mount

修改mypfile.ora，增加_allow_resetlogs_corruption=true
这个参数的意思是允行打开重做日志文件损坏的数据库

*.compatible='9.2.0.0.0'
*.control_files='H:/oracle/oradata/ydgl/control01.ctl','H:/oracle/oradata/ydgl/control02.ctl','H:/oracle/oradata/ydgl/control03.ctl'
*.db_block_size=8192
*.db_cache_size=25165824
*.db_domain=''
*.db_file_multiblock_read_count=16
*.db_name='ydgl'
*.instance_name='ydgl'
*.pga_aggregate_target=25165824
*.shared_pool_size=50331648
#*.undo_management='AUTO'
#*.undo_retention=10800
#*.undo_tablespace='UNDOTBS1'
_allow_resetlogs_corruption=true



SQL> shutdown immediate;
ORA-01109: 数据库未打开


已经卸载数据库。
ORACLE 例程已经关闭。
SQL> startup mount pfile='c:/mypfile.ora'
ORACLE 例程已经启动。

Total System Global Area  114367248 bytes
Fixed Size                   453392 bytes
Variable Size              88080384 bytes
Database Buffers           25165824 bytes
Redo Buffers                 667648 bytes
数据库装载完毕。
SQL>



7.使用resetlogs打开数据库

SQL> alter database open resetlogs;

数据库已更改。


如果未执行第6步，不设置启动参数_allow_resetlogs_corruption=true，打开数据库时则会出现如下的错误提示：

SQL> alter database open resetlogs;
alter database open resetlogs
*
ERROR 位于第 1 行:
ORA-01113: 文件 1 需要介质恢复
ORA-01110: 数据文件 1: 'H:/ORACLE/ORADATA/YDGL/SYSTEM01.DBF'


8.检查丢失的表空间及数据文件

SQL> select a.ts#, a.name, b.file#, b.status, b.name  from ts$ a, v$datafile b where a.TS# = b.TS#(+);

       TS# NAME                                FILE# STATUS  NAME
---------- ------------------------------ ---------- ------- --------------------------------------------------------------------------------
         0 SYSTEM                                  1 SYSTEM  H:/ORACLE/ORADATA/YDGL/SYSTEM01.DBF
         1 UNDOTBS1                                2 RECOVER C:/ORACLE/ORA92/DATABASE/MISSING00002
         2 TEMP
         3 DRSYS                                   3 ONLINE  H:/ORACLE/ORADATA/YDGL/DRSYS01.DBF
         4 INDX                                    4 ONLINE  H:/ORACLE/ORADATA/YDGL/INDX01.DBF
         5 TOOLS                                   5 ONLINE  H:/ORACLE/ORADATA/YDGL/TOOLS01.DBF
         6 USERS                                   6 ONLINE  H:/ORACLE/ORADATA/YDGL/USERS01.DBF
         7 XDB                                     7 ONLINE  H:/ORACLE/ORADATA/YDGL/XDB01.DBF

8 rows selected

SQL>
从中可以看到撤消表空间UNDOTBS1及临时表空间TEMP文件还未恢复

9.增加临时表空间TEMP的文件

SQL> ALTER TABLESPACE TEMP ADD TEMPFILE 'H:/ORACLE/ORADATA/YDGL/TEMP01.DBF' SIZE 50M  REUSE AUTOEXTEND ON NEXT 655360  MAXSIZE 1000M;

Tablespace altered

10.恢复撤消表空间UNDOTBS1

由于撤消表空间的数据文件已经没有了，所以只能重建

首先需删除残余的表空间信息，然后再创建。

SQL> DROP TABLESPACE UNDOTBS1 INCLUDING CONTENTS AND DATAFILES;

Tablespace dropped

SQL> CREATE UNDO TABLESPACE "UNDOTBS1"  DATAFILE 'H:/oracle/oradata/ydgl/UNDOTBS01.dbf' SIZE 50M;

Tablespace created

SQL>


11.创建SPFILE，重启数据库
从mypfile.ora中取消恢复数据时使用的_allow_resetlogs_corruption=true
增加撤消段参数

*.compatible='9.2.0.0.0'
*.control_files='H:/oracle/oradata/ydgl/control01.ctl','H:/oracle/oradata/ydgl/control02.ctl','H:/oracle/oradata/ydgl/control03.ctl'
*.db_block_size=8192
*.db_cache_size=25165824
*.db_domain=''
*.db_file_multiblock_read_count=16
*.db_name='ydgl'
*.instance_name='ydgl'
*.pga_aggregate_target=25165824
*.shared_pool_size=50331648
*.undo_management='AUTO'
*.undo_retention=10800
*.undo_tablespace='UNDOTBS1'


--创建SPFILE
SQL> create spfile from pfile='c:/mypfile.ora';

文件已创建。


--重启数据库
SQL> shutdown immediate;
数据库已经关闭。
已经卸载数据库。
ORACLE 例程已经关闭。

SQL> startup;
ORACLE 例程已经启动。

Total System Global Area  114367248 bytes
Fixed Size                   453392 bytes
Variable Size              88080384 bytes
Database Buffers           25165824 bytes
Redo Buffers                 667648 bytes
数据库装载完毕。
数据库已经打开。
SQL> show parameter spfile;

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
spfile                               string      %ORACLE_HOME%/DATABASE/SPFILE%
                                                 ORACLE_SID%.ORA
SQL>


-----------恢复完成




















-- 数据库升级
alter database open resetlogs upgrade;

SYS@ zh10g SQL>alter database open;
ERROR:
ORA-03114: 未连接到 ORACLE

alter database open
*
第 1 行出现错误:
ORA-01092: ORACLE instance terminated. Disconnection forced
ORA-00704: bootstrap process failure
ORA-39700: database must be opened with UPGRADE option
进程 ID: 5144
会话 ID: 191 序列号: 1
SYS@ zh10g SQL>alter database open resetlogs upgrade;
ERROR:
ORA-04023: Object SYS.STANDARD could not be validated or authorized
Database altered.


-- 重建临时表空间
ALTER TABLESPACE TEMP ADD TEMPFILE 'D:\APP\ADMINISTRATOR\ORADATA\ZH10G\TEMP01.DBF' SIZE 100M REUSE;

-- UPGRADE模式执行catupgrd.sql脚本
spool upgrade.log
@ /rdbms/admin/catupgrd.sql

SYS@ zh10g SQL>@ /rdbms/admin/catupgrd.sql
DOC>#######################################################################
DOC>#######################################################################
DOC>
DOC>   The first time this script is run, there should be no error messages
DOC>   generated; all normal upgrade error messages are suppressed.
DOC>
DOC>   If this script is being re-run after correcting some problem, then
DOC>   expect the following error which is not automatically suppressed:
DOC>
DOC>   ORA-00001: unique constraint () violated
DOC>              possibly in conjunction with
DOC>   ORA-06512: at "", line NN
DOC>
DOC>   These errors will automatically be suppressed by the Database Upgrade
DOC>   Assistant (DBUA) when it re-runs an upgrade.
DOC>
DOC>#######################################################################
DOC>#######################################################################
DOC>#
DOC>######################################################################
DOC>######################################################################
DOC>    The following statement will cause an "ORA-01722: invalid number"
DOC>    error if the user running this script is not SYS.  Disconnect
DOC>    and reconnect with AS SYSDBA.
DOC>######################################################################
DOC>######################################################################
DOC>#
no rows selected
ERROR:
ORA-04023: Object SYS.STANDARD could not be validated or authorized

Disconnected from Oracle Database 11g Enterprise Edition Release 11.2.0.3.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

+ Dbua Upgrade Stops With Error Object ORA-04023:sys.standard could not validated or authorized when select a database for upgrade (Doc ID 1087737.1)
Applies to:
Oracle Database Upgrade Assistant - Version 11.2.0.0 to 11.2.0.0 [Release 11.2]
Information in this document applies to any platform.
Symptoms
Using DBUA to upgrade to 11GR2. Upgrade process stops with error :-
Object sys.standard could not validated or authorized when select a database for upgrade

Changes
One reason could be /etc/oratab has a wrong entry for the source DB location. Second reason could be that /etc/oratab entry has been modified to 11GR2 location before the upgrade is complete using DBUA.
Cause
The cause of the error is /etc/oratab has a wrong entry for the source DB location. Second reason could be that /etc/oratab entry has been modified to 11GR2 location before the upgrade is complete using DBUA.
Solution
The first thing is to refer to NOTE 729909.1 & see if it resolves the problem. The solution could be :-
Run the following query to check for DBUA test mode:
SELECT COUNT(*) FROM obj$ WHERE owner#=0 AND type#=2 AND name='PUIU$DBUA';
If the query returns a value greater than 0 (zero), then remove the PUIU$DBUA table and run DBUA again.

If the above solution does not work, then re-check the entry in /etc/oratab. Make sure that then DB being upgraded has correct ORACLE_HOME & no duplicate lines for the same ORACLE_HOME.
References
NOTE:729909.1 - Upgrading To Oracle11g And DBUA Reports ORA-4023 On SYS.STANDARD

+ Please note that when using DBUA you should not make any changes to the oratab file.  If you manually made changes to the oratab file, then undo them and put the original information back.  DBUA will make changes to the oratab file at the appropriate time during the upgrade.

-- 修复ORA-04023报错
sqlplus / as sysdba
drop table PUIU$DBUA;

spool upgrade.log
@ /rdbms/admin/catupgrd.sql

+ 脚本执行时间约：
    + 改善脚本执行时间方法：00:49:17
        + 在线日志容量增大，减少checkpoint not complete发生
        + 适当增加系统参数：
            SQL>alter system set java_pool_size=512M;
            SQL>alter system set shared_pool_size=800M;
正常结束状态：
SYS@ zh10g SQL>
SYS@ zh10g SQL>
SYS@ zh10g SQL>
SYS@ zh10g SQL>shutdown immediate;
数据库已经关闭。
已经卸载数据库。
ORACLE 例程已经关闭。
SYS@ zh10g SQL>
SYS@ zh10g SQL>
SYS@ zh10g SQL>
SYS@ zh10g SQL>DOC
DOC>#######################################################################
DOC>#######################################################################
DOC>
DOC>   The above sql script is the final step of the upgrade. Please
DOC>   review any errors in the spool log file. If there are any errors in
DOC>   the spool file, consult the Oracle Database Upgrade Guide for
DOC>   troubleshooting recommendations.
DOC>
DOC>   Next restart for normal operation, and then run utlrp.sql to
DOC>   recompile any invalid application objects.
DOC>
DOC>   If the source database had an older time zone version prior to
DOC>   upgrade, then please run the DBMS_DST package.  DBMS_DST will upgrade
DOC>   TIMESTAMP WITH TIME ZONE data to use the latest time zone file shipped
DOC>   with Oracle.
DOC>
DOC>#######################################################################
DOC>#######################################################################
DOC>#
SYS@ zh10g SQL>
SYS@ zh10g SQL>Rem Set errorlogging off
SYS@ zh10g SQL>SET ERRORLOGGING OFF;
SYS@ zh10g SQL>
SYS@ zh10g SQL>REM END OF CATUPGRD.SQL
SYS@ zh10g SQL>
SYS@ zh10g SQL>REM bug 12337546 - Exit current sqlplus session at end of catupgrd.sql.
SYS@ zh10g SQL>REM                This forces user to start a new sqlplus session in order
SYS@ zh10g SQL>REM                to connect to the upgraded db.
SYS@ zh10g SQL>exit
从 Oracle Database 11g Enterprise Edition Release 11.2.0.3.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options 断开
Note:【参考：11gr2 Upgrade, Re-Running catupgrd.sql Causes Ora-00001 Errors】
You canrerunthe catupgrd.sql script as many times as necessary. The firsttimeyou run the script, there should be no error messages returned. If yourerunthe script, then the ORA-00001 messageisdisplayed. You can safely ignore this message.

-- 显示升级过程摘要信息
@ /rdbms/admin/utlu112s.sql

+ 正常状态结束：
SYS@ zh10g SQL>@ /rdbms/admin/utlu112s.sql
.
Oracle Database 11.2 Post-Upgrade Status Tool           12-04-2013 17:31:00
.
Component                               Current      Version     Elapsed Time
Name                                    Status       Number      HH:MM:SS
.
Oracle Server
.   ORA-00942: 表或视图不存在
.                                         VALID      11.2.0.3.0  00:11:59
JServer JAVA Virtual Machine
.                                         VALID      11.2.0.3.0  00:08:01
Oracle Workspace Manager
.                                         VALID      11.2.0.3.0  00:00:26
OLAP Analytic Workspace
.                                         VALID      11.2.0.3.0  00:00:19
OLAP Catalog
.                                         VALID      11.2.0.3.0  00:00:43
Oracle OLAP API
.                                         VALID      11.2.0.3.0  00:00:20
Oracle Enterprise Manager
.                                         VALID      11.2.0.3.0  00:08:45
Oracle XDK
.                                         VALID      11.2.0.3.0  00:02:03
Oracle Text
.                                         VALID      11.2.0.3.0  00:00:45
Oracle XML Database
.                                         VALID      11.2.0.3.0  00:03:44
Oracle Database Java Packages
.                                         VALID      11.2.0.3.0  00:00:13
Oracle Multimedia
.                                         VALID      11.2.0.3.0  00:03:03
Spatial
.                                         VALID      11.2.0.3.0  00:05:39
Oracle Expression Filter
.                                         VALID      11.2.0.3.0  00:00:10
Oracle Rules Manager
.                                         VALID      11.2.0.3.0  00:00:08
Gathering Statistics
.                                                                00:02:47
Total Upgrade Time: 00:49:17
PL/SQL 过程已成功完成。

_USER@ _CONNECT_IDENTIFIER SQL>select comp_id, version, status from DBA_registry;

COMP_ID                                                      VERSION                                              STATUS
------------------------------------------------------------ ------------------------------------------------------------
----------
EM                                                           11.2.0.3.0                                           VALID
AMD                                                          11.2.0.3.0                                           VALID
SDO                                                          11.2.0.3.0                                           VALID
ORDIM                                                        11.2.0.3.0                                           VALID
XDB                                                          11.2.0.3.0                                           VALID
CONTEXT                                                      11.2.0.3.0                                           VALID
ODM                                                          11.2.0.3.0                                           VALID
EXF                                                          11.2.0.3.0                                           VALID
RUL                                                          11.2.0.3.0                                           VALID
OWM                                                          11.2.0.3.0                                           VALID
CATALOG                                                      11.2.0.3.0                                           VALID
CATPROC                                                      11.2.0.3.0                                           VALID
JAVAVM                                                       11.2.0.3.0                                           VALID
XML                                                          11.2.0.3.0                                           VALID
CATJAVA                                                      11.2.0.3.0                                           VALID
APS                                                          11.2.0.3.0                                           VALID
XOQ                                                          11.2.0.3.0                                           VALID

已选择17行。

-- 迁移Baseline数据
@ /rdbms/admin/catuppst.sql
+ 脚本执行时间约：00:00:30

SYS@ zh10g SQL>@ /rdbms/admin/catuppst.sql
TIMESTAMP
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
--------------------------------------------------------
COMP_TIMESTAMP POSTUP_BGN 2013-12-04 17:37:38

PL/SQL 过程已成功完成。

This script will migrate the Baseline data on a pre-11g database
to the 11g database.
Move BL Data "SYS"."WRH$_FILESTATXS" (0 rows in 0 seconds)
Move BL Data "SYS"."WRH$_SQLSTAT" (0 rows in 0 seconds)
Move BL Data "SYS"."WRH$_SYSTEM_EVENT" (0 rows in 0 seconds)
Move BL Data "SYS"."WRH$_WAITSTAT" (0 rows in 0 seconds)
Move BL Data "SYS"."WRH$_LATCH" (0 rows in 0 seconds)
Move BL Data "SYS"."WRH$_LATCH_CHILDREN" (0 rows in 0 seconds)
Move BL Data "SYS"."WRH$_LATCH_PARENT" (0 rows in 0 seconds)
Move BL Data "SYS"."WRH$_LATCH_MISSES_SUMMARY" (0 rows in 0 seconds)
Move BL Data "SYS"."WRH$_DB_CACHE_ADVICE" (0 rows in 0 seconds)
Move BL Data "SYS"."WRH$_ROWCACHE_SUMMARY" (0 rows in 0 seconds)
Move BL Data "SYS"."WRH$_SGASTAT" (0 rows in 0 seconds)
Move BL Data "SYS"."WRH$_SYSSTAT" (0 rows in 0 seconds)
Move BL Data "SYS"."WRH$_PARAMETER" (0 rows in 0 seconds)
Move BL Data "SYS"."WRH$_SEG_STAT" (0 rows in 0 seconds)
Move BL Data "SYS"."WRH$_DLM_MISC" (0 rows in 0 seconds)
Move BL Data "SYS"."WRH$_SERVICE_STAT" (0 rows in 0 seconds)
Move BL Data "SYS"."WRH$_TABLESPACE_STAT" (0 rows in 0 seconds)
Move BL Data "SYS"."WRH$_OSSTAT" (0 rows in 0 seconds)
Move BL Data "SYS"."WRH$_SYS_TIME_MODEL" (0 rows in 0 seconds)
Move BL Data "SYS"."WRH$_SERVICE_WAIT_CLASS" (0 rows in 0 seconds)
Move BL Data "SYS"."WRH$_INST_CACHE_TRANSFER" (0 rows in 0 seconds)
Move BL Data "SYS"."WRH$_ACTIVE_SESSION_HISTORY" (0 rows in 0 seconds)
...                                       ...
... Completed Moving the Baseline Data    ...
...                                       ...
... If there are no Move BL Data messages ...
... above, then there are no renamed      ...
... baseline tables in the system.        ...
...                                       ...
Drop Renamed Baseline Table SYS."WRH$_FILESTATXS_BR"
Drop Renamed Baseline Table SYS."WRH$_SQLSTAT_BR"
Drop Renamed Baseline Table SYS."WRH$_SYSTEM_EVENT_BR"
Drop Renamed Baseline Table SYS."WRH$_WAITSTAT_BR"
Drop Renamed Baseline Table SYS."WRH$_LATCH_BR"
Drop Renamed Baseline Table SYS."WRH$_LATCH_CHILDREN_BR"
Drop Renamed Baseline Table SYS."WRH$_LATCH_PARENT_BR"
Drop Renamed Baseline Table SYS."WRH$_LATCH_MISSES_SUMMARY_BR"
Drop Renamed Baseline Table SYS."WRH$_DB_CACHE_ADVICE_BR"
Drop Renamed Baseline Table SYS."WRH$_ROWCACHE_SUMMARY_BR"
Drop Renamed Baseline Table SYS."WRH$_SGASTAT_BR"
Drop Renamed Baseline Table SYS."WRH$_SYSSTAT_BR"
Drop Renamed Baseline Table SYS."WRH$_PARAMETER_BR"
Drop Renamed Baseline Table SYS."WRH$_SEG_STAT_BR"
Drop Renamed Baseline Table SYS."WRH$_DLM_MISC_BR"
Drop Renamed Baseline Table SYS."WRH$_SERVICE_STAT_BR"
Drop Renamed Baseline Table SYS."WRH$_TABLESPACE_STAT_BR"
Drop Renamed Baseline Table SYS."WRH$_OSSTAT_BR"
Drop Renamed Baseline Table SYS."WRH$_SYS_TIME_MODEL_BR"
Drop Renamed Baseline Table SYS."WRH$_SERVICE_WAIT_CLASS_BR"
Drop Renamed Baseline Table SYS."WRH$_INST_CACHE_TRANSFER_BR"
Drop Renamed Baseline Table SYS."WRH$_ACTIVE_SESSION_HISTORY_BR"
...                                       ...
... Completed the Dropping of the         ...
... Renamed Baseline Tables               ...
...                                       ...
... If there are no Drop Table messages   ...
... above, then there are no renamed      ...
... baseline tables in the system.        ...
...                                       ...
PL/SQL 过程已成功完成。

已创建 0 行。

提交完成。

表已创建。

已创建 2 行。

已更新 1 行。

已更新2行。

已更新0行。

表已删除。

提交完成。

已更新0行。

提交完成。

已更新0行。

提交完成。

已更新0行。

提交完成。

已创建 0 行。

提交完成。

已创建 0 行。

提交完成。

PL/SQL 过程已成功完成。
TIMESTAMP
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
--------------------------------------------------------
COMP_TIMESTAMP POSTUP_END 2013-12-04 17:37:42

PL/SQL 过程已成功完成。

PL/SQL 过程已成功完成。

PL/SQL 过程已成功完成。
Generating apply and rollback scripts...
Check the following file for errors:
D:\app\Administrator\cfgtoollogs\catbundle\catbundle_PSU_ZH10G_GENERATE_2013Dec04_17_37_49.log
Apply script: D:\app\Administrator\product\11.2.0\dbhome_1\rdbms\admin\catbundle_PSU_ZH10G_APPLY.sql
Rollback script: D:\app\Administrator\product\11.2.0\dbhome_1\rdbms\admin\catbundle_PSU_ZH10G_ROLLBACK.sql
PL/SQL 过程已成功完成。
Executing script file...
SYS@ zh10g SQL>COLUMN spool_file NEW_VALUE spool_file NOPRINT
SYS@ zh10g SQL>SELECT 'D:\app\Administrator\cfgtoollogs\catbundle\' || 'catbundle_PSU_' || name || '_APPLY_' || TO_CHAR(SYSDATE, 'YYYYMonDD_hh24_mi_ss', 'NLS_DATE_LANGUAGE=''AMERICAN''') || '.log' AS
spool_file FROM v$database;
SYS@ zh10g SQL>SPOOL &spool_file
SYS@ zh10g SQL>exec dbms_registry.set_session_namespace('SERVER')
PL/SQL 过程已成功完成。
SYS@ zh10g SQL>ALTER SESSION SET current_schema = SYS;
会话已更改。
SYS@ zh10g SQL>PROMPT Updating registry...
Updating registry...
SYS@ zh10g SQL>INSERT INTO registry$history
  2    (action_time, action,
  3     namespace, version, id,
  4     bundle_series, comments)
  5  VALUES
  6    (SYSTIMESTAMP, 'APPLY',
  7     SYS_CONTEXT('REGISTRY$CTX','NAMESPACE'),
  8     '11.2.0.3',
  9     0,
 10     'PSU',
 11     'Patchset 11.2.0.2.0');
已创建 1 行。
SYS@ zh10g SQL>COMMIT;
提交完成。
SYS@ zh10g SQL>SPOOL off
SYS@ zh10g SQL>SET echo off
Check the following log file for errors:
D:\app\Administrator\cfgtoollogs\catbundle\catbundle_PSU_ZH10G_APPLY_2013Dec04_17_37_51.log

-- 重编译无效对象
select count(*) from dba_invalid_objects;

@ /rdbms/admin/utlrp.sql
+ 脚本执行时间约：00:02:00

SYS@ zh10g SQL>select count(*) from dba_invalid_objects;
  COUNT(*)
----------
      5954

-- 查询组件状态
col comp_name for a40
set wrap off
select comp_name,version, statusfrom dba_registry;

SYS@ zh10g SQL>select comp_name,version, status from dba_registry;
COMP_NAME                                VERSION                                                      STATUS
---------------------------------------- ------------------------------------------------------------ -------
Oracle Enterprise Manager                11.2.0.3.0                                                   VALID
OLAP Catalog                             11.2.0.3.0                                                   VALID
Spatial                                  11.2.0.3.0                                                   VALID
Oracle Multimedia                        11.2.0.3.0                                                   VALID
Oracle XML Database                      11.2.0.3.0                                                   VALID
Oracle Text                              11.2.0.3.0                                                   VALID
Oracle Data Mining                       11.2.0.3.0                                                   VALID
Oracle Expression Filter                 11.2.0.3.0                                                   VALID
Oracle Rules Manager                     11.2.0.3.0                                                   VALID
Oracle Workspace Manager                 11.2.0.3.0                                                   VALID
Oracle Database Catalog Views            11.2.0.3.0                                                   VALID
Oracle Database Packages and Types       11.2.0.3.0                                                   VALID
JServer JAVA Virtual Machine             11.2.0.3.0                                                   VALID
Oracle XDK                               11.2.0.3.0                                                   VALID
Oracle Database Java Packages            11.2.0.3.0                                                   VALID
OLAP Analytic Workspace                  11.2.0.3.0                                                   VALID
Oracle OLAP API                          11.2.0.3.0                                                   VALID
已选择17行。


utlu112i.sql这个脚本已经out了，最新的是utlu112i_2.sql
How to Download and Run Oracle's Database Pre-Upgrade Utility [ID 884522.1]

好像就是timezone文件版本的区别



今天在重启一个库的时候，由于等了超过半小时，仍然没有完成数据库的close，于是就用shutdown abort命令关闭数据库。但是在起来的时候，发现在alertlog中有大量的SMON的报错，而且还在持续不断的报错出来。

<--- 正常的启动信息 begin here --->
Mon Sep  1 16:32:02 2008
Starting ORACLE instance (normal)
LICENSE_MAX_SESSION = 0
LICENSE_SESSIONS_WARNING = 0
SCN scheme 1
Using log_archive_dest parameter default value
LICENSE_MAX_USERS = 0
SYS auditing is disabled
Starting up ORACLE RDBMS Version: 9.2.0.6.0.
System parameters with non-default values:
  processes                = 1200
  timed_statistics         = TRUE
  shared_pool_size         = 419430400
  sga_max_size             = 2108652208
  large_pool_size          = 117440512
  java_pool_size           = 117440512
  spfile                   = /dev/vg_ora01/rspfile_128m_01
  control_files            = /dev/vg_ora01/rctrl_128m_01, /dev/vg_ora02/rctrl_128m_02
  db_block_size            = 8192
  db_cache_size            = 1258291200
  compatible               = 9.2.0.0.0
  log_archive_start        = TRUE
  log_archive_dest_1       = location=/arch
  log_archive_format       = arch_%t_%s.arc
  log_buffer               = 10485760
  db_files                 = 800
  db_file_multiblock_read_count= 16
  fast_start_mttr_target   = 300
  undo_management          = AUTO
  undo_tablespace          = UNDOTBS1
  undo_suppress_errors     = TRUE
  undo_retention           = 10800
  remote_login_passwordfile= EXCLUSIVE
  db_domain                =
  instance_name            = gdmocs
  job_queue_processes      = 6
  hash_join_enabled        = TRUE
  background_dump_dest     = /oracle/app/oracle/admin/gdmocs/bdump
  user_dump_dest           = /oracle/app/oracle/admin/gdmocs/udump
  core_dump_dest           = /oracle/app/oracle/admin/gdmocs/cdump
  sort_area_size           = 524288
  db_name                  = gdmocs
  open_cursors             = 500
  star_transformation_enabled= FALSE
  query_rewrite_enabled    = TRUE
  pga_aggregate_target     = 524288000
PMON started with pid=2
DBW0 started with pid=3
LGWR started with pid=4
CKPT started with pid=5
SMON started with pid=6
RECO started with pid=7
CJQ0 started with pid=8
Mon Sep  1 16:32:03 2008
ARCH: STARTING ARCH PROCESSES
ARC0 started with pid=9
ARC0: Archival started
ARC1 started with pid=10
ARC1: Archival started
Mon Sep  1 16:32:03 2008
ARCH: STARTING ARCH PROCESSES COMPLETE
Mon Sep  1 16:32:03 2008
ARC1: Thread not mounted
Mon Sep  1 16:32:03 2008
ARC0: Thread not mounted
Mon Sep  1 16:32:03 2008
ALTER DATABASE   MOUNT
Mon Sep  1 16:32:07 2008
Successful mount of redo thread 1, with mount id 2193310019
Mon Sep  1 16:32:07 2008
Database mounted in Exclusive Mode.
Completed: ALTER DATABASE   MOUNT
Mon Sep  1 16:32:07 2008
<--- 正常的启动信息 end here --->

<--- 开始打开数据，发现需要做实例恢复 begin here --->
ALTER DATABASE OPEN
Mon Sep  1 16:32:08 2008
Beginning crash recovery of 1 threads
Mon Sep  1 16:32:08 2008
Started redo scan
Mon Sep  1 16:32:09 2008
Completed redo scan
 27274 redo blocks read, 46702 data blocks need recovery
Mon Sep  1 16:35:20 2008
<--- 开始打开数据，发现需要做实例恢复 end --->

<--- 开始实例恢复 --->
Started recovery at
 Thread 1: logseq 24462, block 231548, scn 0.0
Mon Sep  1 16:35:20 2008
Recovery of Online Redo Log: Thread 1 Group 1 Seq 24462 Reading mem 0
  Mem# 0 errs 0: /dev/vg_ora01/rredo_256m_01
  Mem# 1 errs 0: /dev/vg_ora02/rredo_256m_11
Mon Sep  1 16:35:22 2008
Completed redo application
Mon Sep  1 16:35:32 2008
Ended recovery at
 Thread 1: logseq 24462, block 258822, scn 13.3684259989
 46702 data blocks read, 46201 data blocks written, 27274 redo blocks read
Crash recovery completed successfully
Mon Sep  1 16:35:33 2008
LGWR: Primary database is in CLUSTER CONSISTENT mode
Thread 1 advanced to log sequence 24463
Thread 1 opened at log sequence 24463
  Current log# 3 seq# 24463 mem# 0: /dev/vg_ora01/rredo_256m_03
  Current log# 3 seq# 24463 mem# 1: /dev/vg_ora02/rredo_256m_13
Successful open of redo thread 1
Mon Sep  1 16:35:33 2008
<--- 开始前滚 --->
SMON: enabling cache recovery
Mon Sep  1 16:35:33 2008
ARC0: Evaluating archive   log 1 thread 1 sequence 24462
ARC0: Beginning to archive log 1 thread 1 sequence 24462
Creating archive destination LOG_ARCHIVE_DEST_1: '/arch/arch_1_24462.arc'
Mon Sep  1 16:35:34 2008
Successfully onlined Undo Tablespace 1.
Mon Sep  1 16:35:34 2008
<--- 开始回滚 --->
SMON: enabling tx recovery
Mon Sep  1 16:35:34 2008
Database Characterset is ZHS16GBK
Mon Sep  1 16:35:34 2008
<--- 开始出现大量的SMON报错 --->
SMON: about to recover undo segment 60
SMON: mark undo segment 60 as available
SMON: about to recover undo segment 60
SMON: mark undo segment 60 as available
SMON: about to recover undo segment 60
SMON: mark undo segment 60 as available
SMON: about to recover undo segment 60
SMON: mark undo segment 60 as available
SMON: about to recover undo segment 60
SMON: mark undo segment 60 as available
Mon Sep  1 16:35:35 2008
replication_dependency_tracking turned off (no async multimaster replication found)
Mon Sep  1 16:35:35 2008
SMON: about to recover undo segment 60
SMON: mark undo segment 60 as available
SMON: about to recover undo segment 60
SMON: mark undo segment 60 as available
SMON: about to recover undo segment 60
SMON: mark undo segment 60 as available
<--- 实例恢复完成，数据库open --->
Mon Sep  1 16:35:35 2008
Completed: ALTER DATABASE OPEN
Mon Sep  1 16:35:35 2008
SMON: about to recover undo segment 60
SMON: mark undo segment 60 as available
SMON: about to recover undo segment 60
SMON: mark undo segment 60 as available
SMON: about to recover undo segment 60
SMON: mark undo segment 60 as available
SMON: about to recover undo segment 60
SMON: mark undo segment 60 as available
SMON: about to recover undo segment 60
SMON: mark undo segment 60 as available
SMON: about to recover undo segment 60
SMON: mark undo segment 60 as available
SMON: about to recover undo segment 60
SMON: mark undo segment 60 as available
SMON: about to recover undo segment 60
SMON: mark undo segment 60 as available
SMON: about to recover undo segment 60
SMON: mark undo segment 60 as available
SMON: about to recover undo segment 60
SMON: mark undo segment 60 as available
SMON: about to recover undo segment 60
SMON: mark undo segment 60 as available
SMON: about to recover undo segment 60
SMON: mark undo segment 60 as available
SMON: about to recover undo segment 60
SMON: mark undo segment 60 as available
SMON: about to recover undo segment 60
SMON: mark undo segment 60 as available
SMON: about to recover undo segment 60
SMON: mark undo segment 60 as available
此时，数据库已经open，但是在alertlog中有大量的这样的报错。查询metalink（Note:266159.1）：

Cause
These errors do not indicate rollback segment corruption.

Oracle 8i:
These messages indicate that there is a problem with the "rollback_segments" parameter in the init.ora.

Oracle 9i:
Automatic Undo management is being used. When the instance is shutdown, during the next startup instance recovery needs to take place.
In AUM we do not have any control over which undo segments will brought online after the instance startup.
In case we require any of the offline undo segments for the instance recovery, these messages will appear in alert log.

This is not a bug, this is the intended behavior.
When SMON finds such offline undo segments with transactions needing recovery ,then it does what is intended to do , ie: perform the transaction recovery in batches of 100 undo records.
看来并不是undo segment损坏块的问题。用metalink上的方法处理，告警不再出现。

目前数据库已经open，但是还是不敢用当前的undo了，新建unodtbs02到系统默认的undo。

Solution

Oracle 8i:
Check that the rollback segment is included in the "rollback_segments" parameter then adding the rollback segment to the parameter. If not, adding the rollback segment and restarting the database will clear up the problem.

Oracle 9i:
Solution 1:
---------------
To stop this messages from appearing you can do the following workaround :

sql> alter session set "_smu_debug_mode"=4;
sql> alter rollback segment "_SYSSMU11$" online;

Where 11 is the number that is appearing in the messages in the alert log.

Solution 2:
---------------
This is fixed in 10g. With the new feature "Fast Ramp-Up" AUM enhancement.
SQL> select SEGMENT_NAME,STATUS from dba_rollback_segs where SEGMENT_ID=60;

SEGMENT_NAME                   STATUS
------------------------------ ----------------
_SYSSMU60$                     PARTLY AVAILABLE

SQL> alter session set "_smu_debug_mode"=4;

Session altered.

SQL> alter rollback segment "_SYSSMU60$" online;

Rollback segment altered.
alterlog中不再报错：

$>tail -f alert_gdmocs.log
SMON: about to recover undo segment 60
SMON: mark undo segment 60 as available
SMON: about to recover undo segment 60
SMON: mark undo segment 60 as available
SMON: about to recover undo segment 60
SMON: mark undo segment 60 as available
Mon Sep  1 16:48:39 2008
alter rollback segment "_SYSSMU60$" online
Mon Sep  1 16:48:39 2008
Completed: alter rollback segment "_SYSSMU60$" online
Mon Sep  1 16:52:33 2008
Thread 1 advanced to log sequence 24466
  Current log# 1 seq# 24466 mem# 0: /dev/vg_ora01/rredo_256m_01
  Current log# 1 seq# 24466 mem# 1: /dev/vg_ora02/rredo_256m_11
Mon Sep  1 16:52:33 2008
ARC0: Evaluating archive   log 4 thread 1 sequence 24465
ARC0: Beginning to archive log 4 thread 1 sequence 24465
Creating archive destination LOG_ARCHIVE_DEST_1: '/arch/arch_1_24465.arc'
（新建undotbs02到系统默认undo过程略）

检查undo segment的状况：

SQL> select TABLESPACE_NAME,SEGMENT_NAME,status from   dba_rollback_segs;

TABLESPACE_NAME                SEGMENT_NAME                   STATUS
------------------------------ ------------------------------ ----------------
SYSTEM                         SYSTEM                         ONLINE
UNDOTBS1                       _SYSSMU1$                      ONLINE
UNDOTBS1                       _SYSSMU2$                      OFFLINE
UNDOTBS1                       _SYSSMU3$                      OFFLINE
……
UNDOTBS1                       _SYSSMU11$                     OFFLINE
UNDOTBS1                       _SYSSMU12$                     ONLINE
UNDOTBS1                       _SYSSMU13$                     ONLINE
UNDOTBS1                       _SYSSMU14$                     OFFLINE
……
UNDOTBS1                       _SYSSMU59$                     OFFLINE
UNDOTBS1                       _SYSSMU60$                     ONLINE
UNDOTBS1                       _SYSSMU61$                     OFFLINE
……
UNDOTBS2                       _SYSSMU858$                    ONLINE
UNDOTBS2                       _SYSSMU859$                    ONLINE
UNDOTBS2                       _SYSSMU860$                    ONLINE
UNDOTBS2                       _SYSSMU861$                    ONLINE
UNDOTBS2                       _SYSSMU862$                    ONLINE
UNDOTBS2                       _SYSSMU863$                    ONLINE
UNDOTBS2                       _SYSSMU864$                    ONLINE
UNDOTBS2                       _SYSSMU865$                    ONLINE
UNDOTBS2                       _SYSSMU866$                    ONLINE
UNDOTBS2                       _SYSSMU867$                    ONLINE

868 rows selected.



analyze index 时validate structure和compute statisti 2010-02-26 22:07:49
分类： Oracle
analyze index index1 validate structure：
analyze index index1 compute statistics：
在分析索引的时候，一般会用到以上二个命令，那么这二个命令是用来干什么呢？
analyze index index1 validate structure：是用来分析索引的数据块是否有坏块，以及根据分析得到的数据（存放在index_stats）來判断索引是否需要重新建立。
什么样的index需要rebuild？
当一个table经常进行DML操作时，它的索引会存在许多block空间的浪费，这是因为index block中的记录只有在全部表示为不可用时， block 才能被加入到freelist中去被重新利用。所以我们需要寻找那些浪费空间很严重的index。
方法是: 1) analyze index index_name validate structure;
           2) select del_lf_blk_len/lf_blk_len from index_stats where name = :index_name;
           3) 如果结果大于20%， 那你的Index就可以被rebuild了。
validate structure有二中模式： online, offline， 默认是offline模式。以offline模式分析时， 会對表加一个4级別的锁（表共享），对run系統可能造成一定的影响。
而online模式则没有表lock的影响，但当以online模式分析时， 在视图index_stats没有统计信息。
analyze index index1 compute statistics：是用来统计index的分析信息，来为CBO服务的。从9i开始，Oracle以建议使用dbms_stats package代替 analyze 了。




【Oracle数据恢复】ORA-00600[6711]错误一例
2010/09/01 BY MACLEAN LIU 5条评论
一套Linux上的10.2.0.4系统，日志中频繁出现ORA-00600[6711]内部错误:

如果自己搞不定可以找ASKMACLEAN专业ORACLE数据库修复团队成员帮您恢复!

Wed Sep  1 21:24:30 2010
Errors in file /s01/10gdb/admin/YOUYUS/bdump/youyus_smon_5622.trc:
ORA-00600: internal error code, arguments: [6711], [4256248], [1], [4256242], [0], [], [], []
Wed Sep  1 21:24:31 2010
Non-fatal internal error happenned while SMON was doing logging scn->time mapping.


MOS上有一个关于6711内部错误十分简单的Note,该文档声称出现6711错误极有可能是部分类型为簇(cluster)的数据字典表存在潜在的讹误，这个Note甚至没有告诉我们该错误argument参数的意义。
不过其实我们可以猜出来,因为是和corruption相关的错误，那么实际上可能关联的几个因素无非是obj#,file#,block#；4256248和4256242 两个数字像极了Data Block Address，把他们当做dba来看待，也就指向了1号数据文件的61938块和61944数据块，我们来看看这些块属于哪个对象：
SQL> set linesize 200;
SQL> select segment_name, segment_type
  2    from dba_extents
  3   where relative_fno = 1
  4     and (61938 between block_id and block_id + blocks or
  5         61944 between block_id and block_id + blocks);

SEGMENT_NAME                                                                      SEGMENT_TYPE
--------------------------------------------------------------------------------- ------------------
SMON_SCN_TO_TIME                                                                  CLUSTER
不出意料是一个cluster，SMON_SCN_TO_TIME是SMON_SCN_TIME表的基簇，SMON_SCN_TIME表用以记录数据库中scn对应的时间戳。我们直接查看用以创建数据字典的sql.bsq文件，可以进一步了解他们的结构:
cat $ORACLE_HOME/rdbms/admin/sql.bsq|grep -A 24 "create cluster smon_scn_to_time"
create cluster smon_scn_to_time (
  thread number                         /* thread, compatibility */
)
/
create index smon_scn_to_time_idx on cluster smon_scn_to_time
/
create table smon_scn_time (
  thread number,                         /* thread, compatibility */
  time_mp number,                        /* time this recent scn represents */
  time_dp date,                          /* time as date, compatibility */
  scn_wrp number,                        /* scn.wrp, compatibility */
  scn_bas number,                        /* scn.bas, compatibility */
  num_mappings number,
  tim_scn_map raw(1200),
  scn number default 0,                  /* scn */
  orig_thread number default 0           /* for downgrade */
) cluster smon_scn_to_time (thread)
/

create unique index smon_scn_time_tim_idx on smon_scn_time(time_mp)
/

create unique index smon_scn_time_scn_idx on smon_scn_time(scn)
/
从以上脚本可以看到这个簇上存在多个索引，我们需要进一步validate验证所有这些对象:
SQL> analyze table SMON_SCN_TIME validate structure;
Table analyzed.

SQL>analyze table SMON_SCN_TIME validate structure cascade;
Table analyzed.

SQL> analyze cluster SMON_SCN_TO_TIME validate structure;
Cluster analyzed.

SQL> analyze cluster SMON_SCN_TO_TIME validate structure cascade;
analyze cluster SMON_SCN_TO_TIME validate structure cascade
*
ERROR at line 1:
ORA-01499: table/index cross reference failure - see trace file
到这里问题已经很清晰了，问题出在SMON_SCN_TO_TIME的索引smon_scn_to_time_idx身上，极有可能是该索引上出现了逻辑讹误。所幸有问题的仅仅是索引，找出问题所在后要解决就显得容易得多了:
SQL> alter index smon_scn_to_time_idx rebuild ;

Index altered.

/* 在索引出现讹误的情况下仅仅rebuild往往是无效的，在我们rebuild的同时告警日志中再次出现了ORA-00600[6711]错误 !!! */

/* 我们需要的彻底把有问题的索引drop掉，并再次创建!!! */

SQL> drop index smon_scn_to_time_idx ;

Index dropped.

SQL> create index smon_scn_to_time_idx on cluster smon_scn_to_time;

Index created.

/* 至此问题解决，告警日志中不再出现错误! * /

/* That's great! * /




 ㈠ 什么是数据块一致性？
    每一个数据块头部都有一个"校验和"字段
    当数据块被写回磁盘前，Oracle会重新计算这个校验和
    并记录到这个字段，最终写回磁盘
    下次数据块被读入内存时，Oracle会重新计算数据块的校验和
    并与校验和字段中的值相比较
    如果有差异，Oracle就会抛出ORA-1578
    也就是，整个校验过程：
    写回时，计算并保存
    读入时，计算并比较
    通过校验和字段进行检查叫物理一致性检查，其侧重于硬件故障，并不关心内容正确与否
    而逻辑一致性检查便是接手这任务，如：记录和索引是否对应；记录是否被不存在的事务锁定等
    db_block_checksum:物理一致性检查
    当值为true时，Oracle除了会对所有表空间的数据块进行校验和检查，还会对redo log块做校验和
    如果置之为false,则只会对system表空间的数据块进行校验
    Oracle建议开启这个参数
    db_block_checking:逻辑一致性检查
    当值为false时，只会对system表空间做逻辑一致性检查
    对性能影响比较大，需DBA自己权衡
    ㈡ 4种工具校验
    ① DBV
    可以对数据文件物理和逻辑进行一致性检查
    但不会检查表和索引的匹配性
    具体参见我之前的博客：
    Oracle 工具dbv的使用介绍

    ② analyze
    同样执行物理和逻辑一致性检查
    能够检查表和索引的匹配性
    若是检查出问题，则会将问题放在USER_DUMP_DEST的trc文件内
    analyze检查对象一致性语法：
    analyze table table_name validate structure cascade online（offline）
    注释：
    ⑴ cascade:可确认每条记录都有相应的索引
    ⑵ online :在线一致性检查，只是不会收集对象统计信息
    ⑶ offline:可收集对象统计信息，只是表会被锁住
    ⑷ 当检查分区表的记录是否在正确分区时，可把检查出来的记录的rowid放在特殊的表invalid_rows中
    这之前需要运行：$ORACLE_HOME/rdbms/admin/utlvalid.sql脚本
    对应的语法：
    analyze table table_name validate structure into invalid_rows;
    由于这个命令也比较重要，我会专门写一个博客介绍！
    ③ RMAN
    使用rman备份时，是先把数据块读到rman的读缓冲区，然后再拷贝到rman的写缓冲区，最后再从写缓冲区写到物理介质上
    在从读缓冲区到写缓冲区的拷贝过程中，rman会对数据块进行一致性检查
    语法：
    backup check logical validate;
    注释：
    这个命令只进行一致性检查，并不进行备份
    检查结果放在v$database_block_corruption
    logical:进行逻辑一致性检查
    validate:进行物理一致性检查
    例子：
    backup check logical validate datafile 1;
    除了可以检查数据文件，rman还可以检查已经备份的文件
    语法：
    restore validate
    例子：
    检查数据库备份
    restore validate database;
    检查备份的控制文件
    restore validate controlfile to '/u01/…';
    检查归档日志文件
    restore validate archivelog from sequence x until sequence y;
    ④ dbms_repair
    发现、标识并修改数据文件中的坏块
    但使用这个包的同时会带来数据丢失、表和索引返回数据不一致，完整性约束破坏等其他问题
    因此，dbms_repair只是在没有备份的情况下使用的一种手段，这种方式一般都会造成数据的丢失
    dbms_repair包的工作原理比较简单，是将检查到的坏块标注出来，使随后的dml操作跳过该块
    同时，dbms_repair包还提供了用于保存索引中包含的标注为坏块中的键值，以及修复freelist和segment bitmap的过程
    有一点需要注意，dbms_repair包没有进行授权，只有sys用户可以执行。


    查看索引是否使用过，如果长期未使用过的索引，就可以删除掉
1.生成监控索引的脚本文件：
Java代码  收藏代码
spool c:\index_monitor.log
select 'alter index '||index_name||' monitoring usage;' from user_indexes;
spool off;
然后对该脚本文件修改一下，并执行，即可监控索引了。


查看索引是否使用过：
select table_name,index_name,used from v$object_usage;
如果used列对应的值为NO，则证明该索引未使用过。在监视过程中
我们不能够启动数据库，因为v$视图会被重新创建，丢失原来的监视。


Java代码  收藏代码
2.生成取消监控索引的脚本文件：
spool c:\index_nomonitor.log
select 'alter index '||index_name||' nomonitoring usage;' from user_indexes;
spool off;



3.生成重建索引的脚本文件
spool /home/oracle/index_rebuild.sql
SELECT 'ALTER INDEX '||INDEX_NAME ||' REBUILD;'FROM USER_INDEXES;
spool off;

4.生成合并索引的脚本文件
spool /home/oracle/index_rebuild.sql
SELECT 'ALTER INDEX '||INDEX_NAME ||' coalesce;'FROM USER_INDEXES;
spool off;




如何确定是否需要重建索引呢？一般认为有两种情况：
1、索引深度大于等于4
2、已删除的索引条目占总索引条目的20%
3、索引空间使用率小于50%
再次不得不提 一个视图index_stats该视图默认是没有任何数据的，当使用analyze index index_name validate structure;对索引结构分析之后将会填充相应的数据，一般该视图可以提供给我们足够的信息去引导我们是否需要对索引进行重建。
查看相关字段信息：

SQL> desc index_stats;
 Name                                      Null     Type
 ----------------------------------------- -------- ----------------------------
 HEIGHT                                             NUMBER  （代表索引高度）
 BLOCKS                                             NUMBER  （索引占用块数）
 NAME                                               VARCHAR2(30)（索引名字）
 PARTITION_NAME                                     VARCHAR2(30)（分区索引名字）
 LF_ROWS                                            NUMBER （叶子行数）
 LF_BLKS                                            NUMBER  （在b树索引中叶子的块数）
 LF_ROWS_LEN                                        NUMBER  （所有叶子行数的长度）
 LF_BLK_LEN                                         NUMBER  （在一片叶子中可用空间）
 BR_ROWS                                            NUMBER  （在B树索引中有多少个分支行）
 BR_BLKS                                            NUMBER  （在B树索引中有多少个分支块）
 BR_ROWS_LEN                                        NUMBER  （在B树索引中所有分支块的总长度）
 BR_BLK_LEN                                         NUMBER  （在分支快中可用的空间）
 DEL_LF_ROWS                                        NUMBER  （在索引中删除叶子行数）
 DEL_LF_ROWS_LEN                                    NUMBER  （在索引中删除叶子行数的总的长度）
 DISTINCT_KEYS                                      NUMBER  （唯一值数目包括删除的行）
 MOST_REPEATED_KEY                                  NUMBER
 BTREE_SPACE                                        NUMBER  （当前分给该 索引总的大小空间）
 USED_SPACE                                         NUMBER  （已经被索引使用的空间大小包含被删的行数空间）
 PCT_USED                                           NUMBER  （索引空间使用率）
 ROWS_PER_KEY                                       NUMBER  （每个不同键值的平均行数不包括删除行）
 BLKS_GETS_PER_ACCESS                               NUMBER
 PRE_ROWS                                           NUMBER  （前缀行数）
 PRE_ROWS_LEN                                       NUMBER  （前缀行的总长度）
 OPT_CMPR_COUNT                                     NUMBER  （压缩长度）
 OPT_CMPR_PCTSAVE                                   NUMBER

SQL>

查看未删除叶子行数占总行数的百分比公式为：(（lf_rows-del_lf_rows)/lf_rows)*100;
查看未删除行占用的空间百分比公式为：（（used_space-del_lf_rows_len)/btree_space)*100;
pct_used计算公式为：（used_space/btree_space)*100
eg：

SQL> create table test as select rownum id,'Amy' text from dual connect by level<=10000;

Table created.

SQL> select count(*) from test;

  COUNT(*)
----------
     10000

SQL> create index test_idx1 on test(id);

Index created.

SQL> select * from index_stats;

no rows selected

SQL> analyze index test_idx1 validate structure;

Index analyzed.
SQL> r
  1  select height,
  2         lf_rows,
  3         lf_blks,
  4         del_lf_rows,
  5         btree_space,
  6         used_space,
  7         pct_used,
  8         ((used_space - del_lf_rows_len) / btree_space) pct_unused,
  9         ((lf_rows - del_lf_rows) / lf_rows) pct_undel_rows
 10    from index_stats
 11   where name = 'TEST_IDX1'
 12*

    HEIGHT    LF_ROWS    LF_BLKS DEL_LF_ROWS BTREE_SPACE USED_SPACE   PCT_USED PCT_UNUSED PCT_UNDEL_ROWS
---------- ---------- ---------- ----------- ----------- ---------- ---------- ---------- --------------
         2      10000         21           0      175944     150021         86 .852663347              1

SQL>
SQL> analyze index test_idx1 validate structure;

Index analyzed.

SQL> select height,
  2         lf_rows,
  3         lf_blks,
  4         del_lf_rows,
  5         btree_space,
  6         used_space,
  7         pct_used,
  8         ((used_space - del_lf_rows_len) / btree_space) pct_unused,
  9         ((lf_rows - del_lf_rows) / lf_rows) pct_undel_rows
 10    from index_stats
 11   where name = 'TEST_IDX1';

    HEIGHT    LF_ROWS    LF_BLKS DEL_LF_ROWS BTREE_SPACE USED_SPACE   PCT_USED PCT_UNUSED PCT_UNDEL_ROWS
---------- ---------- ---------- ----------- ----------- ---------- ---------- ---------- --------------
         2      10000         21        9999      175944     150021         86 .001329969          .0001

SQL>
SQL> alter index test_idx1 deallocate unused;

Index altered.

SQL> analyze index test_idx1 validate structure;

Index analyzed.
SQL> select height,
  2         lf_rows,
  3         lf_blks,
  4         del_lf_rows,
  5         btree_space,
  6         used_space,
  7         pct_used,
  8         ((used_space - del_lf_rows_len) / btree_space) pct_unused,
  9         ((lf_rows - del_lf_rows) / lf_rows) pct_undel_rows
 10    from index_stats
 11   where name = 'TEST_IDX1';

    HEIGHT    LF_ROWS    LF_BLKS DEL_LF_ROWS BTREE_SPACE USED_SPACE   PCT_USED PCT_UNUSED PCT_UNDEL_ROWS
---------- ---------- ---------- ----------- ----------- ---------- ---------- ---------- --------------
         2      10000         21        9999      175944     150021         86 .001329969          .0001

SQL>

收集统计信息，之后可以看到在dba_indexes中依然显示存在的索引叶块，优化器从而使用该索引。

SQL> exec dbms_stats.gather_table_stats('SYS','TEST',cascade=>true);

PL/SQL procedure successfully completed.

SQL>  select index_name,leaf_blocks,num_rows,degree from dba_indexes where index_name='TEST_IDX1';

INDEX_NAME                     LEAF_BLOCKS   NUM_ROWS DEGREE
------------------------------ ----------- ---------- ----------------------------------------
TEST_IDX1                                1          1 1

SQL> set autotrace trace exp
sSQL>
SQL> select * from test where id<20;

Execution Plan
----------------------------------------------------------
Plan hash value: 2624864549

-----------------------------------------------------------------------------------------
| Id  | Operation                   | Name      | Rows  | Bytes | Cost (%CPU)| Time     |
-----------------------------------------------------------------------------------------
|   0 | SELECT STATEMENT            |           |     1 |     7 |     3   (0)| 00:00:01 |
|   1 |  TABLE ACCESS BY INDEX ROWID| TEST      |     1 |     7 |     3   (0)| 00:00:01 |
|*  2 |   INDEX RANGE SCAN          | TEST_IDX1 |     1 |       |     2   (0)| 00:00:01 |
-----------------------------------------------------------------------------------------

Predicate Information (identified by operation id):
---------------------------------------------------

   2 - access("ID"<20)

SQL>

但是注意：使用analyze index index_name validate structure ;进行索引分析的时候会锁定相应的对象直到该命令执行完成，如果不加锁可以使用online参数，但使用online参数数据信息又不会记录到index_stats视图，且在重建索引的过程中会产生很多的redo日志，可以考虑使用nologging参数，另外当在分析完成后在执行插入操作，那么相应的del_lf_rows将会改变从而影响对索引的分析信息提取：
eg：

SQL> select * from test;

        ID TEX
---------- ---
     10000 Amy

SQL> insert into test values(10001,'Rhys');
insert into test values(10001,'Rhys')
                              *
ERROR at line 1:
ORA-12899: value too large for column "SYS"."TEST"."TEXT" (actual: 4, maximum: 3)


SQL> desc test
 Name                                                                                                              Null     Type
 ----------------------------------------------------------------------------------------------------------------- -------- ----------------------------------------------------------------------------
 ID                                                                                                                         NUMBER
 TEXT                                                                                                                       CHAR(3)

SQL> alter table test modify text char(15);

Table altered.

SQL> insert into test values(10001,'Rhys');

1 row created.

SQL> commit;

Commit complete.

SQL> select height,
  2         lf_rows,
  3         lf_blks,
  4         del_lf_rows,
  5         btree_space,
  6         used_space,
       pct_used,
  7    8         ((used_space - del_lf_rows_len) / btree_space) pct_unused,
  9         ((lf_rows - del_lf_rows) / lf_rows) pct_undel_rows
 10    from index_stats
 11   where name = 'TEST_IDX1';

    HEIGHT    LF_ROWS    LF_BLKS DEL_LF_ROWS BTREE_SPACE USED_SPACE   PCT_USED PCT_UNUSED PCT_UNDEL_ROWS
---------- ---------- ---------- ----------- ----------- ---------- ---------- ---------- --------------
         2      10000         21        9999      175944     150021         86 .001329969          .0001

SQL> analyze index test_idx1 validate structure;

Index analyzed.

SQL> select height,
  2         lf_rows,
  3         lf_blks,
       del_lf_rows,
  4    5         btree_space,
  6         used_space,
       pct_used,
  7    8         ((used_space - del_lf_rows_len) / btree_space) pct_unused,
  9         ((lf_rows - del_lf_rows) / lf_rows) pct_undel_rows
 10    from index_stats
 where name = 'TEST_IDX1';
 11
    HEIGHT    LF_ROWS    LF_BLKS DEL_LF_ROWS BTREE_SPACE USED_SPACE   PCT_USED PCT_UNUSED PCT_UNDEL_ROWS
---------- ---------- ---------- ----------- ----------- ---------- ---------- ---------- --------------
         2       9584         21        9582      175944     143786         82 .001420907     .000208681

SQL>

从以上可以看出两点内容，产生索引数据之后剩余的空间不会返还给数据库，但是当插入新数据的时候将有可能重新利用之前被删除数据的空间，另外一点可以看del_lf_row已经评估出现错误，到目前为止刚刚开始删除9999条数据，然后插入一条数据在进行分析，那么现在既然是9582，因此不能仅仅依靠del_lf_rows进行索引重建评估。以前记得有个朋友曾经提过这么一个问题，说是测试环境库执行一条sql会非常的块，但是导到正式环境却很慢，但是执行计划都是一样的，我的怀疑就是需要重建正式环境库的索引。因此，如果确定对 索引相同部分执行了大量删除操作，产生了大量的索引碎片，并且查询每次读取了大量的索引行，索引被频繁使用，这时候重建索引是有价值的。
第二种：合并索引
合并索引就是将索引段中相邻的索引块其中空闲空间进行整合重组，从而释放索引块空间，这比较类似于我们windows的磁盘碎片整理，但是注意该过程不会将腾出的空间返回与数据库，而是加入到空闲空间列表中，以便下次在进行使用。这种操作对于那种以序列或是时间日志为字段的表是有非常重要价值的，因为当我们对这些表删除了大部分数据，那么其中很多空间是无法在进行使用的，那么在我们制定谓词查询的时候通常会扫描索引中很多空快，那么合并索引就将空的索引块进行释放与索引块的空闲列表中。
语句非常简单：
alter index index_name coalesce;
合并索引与重建索引不同事，合并索引不会降低索引的高度，而是对其数据条目进行重组整合，但是重建可能会降低索引高度，另外重建索引需要2倍的磁盘空间，首先需要存储原先的索引条目数据，还需要额外的空间存储新调整 的索引数据直到重建完成才可。

注：合并索引是一种在线操作。
第三种：shrink 索引：
因为shrink是一个耗资源相对严重的过程，因此两个过程，一个是compact参数，另一个是直接shrink space，第一种类似于coalesce但是相比会产生更多的redo日志，执行完后不会释放空间，但是shrink space 除了整理碎片还可以将空间释放给表空间，但是shrink space虽然是在线可以做的，依然会产生过打的redo日志。除此之外shrink space还要启动行移动。
eg：
alter index index_name shrink space compact;
alter index index_name shrink space;
注：Shrink operations can be performed only on segments in locally managed tablespaces with automatic segment space management (ASSM).





双引号与换行的困惑
分类： Oracle 2013-06-03 10:38 928人阅读 评论(0) 收藏 举报
从PL/SQL Developer 中复制查询结果到文本文件中，查询结果本身看不到双引号和换行。但奇怪的是复制出来的记录中都包含了双引号和换行。这个让我感到很困惑，网上简单查了一下，只看到有人提问，却没有答案。看来只有自己想办法来解决这个问题了。



什么原因可能导致结果中出现双引号和换行的问题呢？

思路如下：

1.       工具中的设置有问题。是不是PL/SQL Developer, UltraEdit中有特殊的设置呢？

2.       查询结果是否有异常呢？如查询结果中隐藏着双引号和换行，但在PL/SQL中看不到呢？





验证第一个猜想：

a)       把查询结果分别复制到UltraEdit，csv, Notepad中均发现有双引号和换行。

b)       分别在windows和linux的sql plus中运行同样的sql 查询，发现没有双引号和换行。

c)       查询其它表中的数据复制出来，看不到双引号和换行。

由此可见双引号和换行与数据本身有关.



验证第二个猜想：

在oracle中用dump查看sql的查询结果如下：



SQL> SELECT DUMP(fpath) ,fpath  FROM tarchive1 WHERE ROWID='AAFTSIAARAAA9fcAAA';



DUMP(FPATH)                         FPATH

----------------------------------------------------     ----------------------

Typ=1 Len=8: 49,53,49,46,119,97,118,10    151.wav



Dump出的结果代表什么含义呢？用chr()来查看以下。



SQL> SELECT chr(49),chr(53),chr(49),chr(46),chr(119),chr(97),chr(118), CHR(10) FROM dual;



CHR(49) CHR(53) CHR(49) CHR(46) CHR(119) CHR(97) CHR(118) CHR(10)

-------    -------   -------    -------   --------     -------   -------      -------

1       5       1       .       w        a       v



原来chr(10) 代表换行。原来是他惹的祸，现在把它去掉就可以了。

SQL>update TARCHIVE1  set FPATH=replace(FPATH,chr(10),'') WHERE ROWID='AAFTSIAARAAA9fcAAA';



1 row updated



SQL> commit;



Commit complete



SQL> SELECT DUMP(fpath) ,fpath FROM tarchive1 WHERE ROWID='AAFTSIAARAAA9fcAAA';



DUMP(FPATH)                       FPATH

---------------------------------------------------   ------------

Typ=1 Len=7: 49,53,49,46,119,97,118    151.wav



在把查询结果复制到文本文件中，双引号和换行都不见了。



调查后发现数据是在Windows中编辑，插入到linux下的oracle中的。

由于windows下回车换行是\r\n ，在unix下是\n。 所以导致出现了上述问题。


怎么知道一个表的HWM呢？
(1) 首先对表进行分析：ANALYZE TABLE <tablename> ESTIMATE/COMPUTE STATISTICS;
(2) SELECT table_name, num_rows, blocks, empty_blocks FROM user_tables WHERE table_name = ‘&tablename’;
SQL> ANALYZE TABLE TESTHW COMPUTE STATISTICS;
Table analyzed
SQL> SELECT table_name, num_rows, blocks, empty_blocks FROM user_tables WHERE table_name = 'TESTHW';
TABLE_NAME                       NUM_ROWS     BLOCKS EMPTY_BLOCKS
------------------------------ ---------- ---------- ------------
TESTHW                                  0          0          128
BLOCKS 列代表该表中曾经使用过得数据库块的数目，即水线。EMPTY_BLOCKS 代表分配给该表，但是在水线以上的数据库块，即从来没有使用的数据块。
使用下面语句插入批量数据，此时的HWM是2140 blocks，如图1所示：
下面我就删除一些数据以模拟出一些碎片，此时HWM仍然是2140 blocks ，但是HWM下有很多空块，如图2所示。
declare
  i number := 0;
begin
  for i in 1 .. 1000 loop
    if (mod(i, 3) = 0 or mod(i, 5) = 0) then
      delete from testhw where id = i;
      commit;
    end if;
  end loop;
end;
/
SQL> ANALYZE TABLE testhw COMPUTE STATISTICS;
Table analyzed
SQL> SELECT table_name, num_rows, blocks, empty_blocks,avg_row_len FROM user_tables u WHERE table_name = 'TESTHW';
TABLE_NAME                       NUM_ROWS     BLOCKS EMPTY_BLOCKS AVG_ROW_LEN
------------------------------ ---------- ---------- ------------ -----------
TESTHW                             266332       2140           36          28
SQL> select segment_name,header_file,header_block,blocks,bytes,extents,min_extents,max_extents,segment_type from dba_segments where segment_name='TESTHW';
SEGMENT_NA HEADER_FILE HEADER_BLOCK     BLOCKS      BYTES    EXTENTS MIN_EXTENTS MAX_EXTENTS SEGMENT_TYPE
---------- ----------- ------------ ---------- ---------- ---------- ----------- ----------- ------------
TESTHW              96           12       2176   17825792         17           1  2147483645 TABLE
下面利用oracle 10g的dbms_space包来检查碎片的详细信息，当然也可以用dump文件的方法来查看碎片情况，这里不做介绍，show_space包的代码在文章最后会给出。
SQL> exec show_space('testhw','auto','t','y');
Total Blocks............................2176
Total Bytes.............................17825792
Unused Blocks...........................0
Unused Bytes............................0
Last Used Ext FileId....................96
Last Used Ext BlockId...................2057
Last Used Block.........................128
*************************************************
The segment is analyzed
0% -- 25% free space blocks.............0
0% -- 25% free space bytes..............0
25% -- 50% free space blocks............204
25% -- 50% free space bytes.............1671168
50% -- 75% free space blocks............173
50% -- 75% free space bytes.............1417216
75% -- 100% free space blocks...........804
75% -- 100% free space bytes............6586368
Unused Blocks...........................62
Unused Bytes............................507904
Total Blocks............................897
Total bytes.............................7348224
PL/SQL procedure successfully completed

SQL> select 204+173+804+62+897 Total from dual;

     TOTAL
----------
      2140
说明：结果分两个部分，第一部分是总体情况，第二部分是实际使用情况，第二部分所有block之和等于水位线值。 结果中第一行Total Blocks，是表（segment）testhw已分配的总的block数；倒数第二行的Total Blocks表testhw实际100%使用的block数。
下面的例子是我们经常遇到的，一个全表扫描的sql，虽然表中很多空块，但是sql执行起来仍然很慢，如下testhw表中实际使用了897个块，但是仍然2042次的物理读，即扫描HWM2140以下所有块。
SQL> set autotrace TRACE STAT
SQL> select * from dbmgr.testhw where id=998;
998 rows selected.
Statistics
----------------------------------------------------------
          1  recursive calls
          0  db block gets
       2153  consistent gets
       2042  physical reads
          0  redo size
      17703  bytes sent via SQL*Net to client
       1218  bytes received via SQL*Net from client
         68  SQL*Net roundtrips to/from client
          0  sorts (memory)
          0  sorts (disk)
        998  rows processed
     SQL> set autotrace off
Oracle 10g提供了一个清理碎片的方法：alter table table_name shrink space，该命令将重组表中现有行，在此之前要确保在该表上禁用所有基于行 id 的触发器，这是因为行将会移动（和行迁移有些不同所以姑且称之为行移动），行 id 可能会发生改变。要确保该表支持行移动，如果不支持，您可以使用如下命令来支持它：alter table table_name enable row movement。该命令将会在块内重新分配行并空间返回给表空间，如图 3 所示，该表内所有未用的空间都返回给表空间，以让其他段使用。 如图3 所示，此时会把段中原来空闲的块返回给数据库，HWM 本身也会进行重新分配。





oracle 怎样让索引创建更快？（转） 2010-02-27 13:23:04
分类： Oracle
在大数据迁移中，索引的创建速度是个很重要的因素，如何让索引创建更快呢？
www.dba-oracle.com 上发现一个很不错的文档，可惜的是，这个网站不知怎么无法访问了，使用了google快照，转在这里备用了。需要注意的是，只有oracle 企业版才能支持索引并行创建。
[@more@]
Improve Oracle indexes – Build faster, smaller and better-balanced indexes
Oracle Tips by Burleson Consulting
June 16, 2003
Note: For complete details on index create performance, see my book "Oracle Tuning: The Definitive Reference".
When using the create index syntax to build an Oracle index, there are many options that can dramatically improve the speed of the creation, the space used by the index, and the height of the resulting index. Let’s review a few of these factors:
Index create speed: performance factors
Parallel option – This option allows for parallel processes to scan the table. When an index is created, Oracle must first collect the symbolic key/ROWID pairs with a full-table scan. By making the full-table scan run in parallel, the index creation will run many times faster, depending on the number of CPUs, table partitioning and disk configuration. I recommend a n-1 for the degree option, where n is the number of CPUs on your Oracle server. In this example we create an index on a 36 CPU server and the index create twenty times faster:
CREATE INDEX cust_dup_idx
ON customer(sex, hair_color, customer_id)
PARALLEL 35;
Nologging option – The nologging option bypasses the writing of the redo log, significantly improving performance. The only danger with using nologging is that you must re-run the create index syntax if you perform a roll-forward database recovery. Using nologging with create index can speed index creation by up to 30%
CREATE INDEX cust_dup_idx
ON customer(sex, hair_color, customer_id)
PARALLEL 35
NOLOGGING;
The nologging option is quite convoluted and dependent on several factors.
Database noarchivelog mode - If your database is in "noarchivelog" mode and you are no using the APPEND hint for inserts, you WILL STILL generate redo logs!
Database archivelog mode - If you are in archivelog mode, the table must be altered to nologging mode AND the SQL must be using the APPEND hint. Else, redo WILL be generated.
Create index: Space & structure Factors
Compress option – The compress option is used to repress duplication of keys in non-unique indexes. For concatenated indexes (indexes with multiple columns), the compress option can reduce the size of the index by more than half. The compress option allows you to specify the prefix length for multiple column indexes. In this example we have a non-unique index on several low cardinality columns (sex and hair_color), and a high cardinality column (customer_id):
CREATE INDEX cust_dup_idx
ON customer(sex, hair_color, customer_id)
PARALLEL 35
NOLOGGING
COMPRESS 2;
Tablespace blocksize option – The blocksize of the index tablespace will have a huge impact on the structure of the index. For details, read Proof that large indexes reduce IO. Here is an example of an index created in a 32k tablespace:
create tablespace 23k_ts
datafile ‘/u01/app/oracle/prod/oradata/32k_file.dbf’
blocksize 32k;
CREATE INDEX cust_dup_idx
ON customer(sex, hair_color, customer_id)
PARALLEL 35
NOLOGGING
COMPRESS 2
TABLESPACE 32k_ts;
In sum, there are many parameters that you can use to improve the performance of Oracle index creation, the size of the index tree and the height of the tree structure.






一.说明
一网友问我将一个查询的结果集存放到临时表里，如果估算临时表的大小，当时想的方法是通过统计block来计算。后来想，此方法的操作性也不是很高。 最好是能在查询操作执行之前就能估算出大小。

查看了一下ALL_TABLES 表，其中有个字段：avg_row_len. 该值单位为bytes。 可以一句这个字段来进行一个估算。

AVG_ROW_LEN*

NUMBER



Average length of a row in the table (in bytes)

http://download.Oracle.com/docs/cd/E11882_01/server.112/e17110/statviews_2117.htm#i1592091

根据对表大小的估算，进而可以估算出整个数据库的大小。 在项目测试阶段，可以根据所有对象进行估算，从而可以估算出系统上线以后数据库的大小，根据这些数据可以规划存储。这里要注意一点，要给备份留足存储空间。 一般备份需要的空间是DB的2-3倍。 如果DB 是100G，那么给备份的空间最好是200G以上。

根据dba_segments视图可以查看数据库中占用存储空间的对象：

SYS@anqing2(rac2)> select distinctsegment_type from dba_segments;



SEGMENT_TYPE

------------------

LOBINDEX

INDEX PARTITION

TABLE PARTITION

NESTED TABLE

ROLLBACK

LOB PARTITION

LOBSEGMENT

INDEX

TABLE

CLUSTER

TYPE2 UNDO



11 rows selected.



这里主要就是表和索引。把所有表和索引的大小估算出来，在相加就可以估算出DB的大小了。

二. 估算表的大小

表的大小=记录数*平均字段大小（avg_row_len）

Avg_row_len 可以通过如下SQL 查询。 其单位为bytes。

SYS@anqing2(rac2)> selecttable_name,avg_row_len from all_tables where table_name='T1';



TABLE_NAME                     AVG_ROW_LEN

------------------------------ -----------

T1                                      93

如果T1 表未来估计为1000万行，那么其大小就是1000w*93bytes。

三.估算表上索引的大小

        All_indexes 视图没有all_tables 上的avg_row_len 字段，不过我们可以通过视图和表大小的一个比率进行估算。 表的大小我们可以估算出来，索引的大小可以通过这个比率进行估算。

SQL>create index idx_t1_created on t1(created)

SQL>exec dbms_stats.gather_table_stats('SYS','T1',cascade=>TRUE)

SYS@anqing2(rac2)> selectsegment_name,segment_type,bytes,blocks from dba_segments where segment_namein  ('T1','IDX_T1_CREATED');

SEGMENT_NAME    SEGMENT_TYPE            BYTES     BLOCKS

--------------- ---------------------------- ----------

T1              TABLE                 6291456        768

IDX_T1_CREATED  INDEX                 2097152        256

计算索引和表的比率：

SYS@anqing2(rac2)> select (2097152/6291456)*100,(256/768)*100 from dual;

(2097152/6291456)*100 (256/768)*100

--------------------- -------------

          33.3333333    33.3333333

从bytes 和 blocks 的比率是一样，即索引是表的33%。 那么如果估算表以后的大小是1000M，那么对应的索引大小就是1000M*33%=330M。

把所有表和索引的大小加起来，就是整个数据库大小的估算值。




oracle的rowid和rownumber
http://blog.163.com/jun_ai_ni_13 ... 055201002611117259/
一，什么是伪列RowID？

1,首先是一种数据类型，唯一标识一条记录物理位置的一个id，基于64位编码的18个字符显示。

2,未存储在表中，可以从表中查询，但不支持插入，更新，删除它们的值。

二，RowID的用途

1,在开发中使用频率应该是挺多的，特别在一些update语句中使用更加频繁。所以oracle ERP中大部份的视图都会加入rowid这个字段。

   在一些cursor定义时也少不了加入rowid。但往往我们在开发过程中，由于连接的表很多，再加上程序的复制，有时忽略了rowid对应的是那一个表中rowid，所以有时过程出错，

   往往发上很多时间去查错，最后查出来既然是update时带的rowid并非此表的rowid,所以在发现很多次的错误时，重视rowid起来了，开发中一定要注意rowid的匹配

2，能以做快的方式访问表中的一行。

3，能显示表的行是如何存储的。

4，作为表中唯一标识。
三，RowID的组成

rowid确定了每条记录是在Oracle中的哪一个数据对象，数据文件、块、行上。

ROWID 的格式如下：

   数据对象编号        文件编号        块编号            行编号

   OOOOOO             FFF                BBBBBB    RRR

   由 data_object_id# + rfile# + block# + row#   组成，占用10个bytes的空间，rowid的显示方式：基于64位编码的18个字符显示，其实rowid的存储方式是：10 个字节即80位存储，其中数据对象编号需要32 位，相关文件编号需要10 位，块编号需要22，位行编号需要16 位，由此，我们可以得出:

2bit的object number，每个数据库最多有4G个对象
10bit的file number，每个对象最多有1022个文件（2个文件预留）
22bit的block number，每个文件最多有4M个BLOCK
16bit的row number，每个BLOCK最多有64K个ROWS

   所以每个表空间不能超过1023个 数据文件。
四，RowID的应用

1，查找和删除重复记录

   当试图对库表中的某一列或几列创建唯一索引时，

   系统提示 ORA-01452 ：不能创建唯一索引，发现重复记录。

    /*conn scott/tiger

    Create table empa as select * from emp;

    插入重复记录

    insert into empa select * from emp where empno = 7369;

    insert into empa select * from emp where empno = 7839;

    insert into empa select * from emp where empno = 7934;

    */

   查找重复记录的几种方法：

    查找大量重复记录

    select empno from empa group by empno having count(*) >1;

    Select * From empa Where ROWID Not In(Select Min(ROWID) From empa Group By empno);

    查找少量重复记录

    select * from empa a where rowid<>(select max(rowid) from empa where empno=a.empno );

   删除重复记录的几种方法：

    (1).适用于有大量重复记录的情况(列上建有索引的时候，用以下语句效率会很高)：

    Delete empa Where empno In (Select empno From empa Group By empno Having Count(*) > 1)

    And ROWID Not In (Select Min(ROWID) From empa Group By empno Having Count(*) > 1);



    Delete empa Where ROWID Not In(Select Min(ROWID) From empa Group By empno);



    (2).适用于有少量重复记录的情况(注意，对于有大量重复记录的情况，用以下语句效率会很低)：

    Delete empa a where rowid<>(select max(rowid) from empa where empno=a.empno );

---------------------------------------------------------------------------------------------------------------------------------------------------

注意：rownum从1开始；

           rownum按照记录插入时的顺序给记录排序，所以有order by的子句时一定要注意啊！

           使用时rownum，order by字段是否为主键有什么影响？

           子查询中rownum rn，而rn用到外查询中到底是怎样的序列？

            若id主键是按照从小到大的顺序插入的，select语句没有group by 和order by的子句时，rownum的顺序和id顺序基本一致。

对于 Oracle 的 rownum 问题，很多资料都说不支持>,>=,=,between...and，只能用以上符号(<、<=、!=)，并非说用>,>=,=,between..and 时会提示SQL语法错误，而是经常是查不出一条记录来，还会出现似乎是莫名其妙的结果来，其实您只要理解好了这个 rownum 伪列的意义就不应该感到惊奇，同样是伪列，rownum 与 rowid 可有些不一样，下面以例子说明

假设某个表 t1(c1) 有 20 条记录

如果用 select rownum,c1 from t1 where rownum < 10, 只要是用小于号，查出来的结果很容易地与一般理解在概念上能达成一致，应该不会有任何疑问的。

可如果用 select rownum,c1 from t1 where rownum > 10 (如果写下这样的查询语句，这时候在您的头脑中应该是想得到表中后面10条记录)，你就会发现，显示出来的结果要让您失望了，也许您还会怀疑是不谁删了一些记录，然后查看记录数，仍然是 20 条啊？那问题是出在哪呢？

先好好理解 rownum 的意义吧。因为ROWNUM是对结果集加的一个伪列，即先查到结果集之后再加上去的一个列 (强调：先要有结果集)。简单的说 rownum 是对符合条件结果的序列号。它总是从1开始排起的。所以你选出的结果不可能没有1，而有其他大于1的值。所以您没办法期望得到下面的结果集：

11 aaaaaaaa

12 bbbbbbb

13 ccccccc

.................

rownum >10 没有记录，因为第一条不满足去掉的话，第二条的ROWNUM又成了1，所以永远没有满足条件的记录。或者可以这样理解：

ROWNUM是一个序列，是oracle数据库从数据文件或缓冲区中读取数据的顺序。它取得第一条记录则rownum值为1，第二条为2，依次类推。如果你用>,>=,=,between...and这些条件，因为从缓冲区或数据文件中得到的第一条记录的rownum为1，则被删除，接着取下条，可是它的rownum还是1，又被删除，依次类推，便没有了数据。

有了以上从不同方面建立起来的对 rownum 的概念，那我们可以来认识使用 rownum 的几种现像

1. select rownum,c1 from t1 where rownum != 10 为何是返回前9条数据呢？它与 select rownum,c1 from tablename where rownum < 10 返回的结果集是一样的呢？

      因为是在查询到结果集后，显示完第 9 条记录后，之后的记录也都是 != 10,或者 >=10,所以只显示前面9条记录。也可以这样理解，rownum 为9后的记录的 rownum为10，因条件为 !=10，所以去掉，其后记录补上，rownum又是10，也去掉，如果下去也就只会显示前面9条记录了。

2. 为什么 rownum >1 时查不到一条记录，而 rownum >0 或 rownum >=1 却总显示所有的记录？

      因为 rownum 是在查询到的结果集后加上去的，它总是从1开始。

3. 为什么 between 1 and 10 或者 between 0 and 10 能查到结果，而用 between 2 and 10 却得不到结果？

       原因同上一样，因为 rownum 总是从 1 开始。从上可以看出，任何时候想把 rownum = 1 这条记录抛弃是不对的，它在结果集中是不可或缺的，少了rownum=1 就像空中楼阁一般不能存在，所以你的 rownum 条件要包含到 1 。

但如果就是想要用 rownum > 10 这种条件的话话就要用嵌套语句,把 rownum 先生成，然后对他进行查询。

select *

from (selet rownum as rn，t1.* from a where ...)

where rn >10一般代码中对结果集进行分页就是这么干的。

另外：rowid 与 rownum 虽都被称为伪列，但它们的存在方式是不一样的，rowid 可以说是物理存在的，表示记录在表空间中的唯一位置ID，在DB中唯一。只要记录没被搬动过，rowid是不变的。rowid 相对于表来说又像表中的一般列，所以以 rowid 为条件就不会有 rownum那些情况发生。

另外还要注意：rownum不能以任何基表的名称作为前缀。

对于rownum来说它是oracle系统顺序分配为从查询返回的行的编号，返回的第一行分配的是1，第二行是2，依此类推，这个伪字段可以用于限制查询返回的总行数，且rownum不能以任何表的名称作为前缀。

(1) rownum 对于等于某值的查询条件

如果希望找到学生表中第一条学生的信息，可以使用rownum=1作为条件。但是想找到学生表中第二条学生的信息，使用rownum=2结果查不到数据。因为rownum都是从1开始，但是1以上的自然数在rownum做等于判断是时认为都是false条件，所以无法查到rownum = n（n>1的自然数）。

SQL> select rownum,id,name from student where rownum=1;（可以用在限制返回记录条数的地方，保证不出错，如：隐式游标）

SQL> select rownum,id,name from student where rownum =2;

    ROWNUM ID     NAME

（2）rownum对于大于某值的查询条件

   如果想找到从第二行记录以后的记录，当使用rownum>2是查不出记录的，原因是由于rownum是一个总是从1开始的伪列，Oracle 认为rownum> n(n>1的自然数)这种条件依旧不成立，所以查不到记录。

查找到第二行以后的记录可使用以下的子查询方法来解决。注意子查询中的rownum必须要有别名，否则还是不会查出记录来，这是因为rownum不是某个表的列，如果不起别名的话，无法知道rownum是子查询的列还是主查询的列。

SQL>select * from(select rownum no ,id,name from student) where no>2;

        NO ID     NAME

---------- ------ ---------------------------------------------------

         3 200003 李三

         4 200004 赵四

（3）rownum对于小于某值的查询条件

rownum对于rownum<n（(n>1的自然数）的条件认为是成立的，所以可以找到记录。

SQL> select rownum,id,name from student where rownum <3;

    ROWNUM ID     NAME

---------- ------ ---------------------------------------------------

        1 200001 张一

        2 200002 王二

查询rownum在某区间的数据，必须使用子查询。例如要查询rownum在第二行到第三行之间的数据，包括第二行和第三行数据，那么我们只能写以下语句，先让它返回小于等于三的记录行，然后在主查询中判断新的rownum的别名列大于等于二的记录行。但是这样的操作会在大数据集中影响速度。

SQL> select * from (select rownum no,id,name from student where rownum<=3 ) where no >=2;

        NO ID     NAME

---------- ------ ---------------------------------------------------

         2 200002 王二

         3 200003 李三

（4）rownum和排序

Oracle中的rownum的是在取数据的时候产生的序号，所以想对指定排序的数据去指定的rowmun行数据就必须注意了。

SQL> select rownum ,id,name from student order by name;

    ROWNUM ID     NAME

---------- ------ ---------------------------------------------------

         3 200003 李三

         2 200002 王二

         1 200001 张一

         4 200004 赵四

可以看出，rownum并不是按照name列来生成的序号。系统是按照记录插入时的顺序给记录排的号，rowid也是顺序分配的。为了解决这个问题，必须使用子查询；

SQL> select rownum ,id,name from (select * from student order by name);

    ROWNUM ID     NAME

---------- ------ ---------------------------------------------------

         1 200003 李三

         2 200002 王二

         3 200001 张一

         4 200004 赵四

这样就成了按name排序，并且用rownum标出正确序号（有小到大）

笔者在工作中有一上百万条记录的表，在jsp页面中需对该表进行分页显示，便考虑用rownum来作，下面是具体方法(每页显示20条)：

“select * from tabname where rownum<20 order by name" 但却发现oracle却不能按自己的意愿来执行，而是先随便取20条记录，然后再order by，后经咨询oracle,说rownum确实就这样，想用的话，只能用子查询来实现先排序，后rownum，方法如下：

"select * from (select * from tabname order by name) where rownum<20",但这样一来，效率会低很多。
后经笔者试验，只需在order by 的字段上加主键或索引即可让oracle先按该字段排序，然后再rownum；方法不变：    “select * from tabname where rownum<20 order by name"

取得某列中第N大的行

select column_name from

(select table_name.*,dense_rank() over (order by column desc) rank from table_name)

where rank = &N；

假如要返回前5条记录：

select * from tablename where rownum<6;(或是rownum <= 5 或是rownum != 6)

假如要返回第5-9条记录：

select * from tablename

where …

and rownum<10

minus

select * from tablename

where …

and rownum<5

order by name

选出结果后用name排序显示结果。(先选再排序)

注意：只能用以上符号(<、<=、!=)。

select * from tablename where rownum != 10;返回的是前９条记录。

不能用：>,>=,=,Between...and。由于rownum是一个总是从1开始的伪列，Oracle 认为这种条件不成立。

另外，这个方法更快：

select * from (

select rownum r,a from yourtable

where rownum <= 20

order by name )

where r > 10

这样取出第11-20条记录!(先选再排序再选)

要先排序再选则须用select嵌套：内层排序外层选。

rownum是随着结果集生成的，一旦生成，就不会变化了；同时,生成的结果是依次递加的，没有1就永远不会有2!

rownum 是在查询集合产生的过程中产生的伪列，并且如果where条件中存在 rownum 条件的话，则:

1： 假如判定条件是常量，则：

只能 rownum = 1, <= 大于1 的自然数， = 大于1 的数是没有结果的；大于一个数也是没有结果的

即 当出现一个 rownum 不满足条件的时候则 查询结束 this is stop key（一个不满足，系统将该记录过滤掉，则下一条记录的rownum还是这个，所以后面的就不再有满足记录，this is stop key）；

2： 假如判定值不是常量，则：

若条件是 = var , 则只有当 var 为1 的时候才满足条件，这个时候不存在 stop key ,必须进行full scan ,对每个满足其他where条件的数据进行判定，选出一行后才能去选rownum=2的行……

以下摘自《中国IT实验室》

1.在oracle中实现select top n

   由于oracle不支持select top语句，所以在oracle中经常是用order by跟rownum的组合来实现select top n的查询。

简单地说，实现方法如下所示：

select　列名１．．．列名ｎ　from

(select　列名１．．．列名ｎ　from 表名 order by 列名１．．．列名ｎ)

where rownum<=n（抽出记录数）

order by rownum asc

   下面举个例子简单说明一下。

顾客表customer(id,name)有如下数据：

ID NAME

   01 first

   02 Second

   03 third

   04 forth

   05 fifth

   06 sixth

   07 seventh

   08 eighth

   09 ninth

   10 last

   则按NAME的字母顺抽出前三个顾客的SQL语句如下所示：

select * from

   (select * from customer order by name)

   where rownum<=3

   order by rownum asc

   输出结果为：

   ID NAME

   08 eighth

   05 fifth

   01 first



   Oracle删除重复记录的几种方式

如果把一个文件多次导入数据库，可能会引入重复记录，那么有哪些方法可以删除重复记录呢？

    REATE TABLE tbl_test(
         SER_NO NUMBER,
         FST_NM VARCHAR2(30),
         DEPTID NUMBER,
         CMNT   VARCHAR2(30));

    INSERT INTO tbl_test VALUES(1, 'aaaaa', 2004, 'xxx');
    INSERT INTO tbl_test VALUES(2, 'bbbbb', 2005, 'yyy');
    INSERT INTO tbl_test VALUES(1, 'aaaaa', 2004, 'xxx');
    INSERT INTO tbl_test VALUES(1, 'aaaaa', 2004, 'xxx');
    INSERT INTO tbl_test VALUES(3, 'ccccc', 2005, 'zzz');
    INSERT INTO tbl_test VALUES(2, 'bbbbb', 2005, 'yyy');

1.Using MIN(rowid) 最常用的方法，但是数据量大的话执行会很长时间

    DELETE FROM tbl_test
          WHERE ROWID NOT IN (SELECT   MIN (ROWID)
                                  FROM tbl_test
                              GROUP BY ser_no, fst_nm, deptid, cmnt);

2.Using MIN(rowid) & Join 跟第一条差不多

    DELETE FROM tbl_test t
          WHERE t.ROWID NOT IN (SELECT MIN (b.ROWID)
                                  FROM tbl_test b
                                 WHERE b.ser_no = t.ser_no
                                   AND b.fst_nm = t.fst_nm
                                   AND b.deptid = t.deptid
                                   AND b.cmnt   = t.cmnt);

3.Using Subquery

    DELETE FROM tbl_test
    WHERE ser_no IN (SELECT ser_no FROM tbl_test GROUP BY ser_no, fst_nm, deptid, cmnt HAVING COUNT (*) > 1)
    AND fst_nm IN (SELECT fst_nm FROM tbl_test GROUP BY ser_no, fst_nm, deptid, cmnt HAVING COUNT (*) > 1)
    AND deptid IN (SELECT deptid FROM tbl_test GROUP BY ser_no, fst_nm, deptid, cmnt HAVING COUNT (*) > 1)
    AND cmnt   IN (SELECT cmnt   FROM tbl_test GROUP BY ser_no, fst_nm, deptid, cmnt HAVING COUNT (*) > 1)
    AND ROWID NOT IN (SELECT   MIN (ROWID)
    FROM tbl_test
    GROUP BY ser_no, fst_nm, deptid, cmnt
    HAVING COUNT (*) > 1)

4. Using Nested Subqueries

    DELETE FROM tbl_test a WHERE (a.ser_no, a.fst_nm, a.deptid, a.cmnt) IN (SELECT b.ser_no, b.fst_nm, b.deptid, b.cmnt
    FROM tbl_test b WHERE a.ser_no = b.ser_no AND a.fst_nm = b.fst_nm AND a.deptid = b.deptid AND a.cmnt  = b.cmnt AND
    a.ROWID  > b.ROWID);

5. Using Analytic Fucntions: 对于大表这是最有效的方法

    DELETE FROM tbl_test WHERE ROWID IN (SELECT rid FROM (SELECT ROWID rid,
    ROW_NUMBER () OVER (PARTITION BY ser_no, fst_nm, deptid, cmnt ORDER BY ROWID) rn FROM tbl_test)WHERE rn <> 1);

6. CREATE-DROP-RENAME 对资源使用比较合理，特别对于大表。但是如果需要回滚则会产生大量undo日志信息。

    CREATE  TABLE tbl_test1 NOLOGGING AS SELECT tbl_test .*
    FROM tbl_test tbl_test WHERE ROWID IN (SELECT rid
    FROM (SELECT ROWID rid, ROW_NUMBER() OVER (PARTITION BY ser_no, fst_nm, deptid, cmnt ORDER BY ROWID) rn
    FROM tbl_test) WHERE rn=1);

    DROP TABLE tbl_test; --drop the original table with lots of duplicate

    RENAME tbl_test1 TO tbl_test; -- your original table without duplicates.



     系统不支持使用DBMS_XMLDOM，DBMS_XMLPARSER的存储过程的解决方法 2005-03-25 08:21:38
分类： Web开发
初到项目现场，华南咨讯给安装的Oracle 9.2.0.5数据库不支持DBMS_XMLDOM, DBMS_XMLPARSER包，
结果导致我们的一个使用到这两个包的所有存储过程不能正常工作。经过苦苦寻觅和试验，终于发现问题
所在。如下是解决过程：
1 建立XDB用户（为建立XDB用户，先建立XDB表空间），并且给XDB用户授予connect, resource权限。
2 运行/ORACLE_HOME/rdbms/admin/catqm.sql脚本（运行该脚本时，需要输入xdb用户的密码，缺省表空间名称，缺省临时表空间 名称）。
3 脚本运行成功后，重新编译DBMS_XMLDOM, DBMS_XMLPARSER所在的包，问题即得到解决。
[@more@]

CREATE OR REPLACE DIRECTORY xml_dir AS '/paic/viptmp/oradata/dkf_smi_ext';

DROP SEQUENCE seq_filename;
CREATE SEQUENCE seq_filename
    MINVALUE 10000
    MAXVALUE 99999
    INCREMENT BY 1
    START WITH 10000
    NOCYCLE;

[sql] view plaincopy在CODE上查看代码片派生到我的代码片
DECLARE
    v_filename  Varchar2(50)  := 'Empmsg_table000.xml';
    xml_str     clob;
    xml_file    utl_file.file_type;
    offset      number;
    buffer      varchar2(32767);
    buffer_size number;
BEGIN
    offset      := 1;
    buffer_size := 3000;
    xml_file := utl_file.fopen('XML_DIR', v_filename, 'A');
    xml_str  := dbms_xmlquery.getxml('select * from dkf_dong.myob');
    while (offset < dbms_lob.getlength(xml_str)) loop
      buffer := dbms_lob.substr(xml_str, buffer_size, offset);
      utl_file.put(xml_file, buffer);
      utl_file.fflush(xml_file);
      offset := offset + buffer_size;
    end loop;
    utl_file.fclose(xml_file);
END;
/


create or replace function dump_csv(p_query     in varchar2,
                                    p_separator in varchar2 default ',',
                                    p_dir       in varchar2,
                                    p_filename  in varchar2) return number
  AUTHID CURRENT_USER is
  l_output      utl_file.file_type;
  l_theCursor   integer default dbms_sql.open_cursor;
  l_columnValue varchar2(2000);
  l_status      integer;
  l_colCnt      number default 0;
  l_separator   varchar2(10) default '';
  l_cnt         number default 0;
 begin
  l_output := utl_file.fopen(p_dir, p_filename, 'w');
  dbms_sql.parse(l_theCursor, p_query, dbms_sql.native);
  for i in 1 .. 255 loop
    begin
      dbms_sql.define_column(l_theCursor, i, l_columnValue, 2000);
      l_colCnt := i;
    exception
      when others then
        if (sqlcode = -1007) then
          exit;
        else
          raise;
        end if;
    end;
  end loop;
  dbms_sql.define_column(l_theCursor, 1, l_columnValue, 2000);
  l_status := dbms_sql.execute(l_theCursor);
  loop
    exit when(dbms_sql.fetch_rows(l_theCursor) <= 0);
    l_separator := '';
    for i in 1 .. l_colCnt loop
      dbms_sql.column_value(l_theCursor, i, l_columnValue);
      utl_file.put(l_output, l_separator || '"' || l_columnValue || '"');
      l_separator := p_separator;
    end loop;
    utl_file.new_line(l_output);
    l_cnt := l_cnt + 1;
  end loop;
  dbms_sql.close_cursor(l_theCursor);
  utl_file.fclose(l_output);
  return l_cnt;
 end dump_csv;
 /


 select dump_csv('select * from dba_objects where rownum<30',',','DKF','emp.csv') from dual;




 oracle9i
sqlplus /nolog
conn peng/peng@mispeng
报错：
SQL> conn peng/peng
访问 PRODUCT_USER_PROFILE 时出错
警告: 未加载产品用户概要文件信息！
您需要将 PUPBLD.SQL 作为 SYSTEM 运行
已连接。
SQL> conn peng/peng@mispeng
已连接。
但是用pl/sql 用户peng登陆的时候，不会报错。
解决办法：
先找到pupbld.sql路径
$ORACLE_HOME/sqlplus/admin/pupbld.sql
@$ORACLE_HOME/sqlplus/admin/pupbld.sql
[@more@]